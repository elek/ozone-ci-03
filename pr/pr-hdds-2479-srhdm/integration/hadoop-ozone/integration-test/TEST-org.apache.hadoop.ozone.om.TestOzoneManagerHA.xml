<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="704.72" tests="27" errors="2" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="ANSI_X3.4-1968"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/integration-test/target/test-classes:/workdir/hadoop-ozone/integration-test/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.5.0-d6d58d0-SNAPSHOT/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.5.0-d6d58d0-SNAPSHOT/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.5.0-d6d58d0-SNAPSHOT/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.5.0-d6d58d0-SNAPSHOT/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.5.0-d6d58d0-SNAPSHOT/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.5.0-d6d58d0-SNAPSHOT/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.5.0-d6d58d0-SNAPSHOT/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.2.0/hadoop-minikdc-3.2.0.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-core/1.19/jmh-core-1.19.jar:/home/user/.m2/repository/net/sf/jopt-simple/jopt-simple/4.6/jopt-simple-4.6.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.19/jmh-generator-annprocess-1.19.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/../lib/tools.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:"/>
    <property name="java.vm.vendor" value="Oracle Corporation"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/integration-test/target/surefire/surefirebooter1269338507797611525.jar /workdir/hadoop-ozone/integration-test/target/surefire 2019-11-14T12-21-08_879-jvmRun1 surefire3885490845824638140tmp surefire_801628993071292487373tmp"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/integration-test/target/test-classes:/workdir/hadoop-ozone/integration-test/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.5.0-d6d58d0-SNAPSHOT/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.5.0-d6d58d0-SNAPSHOT/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.5.0-d6d58d0-SNAPSHOT/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.5.0-d6d58d0-SNAPSHOT/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.5.0-d6d58d0-SNAPSHOT/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.5.0-d6d58d0-SNAPSHOT/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.5.0-d6d58d0-SNAPSHOT/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.2.0/hadoop-minikdc-3.2.0.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-core/1.19/jmh-core-1.19.jar:/home/user/.m2/repository/net/sf/jopt-simple/jopt-simple/4.6/jopt-simple-4.6.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.19/jmh-generator-annprocess-1.19.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/../lib/tools.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre"/>
    <property name="surefire.excludesFile" value="/tools/ozone-bad-unit-tests"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/integration-test"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/integration-test/target/surefire/surefirebooter1269338507797611525.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/resources.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/rt.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jce.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_222-b10"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="ANSI_X3.4-1968"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_222"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/lib:/workdir/hadoop-ozone/integration-test/target/native/target/usr/local/lib:/workdir/hadoop-ozone/integration-test/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="Oracle Corporation"/>
    <property name="java.vm.version" value="25.222-b10"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testMultipartUpload" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="27.905"/>
  <testcase name="testOMRatisSnapshot" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="25.455"/>
  <testcase name="testFileOperationsWithRecursive" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="22.424"/>
  <testcase name="testOMRetryProxy" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="26.207"/>
  <testcase name="testOMProxyProviderFailoverToCurrentLeader" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="23.415"/>
  <testcase name="testAddBucketAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="21.594"/>
  <testcase name="testMultipartUploadWithOneOmNodeDown" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="25.976"/>
  <testcase name="testAllBucketOperations" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="22.095"/>
  <testcase name="testOMProxyProviderFailoverOnConnectionFailure" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="22.588">
    <error message="Call From pr-hdds-2479-srhdm-1052850629/192.168.157.199 to localhost:13764 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused" type="java.net.ConnectException">java.net.ConnectException: Call From pr-hdds-2479-srhdm-1052850629/192.168.157.199 to localhost:13764 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:755)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:361)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createVolume(OzoneManagerProtocolClientSideTranslatorPB.java:400)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy38.createVolume(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createVolume(RpcClient.java:297)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ozone.client.OzoneClientInvocationHandler.invoke(OzoneClientInvocationHandler.java:54)
	at com.sun.proxy.$Proxy40.createVolume(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy40.createVolume(Unknown Source)
	at org.apache.hadoop.ozone.client.ObjectStore.createVolume(ObjectStore.java:102)
	at org.apache.hadoop.ozone.om.TestOzoneManagerHA.createVolumeTest(TestOzoneManagerHA.java:606)
	at org.apache.hadoop.ozone.om.TestOzoneManagerHA.testOMProxyProviderFailoverOnConnectionFailure(TestOzoneManagerHA.java:681)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 49 more
</error>
    <system-out><![CDATA[2019-11-14 13:56:17,324 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:17,348 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:17,348 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:17,349 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-14 13:56:17,349 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-14 13:56:17,349 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-14 13:56:17,349 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-14 13:56:17,349 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-14 13:56:17,349 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-14 13:56:17,350 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-14 13:56:17,350 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-14 13:56:17,350 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-14 13:56:17,610 [Thread-2939] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@1386e66f
2019-11-14 13:56:17,610 [Thread-2939] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-14 13:56:17,615 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-14 13:56:17,615 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-14 13:56:17,615 [Thread-2939] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-14 13:56:17,616 [Thread-2939] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-14 13:56:17,616 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:17,717 [Thread-2939] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-14 13:56:17,717 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:17,822 [Thread-2939] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-14 13:56:17,823 [Thread-2939] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:56:17,824 [Socket Reader #1 for port 41792] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41792
2019-11-14 13:56:17,826 [Thread-2939] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:56:17,826 [Socket Reader #1 for port 37796] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37796
2019-11-14 13:56:17,828 [Thread-2939] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:56:17,828 [Socket Reader #1 for port 35585] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35585
2019-11-14 13:56:17,831 [Thread-2939] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-14 13:56:17,833 [Thread-2939] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:56:17,834 [Thread-2939] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:56:17,835 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:56:17,836 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-14 13:56:17,836 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:56:17,836 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:56:17,838 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:start(766)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35585
2019-11-14 13:56:17,841 [Thread-2939] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-14 13:56:17,842 [Thread-2939] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-14 13:56:17,842 [Thread-2939] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-14 13:56:17,877 [Thread-2939] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:56:18,176 [Thread-2939] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(160)) - RPC server for Client  is listening at /0.0.0.0:35585
2019-11-14 13:56:18,177 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:56:18,177 [IPC Server listener on 35585] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35585: starting
2019-11-14 13:56:18,180 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:start(776)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37796
2019-11-14 13:56:18,181 [Thread-2939] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:37796
2019-11-14 13:56:18,181 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:56:18,181 [IPC Server listener on 37796] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37796: starting
2019-11-14 13:56:18,185 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:41792
2019-11-14 13:56:18,185 [Thread-2939] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:41792
2019-11-14 13:56:18,185 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:56:18,186 [IPC Server listener on 41792] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41792: starting
2019-11-14 13:56:18,189 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33886
2019-11-14 13:56:18,189 [Thread-2939] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:56:18,191 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@517fd60e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:56:18,191 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@386be989{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-14 13:56:18,194 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e4e60e{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-14 13:56:18,195 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4e0412cd{HTTP/1.1,[http/1.1]}{0.0.0.0:33886}
2019-11-14 13:56:18,195 [Thread-2939] INFO  server.Server (Server.java:doStart(419)) - Started @196381ms
2019-11-14 13:56:18,195 [Thread-2939] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:56:18,197 [Thread-2939] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:33886
2019-11-14 13:56:18,198 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ab0dd6d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-14 13:56:18,198 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:18,241 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(165)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-1, RPC Address: localhost:13764 and Ratis port: 13768
2019-11-14 13:56:18,241 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-1: 127.0.0.1:13766
2019-11-14 13:56:18,241 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-1: 127.0.0.1:13767
2019-11-14 13:56:18,242 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.address with value of key ozone.om.address.omNode-1: 127.0.0.1:13764
2019-11-14 13:56:18,242 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:18,242 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:18,252 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:18,252 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-14 13:56:18,253 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-14 13:56:18,254 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-14 13:56:18,255 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-14 13:56:18,255 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-14 13:56:18,255 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-14 13:56:18,255 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-14 13:56:18,255 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-14 13:56:18,896 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:18,897 [Thread-2939] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(243)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:13768, localhost:13774, localhost:13780
2019-11-14 13:56:18,898 [Thread-2939] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-14 13:56:18,898 [Thread-2939] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-14 13:56:18,898 [Thread-2939] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 13768 (custom)
2019-11-14 13:56:18,898 [Thread-2939] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-11-14 13:56:18,899 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:18,899 [Thread-2939] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-14 13:56:18,899 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:56:18,899 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-1/ratis] (custom)
2019-11-14 13:56:18,900 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-1: addNew group-523986131536:[omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774] returns group-523986131536:java.util.concurrent.CompletableFuture@1c568a76[Not completed]
2019-11-14 13:56:18,900 [pool-567-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - omNode-1: new RaftServerImpl for group-523986131536:[omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774] with OzoneManagerStateMachine:uninitialized
2019-11-14 13:56:18,900 [Thread-2939] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1223)) - OzoneManager Ratis server initialized at port 13768
2019-11-14 13:56:18,902 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-11-14 13:56:18,902 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:18,902 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-11-14 13:56:18,902 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:18,902 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-11-14 13:56:18,902 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:56:18,902 [Thread-2939] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-11-14 13:56:18,902 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:56:18,903 [pool-567-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-1@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null, confs=<EMPTY_MAP>
2019-11-14 13:56:18,903 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-1/ratis] (custom)
2019-11-14 13:56:18,903 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:56:18,904 [pool-567-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-11-14 13:56:18,904 [Thread-2939] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:56:18,905 [Socket Reader #1 for port 13764] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 13764
2019-11-14 13:56:18,918 [Thread-2939] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:13764
2019-11-14 13:56:18,918 [Thread-2939] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-14 13:56:18,918 [Thread-2939] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(333)) - Starting OzoneManagerRatisServer omNode-1 at port 13768
2019-11-14 13:56:18,927 [pool-567-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:56:18,952 [pool-567-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-11-14 13:56:18,953 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-11-14 13:56:18,953 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:56:18,953 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 50 (custom)
2019-11-14 13:56:18,953 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:18,954 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:56:18,954 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:56:18,954 [pool-567-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new omNode-1@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-11-14 13:56:18,954 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-11-14 13:56:18,954 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-11-14 13:56:18,954 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:56:18,955 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:56:18,955 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-11-14 13:56:18,955 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:56:18,955 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:56:18,955 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:56:18,955 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:56:18,956 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-11-14 13:56:18,956 [pool-567-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:56:18,956 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:56:18,957 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 50 (custom)
2019-11-14 13:56:18,957 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = -1 (default)
2019-11-14 13:56:18,957 [pool-567-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:56:18,959 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - omNode-1@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:18,959 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-1@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:56:18,959 [Thread-2939] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start FollowerState
2019-11-14 13:56:18,960 [Thread-2939] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-1
2019-11-14 13:56:18,961 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-1: start RPC server
2019-11-14 13:56:18,963 [Thread-2939] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-1: GrpcService started, listening on 0.0.0.0/0.0.0.0:13768
2019-11-14 13:56:18,965 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:56:18,967 [IPC Server listener on 13764] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 13764: starting
2019-11-14 13:56:18,972 [Thread-2939] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:13766
2019-11-14 13:56:18,974 [Thread-2939] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:56:18,975 [Thread-2939] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:56:18,977 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:56:18,977 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-14 13:56:18,977 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:56:18,978 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:56:18,979 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 13766
2019-11-14 13:56:18,979 [Thread-2939] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:56:18,981 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a25be30{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:56:18,981 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1157fd2c{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-14 13:56:18,986 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@bf89989{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-14 13:56:18,987 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@695f06bc{HTTP/1.1,[http/1.1]}{0.0.0.0:13766}
2019-11-14 13:56:18,988 [Thread-2939] INFO  server.Server (Server.java:doStart(419)) - Started @197174ms
2019-11-14 13:56:18,988 [Thread-2939] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:56:18,989 [Thread-2939] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:13766
2019-11-14 13:56:18,989 [Thread-2939] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:13764
2019-11-14 13:56:18,990 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:19,014 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(165)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-2, RPC Address: localhost:13770 and Ratis port: 13774
2019-11-14 13:56:19,014 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-2: 127.0.0.1:13772
2019-11-14 13:56:19,015 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-2: 127.0.0.1:13773
2019-11-14 13:56:19,015 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.address with value of key ozone.om.address.omNode-2: 127.0.0.1:13770
2019-11-14 13:56:19,015 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:19,015 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:19,021 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:19,021 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-14 13:56:19,021 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-14 13:56:19,022 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-14 13:56:19,022 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-14 13:56:19,022 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-14 13:56:19,022 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-14 13:56:19,022 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-14 13:56:19,022 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-14 13:56:19,022 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-14 13:56:19,023 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-14 13:56:19,023 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-14 13:56:19,023 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-14 13:56:19,023 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-14 13:56:19,023 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-14 13:56:19,023 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-14 13:56:19,023 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-14 13:56:19,024 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-14 13:56:19,024 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-14 13:56:19,024 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-14 13:56:19,024 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-14 13:56:19,024 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-14 13:56:19,024 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-14 13:56:19,024 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-14 13:56:19,025 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-14 13:56:19,025 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-14 13:56:19,677 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:19,678 [Thread-2939] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(243)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:13774, localhost:13768, localhost:13780
2019-11-14 13:56:19,678 [Thread-2939] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-14 13:56:19,678 [Thread-2939] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-14 13:56:19,679 [Thread-2939] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 13774 (custom)
2019-11-14 13:56:19,679 [Thread-2939] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-11-14 13:56:19,679 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:19,679 [Thread-2939] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-14 13:56:19,679 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:56:19,679 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-2/ratis] (custom)
2019-11-14 13:56:19,680 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-2: addNew group-523986131536:[omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774] returns group-523986131536:java.util.concurrent.CompletableFuture@448bfd84[Not completed]
2019-11-14 13:56:19,680 [pool-583-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - omNode-2: new RaftServerImpl for group-523986131536:[omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774] with OzoneManagerStateMachine:uninitialized
2019-11-14 13:56:19,680 [Thread-2939] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1223)) - OzoneManager Ratis server initialized at port 13774
2019-11-14 13:56:19,682 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-11-14 13:56:19,682 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:19,682 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-11-14 13:56:19,682 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:19,682 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-11-14 13:56:19,682 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:56:19,682 [Thread-2939] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-11-14 13:56:19,682 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:56:19,683 [pool-583-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-2@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null, confs=<EMPTY_MAP>
2019-11-14 13:56:19,683 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-2/ratis] (custom)
2019-11-14 13:56:19,683 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:56:19,683 [pool-583-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-11-14 13:56:19,684 [Thread-2939] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:56:19,687 [Socket Reader #1 for port 13770] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 13770
2019-11-14 13:56:19,706 [Thread-2939] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:13770
2019-11-14 13:56:19,706 [Thread-2939] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-14 13:56:19,706 [Thread-2939] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(333)) - Starting OzoneManagerRatisServer omNode-2 at port 13774
2019-11-14 13:56:19,711 [pool-583-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:56:19,735 [pool-583-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-11-14 13:56:19,736 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-11-14 13:56:19,736 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:56:19,736 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 50 (custom)
2019-11-14 13:56:19,736 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:19,736 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:56:19,737 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:56:19,737 [pool-583-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new omNode-2@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-11-14 13:56:19,737 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-11-14 13:56:19,737 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-11-14 13:56:19,737 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:56:19,737 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:56:19,737 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-11-14 13:56:19,737 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:56:19,738 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:56:19,738 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:56:19,738 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:56:19,738 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-11-14 13:56:19,738 [pool-583-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:56:19,739 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:56:19,739 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 50 (custom)
2019-11-14 13:56:19,739 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = -1 (default)
2019-11-14 13:56:19,739 [pool-583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:56:19,741 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - omNode-2@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:19,741 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:56:19,741 [Thread-2939] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-11-14 13:56:19,741 [Thread-2939] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-2
2019-11-14 13:56:19,742 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-2: start RPC server
2019-11-14 13:56:19,743 [Thread-2939] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-2: GrpcService started, listening on 0.0.0.0/0.0.0.0:13774
2019-11-14 13:56:19,745 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:56:19,745 [IPC Server listener on 13770] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 13770: starting
2019-11-14 13:56:19,751 [Thread-2939] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:13772
2019-11-14 13:56:19,753 [Thread-2939] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:56:19,754 [Thread-2939] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:56:19,756 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:56:19,757 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-14 13:56:19,757 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:56:19,757 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:56:19,758 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 13772
2019-11-14 13:56:19,758 [Thread-2939] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:56:19,760 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@42c2a79e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:56:19,761 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e77b774{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-14 13:56:19,766 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@52abd0a8{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-14 13:56:19,766 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@234aca0d{HTTP/1.1,[http/1.1]}{0.0.0.0:13772}
2019-11-14 13:56:19,768 [Thread-2939] INFO  server.Server (Server.java:doStart(419)) - Started @197954ms
2019-11-14 13:56:19,768 [Thread-2939] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:56:19,769 [Thread-2939] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:13772
2019-11-14 13:56:19,769 [Thread-2939] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:13770
2019-11-14 13:56:19,770 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:19,794 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(165)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-3, RPC Address: localhost:13776 and Ratis port: 13780
2019-11-14 13:56:19,795 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-3: 127.0.0.1:13778
2019-11-14 13:56:19,795 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-3: 127.0.0.1:13779
2019-11-14 13:56:19,795 [Thread-2939] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.address with value of key ozone.om.address.omNode-3: 127.0.0.1:13776
2019-11-14 13:56:19,795 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:19,795 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:19,800 [Thread-2939] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:56:19,800 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-14 13:56:19,801 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-14 13:56:19,801 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-14 13:56:19,801 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-14 13:56:19,801 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-14 13:56:19,801 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-14 13:56:19,801 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-14 13:56:19,801 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-14 13:56:19,802 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-14 13:56:19,802 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-14 13:56:19,802 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-14 13:56:19,802 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-14 13:56:19,802 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-14 13:56:19,802 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-14 13:56:19,802 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-14 13:56:19,803 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-14 13:56:19,803 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-14 13:56:19,803 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-14 13:56:19,803 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-14 13:56:19,803 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-14 13:56:19,803 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-14 13:56:19,803 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-14 13:56:19,803 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-14 13:56:19,804 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-14 13:56:19,804 [Thread-2939] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-14 13:56:19,999 [Thread-3031] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-1@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1039ms, electionTimeout:1039ms
2019-11-14 13:56:19,999 [Thread-3031] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-1: shutdown FollowerState
2019-11-14 13:56:19,999 [Thread-3031] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-1@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-14 13:56:19,999 [Thread-3031] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start LeaderElection
2019-11-14 13:56:20,036 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-1@group-523986131536-LeaderElection18: begin an election at term 1 for -1: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:20,044 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-1@group-523986131536-LeaderElection18 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:13780
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:56:20,049 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:omNode-1
2019-11-14 13:56:20,049 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-11-14 13:56:20,049 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-11-14 13:56:20,049 [Thread-3070] INFO  impl.FollowerState (FollowerState.java:run(120)) - omNode-2@group-523986131536-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-14 13:56:20,084 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-1@group-523986131536-LeaderElection18: Election PASSED; received 1 response(s) [omNode-1<-omNode-2#0:OK-t1] and 1 exception(s); omNode-1@group-523986131536:t1, leader=null, voted=omNode-1, raftlog=omNode-1@group-523986131536-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:20,085 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:13780
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:56:20,085 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-1: shutdown LeaderElection
2019-11-14 13:56:20,086 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-1@group-523986131536: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-14 13:56:20,086 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-1@group-523986131536: change Leader from null to omNode-1 at term 1 for becomeLeader, leader elected after 1132ms
2019-11-14 13:56:20,086 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-14 13:56:20,086 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-14 13:56:20,086 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-14 13:56:20,086 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-14 13:56:20,086 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-14 13:56:20,086 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-14 13:56:20,087 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-11-14 13:56:20,087 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:20,087 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2019-11-14 13:56:20,087 [omNode-1@group-523986131536-LeaderElection18] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-11-14 13:56:20,087 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:56:20,087 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:56:20,087 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-11-14 13:56:20,088 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:20,088 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2019-11-14 13:56:20,088 [omNode-1@group-523986131536-LeaderElection18] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-11-14 13:56:20,088 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:56:20,088 [omNode-1@group-523986131536-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:56:20,088 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start LeaderState
2019-11-14 13:56:20,088 [omNode-1@group-523986131536-LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-14 13:56:20,089 [omNode-1@group-523986131536-LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - omNode-1@group-523986131536: set configuration 0: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null at 0
2019-11-14 13:56:20,090 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-11-14 13:56:20,091 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 0 -> 0
2019-11-14 13:56:20,097 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-2@group-523986131536: change Leader from null to omNode-1 at term 1 for appendEntries, leader elected after 361ms
2019-11-14 13:56:20,099 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - omNode-2@group-523986131536: set configuration 0: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null at 0
2019-11-14 13:56:20,100 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-14 13:56:20,109 [omNode-1@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-11-14 13:56:20,111 [omNode-2@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-11-14 13:56:20,114 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-11-14 13:56:20,116 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 1 -> 0
2019-11-14 13:56:20,571 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:20,572 [Thread-2939] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(243)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:13780, localhost:13768, localhost:13774
2019-11-14 13:56:20,572 [Thread-2939] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-14 13:56:20,573 [Thread-2939] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-14 13:56:20,573 [Thread-2939] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 13780 (custom)
2019-11-14 13:56:20,573 [Thread-2939] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-11-14 13:56:20,573 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:20,573 [Thread-2939] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-14 13:56:20,574 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:56:20,574 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-3/ratis] (custom)
2019-11-14 13:56:20,575 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-3: addNew group-523986131536:[omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774] returns group-523986131536:java.util.concurrent.CompletableFuture@47f52aff[Not completed]
2019-11-14 13:56:20,575 [pool-599-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - omNode-3: new RaftServerImpl for group-523986131536:[omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774] with OzoneManagerStateMachine:uninitialized
2019-11-14 13:56:20,577 [Thread-2939] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1223)) - OzoneManager Ratis server initialized at port 13780
2019-11-14 13:56:20,577 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-11-14 13:56:20,578 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:20,578 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-11-14 13:56:20,578 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-11-14 13:56:20,578 [Thread-2939] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:56:20,578 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:56:20,578 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:56:20,578 [Thread-2939] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-11-14 13:56:20,579 [pool-599-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-3@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null, confs=<EMPTY_MAP>
2019-11-14 13:56:20,579 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-3/ratis] (custom)
2019-11-14 13:56:20,579 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:56:20,579 [pool-599-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-11-14 13:56:20,580 [Thread-2939] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:56:20,581 [Socket Reader #1 for port 13776] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 13776
2019-11-14 13:56:20,599 [Thread-2939] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:13776
2019-11-14 13:56:20,600 [Thread-2939] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-14 13:56:20,600 [Thread-2939] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(333)) - Starting OzoneManagerRatisServer omNode-3 at port 13780
2019-11-14 13:56:20,610 [pool-599-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:56:20,615 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-11-14 13:56:20,617 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 0 -> 0
2019-11-14 13:56:20,634 [pool-599-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-11-14 13:56:20,634 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-11-14 13:56:20,634 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:56:20,634 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 50 (custom)
2019-11-14 13:56:20,634 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new omNode-3@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-11-14 13:56:20,635 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:56:20,636 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:56:20,636 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:56:20,636 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:56:20,636 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-11-14 13:56:20,636 [pool-599-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:56:20,636 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:56:20,637 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 50 (custom)
2019-11-14 13:56:20,637 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = -1 (default)
2019-11-14 13:56:20,637 [pool-599-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:56:20,638 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - omNode-3@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:20,638 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:56:20,639 [Thread-2939] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start FollowerState
2019-11-14 13:56:20,639 [Thread-2939] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-3
2019-11-14 13:56:20,640 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-3: start RPC server
2019-11-14 13:56:20,644 [Thread-2939] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-3: GrpcService started, listening on 0.0.0.0/0.0.0.0:13780
2019-11-14 13:56:20,661 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:56:20,663 [IPC Server listener on 13776] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 13776: starting
2019-11-14 13:56:20,668 [Thread-2939] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:13778
2019-11-14 13:56:20,670 [Thread-2939] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:56:20,671 [Thread-2939] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:56:20,674 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:56:20,674 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-14 13:56:20,675 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:56:20,675 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:56:20,676 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 13778
2019-11-14 13:56:20,676 [Thread-2939] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:56:20,678 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@377a6ffc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:56:20,679 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@483036e1{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-14 13:56:20,684 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b4685d3{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-14 13:56:20,685 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@547dd301{HTTP/1.1,[http/1.1]}{0.0.0.0:13778}
2019-11-14 13:56:20,686 [Thread-2939] INFO  server.Server (Server.java:doStart(419)) - Started @198872ms
2019-11-14 13:56:20,686 [Thread-2939] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:56:20,687 [Thread-2939] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:13778
2019-11-14 13:56:20,688 [Thread-2939] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:13776
2019-11-14 13:56:20,692 [Thread-2939] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-14 13:56:20,698 [Thread-2939] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2479-srhdm-1052850629 ip:192.168.157.199
2019-11-14 13:56:20,711 [Thread-2939] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-14 13:56:20,712 [Thread-2939] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/containers/hdds to VolumeSet
2019-11-14 13:56:20,712 [Thread-2939] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/containers/hdds
2019-11-14 13:56:20,713 [Thread-2939] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/containers/hdds
2019-11-14 13:56:20,726 [Thread-2939] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-14 13:56:20,726 [Thread-2939] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-14 13:56:20,726 [Thread-2939] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-14 13:56:20,726 [Thread-2939] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-14 13:56:20,726 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:20,727 [Thread-2939] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-14 13:56:20,727 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:56:20,727 [Thread-2939] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis] (custom)
2019-11-14 13:56:20,729 [Thread-2939] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-14 13:56:20,732 [Thread-2939] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:56:20,732 [Thread-2939] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:56:20,734 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:56:20,735 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-14 13:56:20,735 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:56:20,735 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:56:20,736 [Thread-2939] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40965
2019-11-14 13:56:20,737 [Thread-2939] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:56:20,739 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c495753{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:56:20,740 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@613a4846{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-14 13:56:20,786 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@52e8f18d{/,file:///tmp/jetty-0.0.0.0-40965-hddsDatanode-_-any-43935038860277462.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-14 13:56:20,787 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a8fa3bb{HTTP/1.1,[http/1.1]}{0.0.0.0:40965}
2019-11-14 13:56:20,788 [Thread-2939] INFO  server.Server (Server.java:doStart(419)) - Started @198974ms
2019-11-14 13:56:20,789 [Thread-2939] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:56:20,790 [Thread-2939] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40965
2019-11-14 13:56:20,790 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:56:20,794 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2907e557] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-14 13:56:20,797 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/meta/datanode.id
2019-11-14 13:56:21,152 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-3@group-523986131536: change Leader from null to omNode-1 at term 1 for appendEntries, leader elected after 518ms
2019-11-14 13:56:21,159 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - omNode-3@group-523986131536: set configuration 0: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null at 0
2019-11-14 13:56:21,159 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-14 13:56:21,183 [omNode-3@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-11-14 13:56:21,791 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:56:22,792 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:56:23,362 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-14 13:56:23,366 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-14 13:56:23,366 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis d5daeb17-e242-475d-82a2-bdbd20d49d7e at port 0
2019-11-14 13:56:23,374 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: start RPC server
2019-11-14 13:56:23,376 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: GrpcService started, listening on 0.0.0.0/0.0.0.0:35859
2019-11-14 13:56:23,376 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis d5daeb17-e242-475d-82a2-bdbd20d49d7e is started using port 35859
2019-11-14 13:56:23,376 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc d5daeb17-e242-475d-82a2-bdbd20d49d7e is started using port 36458
2019-11-14 13:56:23,792 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:56:24,793 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:56:24,803 [IPC Server handler 0 on 41792] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/d5daeb17-e242-475d-82a2-bdbd20d49d7e
2019-11-14 13:56:24,806 [IPC Server handler 0 on 41792] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : d5daeb17-e242-475d-82a2-bdbd20d49d7e{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}
2019-11-14 13:56:24,809 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-11-14 13:56:24,811 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-11-14 13:56:24,811 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-11-14 13:56:24,830 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: addNew group-4F476F8B8E17:[d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859] returns group-4F476F8B8E17:java.util.concurrent.CompletableFuture@8f30e9[Not completed]
2019-11-14 13:56:24,833 [pool-607-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: new RaftServerImpl for group-4F476F8B8E17:[d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859] with ContainerStateMachine:uninitialized
2019-11-14 13:56:24,834 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-14 13:56:24,835 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-14 13:56:24,835 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-14 13:56:24,835 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:56:24,835 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:56:24,835 [pool-607-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17: ConfigurationManager, init=-1: [d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859], old=null, confs=<EMPTY_MAP>
2019-11-14 13:56:24,835 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis] (custom)
2019-11-14 13:56:24,836 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:56:24,836 [pool-607-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/93f344ed-8b15-48f9-8adf-4f476f8b8e17 does not exist. Creating ...
2019-11-14 13:56:25,550 [pool-607-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/93f344ed-8b15-48f9-8adf-4f476f8b8e17/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:56:26,393 [pool-607-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/93f344ed-8b15-48f9-8adf-4f476f8b8e17 has been successfully formatted.
2019-11-14 13:56:26,393 [pool-607-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-4F476F8B8E17: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-14 13:56:26,394 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-14 13:56:26,394 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:56:26,394 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-14 13:56:26,394 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:26,394 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:56:26,394 [pool-607-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:56:26,395 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:56:26,395 [pool-607-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/93f344ed-8b15-48f9-8adf-4f476f8b8e17
2019-11-14 13:56:26,395 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-14 13:56:26,395 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-14 13:56:26,395 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:56:26,395 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:56:26,396 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-14 13:56:26,396 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:56:26,396 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:56:26,396 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:56:26,396 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:56:26,396 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-14 13:56:26,397 [pool-607-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:56:26,439 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:56:26,440 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-14 13:56:26,440 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-14 13:56:26,440 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:56:26,440 [pool-607-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:56:26,440 [pool-607-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:56:26,440 [pool-607-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17: start as a follower, conf=-1: [d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859], old=null
2019-11-14 13:56:26,441 [pool-607-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:56:26,441 [pool-607-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: start FollowerState
2019-11-14 13:56:26,451 [pool-607-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4F476F8B8E17,id=d5daeb17-e242-475d-82a2-bdbd20d49d7e
2019-11-14 13:56:26,452 [pool-607-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:56:26,461 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(55)) - Created pipeline Pipeline[ Id: 93f344ed-8b15-48f9-8adf-4f476f8b8e17, Nodes: d5daeb17-e242-475d-82a2-bdbd20d49d7e{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
2019-11-14 13:56:26,462 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-14 13:56:27,462 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-14 13:56:27,814 [Thread-3194] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-11-14 13:56:27,816 [Thread-3194] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 93f344ed-8b15-48f9-8adf-4f476f8b8e17, Nodes: d5daeb17-e242-475d-82a2-bdbd20d49d7e{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
2019-11-14 13:56:27,817 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-11-14 13:56:27,817 [Thread-3194] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(121)) - Pipeline Pipeline[ Id: 93f344ed-8b15-48f9-8adf-4f476f8b8e17, Nodes: d5daeb17-e242-475d-82a2-bdbd20d49d7e{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-11-14 13:56:27,835 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: remove  FOLLOWER d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17:t0, leader=null, voted=null, raftlog=d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859], old=null RUNNING
2019-11-14 13:56:27,835 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17: shutdown
2019-11-14 13:56:27,836 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4F476F8B8E17,id=d5daeb17-e242-475d-82a2-bdbd20d49d7e
2019-11-14 13:56:27,836 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: shutdown FollowerState
2019-11-14 13:56:27,836 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17-StateMachineUpdater: set stopIndex = -1
2019-11-14 13:56:27,836 [Thread-3203] INFO  impl.FollowerState (FollowerState.java:run(120)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-14 13:56:27,838 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17: closes. applyIndex: -1
2019-11-14 13:56:27,839 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:56:27,840 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-4F476F8B8E17-SegmentedRaftLogWorker close()
2019-11-14 13:56:27,847 [Thread-3194] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(106)) - Pipeline Pipeline[ Id: 93f344ed-8b15-48f9-8adf-4f476f8b8e17, Nodes: d5daeb17-e242-475d-82a2-bdbd20d49d7e{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-11-14 13:56:27,856 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: addNew group-8B1BA0A55FBC:[d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859] returns group-8B1BA0A55FBC:java.util.concurrent.CompletableFuture@54540dca[Not completed]
2019-11-14 13:56:27,857 [pool-607-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: new RaftServerImpl for group-8B1BA0A55FBC:[d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859] with ContainerStateMachine:uninitialized
2019-11-14 13:56:27,857 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-14 13:56:27,858 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-14 13:56:27,858 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-14 13:56:27,858 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:56:27,858 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:56:27,858 [pool-607-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: ConfigurationManager, init=-1: [d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859], old=null, confs=<EMPTY_MAP>
2019-11-14 13:56:27,858 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis] (custom)
2019-11-14 13:56:27,859 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:56:27,859 [pool-607-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/9202dcc1-1153-42db-a8da-8b1ba0a55fbc does not exist. Creating ...
2019-11-14 13:56:28,336 [pool-607-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/9202dcc1-1153-42db-a8da-8b1ba0a55fbc/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:56:30,858 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$433/296453151@16c459ce for d5daeb17-e242-475d-82a2-bdbd20d49d7e
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999763131ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:220)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999763131ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-11-14 13:56:30,862 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-11-14 13:56:30,916 [Thread-2939] INFO  rpc.RpcClient (RpcClient.java:createVolume(292)) - Creating Volume: volume03299, with user55342 as owner.
2019-11-14 13:56:30,934 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(193)) - created volume:volume03299 for user:user55342
2019-11-14 13:56:30,943 [Thread-2939] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 13764
2019-11-14 13:56:30,946 [IPC Server listener on 13764] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 13764
2019-11-14 13:56:30,946 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:56:30,952 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-1: close
2019-11-14 13:56:30,952 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - omNode-1@group-523986131536: shutdown
2019-11-14 13:56:30,952 [Thread-2939] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-1
2019-11-14 13:56:30,952 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(193)) - created volume:volume03299 for user:user55342
2019-11-14 13:56:30,952 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(193)) - created volume:volume03299 for user:user55342
2019-11-14 13:56:30,952 [Thread-2939] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - omNode-1: shutdown LeaderState
2019-11-14 13:56:30,957 [Thread-2939] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - omNode-1@group-523986131536-PendingRequests: sendNotLeaderResponses
2019-11-14 13:56:30,957 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$261/658393789@711a6068] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(151)) - omNode-1@group-523986131536->omNode-3-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-11-14 13:56:30,957 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$261/658393789@2b4aef3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(151)) - omNode-1@group-523986131536->omNode-2-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-11-14 13:56:30,964 [Thread-2939] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - omNode-1@group-523986131536-StateMachineUpdater: set stopIndex = 2
2019-11-14 13:56:30,964 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - omNode-3: Completed APPEND_ENTRIES, lastRequest: omNode-1->omNode-3#25-t1, previous=(t:1, i:1), leaderCommit=1, initializing? false, entries: size=1, first=(t:1, i:2), METADATAENTRY(c1)
2019-11-14 13:56:30,964 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - omNode-2: Completed APPEND_ENTRIES, lastRequest: omNode-1->omNode-2#24-t1, previous=(t:1, i:1), leaderCommit=1, initializing? false, entries: size=1, first=(t:1, i:2), METADATAENTRY(c1)
2019-11-14 13:56:30,964 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-11-14 13:56:30,964 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-11-14 13:56:30,967 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - omNode-1@group-523986131536->omNode-2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-11-14 13:56:30,968 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 3 -> 2
2019-11-14 13:56:30,969 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-2: nextIndex: updateUnconditionally 3 -> 2
2019-11-14 13:56:30,969 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 1
2019-11-14 13:56:30,969 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - omNode-1@group-523986131536-StateMachineUpdater: Took a snapshot at index 1
2019-11-14 13:56:30,969 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - omNode-1@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 1
2019-11-14 13:56:30,969 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-11-14 13:56:30,969 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 1
2019-11-14 13:56:30,970 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - omNode-1@group-523986131536-StateMachineUpdater: Took a snapshot at index 1
2019-11-14 13:56:30,970 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - omNode-1@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly 1 -> 1
2019-11-14 13:56:30,970 [Thread-2939] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - omNode-1@group-523986131536: closes. applyIndex: 2
2019-11-14 13:56:30,970 [omNode-1@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - omNode-1@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:56:30,971 [Thread-2939] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - omNode-1@group-523986131536-SegmentedRaftLogWorker close()
2019-11-14 13:56:30,973 [Thread-2939] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-1: shutdown server with port 13768 now
2019-11-14 13:56:30,973 [Thread-2939] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-1: shutdown server with port 13768 successfully
2019-11-14 13:56:30,973 [Thread-2939] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-14 13:56:30,974 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-14 13:56:30,974 [Thread-2939] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-14 13:56:30,975 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@bf89989{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-14 13:56:30,976 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@695f06bc{HTTP/1.1,[http/1.1]}{0.0.0.0:13766}
2019-11-14 13:56:30,976 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1157fd2c{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-14 13:56:30,976 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a25be30{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:56:31,413 [pool-607-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/9202dcc1-1153-42db-a8da-8b1ba0a55fbc has been successfully formatted.
2019-11-14 13:56:31,413 [pool-607-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-8B1BA0A55FBC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-14 13:56:31,413 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-14 13:56:31,413 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:56:31,413 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/9202dcc1-1153-42db-a8da-8b1ba0a55fbc
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:56:31,414 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-14 13:56:31,415 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:56:31,415 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:56:31,415 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:56:31,415 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:56:31,415 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-14 13:56:31,415 [pool-607-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:56:31,416 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:56:31,416 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-14 13:56:31,416 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-14 13:56:31,416 [pool-607-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:56:31,416 [pool-607-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:56:31,416 [pool-607-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:56:31,416 [pool-607-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: start as a follower, conf=-1: [d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859], old=null
2019-11-14 13:56:31,416 [pool-607-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:56:31,417 [pool-607-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: start FollowerState
2019-11-14 13:56:31,417 [pool-607-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8B1BA0A55FBC,id=d5daeb17-e242-475d-82a2-bdbd20d49d7e
2019-11-14 13:56:31,417 [pool-607-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:56:32,158 [Thread-3106] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-2@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1213ms, electionTimeout:1054ms
2019-11-14 13:56:32,158 [Thread-3106] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-11-14 13:56:32,158 [Thread-3106] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-11-14 13:56:32,158 [Thread-3106] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start LeaderElection
2019-11-14 13:56:32,160 [omNode-2@group-523986131536-LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-2@group-523986131536: change Leader from omNode-1 to null at term 1 for initElection
2019-11-14 13:56:32,612 [Thread-3120] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-3@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1668ms, electionTimeout:1051ms
2019-11-14 13:56:32,613 [Thread-3120] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-3: shutdown FollowerState
2019-11-14 13:56:32,613 [Thread-3120] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-11-14 13:56:32,613 [Thread-3120] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start LeaderElection
2019-11-14 13:56:32,615 [omNode-3@group-523986131536-LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-3@group-523986131536: change Leader from omNode-1 to null at term 1 for initElection
2019-11-14 13:56:33,002 [Thread-2939] INFO  rpc.RpcClient (RpcClient.java:createVolume(292)) - Creating Volume: volume39512, with user07703 as owner.
2019-11-14 13:56:33,004 [Thread-2939] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "pr-hdds-2479-srhdm-1052850629/192.168.157.199"; destination host is: "localhost":13764; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy37.submitRequest over nodeId=omNode-1,nodeAddress=127.0.0.1:13764. Trying to failover immediately.
2019-11-14 13:56:33,016 [IPC Server handler 1 on 13770] INFO  ipc.Server (Server.java:logException(2726)) - IPC Server handler 1 on 13770, call Call#320 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:37726
org.apache.hadoop.ozone.om.exceptions.NotLeaderException: OM:omNode-2 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:128)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-11-14 13:56:33,018 [Thread-2939] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.NotLeaderException): OM:omNode-2 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:128)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy37.submitRequest over nodeId=omNode-2,nodeAddress=127.0.0.1:13770 after 1 failover attempts. Trying to failover immediately.
2019-11-14 13:56:33,026 [IPC Server handler 0 on 13776] INFO  ipc.Server (Server.java:logException(2726)) - IPC Server handler 0 on 13776, call Call#320 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:48058
org.apache.hadoop.ozone.om.exceptions.NotLeaderException: OM:omNode-3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:128)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-11-14 13:56:33,029 [Thread-2939] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.NotLeaderException): OM:omNode-3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:128)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy37.submitRequest over nodeId=omNode-3,nodeAddress=127.0.0.1:13776 after 2 failover attempts. Trying to failover immediately.
2019-11-14 13:56:33,231 [Thread-2939] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:13764. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:56:33,432 [Thread-2939] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:13764. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:56:33,633 [Thread-2939] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:13764. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:56:33,835 [Thread-2939] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:13764. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:56:33,836 [Thread-2939] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Call From pr-hdds-2479-srhdm-1052850629/192.168.157.199 to localhost:13764 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy37.submitRequest over nodeId=omNode-1,nodeAddress=127.0.0.1:13764 after 3 failover attempts. Trying to failover immediately.
2019-11-14 13:56:33,838 [IPC Server handler 1 on 13770] INFO  ipc.Server (Server.java:logException(2726)) - IPC Server handler 1 on 13770, call Call#320 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:37726
org.apache.hadoop.ozone.om.exceptions.NotLeaderException: OM:omNode-2 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:128)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-11-14 13:56:33,842 [Thread-2939] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.NotLeaderException): OM:omNode-2 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:128)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy37.submitRequest over nodeId=omNode-2,nodeAddress=127.0.0.1:13770 after 4 failover attempts. Trying to failover immediately.
2019-11-14 13:56:33,845 [IPC Server handler 0 on 13776] INFO  ipc.Server (Server.java:logException(2726)) - IPC Server handler 0 on 13776, call Call#320 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:48058
org.apache.hadoop.ozone.om.exceptions.NotLeaderException: OM:omNode-3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:128)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-11-14 13:56:33,848 [Thread-2939] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.NotLeaderException): OM:omNode-3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:128)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy37.submitRequest over nodeId=omNode-3,nodeAddress=127.0.0.1:13776 after 5 failover attempts. Trying to failover immediately.
2019-11-14 13:56:34,050 [Thread-2939] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:13764. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:56:34,057 [omNode-2@group-523986131536-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-2@group-523986131536-LeaderElection19: begin an election at term 2 for 0: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:34,059 [omNode-3@group-523986131536-LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-3@group-523986131536-LeaderElection20: begin an election at term 2 for 0: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:34,063 [omNode-2@group-523986131536-LeaderElection19] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-2@group-523986131536-LeaderElection19 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:13768
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:56:34,063 [omNode-3@group-523986131536-LeaderElection20] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-3@group-523986131536-LeaderElection20 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:13768
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:56:34,078 [omNode-3@group-523986131536-LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-3@group-523986131536-LeaderElection20: Election REJECTED; received 1 response(s) [omNode-3<-omNode-2#0:FAIL-t2] and 1 exception(s); omNode-3@group-523986131536:t2, leader=null, voted=omNode-3, raftlog=omNode-3@group-523986131536-SegmentedRaftLog:OPENED:c1,f2,i2, conf=0: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:34,080 [omNode-3@group-523986131536-LeaderElection20] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:13768
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:56:34,080 [omNode-3@group-523986131536-LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
2019-11-14 13:56:34,083 [omNode-3@group-523986131536-LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-3: shutdown LeaderElection
2019-11-14 13:56:34,083 [omNode-2@group-523986131536-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-2@group-523986131536-LeaderElection19: Election REJECTED; received 1 response(s) [omNode-2<-omNode-3#0:FAIL-t2] and 1 exception(s); omNode-2@group-523986131536:t2, leader=null, voted=omNode-2, raftlog=omNode-2@group-523986131536-SegmentedRaftLog:OPENED:c1,f2,i2, conf=0: [omNode-3:localhost:13780, omNode-1:localhost:13768, omNode-2:localhost:13774], old=null
2019-11-14 13:56:34,083 [omNode-3@group-523986131536-LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start FollowerState
2019-11-14 13:56:34,083 [omNode-2@group-523986131536-LeaderElection19] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:13768
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:56:34,085 [omNode-2@group-523986131536-LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
2019-11-14 13:56:34,086 [omNode-2@group-523986131536-LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-2: shutdown LeaderElection
2019-11-14 13:56:34,087 [omNode-2@group-523986131536-LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-11-14 13:56:34,251 [Thread-2939] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:13764. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:56:34,452 [Thread-2939] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:13764. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:56:34,653 [Thread-2939] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:13764. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:56:34,654 [Thread-2939] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(274)) - Failed to connect to OMs: [nodeId=omNode-3,nodeAddress=127.0.0.1:13776, nodeId=omNode-1,nodeAddress=127.0.0.1:13764, nodeId=omNode-2,nodeAddress=127.0.0.1:13770]. Attempted 5 failovers.
2019-11-14 13:56:34,655 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(352)) - Shutting down the Mini Ozone Cluster
2019-11-14 13:56:34,655 [Thread-2939] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-3
2019-11-14 13:56:34,655 [Thread-2939] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 13776
2019-11-14 13:56:34,657 [IPC Server listener on 13776] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 13776
2019-11-14 13:56:34,663 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-3: close
2019-11-14 13:56:34,663 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:56:34,663 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - omNode-3@group-523986131536: shutdown
2019-11-14 13:56:34,664 [Thread-2939] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-3
2019-11-14 13:56:34,664 [Thread-2939] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-3: shutdown FollowerState
2019-11-14 13:56:34,664 [Thread-2939] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - omNode-3@group-523986131536-StateMachineUpdater: set stopIndex = 1
2019-11-14 13:56:34,664 [Thread-3262] INFO  impl.FollowerState (FollowerState.java:run(120)) - omNode-3@group-523986131536-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-14 13:56:34,664 [omNode-3@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-11-14 13:56:34,667 [omNode-3@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 1
2019-11-14 13:56:34,667 [omNode-3@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - omNode-3@group-523986131536-StateMachineUpdater: Took a snapshot at index 1
2019-11-14 13:56:34,667 [omNode-3@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - omNode-3@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 1
2019-11-14 13:56:34,667 [Thread-2939] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - omNode-3@group-523986131536: closes. applyIndex: 1
2019-11-14 13:56:34,667 [omNode-3@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - omNode-3@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:56:34,669 [Thread-2939] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - omNode-3@group-523986131536-SegmentedRaftLogWorker close()
2019-11-14 13:56:34,671 [Thread-2939] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-3: shutdown server with port 13780 now
2019-11-14 13:56:34,675 [Thread-2939] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-3: shutdown server with port 13780 successfully
2019-11-14 13:56:34,675 [Thread-2939] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-14 13:56:34,675 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-14 13:56:34,676 [Thread-2939] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-14 13:56:34,677 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b4685d3{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-14 13:56:34,677 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@547dd301{HTTP/1.1,[http/1.1]}{0.0.0.0:13778}
2019-11-14 13:56:34,677 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@483036e1{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-14 13:56:34,678 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@377a6ffc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:56:34,686 [Thread-2939] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-1
2019-11-14 13:56:34,686 [Thread-2939] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 13764
2019-11-14 13:56:34,686 [Thread-2939] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-2
2019-11-14 13:56:34,686 [Thread-2939] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 13770
2019-11-14 13:56:34,687 [IPC Server listener on 13770] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 13770
2019-11-14 13:56:34,688 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-2: close
2019-11-14 13:56:34,688 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - omNode-2@group-523986131536: shutdown
2019-11-14 13:56:34,688 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:56:34,689 [Thread-2939] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-2
2019-11-14 13:56:34,689 [Thread-2939] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-11-14 13:56:34,689 [Thread-2939] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - omNode-2@group-523986131536-StateMachineUpdater: set stopIndex = 1
2019-11-14 13:56:34,689 [omNode-2@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-11-14 13:56:34,689 [Thread-3263] INFO  impl.FollowerState (FollowerState.java:run(120)) - omNode-2@group-523986131536-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-14 13:56:34,691 [omNode-2@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 1
2019-11-14 13:56:34,691 [omNode-2@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - omNode-2@group-523986131536-StateMachineUpdater: Took a snapshot at index 1
2019-11-14 13:56:34,691 [omNode-2@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - omNode-2@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 1
2019-11-14 13:56:34,691 [Thread-2939] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - omNode-2@group-523986131536: closes. applyIndex: 1
2019-11-14 13:56:34,692 [omNode-2@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - omNode-2@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:56:34,693 [Thread-2939] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - omNode-2@group-523986131536-SegmentedRaftLogWorker close()
2019-11-14 13:56:34,695 [Thread-2939] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-2: shutdown server with port 13774 now
2019-11-14 13:56:34,697 [Thread-2939] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-2: shutdown server with port 13774 successfully
2019-11-14 13:56:34,697 [Thread-2939] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-14 13:56:34,697 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-14 13:56:34,697 [Thread-2939] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-14 13:56:34,698 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@52abd0a8{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-14 13:56:34,699 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@234aca0d{HTTP/1.1,[http/1.1]}{0.0.0.0:13772}
2019-11-14 13:56:34,699 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e77b774{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-14 13:56:34,700 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@42c2a79e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:56:34,702 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(368)) - Stopping the Mini Ozone Cluster
2019-11-14 13:56:34,702 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(415)) - Stopping the HddsDatanodes
2019-11-14 13:56:34,794 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-14 13:56:36,480 [Thread-3240] INFO  impl.FollowerState (FollowerState.java:run(111)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-FollowerState: change to CANDIDATE, lastRpcTime:5063ms, electionTimeout:5063ms
2019-11-14 13:56:36,480 [Thread-3240] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: shutdown FollowerState
2019-11-14 13:56:36,480 [Thread-3240] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-14 13:56:36,481 [Thread-3240] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: start LeaderElection
2019-11-14 13:56:36,509 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21: begin an election at term 1 for -1: [d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859], old=null
2019-11-14 13:56:36,509 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: shutdown LeaderElection
2019-11-14 13:56:36,510 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-14 13:56:36,510 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(697)) - Leader change notification received for group: group-8B1BA0A55FBC with new leaderId: d5daeb17-e242-475d-82a2-bdbd20d49d7e
2019-11-14 13:56:36,511 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: change Leader from null to d5daeb17-e242-475d-82a2-bdbd20d49d7e at term 1 for becomeLeader, leader elected after 5096ms
2019-11-14 13:56:36,511 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-14 13:56:36,511 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-14 13:56:36,512 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-14 13:56:36,512 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-14 13:56:36,512 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-14 13:56:36,512 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-14 13:56:36,512 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: start LeaderState
2019-11-14 13:56:36,513 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-14 13:56:36,513 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: set configuration 0: [d5daeb17-e242-475d-82a2-bdbd20d49d7e:192.168.157.199:35859], old=null at 0
2019-11-14 13:56:36,571 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/ratis/9202dcc1-1153-42db-a8da-8b1ba0a55fbc/current/log_inprogress_0
2019-11-14 13:56:39,704 [Thread-2939] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-14 13:56:39,705 [Thread-2939] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: close
2019-11-14 13:56:39,705 [Thread-2939] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: shutdown
2019-11-14 13:56:39,706 [Thread-2939] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8B1BA0A55FBC,id=d5daeb17-e242-475d-82a2-bdbd20d49d7e
2019-11-14 13:56:39,706 [Thread-2939] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: shutdown LeaderState
2019-11-14 13:56:39,707 [Thread-2939] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-PendingRequests: sendNotLeaderResponses
2019-11-14 13:56:39,707 [Thread-2939] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-StateMachineUpdater: set stopIndex = 0
2019-11-14 13:56:39,712 [Thread-2939] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC: closes. applyIndex: 0
2019-11-14 13:56:39,712 [d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:56:39,713 [Thread-2939] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e@group-8B1BA0A55FBC-SegmentedRaftLogWorker close()
2019-11-14 13:56:39,724 [Thread-2939] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: shutdown server with port 35859 now
2019-11-14 13:56:39,727 [Thread-2939] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - d5daeb17-e242-475d-82a2-bdbd20d49d7e: shutdown server with port 35859 successfully
2019-11-14 13:56:39,732 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-65b84101-c64d-4e59-9880-f0be53a6ca9a/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-14 13:56:39,746 [Thread-2939] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-14 13:56:39,749 [Thread-2939] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-14 13:56:39,750 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@52e8f18d{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-14 13:56:39,751 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a8fa3bb{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-14 13:56:39,752 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@613a4846{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-14 13:56:39,752 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c495753{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:56:39,753 [Thread-2939] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(430)) - Stopping the StorageContainerManager
2019-11-14 13:56:39,753 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(804)) - Stopping Replication Manager Service.
2019-11-14 13:56:39,753 [Thread-2939] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-11-14 13:56:39,753 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping Lease Manager of the command watchers
2019-11-14 13:56:39,753 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(818)) - Stopping datanode service RPC server
2019-11-14 13:56:39,753 [Thread-2939] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-14 13:56:39,753 [Thread-2939] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41792
2019-11-14 13:56:39,755 [IPC Server listener on 41792] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41792
2019-11-14 13:56:39,756 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:56:39,855 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-11-14 13:56:39,855 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(826)) - Stopping block service RPC server
2019-11-14 13:56:39,855 [Thread-2939] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-14 13:56:39,855 [Thread-2939] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37796
2019-11-14 13:56:39,857 [IPC Server listener on 37796] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37796
2019-11-14 13:56:39,858 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(833)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-14 13:56:39,858 [Thread-2939] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(169)) - Stopping the RPC server for Client Protocol
2019-11-14 13:56:39,858 [Thread-2939] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35585
2019-11-14 13:56:39,858 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:56:39,859 [IPC Server listener on 35585] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35585
2019-11-14 13:56:39,860 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(840)) - Stopping Storage Container Manager HTTP server.
2019-11-14 13:56:39,860 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:56:39,861 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e4e60e{/,null,UNAVAILABLE}{/scm}
2019-11-14 13:56:39,861 [Thread-2939] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4e0412cd{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-14 13:56:39,861 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@386be989{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-14 13:56:39,862 [Thread-2939] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@517fd60e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:56:39,862 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(851)) - Stopping Block Manager Service.
2019-11-14 13:56:39,862 [Thread-2939] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-14 13:56:39,863 [Thread-2939] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-14 13:56:39,863 [Thread-2939] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(873)) - Stopping SCM Event Queue.
2019-11-14 13:56:39,867 [Thread-2939] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-11-14 13:56:39,875 [Thread-2939] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
]]></system-out>
    <system-err><![CDATA[Nov 14, 2019 1:56:20 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=415, target=192.168.157.199:42816} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:128)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:55)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:62)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:202)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:109)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:66)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:233)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:188)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:278)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:257)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:169)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:102)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:119)
	at org.apache.ratis.client.impl.RaftClientImpl.sendAsync(RaftClientImpl.java:144)
	at org.apache.ratis.client.impl.RaftClientImpl.sendAsync(RaftClientImpl.java:124)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:236)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:317)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:310)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:604)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:462)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:473)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
	at org.apache.hadoop.ozone.om.TestOzoneManagerHA.createMultipartKeyAndReadKey(TestOzoneManagerHA.java:516)
	at org.apache.hadoop.ozone.om.TestOzoneManagerHA.testMultipartUploadWithOneOmNodeDown(TestOzoneManagerHA.java:487)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

Nov 14, 2019 1:56:20 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=440, target=192.168.157.199:33127} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:189)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:138)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:242)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:226)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4767)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3568)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2350)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2313)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2228)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3965)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4764)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:226)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:172)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:162)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:154)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.om.TestOzoneManagerHA.createMultipartKeyAndReadKey(TestOzoneManagerHA.java:531)
	at org.apache.hadoop.ozone.om.TestOzoneManagerHA.testMultipartUploadWithOneOmNodeDown(TestOzoneManagerHA.java:487)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

]]></system-err>
  </testcase>
  <testcase name="testAllOMNodesRunning" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="32.796"/>
  <testcase name="testListParts" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="48.295">
    <error message="Call From pr-hdds-2479-srhdm-1052850629/192.168.157.199 to localhost:11724 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused" type="java.net.ConnectException">java.net.ConnectException: Call From pr-hdds-2479-srhdm-1052850629/192.168.157.199 to localhost:11724 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:755)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:361)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.listParts(OzoneManagerProtocolClientSideTranslatorPB.java:1178)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy38.listParts(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.listParts(RpcClient.java:946)
	at org.apache.hadoop.ozone.client.OzoneBucket.listParts(OzoneBucket.java:475)
	at org.apache.hadoop.ozone.om.TestOzoneManagerHA.validateListParts(TestOzoneManagerHA.java:1366)
	at org.apache.hadoop.ozone.om.TestOzoneManagerHA.testListParts(TestOzoneManagerHA.java:1291)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 37 more
</error>
    <system-out><![CDATA[2019-11-14 13:57:12,720 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:13,946 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:13,947 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:13,948 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-14 13:57:13,948 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-14 13:57:13,948 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-14 13:57:13,949 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-14 13:57:13,949 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-14 13:57:13,949 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-14 13:57:13,949 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-14 13:57:13,949 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-14 13:57:13,950 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-14 13:57:16,451 [Thread-3665] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@63dabae1
2019-11-14 13:57:16,452 [Thread-3665] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-14 13:57:16,458 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-14 13:57:16,458 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-14 13:57:16,459 [Thread-3665] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-14 13:57:16,460 [Thread-3665] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-14 13:57:16,460 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:16,563 [Thread-3665] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-14 13:57:16,563 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:16,672 [Thread-3665] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-14 13:57:16,673 [Thread-3665] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:57:16,675 [Socket Reader #1 for port 38708] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38708
2019-11-14 13:57:16,679 [Thread-3665] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:57:16,680 [Socket Reader #1 for port 40674] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40674
2019-11-14 13:57:16,681 [Thread-3665] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:57:16,682 [Socket Reader #1 for port 35083] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35083
2019-11-14 13:57:16,685 [Thread-3665] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-14 13:57:16,688 [Thread-3665] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:57:16,689 [Thread-3665] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:57:16,691 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:57:16,692 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-14 13:57:16,692 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:57:16,692 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:57:16,694 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:start(766)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35083
2019-11-14 13:57:16,697 [Thread-3665] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-14 13:57:16,699 [Thread-3665] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-14 13:57:16,699 [Thread-3665] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-14 13:57:16,723 [Thread-3665] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:57:16,797 [Thread-3665] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(160)) - RPC server for Client  is listening at /0.0.0.0:35083
2019-11-14 13:57:16,797 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:57:16,798 [IPC Server listener on 35083] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35083: starting
2019-11-14 13:57:16,802 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:start(776)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:40674
2019-11-14 13:57:16,802 [Thread-3665] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:40674
2019-11-14 13:57:16,802 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:57:16,802 [IPC Server listener on 40674] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40674: starting
2019-11-14 13:57:16,806 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:38708
2019-11-14 13:57:16,806 [Thread-3665] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:38708
2019-11-14 13:57:16,806 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:57:16,806 [IPC Server listener on 38708] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38708: starting
2019-11-14 13:57:16,816 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40463
2019-11-14 13:57:16,816 [Thread-3665] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:57:16,817 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f00c9cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:57:16,818 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b679ac9{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-14 13:57:16,821 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5166f706{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-14 13:57:16,821 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@45b5bfa8{HTTP/1.1,[http/1.1]}{0.0.0.0:40463}
2019-11-14 13:57:16,823 [Thread-3665] INFO  server.Server (Server.java:doStart(419)) - Started @255009ms
2019-11-14 13:57:16,823 [Thread-3665] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:57:16,824 [Thread-3665] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:40463
2019-11-14 13:57:16,826 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6fa1a1cc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-14 13:57:16,826 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:16,850 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(165)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-1, RPC Address: localhost:11724 and Ratis port: 11728
2019-11-14 13:57:16,851 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-1: 127.0.0.1:11726
2019-11-14 13:57:16,851 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-1: 127.0.0.1:11727
2019-11-14 13:57:16,851 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.address with value of key ozone.om.address.omNode-1: 127.0.0.1:11724
2019-11-14 13:57:16,851 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:16,851 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:16,863 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-14 13:57:16,864 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-14 13:57:16,865 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-14 13:57:16,866 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-14 13:57:16,866 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-14 13:57:16,866 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-14 13:57:16,866 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-14 13:57:16,866 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-14 13:57:16,866 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-14 13:57:16,866 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-14 13:57:17,458 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:17,458 [Thread-3665] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(243)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:11728, localhost:11734, localhost:11740
2019-11-14 13:57:17,459 [Thread-3665] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-14 13:57:17,460 [Thread-3665] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-14 13:57:17,460 [Thread-3665] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 11728 (custom)
2019-11-14 13:57:17,460 [Thread-3665] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-11-14 13:57:17,460 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:17,460 [Thread-3665] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-14 13:57:17,461 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:57:17,461 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-1/ratis] (custom)
2019-11-14 13:57:17,462 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-1: addNew group-523986131536:[omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734] returns group-523986131536:java.util.concurrent.CompletableFuture@597b448e[Not completed]
2019-11-14 13:57:17,462 [pool-696-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - omNode-1: new RaftServerImpl for group-523986131536:[omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734] with OzoneManagerStateMachine:uninitialized
2019-11-14 13:57:17,462 [Thread-3665] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1223)) - OzoneManager Ratis server initialized at port 11728
2019-11-14 13:57:17,464 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:17,464 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-11-14 13:57:17,465 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:17,465 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-11-14 13:57:17,465 [Thread-3665] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-11-14 13:57:17,465 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-11-14 13:57:17,465 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:57:17,465 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:57:17,466 [pool-696-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-1@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null, confs=<EMPTY_MAP>
2019-11-14 13:57:17,466 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-1/ratis] (custom)
2019-11-14 13:57:17,467 [Thread-3665] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:57:17,467 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:57:17,467 [pool-696-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-11-14 13:57:17,468 [Socket Reader #1 for port 11724] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 11724
2019-11-14 13:57:17,485 [Thread-3665] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:11724
2019-11-14 13:57:17,485 [Thread-3665] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-14 13:57:17,485 [Thread-3665] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(333)) - Starting OzoneManagerRatisServer omNode-1 at port 11728
2019-11-14 13:57:17,490 [pool-696-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:57:17,512 [pool-696-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-11-14 13:57:17,512 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-11-14 13:57:17,512 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:57:17,512 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 50 (custom)
2019-11-14 13:57:17,513 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:17,513 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:57:17,513 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:57:17,513 [pool-696-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new omNode-1@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-11-14 13:57:17,513 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-11-14 13:57:17,513 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-11-14 13:57:17,514 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:57:17,514 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:57:17,514 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-11-14 13:57:17,514 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:57:17,514 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:57:17,514 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:57:17,514 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:57:17,515 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-11-14 13:57:17,515 [pool-696-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:57:17,515 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:57:17,515 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 50 (custom)
2019-11-14 13:57:17,516 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = -1 (default)
2019-11-14 13:57:17,516 [pool-696-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:57:17,518 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - omNode-1@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:17,518 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-1@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:57:17,519 [Thread-3665] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start FollowerState
2019-11-14 13:57:17,519 [Thread-3665] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-1
2019-11-14 13:57:17,521 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-1: start RPC server
2019-11-14 13:57:17,523 [Thread-3665] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-1: GrpcService started, listening on 0.0.0.0/0.0.0.0:11728
2019-11-14 13:57:17,526 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:57:17,526 [IPC Server listener on 11724] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 11724: starting
2019-11-14 13:57:17,533 [Thread-3665] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:11726
2019-11-14 13:57:17,534 [Thread-3665] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:57:17,535 [Thread-3665] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:57:17,537 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:57:17,537 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-14 13:57:17,537 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:57:17,537 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:57:17,538 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 11726
2019-11-14 13:57:17,538 [Thread-3665] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:57:17,540 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5160359d{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:57:17,540 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13240fd8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-14 13:57:17,544 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27e2a730{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-14 13:57:17,545 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@281089d9{HTTP/1.1,[http/1.1]}{0.0.0.0:11726}
2019-11-14 13:57:17,545 [Thread-3665] INFO  server.Server (Server.java:doStart(419)) - Started @255731ms
2019-11-14 13:57:17,546 [Thread-3665] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:57:17,549 [Thread-3665] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:11726
2019-11-14 13:57:17,549 [Thread-3665] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:11724
2019-11-14 13:57:17,550 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:17,574 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(165)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-2, RPC Address: localhost:11730 and Ratis port: 11734
2019-11-14 13:57:17,574 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-2: 127.0.0.1:11732
2019-11-14 13:57:17,574 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-2: 127.0.0.1:11733
2019-11-14 13:57:17,575 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.address with value of key ozone.om.address.omNode-2: 127.0.0.1:11730
2019-11-14 13:57:17,575 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:17,575 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:17,583 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:17,584 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-14 13:57:17,584 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-14 13:57:17,584 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-14 13:57:17,584 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-14 13:57:17,585 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-14 13:57:17,585 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-14 13:57:17,585 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-14 13:57:17,585 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-14 13:57:17,585 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-14 13:57:17,586 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-14 13:57:17,586 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-14 13:57:17,586 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-14 13:57:17,586 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-14 13:57:17,586 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-14 13:57:17,587 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-14 13:57:17,587 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-14 13:57:17,587 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-14 13:57:17,587 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-14 13:57:17,587 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-14 13:57:17,588 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-14 13:57:17,588 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-14 13:57:17,588 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-14 13:57:17,588 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-14 13:57:17,588 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-14 13:57:17,589 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-14 13:57:18,149 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:18,150 [Thread-3665] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(243)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:11734, localhost:11728, localhost:11740
2019-11-14 13:57:18,150 [Thread-3665] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-14 13:57:18,151 [Thread-3665] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-14 13:57:18,151 [Thread-3665] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 11734 (custom)
2019-11-14 13:57:18,151 [Thread-3665] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-11-14 13:57:18,151 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:18,151 [Thread-3665] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-14 13:57:18,151 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:57:18,152 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-2/ratis] (custom)
2019-11-14 13:57:18,155 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-2: addNew group-523986131536:[omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734] returns group-523986131536:java.util.concurrent.CompletableFuture@306cb790[Not completed]
2019-11-14 13:57:18,155 [pool-712-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - omNode-2: new RaftServerImpl for group-523986131536:[omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734] with OzoneManagerStateMachine:uninitialized
2019-11-14 13:57:18,155 [Thread-3665] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1223)) - OzoneManager Ratis server initialized at port 11734
2019-11-14 13:57:18,157 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:18,157 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-11-14 13:57:18,157 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:18,157 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-11-14 13:57:18,157 [Thread-3665] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-11-14 13:57:18,157 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-11-14 13:57:18,157 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:57:18,157 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:57:18,157 [pool-712-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-2@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null, confs=<EMPTY_MAP>
2019-11-14 13:57:18,158 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-2/ratis] (custom)
2019-11-14 13:57:18,158 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:57:18,158 [Thread-3665] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:57:18,158 [pool-712-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-11-14 13:57:18,159 [Socket Reader #1 for port 11730] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 11730
2019-11-14 13:57:18,170 [Thread-3665] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:11730
2019-11-14 13:57:18,170 [Thread-3665] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-14 13:57:18,170 [Thread-3665] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(333)) - Starting OzoneManagerRatisServer omNode-2 at port 11734
2019-11-14 13:57:18,181 [pool-712-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:57:18,204 [pool-712-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-11-14 13:57:18,205 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-11-14 13:57:18,205 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:57:18,205 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 50 (custom)
2019-11-14 13:57:18,205 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:18,205 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:57:18,205 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:57:18,205 [pool-712-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new omNode-2@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-11-14 13:57:18,206 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-11-14 13:57:18,206 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-11-14 13:57:18,206 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:57:18,206 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:57:18,206 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-11-14 13:57:18,206 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:57:18,206 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:57:18,206 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:57:18,207 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:57:18,207 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-11-14 13:57:18,207 [pool-712-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:57:18,207 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:57:18,207 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 50 (custom)
2019-11-14 13:57:18,207 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = -1 (default)
2019-11-14 13:57:18,208 [pool-712-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:57:18,209 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - omNode-2@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:18,210 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:57:18,210 [Thread-3665] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-11-14 13:57:18,210 [Thread-3665] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-2
2019-11-14 13:57:18,212 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-2: start RPC server
2019-11-14 13:57:18,213 [Thread-3665] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-2: GrpcService started, listening on 0.0.0.0/0.0.0.0:11734
2019-11-14 13:57:18,215 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:57:18,216 [IPC Server listener on 11730] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 11730: starting
2019-11-14 13:57:18,221 [Thread-3665] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:11732
2019-11-14 13:57:18,223 [Thread-3665] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:57:18,224 [Thread-3665] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:57:18,226 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:57:18,227 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-14 13:57:18,227 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:57:18,227 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:57:18,228 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 11732
2019-11-14 13:57:18,228 [Thread-3665] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:57:18,230 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@aeefd9a{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:57:18,231 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@350167b8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-14 13:57:18,235 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@228221f1{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-14 13:57:18,236 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5b6593c6{HTTP/1.1,[http/1.1]}{0.0.0.0:11732}
2019-11-14 13:57:18,237 [Thread-3665] INFO  server.Server (Server.java:doStart(419)) - Started @256423ms
2019-11-14 13:57:18,237 [Thread-3665] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:57:18,238 [Thread-3665] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:11732
2019-11-14 13:57:18,239 [Thread-3665] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:11730
2019-11-14 13:57:18,240 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:18,265 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(165)) - Found matching OM address with OMServiceId: om-service-test1, OMNodeId: omNode-3, RPC Address: localhost:11736 and Ratis port: 11740
2019-11-14 13:57:18,265 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.omNode-3: 127.0.0.1:11738
2019-11-14 13:57:18,265 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address.omNode-3: 127.0.0.1:11739
2019-11-14 13:57:18,265 [Thread-3665] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(298)) - Setting configuration key ozone.om.address with value of key ozone.om.address.omNode-3: 127.0.0.1:11736
2019-11-14 13:57:18,265 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:18,266 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:18,271 [Thread-3665] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-14 13:57:18,271 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-14 13:57:18,271 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-14 13:57:18,271 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-14 13:57:18,271 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-14 13:57:18,272 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-14 13:57:18,272 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-14 13:57:18,272 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-14 13:57:18,272 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-14 13:57:18,272 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-14 13:57:18,272 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-14 13:57:18,273 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-14 13:57:18,273 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-14 13:57:18,273 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-14 13:57:18,273 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-14 13:57:18,273 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-14 13:57:18,273 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-14 13:57:18,274 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-14 13:57:18,274 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-14 13:57:18,274 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-14 13:57:18,274 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-14 13:57:18,274 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-14 13:57:18,274 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-14 13:57:18,274 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-14 13:57:18,275 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-14 13:57:18,275 [Thread-3665] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-14 13:57:18,569 [Thread-3760] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-1@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1050ms, electionTimeout:1050ms
2019-11-14 13:57:18,570 [Thread-3760] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-1: shutdown FollowerState
2019-11-14 13:57:18,570 [Thread-3760] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-1@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-14 13:57:18,570 [Thread-3760] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start LeaderElection
2019-11-14 13:57:18,593 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-1@group-523986131536-LeaderElection24: begin an election at term 1 for -1: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:18,598 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-1@group-523986131536-LeaderElection24 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11740
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:18,602 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:omNode-1
2019-11-14 13:57:18,602 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-11-14 13:57:18,602 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-11-14 13:57:18,603 [Thread-3799] INFO  impl.FollowerState (FollowerState.java:run(120)) - omNode-2@group-523986131536-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-14 13:57:18,629 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-1@group-523986131536-LeaderElection24: Election PASSED; received 1 response(s) [omNode-1<-omNode-2#0:OK-t1] and 1 exception(s); omNode-1@group-523986131536:t1, leader=null, voted=omNode-1, raftlog=omNode-1@group-523986131536-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:18,630 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11740
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:18,630 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-1: shutdown LeaderElection
2019-11-14 13:57:18,631 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-1@group-523986131536: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-14 13:57:18,631 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-1@group-523986131536: change Leader from null to omNode-1 at term 1 for becomeLeader, leader elected after 1119ms
2019-11-14 13:57:18,632 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-14 13:57:18,632 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-14 13:57:18,632 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-14 13:57:18,632 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-14 13:57:18,632 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-14 13:57:18,632 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-14 13:57:18,633 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-11-14 13:57:18,633 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:18,633 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2019-11-14 13:57:18,633 [omNode-1@group-523986131536-LeaderElection24] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-11-14 13:57:18,634 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:57:18,634 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:57:18,634 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-11-14 13:57:18,634 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:18,634 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2019-11-14 13:57:18,634 [omNode-1@group-523986131536-LeaderElection24] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-11-14 13:57:18,635 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:57:18,635 [omNode-1@group-523986131536-LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:57:18,635 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-1: start LeaderState
2019-11-14 13:57:18,635 [omNode-1@group-523986131536-LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-14 13:57:18,636 [omNode-1@group-523986131536-LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - omNode-1@group-523986131536: set configuration 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null at 0
2019-11-14 13:57:18,638 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-11-14 13:57:18,639 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 0 -> 0
2019-11-14 13:57:18,640 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-2@group-523986131536: change Leader from null to omNode-1 at term 1 for appendEntries, leader elected after 435ms
2019-11-14 13:57:18,642 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - omNode-2@group-523986131536: set configuration 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null at 0
2019-11-14 13:57:18,643 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-14 13:57:18,662 [omNode-1@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - omNode-1@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-1/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-11-14 13:57:18,676 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-11-14 13:57:18,678 [omNode-2@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - omNode-2@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-2/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-11-14 13:57:18,678 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 1 -> 0
2019-11-14 13:57:18,919 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:18,919 [Thread-3665] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(243)) - Instantiating OM Ratis server with GroupID: om-service-test1 and Raft Peers: localhost:11740, localhost:11728, localhost:11734
2019-11-14 13:57:18,920 [Thread-3665] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-14 13:57:18,920 [Thread-3665] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-14 13:57:18,920 [Thread-3665] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 11740 (custom)
2019-11-14 13:57:18,921 [Thread-3665] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-11-14 13:57:18,921 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:18,921 [Thread-3665] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-14 13:57:18,921 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:57:18,921 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-3/ratis] (custom)
2019-11-14 13:57:18,922 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - omNode-3: addNew group-523986131536:[omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734] returns group-523986131536:java.util.concurrent.CompletableFuture@25385bc9[Not completed]
2019-11-14 13:57:18,922 [pool-728-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - omNode-3: new RaftServerImpl for group-523986131536:[omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734] with OzoneManagerStateMachine:uninitialized
2019-11-14 13:57:18,922 [Thread-3665] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1223)) - OzoneManager Ratis server initialized at port 11740
2019-11-14 13:57:18,924 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-11-14 13:57:18,924 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:18,925 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-11-14 13:57:18,925 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 2s (custom)
2019-11-14 13:57:18,925 [Thread-3665] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-14 13:57:18,925 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:57:18,925 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:57:18,925 [Thread-3665] INFO  snapshot.OzoneManagerSnapshotProvider (OzoneManagerSnapshotProvider.java:<init>(81)) - Initializing OM Snapshot Provider
2019-11-14 13:57:18,926 [pool-728-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - omNode-3@group-523986131536: ConfigurationManager, init=-1: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null, confs=<EMPTY_MAP>
2019-11-14 13:57:18,926 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-3/ratis] (custom)
2019-11-14 13:57:18,926 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:57:18,927 [pool-728-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 does not exist. Creating ...
2019-11-14 13:57:18,927 [Thread-3665] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-14 13:57:18,928 [Socket Reader #1 for port 11736] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 11736
2019-11-14 13:57:18,947 [Thread-3665] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:11736
2019-11-14 13:57:18,947 [Thread-3665] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-14 13:57:18,947 [Thread-3665] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(333)) - Starting OzoneManagerRatisServer omNode-3 at port 11740
2019-11-14 13:57:18,950 [pool-728-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:57:18,974 [pool-728-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536 has been successfully formatted.
2019-11-14 13:57:18,974 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 2s (custom)
2019-11-14 13:57:18,974 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:57:18,974 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 50 (custom)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new omNode-3@group-523986131536-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-11-14 13:57:18,975 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:57:18,976 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:57:18,976 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:57:18,976 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:57:18,976 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-11-14 13:57:18,976 [pool-728-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:57:18,976 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:57:18,977 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 50 (custom)
2019-11-14 13:57:18,977 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = -1 (default)
2019-11-14 13:57:18,977 [pool-728-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:57:18,979 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - omNode-3@group-523986131536: start as a follower, conf=-1: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:18,979 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:57:18,979 [Thread-3665] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start FollowerState
2019-11-14 13:57:18,980 [Thread-3665] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-3
2019-11-14 13:57:18,981 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - omNode-3: start RPC server
2019-11-14 13:57:18,982 [Thread-3665] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - omNode-3: GrpcService started, listening on 0.0.0.0/0.0.0.0:11740
2019-11-14 13:57:18,985 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-14 13:57:18,985 [IPC Server listener on 11736] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 11736: starting
2019-11-14 13:57:18,992 [Thread-3665] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:11738
2019-11-14 13:57:18,993 [Thread-3665] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:57:18,994 [Thread-3665] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:57:18,996 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:57:18,996 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-14 13:57:18,996 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:57:18,997 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:57:18,997 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 11738
2019-11-14 13:57:18,998 [Thread-3665] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:57:18,999 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a685db{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:57:19,000 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75cd313a{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-14 13:57:19,004 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@14ca21f1{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-14 13:57:19,004 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@33bb5fd3{HTTP/1.1,[http/1.1]}{0.0.0.0:11738}
2019-11-14 13:57:19,006 [Thread-3665] INFO  server.Server (Server.java:doStart(419)) - Started @257192ms
2019-11-14 13:57:19,006 [Thread-3665] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:57:19,007 [Thread-3665] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:11738
2019-11-14 13:57:19,007 [Thread-3665] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createOMService(274)) - Started OzoneManager RPC server at localhost/127.0.0.1:11736
2019-11-14 13:57:19,012 [Thread-3665] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-14 13:57:19,021 [Thread-3665] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2479-srhdm-1052850629 ip:192.168.157.199
2019-11-14 13:57:19,031 [Thread-3665] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-14 13:57:19,032 [Thread-3665] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/containers/hdds to VolumeSet
2019-11-14 13:57:19,032 [Thread-3665] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/containers/hdds
2019-11-14 13:57:19,032 [Thread-3665] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/containers/hdds
2019-11-14 13:57:19,045 [Thread-3665] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-14 13:57:19,045 [Thread-3665] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-14 13:57:19,045 [Thread-3665] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-14 13:57:19,045 [Thread-3665] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-14 13:57:19,046 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:19,046 [Thread-3665] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-14 13:57:19,046 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-14 13:57:19,046 [Thread-3665] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis] (custom)
2019-11-14 13:57:19,048 [Thread-3665] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-14 13:57:19,049 [Thread-3665] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-14 13:57:19,050 [Thread-3665] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-14 13:57:19,051 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-14 13:57:19,052 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-14 13:57:19,052 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-14 13:57:19,052 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-14 13:57:19,053 [Thread-3665] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34804
2019-11-14 13:57:19,053 [Thread-3665] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-14 13:57:19,055 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e4cfa9{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-14 13:57:19,055 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@457928d8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-14 13:57:19,085 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70387d5{/,file:///tmp/jetty-0.0.0.0-34804-hddsDatanode-_-any-9013497577210189535.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-14 13:57:19,085 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@76b3ff9f{HTTP/1.1,[http/1.1]}{0.0.0.0:34804}
2019-11-14 13:57:19,085 [Thread-3665] INFO  server.Server (Server.java:doStart(419)) - Started @257271ms
2019-11-14 13:57:19,087 [Thread-3665] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-14 13:57:19,088 [Thread-3665] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34804
2019-11-14 13:57:19,089 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:57:19,091 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20bb4e1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-14 13:57:19,096 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/meta/datanode.id
2019-11-14 13:57:19,208 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-3@group-523986131536: change Leader from null to omNode-1 at term 1 for appendEntries, leader elected after 233ms
2019-11-14 13:57:19,214 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - omNode-3@group-523986131536: set configuration 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null at 0
2019-11-14 13:57:19,214 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-14 13:57:19,241 [omNode-3@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - omNode-3@group-523986131536-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/omNode-3/ratis/c9bc4cf4-3bc3-3c60-a66b-523986131536/current/log_inprogress_0
2019-11-14 13:57:20,090 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:57:21,091 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:57:22,091 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:57:22,147 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-14 13:57:22,150 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-14 13:57:22,150 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis bff262f9-ca21-4b62-ac54-e214c0147916 at port 0
2019-11-14 13:57:22,158 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - bff262f9-ca21-4b62-ac54-e214c0147916: start RPC server
2019-11-14 13:57:22,159 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - bff262f9-ca21-4b62-ac54-e214c0147916: GrpcService started, listening on 0.0.0.0/0.0.0.0:44080
2019-11-14 13:57:22,160 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis bff262f9-ca21-4b62-ac54-e214c0147916 is started using port 44080
2019-11-14 13:57:22,161 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc bff262f9-ca21-4b62-ac54-e214c0147916 is started using port 44162
2019-11-14 13:57:23,092 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-14 13:57:23,098 [IPC Server handler 0 on 38708] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/bff262f9-ca21-4b62-ac54-e214c0147916
2019-11-14 13:57:23,100 [IPC Server handler 0 on 38708] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : bff262f9-ca21-4b62-ac54-e214c0147916{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}
2019-11-14 13:57:23,103 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-11-14 13:57:23,105 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-11-14 13:57:23,105 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-11-14 13:57:23,114 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bff262f9-ca21-4b62-ac54-e214c0147916: addNew group-96956048B1FB:[bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080] returns group-96956048B1FB:java.util.concurrent.CompletableFuture@feac8f6[Not completed]
2019-11-14 13:57:23,117 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - bff262f9-ca21-4b62-ac54-e214c0147916: new RaftServerImpl for group-96956048B1FB:[bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080] with ContainerStateMachine:uninitialized
2019-11-14 13:57:23,118 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-14 13:57:23,118 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-14 13:57:23,118 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-14 13:57:23,118 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:57:23,119 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:57:23,119 [pool-736-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB: ConfigurationManager, init=-1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null, confs=<EMPTY_MAP>
2019-11-14 13:57:23,119 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis] (custom)
2019-11-14 13:57:23,119 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:57:23,120 [pool-736-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/1c75508a-b474-4d0c-8289-96956048b1fb does not exist. Creating ...
2019-11-14 13:57:23,823 [pool-736-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/1c75508a-b474-4d0c-8289-96956048b1fb/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:57:24,827 [pool-736-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/1c75508a-b474-4d0c-8289-96956048b1fb has been successfully formatted.
2019-11-14 13:57:24,829 [pool-736-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-96956048B1FB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-14 13:57:24,829 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-14 13:57:24,830 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:57:24,830 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-14 13:57:24,831 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:24,831 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:57:24,831 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:24,832 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:57:24,832 [pool-736-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/1c75508a-b474-4d0c-8289-96956048b1fb
2019-11-14 13:57:24,832 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-14 13:57:24,832 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-14 13:57:24,832 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:57:24,832 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:57:24,833 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-14 13:57:24,833 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:57:24,833 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:57:24,833 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:57:24,833 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:57:24,834 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-14 13:57:24,835 [pool-736-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:57:24,835 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:57:24,835 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-14 13:57:24,835 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-14 13:57:24,836 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:57:24,836 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:24,836 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:24,837 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB: start as a follower, conf=-1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null
2019-11-14 13:57:24,837 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:57:24,837 [pool-736-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bff262f9-ca21-4b62-ac54-e214c0147916: start FollowerState
2019-11-14 13:57:24,839 [pool-736-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-96956048B1FB,id=bff262f9-ca21-4b62-ac54-e214c0147916
2019-11-14 13:57:24,839 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:24,854 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(55)) - Created pipeline Pipeline[ Id: 1c75508a-b474-4d0c-8289-96956048b1fb, Nodes: bff262f9-ca21-4b62-ac54-e214c0147916{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
2019-11-14 13:57:24,855 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-14 13:57:25,856 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-14 13:57:26,107 [Thread-3924] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-11-14 13:57:26,107 [Thread-3924] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 1c75508a-b474-4d0c-8289-96956048b1fb, Nodes: bff262f9-ca21-4b62-ac54-e214c0147916{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
2019-11-14 13:57:26,109 [Thread-3924] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(121)) - Pipeline Pipeline[ Id: 1c75508a-b474-4d0c-8289-96956048b1fb, Nodes: bff262f9-ca21-4b62-ac54-e214c0147916{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-11-14 13:57:26,110 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-11-14 13:57:26,120 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - bff262f9-ca21-4b62-ac54-e214c0147916: remove  FOLLOWER bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB:t0, leader=null, voted=null, raftlog=bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null RUNNING
2019-11-14 13:57:26,120 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB: shutdown
2019-11-14 13:57:26,120 [grpc-default-executor-4] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-96956048B1FB,id=bff262f9-ca21-4b62-ac54-e214c0147916
2019-11-14 13:57:26,121 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bff262f9-ca21-4b62-ac54-e214c0147916: shutdown FollowerState
2019-11-14 13:57:26,121 [grpc-default-executor-4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB-StateMachineUpdater: set stopIndex = -1
2019-11-14 13:57:26,121 [Thread-3934] INFO  impl.FollowerState (FollowerState.java:run(120)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-14 13:57:26,123 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB: closes. applyIndex: -1
2019-11-14 13:57:26,124 [bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:57:26,124 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-96956048B1FB-SegmentedRaftLogWorker close()
2019-11-14 13:57:26,261 [Thread-3924] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(106)) - Pipeline Pipeline[ Id: 1c75508a-b474-4d0c-8289-96956048b1fb, Nodes: bff262f9-ca21-4b62-ac54-e214c0147916{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-11-14 13:57:26,278 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bff262f9-ca21-4b62-ac54-e214c0147916: addNew group-59CB2B3BF6F2:[bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080] returns group-59CB2B3BF6F2:java.util.concurrent.CompletableFuture@34b0950c[Not completed]
2019-11-14 13:57:26,279 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - bff262f9-ca21-4b62-ac54-e214c0147916: new RaftServerImpl for group-59CB2B3BF6F2:[bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080] with ContainerStateMachine:uninitialized
2019-11-14 13:57:26,279 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-14 13:57:26,280 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-14 13:57:26,280 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-14 13:57:26,280 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:57:26,280 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:57:26,280 [pool-736-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2: ConfigurationManager, init=-1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null, confs=<EMPTY_MAP>
2019-11-14 13:57:26,280 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis] (custom)
2019-11-14 13:57:26,281 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:57:26,281 [pool-736-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2 does not exist. Creating ...
2019-11-14 13:57:27,905 [pool-736-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:57:29,271 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$433/296453151@179ce4c7 for bff262f9-ca21-4b62-ac54-e214c0147916
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999825005ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:220)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999825005ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-11-14 13:57:29,274 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-11-14 13:57:29,322 [Thread-3665] INFO  rpc.RpcClient (RpcClient.java:createVolume(292)) - Creating Volume: volume65827, with user56700 as owner.
2019-11-14 13:57:29,339 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(193)) - created volume:volume65827 for user:user56700
2019-11-14 13:57:29,348 [Thread-3665] INFO  rpc.RpcClient (RpcClient.java:createBucket(431)) - Creating Bucket: volume65827/80e416a7-fff1-43d6-8877-7f692d5b7118, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-11-14 13:57:29,352 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(193)) - created volume:volume65827 for user:user56700
2019-11-14 13:57:29,353 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(193)) - created volume:volume65827 for user:user56700
2019-11-14 13:57:29,394 [Thread-3665] INFO  io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateNewBlock(257)) - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
2019-11-14 13:57:29,405 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bff262f9-ca21-4b62-ac54-e214c0147916: addNew group-F86B086B289D:[bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080] returns group-F86B086B289D:java.util.concurrent.CompletableFuture@64c85e53[Not completed]
2019-11-14 13:57:30,310 [pool-736-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2 has been successfully formatted.
2019-11-14 13:57:30,310 [pool-736-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-59CB2B3BF6F2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-14 13:57:30,311 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-14 13:57:30,312 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:57:30,312 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:57:30,312 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-14 13:57:30,312 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:57:30,312 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:57:30,312 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:57:30,312 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:57:30,312 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-14 13:57:30,313 [pool-736-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:57:30,313 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:57:30,313 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-14 13:57:30,313 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-14 13:57:30,313 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:57:30,313 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:30,313 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:30,315 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - bff262f9-ca21-4b62-ac54-e214c0147916: new RaftServerImpl for group-F86B086B289D:[bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080] with ContainerStateMachine:uninitialized
2019-11-14 13:57:30,315 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-14 13:57:30,315 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-14 13:57:30,315 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-14 13:57:30,315 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-14 13:57:30,315 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-14 13:57:30,315 [pool-736-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: ConfigurationManager, init=-1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null, confs=<EMPTY_MAP>
2019-11-14 13:57:30,315 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis] (custom)
2019-11-14 13:57:30,480 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-14 13:57:30,480 [pool-736-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/59c7fc43-f5a5-43fb-b84f-f86b086b289d does not exist. Creating ...
2019-11-14 13:57:30,501 [pool-736-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/59c7fc43-f5a5-43fb-b84f-f86b086b289d/in_use.lock acquired by nodename 29050@pr-hdds-2479-srhdm-1052850629
2019-11-14 13:57:30,526 [pool-736-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/59c7fc43-f5a5-43fb-b84f-f86b086b289d has been successfully formatted.
2019-11-14 13:57:30,526 [pool-736-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-F86B086B289D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-14 13:57:30,527 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-14 13:57:30,527 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-14 13:57:30,527 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-14 13:57:30,527 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-14 13:57:30,527 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:57:30,528 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-14 13:57:30,528 [pool-736-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/59c7fc43-f5a5-43fb-b84f-f86b086b289d
2019-11-14 13:57:30,528 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-14 13:57:30,528 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-14 13:57:30,528 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-14 13:57:30,528 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-14 13:57:30,529 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-14 13:57:30,529 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-14 13:57:30,529 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-14 13:57:30,529 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-14 13:57:30,529 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-14 13:57:30,530 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-14 13:57:30,530 [pool-736-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-14 13:57:30,530 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-14 13:57:30,530 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-14 13:57:30,530 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-14 13:57:30,530 [pool-736-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-14 13:57:30,531 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:30,531 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:30,531 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2: start as a follower, conf=-1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null
2019-11-14 13:57:30,531 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:57:30,531 [pool-736-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bff262f9-ca21-4b62-ac54-e214c0147916: start FollowerState
2019-11-14 13:57:30,532 [pool-736-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59CB2B3BF6F2,id=bff262f9-ca21-4b62-ac54-e214c0147916
2019-11-14 13:57:30,532 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:30,532 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: start as a follower, conf=-1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null
2019-11-14 13:57:30,532 [pool-736-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-14 13:57:30,533 [pool-736-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bff262f9-ca21-4b62-ac54-e214c0147916: start FollowerState
2019-11-14 13:57:30,533 [pool-736-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F86B086B289D,id=bff262f9-ca21-4b62-ac54-e214c0147916
2019-11-14 13:57:30,533 [pool-736-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-14 13:57:30,537 [IPC Server handler 4 on 40674] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(55)) - Created pipeline Pipeline[ Id: 59c7fc43-f5a5-43fb-b84f-f86b086b289d, Nodes: bff262f9-ca21-4b62-ac54-e214c0147916{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
2019-11-14 13:57:35,563 [Thread-3992] INFO  impl.FollowerState (FollowerState.java:run(111)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-FollowerState: change to CANDIDATE, lastRpcTime:5030ms, electionTimeout:5030ms
2019-11-14 13:57:35,563 [Thread-3992] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bff262f9-ca21-4b62-ac54-e214c0147916: shutdown FollowerState
2019-11-14 13:57:35,564 [Thread-3992] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-14 13:57:35,564 [Thread-3992] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bff262f9-ca21-4b62-ac54-e214c0147916: start LeaderElection
2019-11-14 13:57:35,589 [Thread-3990] INFO  impl.FollowerState (FollowerState.java:run(111)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-FollowerState: change to CANDIDATE, lastRpcTime:5057ms, electionTimeout:5057ms
2019-11-14 13:57:35,589 [Thread-3990] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bff262f9-ca21-4b62-ac54-e214c0147916: shutdown FollowerState
2019-11-14 13:57:35,589 [Thread-3990] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-14 13:57:35,589 [Thread-3990] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bff262f9-ca21-4b62-ac54-e214c0147916: start LeaderElection
2019-11-14 13:57:36,802 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25: begin an election at term 1 for -1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null
2019-11-14 13:57:36,802 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bff262f9-ca21-4b62-ac54-e214c0147916: shutdown LeaderElection
2019-11-14 13:57:36,802 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-14 13:57:36,803 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(697)) - Leader change notification received for group: group-F86B086B289D with new leaderId: bff262f9-ca21-4b62-ac54-e214c0147916
2019-11-14 13:57:36,806 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: change Leader from null to bff262f9-ca21-4b62-ac54-e214c0147916 at term 1 for becomeLeader, leader elected after 6275ms
2019-11-14 13:57:36,806 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-14 13:57:36,807 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-14 13:57:36,807 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-14 13:57:36,807 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-14 13:57:36,807 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-14 13:57:36,807 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-14 13:57:36,808 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bff262f9-ca21-4b62-ac54-e214c0147916: start LeaderState
2019-11-14 13:57:36,809 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-14 13:57:36,809 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: set configuration 0: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null at 0
2019-11-14 13:57:36,853 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - bff262f9-ca21-4b62-ac54-e214c0147916: remove CANDIDATE bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2:t1, leader=null, voted=bff262f9-ca21-4b62-ac54-e214c0147916, raftlog=bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bff262f9-ca21-4b62-ac54-e214c0147916:192.168.157.199:44080], old=null RUNNING
2019-11-14 13:57:36,854 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2: shutdown
2019-11-14 13:57:36,854 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-59CB2B3BF6F2,id=bff262f9-ca21-4b62-ac54-e214c0147916
2019-11-14 13:57:36,854 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bff262f9-ca21-4b62-ac54-e214c0147916: shutdown LeaderElection
2019-11-14 13:57:36,855 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-StateMachineUpdater: set stopIndex = -1
2019-11-14 13:57:36,856 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2: closes. applyIndex: -1
2019-11-14 13:57:36,857 [bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:57:36,857 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-SegmentedRaftLogWorker close()
2019-11-14 13:57:36,864 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:openPipeline(134)) - Pipeline Pipeline[ Id: 59c7fc43-f5a5-43fb-b84f-f86b086b289d, Nodes: bff262f9-ca21-4b62-ac54-e214c0147916{ip: 192.168.157.199, host: pr-hdds-2479-srhdm-1052850629, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN] moved to OPEN state
2019-11-14 13:57:37,226 [bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-LeaderElection26] WARN  util.FileUtils (LogUtils.java:runAndLog(55)) - Failed to Files.move /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2/current/raft-meta.tmp to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2/current/raft-meta: java.nio.file.NoSuchFileException: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2/current/raft-meta.tmp
2019-11-14 13:57:37,226 [bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-LeaderElection26] WARN  util.AtomicFileOutputStream (AtomicFileOutputStream.java:abort(100)) - Unable to delete tmp file during abort /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2/current/raft-meta.tmp
2019-11-14 13:57:37,226 [bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:run(137)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-59CB2B3BF6F2-LeaderElection26: NoSuchFileException is safely ignored since this is already CLOSING
java.nio.file.NoSuchFileException: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/25f62615-85c0-4f28-8c7e-59cb2b3bf6f2/current/raft-meta.tmp
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixCopyFile.move(UnixCopyFile.java:409)
	at sun.nio.fs.UnixFileSystemProvider.move(UnixFileSystemProvider.java:262)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.ratis.util.FileUtils.lambda$move$6(FileUtils.java:79)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
	at org.apache.ratis.util.FileUtils.move(FileUtils.java:78)
	at org.apache.ratis.util.FileUtils.move(FileUtils.java:74)
	at org.apache.ratis.util.AtomicFileOutputStream.close(AtomicFileOutputStream.java:73)
	at org.apache.ratis.server.storage.MetaFile.writeFile(MetaFile.java:96)
	at org.apache.ratis.server.storage.MetaFile.set(MetaFile.java:75)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.writeMetadata(SegmentedRaftLog.java:473)
	at org.apache.ratis.server.impl.ServerState.persistMetadata(ServerState.java:231)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:176)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
2019-11-14 13:57:38,990 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/59c7fc43-f5a5-43fb-b84f-f86b086b289d/current/log_inprogress_0
2019-11-14 13:57:48,030 [Thread-3665] INFO  io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateNewBlock(257)) - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
2019-11-14 13:57:48,310 [Thread-3665] INFO  io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateNewBlock(257)) - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
2019-11-14 13:57:48,559 [Thread-3665] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 11724
2019-11-14 13:57:48,563 [IPC Server listener on 11724] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 11724
2019-11-14 13:57:48,563 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:57:48,564 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-1: close
2019-11-14 13:57:48,565 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - omNode-1@group-523986131536: shutdown
2019-11-14 13:57:48,565 [Thread-3665] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-1
2019-11-14 13:57:48,566 [Thread-3665] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - omNode-1: shutdown LeaderState
2019-11-14 13:57:48,568 [Thread-3665] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - omNode-1@group-523986131536-PendingRequests: sendNotLeaderResponses
2019-11-14 13:57:48,568 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$261/658393789@6d91ff80] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(151)) - omNode-1@group-523986131536->omNode-3-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-11-14 13:57:48,568 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$261/658393789@1154dc63] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(151)) - omNode-1@group-523986131536->omNode-2-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-11-14 13:57:48,569 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - omNode-2: Completed APPEND_ENTRIES, lastRequest: omNode-1->omNode-2#82-t1, previous=(t:1, i:23), leaderCommit=23, initializing? false, entries: size=1, first=(t:1, i:24), METADATAENTRY(c23)
2019-11-14 13:57:48,570 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-11-14 13:57:48,569 [Thread-3665] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - omNode-1@group-523986131536-StateMachineUpdater: set stopIndex = 24
2019-11-14 13:57:48,569 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - omNode-3: Completed APPEND_ENTRIES, lastRequest: omNode-1->omNode-3#83-t1, previous=(t:1, i:23), leaderCommit=23, initializing? false, entries: size=1, first=(t:1, i:24), METADATAENTRY(c23)
2019-11-14 13:57:48,570 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - omNode-1@group-523986131536->omNode-2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-11-14 13:57:48,572 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - omNode-1@group-523986131536->omNode-3-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-11-14 13:57:48,573 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 23
2019-11-14 13:57:48,573 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - omNode-1@group-523986131536-StateMachineUpdater: Took a snapshot at index 23
2019-11-14 13:57:48,573 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - omNode-1@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 23
2019-11-14 13:57:48,573 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-11-14 13:57:48,573 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-2: nextIndex: updateUnconditionally 25 -> 24
2019-11-14 13:57:48,573 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - omNode-1@group-523986131536->omNode-3: nextIndex: updateUnconditionally 25 -> 24
2019-11-14 13:57:48,573 [omNode-1@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 23
2019-11-14 13:57:48,573 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - omNode-1@group-523986131536-StateMachineUpdater: Took a snapshot at index 23
2019-11-14 13:57:48,574 [omNode-1@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - omNode-1@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly 23 -> 23
2019-11-14 13:57:48,574 [Thread-3665] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - omNode-1@group-523986131536: closes. applyIndex: 24
2019-11-14 13:57:48,574 [omNode-1@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - omNode-1@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:57:48,575 [Thread-3665] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - omNode-1@group-523986131536-SegmentedRaftLogWorker close()
2019-11-14 13:57:48,578 [Thread-3665] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-1: shutdown server with port 11728 now
2019-11-14 13:57:48,578 [Thread-3665] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-1: shutdown server with port 11728 successfully
2019-11-14 13:57:48,578 [Thread-3665] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-14 13:57:48,579 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-14 13:57:48,579 [Thread-3665] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-14 13:57:48,580 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27e2a730{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-14 13:57:48,580 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@281089d9{HTTP/1.1,[http/1.1]}{0.0.0.0:11726}
2019-11-14 13:57:48,581 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13240fd8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-14 13:57:48,581 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5160359d{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:57:50,383 [Thread-3836] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-2@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1831ms, electionTimeout:1143ms
2019-11-14 13:57:50,384 [Thread-3836] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-11-14 13:57:50,384 [Thread-3836] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-11-14 13:57:50,384 [Thread-3836] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start LeaderElection
2019-11-14 13:57:50,386 [omNode-2@group-523986131536-LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-2@group-523986131536: change Leader from omNode-1 to null at term 1 for initElection
2019-11-14 13:57:50,387 [Thread-3848] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-3@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1835ms, electionTimeout:1194ms
2019-11-14 13:57:50,387 [Thread-3848] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-3: shutdown FollowerState
2019-11-14 13:57:50,387 [Thread-3848] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-11-14 13:57:50,387 [Thread-3848] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start LeaderElection
2019-11-14 13:57:50,389 [omNode-3@group-523986131536-LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - omNode-3@group-523986131536: change Leader from omNode-1 to null at term 1 for initElection
2019-11-14 13:57:50,411 [omNode-3@group-523986131536-LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-3@group-523986131536-LeaderElection28: begin an election at term 2 for 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:50,411 [omNode-2@group-523986131536-LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-2@group-523986131536-LeaderElection27: begin an election at term 2 for 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:50,415 [omNode-3@group-523986131536-LeaderElection28] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-3@group-523986131536-LeaderElection28 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:50,415 [omNode-2@group-523986131536-LeaderElection27] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-2@group-523986131536-LeaderElection27 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:50,427 [omNode-2@group-523986131536-LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-2@group-523986131536-LeaderElection27: Election REJECTED; received 1 response(s) [omNode-2<-omNode-3#0:FAIL-t2] and 1 exception(s); omNode-2@group-523986131536:t2, leader=null, voted=omNode-2, raftlog=omNode-2@group-523986131536-SegmentedRaftLog:OPENED:c23,f24,i24, conf=0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:50,427 [omNode-2@group-523986131536-LeaderElection27] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:50,427 [omNode-3@group-523986131536-LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-3@group-523986131536-LeaderElection28: Election REJECTED; received 1 response(s) [omNode-3<-omNode-2#0:FAIL-t2] and 1 exception(s); omNode-3@group-523986131536:t2, leader=null, voted=omNode-3, raftlog=omNode-3@group-523986131536-SegmentedRaftLog:OPENED:c23,f24,i24, conf=0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:50,429 [omNode-3@group-523986131536-LeaderElection28] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:50,428 [omNode-2@group-523986131536-LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
2019-11-14 13:57:50,429 [omNode-3@group-523986131536-LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
2019-11-14 13:57:50,431 [omNode-2@group-523986131536-LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-2: shutdown LeaderElection
2019-11-14 13:57:50,431 [omNode-3@group-523986131536-LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-3: shutdown LeaderElection
2019-11-14 13:57:50,431 [omNode-2@group-523986131536-LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-11-14 13:57:50,431 [omNode-3@group-523986131536-LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start FollowerState
2019-11-14 13:57:51,483 [Thread-4153] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-2@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1051ms, electionTimeout:1051ms
2019-11-14 13:57:51,483 [Thread-4153] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-11-14 13:57:51,483 [Thread-4153] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-11-14 13:57:51,484 [Thread-4153] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start LeaderElection
2019-11-14 13:57:51,493 [Thread-4154] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-3@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1062ms, electionTimeout:1059ms
2019-11-14 13:57:51,494 [Thread-4154] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-3: shutdown FollowerState
2019-11-14 13:57:51,494 [Thread-4154] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-11-14 13:57:51,494 [Thread-4154] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start LeaderElection
2019-11-14 13:57:51,515 [omNode-3@group-523986131536-LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-3@group-523986131536-LeaderElection30: begin an election at term 3 for 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:51,515 [omNode-2@group-523986131536-LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-2@group-523986131536-LeaderElection29: begin an election at term 3 for 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:51,518 [omNode-2@group-523986131536-LeaderElection29] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-2@group-523986131536-LeaderElection29 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:51,518 [omNode-3@group-523986131536-LeaderElection30] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-3@group-523986131536-LeaderElection30 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:51,526 [omNode-3@group-523986131536-LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-3@group-523986131536-LeaderElection30: Election REJECTED; received 1 response(s) [omNode-3<-omNode-2#0:FAIL-t3] and 1 exception(s); omNode-3@group-523986131536:t3, leader=null, voted=omNode-3, raftlog=omNode-3@group-523986131536-SegmentedRaftLog:OPENED:c23,f24,i24, conf=0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:51,526 [omNode-2@group-523986131536-LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-2@group-523986131536-LeaderElection29: Election REJECTED; received 1 response(s) [omNode-2<-omNode-3#0:FAIL-t3] and 1 exception(s); omNode-2@group-523986131536:t3, leader=null, voted=omNode-2, raftlog=omNode-2@group-523986131536-SegmentedRaftLog:OPENED:c23,f24,i24, conf=0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:51,526 [omNode-3@group-523986131536-LeaderElection30] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:51,526 [omNode-2@group-523986131536-LeaderElection29] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:51,527 [omNode-3@group-523986131536-LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
2019-11-14 13:57:51,530 [omNode-2@group-523986131536-LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
2019-11-14 13:57:51,531 [omNode-3@group-523986131536-LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-3: shutdown LeaderElection
2019-11-14 13:57:51,531 [omNode-2@group-523986131536-LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-2: shutdown LeaderElection
2019-11-14 13:57:51,532 [omNode-3@group-523986131536-LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start FollowerState
2019-11-14 13:57:51,532 [omNode-2@group-523986131536-LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-11-14 13:57:52,586 [Thread-3665] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "pr-hdds-2479-srhdm-1052850629/192.168.157.199"; destination host is: "localhost":11724; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy37.submitRequest over nodeId=omNode-1,nodeAddress=127.0.0.1:11724. Trying to failover immediately.
2019-11-14 13:57:52,589 [Thread-4162] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-3@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1057ms, electionTimeout:1054ms
2019-11-14 13:57:52,589 [Thread-4162] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-3: shutdown FollowerState
2019-11-14 13:57:52,594 [Thread-4162] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-3@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2019-11-14 13:57:52,596 [Thread-4162] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-3: start LeaderElection
2019-11-14 13:57:52,600 [IPC Server handler 0 on 11730] INFO  ipc.Server (Server.java:logException(2726)) - IPC Server handler 0 on 11730, call Call#416 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:38294
org.apache.hadoop.ozone.om.exceptions.NotLeaderException: OM:omNode-2 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:176)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:110)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-11-14 13:57:52,604 [Thread-3665] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.NotLeaderException): OM:omNode-2 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:176)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:110)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy37.submitRequest over nodeId=omNode-2,nodeAddress=127.0.0.1:11730 after 1 failover attempts. Trying to failover immediately.
2019-11-14 13:57:52,609 [IPC Server handler 1 on 11736] INFO  ipc.Server (Server.java:logException(2726)) - IPC Server handler 1 on 11736, call Call#416 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:44404
org.apache.hadoop.ozone.om.exceptions.NotLeaderException: OM:omNode-3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:176)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:110)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-11-14 13:57:52,611 [Thread-3665] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.NotLeaderException): OM:omNode-3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:176)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:110)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy37.submitRequest over nodeId=omNode-3,nodeAddress=127.0.0.1:11736 after 2 failover attempts. Trying to failover immediately.
2019-11-14 13:57:52,661 [Thread-4163] INFO  impl.FollowerState (FollowerState.java:run(111)) - omNode-2@group-523986131536-FollowerState: change to CANDIDATE, lastRpcTime:1129ms, electionTimeout:1126ms
2019-11-14 13:57:52,661 [Thread-4163] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-11-14 13:57:52,661 [Thread-4163] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2019-11-14 13:57:52,661 [Thread-4163] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start LeaderElection
2019-11-14 13:57:52,813 [Thread-3665] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:11724. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:57:53,016 [Thread-3665] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:11724. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:57:53,218 [Thread-3665] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:11724. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:57:53,418 [Thread-3665] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:11724. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:57:53,419 [Thread-3665] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Call From pr-hdds-2479-srhdm-1052850629/192.168.157.199 to localhost:11724 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy37.submitRequest over nodeId=omNode-1,nodeAddress=127.0.0.1:11724 after 3 failover attempts. Trying to failover immediately.
2019-11-14 13:57:53,421 [IPC Server handler 0 on 11730] INFO  ipc.Server (Server.java:logException(2726)) - IPC Server handler 0 on 11730, call Call#416 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:38294
org.apache.hadoop.ozone.om.exceptions.NotLeaderException: OM:omNode-2 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:176)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:110)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-11-14 13:57:53,425 [Thread-3665] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.NotLeaderException): OM:omNode-2 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:176)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:110)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy37.submitRequest over nodeId=omNode-2,nodeAddress=127.0.0.1:11730 after 4 failover attempts. Trying to failover immediately.
2019-11-14 13:57:53,428 [IPC Server handler 1 on 11736] INFO  ipc.Server (Server.java:logException(2726)) - IPC Server handler 1 on 11736, call Call#416 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:44404
org.apache.hadoop.ozone.om.exceptions.NotLeaderException: OM:omNode-3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:176)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:110)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-11-14 13:57:53,430 [Thread-3665] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.NotLeaderException): OM:omNode-3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:190)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:176)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:110)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy37.submitRequest over nodeId=omNode-3,nodeAddress=127.0.0.1:11736 after 5 failover attempts. Trying to failover immediately.
2019-11-14 13:57:53,632 [Thread-3665] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:11724. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:57:53,833 [Thread-3665] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:11724. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:57:54,033 [Thread-3665] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:11724. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:57:54,234 [Thread-3665] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:11724. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=4, sleepTime=200 MILLISECONDS)
2019-11-14 13:57:54,235 [Thread-3665] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(274)) - Failed to connect to OMs: [nodeId=omNode-3,nodeAddress=127.0.0.1:11736, nodeId=omNode-1,nodeAddress=127.0.0.1:11724, nodeId=omNode-2,nodeAddress=127.0.0.1:11730]. Attempted 5 failovers.
2019-11-14 13:57:54,236 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(352)) - Shutting down the Mini Ozone Cluster
2019-11-14 13:57:54,236 [Thread-3665] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-3
2019-11-14 13:57:54,236 [Thread-3665] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 11736
2019-11-14 13:57:54,242 [IPC Server listener on 11736] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 11736
2019-11-14 13:57:54,244 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:57:54,245 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-3: close
2019-11-14 13:57:54,246 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - omNode-3@group-523986131536: shutdown
2019-11-14 13:57:54,246 [Thread-3665] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-3
2019-11-14 13:57:54,247 [Thread-3665] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-3: shutdown LeaderElection
2019-11-14 13:57:54,247 [Thread-3665] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - omNode-3@group-523986131536-StateMachineUpdater: set stopIndex = 23
2019-11-14 13:57:54,247 [omNode-3@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-11-14 13:57:54,285 [omNode-3@group-523986131536-LeaderElection31] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-3@group-523986131536-LeaderElection31: begin an election at term 4 for 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:54,286 [omNode-3@group-523986131536-LeaderElection31] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-3@group-523986131536-LeaderElection31: Election REJECTED; received 0 response(s) [] and 0 exception(s); omNode-3@group-523986131536:t4, leader=null, voted=omNode-3, raftlog=omNode-3@group-523986131536-SegmentedRaftLog:OPENED:c23,f24,i24, conf=0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:54,288 [omNode-3@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 23
2019-11-14 13:57:54,288 [omNode-3@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - omNode-3@group-523986131536-StateMachineUpdater: Took a snapshot at index 23
2019-11-14 13:57:54,289 [omNode-3@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - omNode-3@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 23
2019-11-14 13:57:54,289 [Thread-3665] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - omNode-3@group-523986131536: closes. applyIndex: 23
2019-11-14 13:57:54,291 [omNode-3@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - omNode-3@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:57:54,293 [Thread-3665] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - omNode-3@group-523986131536-SegmentedRaftLogWorker close()
2019-11-14 13:57:54,296 [Thread-3665] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-3: shutdown server with port 11740 now
2019-11-14 13:57:55,731 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - omNode-2@group-523986131536-LeaderElection32: begin an election at term 4 for 0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:55,734 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-2@group-523986131536-LeaderElection32 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:55,734 [Thread-3665] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-3: shutdown server with port 11740 successfully
2019-11-14 13:57:55,738 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - omNode-2@group-523986131536-LeaderElection32 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11740
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:55,739 [Thread-3665] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-14 13:57:55,752 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - omNode-2@group-523986131536-LeaderElection32: Election REJECTED; received 0 response(s) [] and 2 exception(s); omNode-2@group-523986131536:t4, leader=null, voted=omNode-2, raftlog=omNode-2@group-523986131536-SegmentedRaftLog:OPENED:c23,f24,i24, conf=0: [omNode-3:localhost:11740, omNode-1:localhost:11728, omNode-2:localhost:11734], old=null
2019-11-14 13:57:55,752 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11728
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:55,753 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 1: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:11740
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-14 13:57:55,752 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-14 13:57:55,757 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - omNode-2@group-523986131536: changes role from CANDIDATE to FOLLOWER at term 4 for DISCOVERED_A_NEW_TERM
2019-11-14 13:57:55,758 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - omNode-2: shutdown LeaderElection
2019-11-14 13:57:55,758 [omNode-2@group-523986131536-LeaderElection32] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - omNode-2: start FollowerState
2019-11-14 13:57:55,759 [Thread-3665] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-14 13:57:55,761 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@14ca21f1{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-14 13:57:55,763 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@33bb5fd3{HTTP/1.1,[http/1.1]}{0.0.0.0:11738}
2019-11-14 13:57:55,763 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75cd313a{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-14 13:57:55,764 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a685db{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:57:55,768 [Thread-3665] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-1
2019-11-14 13:57:55,768 [Thread-3665] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 11724
2019-11-14 13:57:55,768 [Thread-3665] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(147)) - Stopping the OzoneManager omNode-2
2019-11-14 13:57:55,768 [Thread-3665] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 11730
2019-11-14 13:57:55,772 [IPC Server listener on 11730] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 11730
2019-11-14 13:57:55,772 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:57:55,773 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - omNode-2: close
2019-11-14 13:57:55,775 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - omNode-2@group-523986131536: shutdown
2019-11-14 13:57:55,775 [Thread-3665] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-523986131536,id=omNode-2
2019-11-14 13:57:55,776 [Thread-3665] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - omNode-2: shutdown FollowerState
2019-11-14 13:57:55,776 [Thread-3665] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - omNode-2@group-523986131536-StateMachineUpdater: set stopIndex = 23
2019-11-14 13:57:55,776 [omNode-2@group-523986131536-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-11-14 13:57:55,776 [Thread-4181] INFO  impl.FollowerState (FollowerState.java:run(120)) - omNode-2@group-523986131536-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-14 13:57:55,779 [omNode-2@group-523986131536-StateMachineUpdater] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 23
2019-11-14 13:57:55,780 [omNode-2@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - omNode-2@group-523986131536-StateMachineUpdater: Took a snapshot at index 23
2019-11-14 13:57:55,780 [omNode-2@group-523986131536-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - omNode-2@group-523986131536-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 23
2019-11-14 13:57:55,781 [Thread-3665] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - omNode-2@group-523986131536: closes. applyIndex: 23
2019-11-14 13:57:55,781 [omNode-2@group-523986131536-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - omNode-2@group-523986131536-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:57:55,783 [Thread-3665] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - omNode-2@group-523986131536-SegmentedRaftLogWorker close()
2019-11-14 13:57:55,785 [Thread-3665] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - omNode-2: shutdown server with port 11734 now
2019-11-14 13:57:55,785 [Thread-3665] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - omNode-2: shutdown server with port 11734 successfully
2019-11-14 13:57:55,786 [Thread-3665] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-14 13:57:55,786 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-14 13:57:55,786 [Thread-3665] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-14 13:57:55,787 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@228221f1{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-14 13:57:55,788 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5b6593c6{HTTP/1.1,[http/1.1]}{0.0.0.0:11732}
2019-11-14 13:57:55,788 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@350167b8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-14 13:57:55,789 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@aeefd9a{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:57:55,791 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(368)) - Stopping the Mini Ozone Cluster
2019-11-14 13:57:55,791 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(415)) - Stopping the HddsDatanodes
2019-11-14 13:57:56,432 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-14 13:58:00,794 [Thread-3665] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-14 13:58:00,796 [Thread-3665] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - bff262f9-ca21-4b62-ac54-e214c0147916: close
2019-11-14 13:58:00,796 [Thread-3665] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: shutdown
2019-11-14 13:58:00,796 [Thread-3665] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F86B086B289D,id=bff262f9-ca21-4b62-ac54-e214c0147916
2019-11-14 13:58:00,797 [Thread-3665] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - bff262f9-ca21-4b62-ac54-e214c0147916: shutdown LeaderState
2019-11-14 13:58:00,797 [Thread-3665] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-PendingRequests: sendNotLeaderResponses
2019-11-14 13:58:00,802 [Thread-3665] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-StateMachineUpdater: set stopIndex = 9
2019-11-14 13:58:00,802 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(285)) - group-F86B086B289D: Taking a snapshot at:(t:1, i:9) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/59c7fc43-f5a5-43fb-b84f-f86b086b289d/sm/snapshot.1_9
2019-11-14 13:58:00,827 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(296)) - group-F86B086B289D: Finished taking a snapshot at:(t:1, i:9) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/ratis/59c7fc43-f5a5-43fb-b84f-f86b086b289d/sm/snapshot.1_9 time:24
2019-11-14 13:58:00,827 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-StateMachineUpdater: Took a snapshot at index 9
2019-11-14 13:58:00,827 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 9
2019-11-14 13:58:00,828 [Thread-3665] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D: closes. applyIndex: 9
2019-11-14 13:58:00,828 [bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-14 13:58:00,830 [Thread-3665] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - bff262f9-ca21-4b62-ac54-e214c0147916@group-F86B086B289D-SegmentedRaftLogWorker close()
2019-11-14 13:58:00,833 [Thread-3665] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - bff262f9-ca21-4b62-ac54-e214c0147916: shutdown server with port 44080 now
2019-11-14 13:58:00,834 [Thread-3665] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - bff262f9-ca21-4b62-ac54-e214c0147916: shutdown server with port 44080 successfully
2019-11-14 13:58:00,836 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1749fda9-49c8-43f4-a780-9fd2bcfb2ea0/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-14 13:58:00,849 [Thread-3665] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-14 13:58:00,860 [Thread-3665] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-14 13:58:00,861 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70387d5{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-14 13:58:00,862 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@76b3ff9f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-14 13:58:00,863 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@457928d8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-14 13:58:00,863 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e4cfa9{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:58:00,875 [Thread-3665] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(430)) - Stopping the StorageContainerManager
2019-11-14 13:58:00,876 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(804)) - Stopping Replication Manager Service.
2019-11-14 13:58:00,876 [Thread-3665] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-11-14 13:58:00,876 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping Lease Manager of the command watchers
2019-11-14 13:58:00,876 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(818)) - Stopping datanode service RPC server
2019-11-14 13:58:00,876 [Thread-3665] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-14 13:58:00,876 [Thread-3665] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38708
2019-11-14 13:58:00,881 [IPC Server listener on 38708] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38708
2019-11-14 13:58:00,882 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:58:00,940 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-11-14 13:58:00,940 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(826)) - Stopping block service RPC server
2019-11-14 13:58:00,941 [Thread-3665] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-14 13:58:00,941 [Thread-3665] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40674
2019-11-14 13:58:00,944 [IPC Server listener on 40674] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40674
2019-11-14 13:58:00,944 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:58:00,944 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(833)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-14 13:58:00,946 [Thread-3665] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(169)) - Stopping the RPC server for Client Protocol
2019-11-14 13:58:00,946 [Thread-3665] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35083
2019-11-14 13:58:00,948 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(840)) - Stopping Storage Container Manager HTTP server.
2019-11-14 13:58:00,948 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-14 13:58:00,948 [IPC Server listener on 35083] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35083
2019-11-14 13:58:00,951 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5166f706{/,null,UNAVAILABLE}{/scm}
2019-11-14 13:58:00,951 [Thread-3665] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@45b5bfa8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-14 13:58:00,951 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b679ac9{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-14 13:58:00,952 [Thread-3665] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f00c9cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-14 13:58:00,953 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(851)) - Stopping Block Manager Service.
2019-11-14 13:58:00,953 [Thread-3665] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-14 13:58:00,953 [Thread-3665] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-14 13:58:00,953 [Thread-3665] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(873)) - Stopping SCM Event Queue.
2019-11-14 13:58:00,959 [Thread-3665] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-11-14 13:58:00,977 [Thread-3665] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
]]></system-out>
  </testcase>
  <testcase name="testRemoveBucketAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="21.226"/>
  <testcase name="testAddPrefixAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="22.113"/>
  <testcase name="testReadRequest" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="21.716"/>
  <testcase name="testRemoveKeyAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="27.042"/>
  <testcase name="testAllVolumeOperations" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="21.808"/>
  <testcase name="testSetBucketAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="21.722"/>
  <testcase name="testListVolumes" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="32.063"/>
  <testcase name="testAddKeyAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="32.67"/>
  <testcase name="testFileOperationsWithNonRecursive" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="23.212"/>
  <testcase name="testOMProxyProviderInitialization" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="22.006"/>
  <testcase name="testRemovePrefixAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="21.84"/>
  <testcase name="testOneOMNodeDown" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="26.23"/>
  <testcase name="testSetKeyAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="22.153"/>
  <testcase name="testTwoOMNodesDown" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="33.442"/>
  <testcase name="testSetPrefixAcl" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="24.552"/>
  <testcase name="testOMRestart" classname="org.apache.hadoop.ozone.om.TestOzoneManagerHA" time="32.083"/>
</testsuite>