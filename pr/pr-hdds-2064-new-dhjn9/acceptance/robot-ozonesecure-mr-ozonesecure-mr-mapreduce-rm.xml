<?xml version="1.0" encoding="UTF-8"?>
<robot rpa="false" generated="20191105 17:14:56.642" generator="Robot 3.1.1 (Python 2.7.5 on linux2)">
<suite source="/opt/ozone/smoketest/mapreduce.robot" id="s1" name="ozonesecure-mr-mapreduce">
<test id="s1-t1" name="Execute PI calculation">
<kw name="Execute" library="commonlib">
<arguments>
<arg>yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-${hadoop.version}.jar pi 3 3</arg>
</arguments>
<assign>
<var>${output}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191105 17:14:56.697" level="INFO">Running command 'yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar pi 3 3 2&gt;&amp;1'.</msg>
<msg timestamp="20191105 17:15:52.903" level="INFO">${rc} = 255</msg>
<msg timestamp="20191105 17:15:52.903" level="INFO">${output} = Number of Maps  = 3
Samples per Map = 3
2019-11-05 17:14:59 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-05 17:14:59 INFO  MetricsSystemImpl:374 - Scheduled Metr...</msg>
<status status="PASS" endtime="20191105 17:15:52.903" starttime="20191105 17:14:56.696"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191105 17:15:52.905" level="INFO">Number of Maps  = 3
Samples per Map = 3
2019-11-05 17:14:59 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-05 17:14:59 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-11-05 17:14:59 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
Wrote input for Map #0
Wrote input for Map #1
Wrote input for Map #2
Starting Job
2019-11-05 17:15:01 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.19.0.6:8032
2019-11-05 17:15:02 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.19.0.3:10200
2019-11-05 17:15:02 INFO  KMSClientProvider:1041 - New token created: (Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572974102506, maxDate=1573578902506, sequenceNumber=1, masterKeyId=2))
2019-11-05 17:15:02 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: OzoneToken, Service: 172.19.0.10:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1572974102190, maxDate=1573578902190, sequenceNumber=1, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null)
2019-11-05 17:15:02 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572974102506, maxDate=1573578902506, sequenceNumber=1, masterKeyId=2)
2019-11-05 17:15:02 INFO  FileInputFormat:292 - Total input files to process : 3
2019-11-05 17:15:03 INFO  JobSubmitter:202 - number of splits:3
2019-11-05 17:15:03 INFO  deprecation:1394 - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2019-11-05 17:15:03 INFO  JobSubmitter:298 - Submitting tokens for job: job_1572974048799_0001
2019-11-05 17:15:03 INFO  JobSubmitter:299 - Executing with tokens: [Kind: OzoneToken, Service: 172.19.0.10:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1572974102190, maxDate=1573578902190, sequenceNumber=1, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null), Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572974102506, maxDate=1573578902506, sequenceNumber=1, masterKeyId=2)]
2019-11-05 17:15:03 INFO  Configuration:2752 - resource-types.xml not found
2019-11-05 17:15:03 INFO  ResourceUtils:419 - Unable to find 'resource-types.xml'.
2019-11-05 17:15:03 INFO  TimelineClientImpl:129 - Timeline service address: jhs:8188
2019-11-05 17:15:06 INFO  YarnClientImpl:311 - Submitted application application_1572974048799_0001
2019-11-05 17:15:06 INFO  Job:1574 - The url to track the job: http://rm:8088/proxy/application_1572974048799_0001/
2019-11-05 17:15:06 INFO  Job:1619 - Running job: job_1572974048799_0001
2019-11-05 17:15:20 INFO  Job:1640 - Job job_1572974048799_0001 running in uber mode : false
2019-11-05 17:15:20 INFO  Job:1647 -  map 0% reduce 0%
2019-11-05 17:15:26 INFO  Job:1686 - Task Id : attempt_1572974048799_0001_m_000000_1000, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:52)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1962)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1923)
	at org.apache.hadoop.io.SequenceFile$Reader.&lt;init&gt;(SequenceFile.java:1872)
	at org.apache.hadoop.io.SequenceFile$Reader.&lt;init&gt;(SequenceFile.java:1886)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:54)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:560)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:798)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-05 17:15:28 INFO  Job:1647 -  map 33% reduce 0%
2019-11-05 17:15:28 INFO  Job:1686 - Task Id : attempt_1572974048799_0001_m_000002_1000, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-05 17:15:33 INFO  Job:1647 -  map 67% reduce 0%
2019-11-05 17:15:34 INFO  Job:1686 - Task Id : attempt_1572974048799_0001_m_000002_1001, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-05 17:15:41 INFO  Job:1686 - Task Id : attempt_1572974048799_0001_m_000002_1002, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-05 17:15:46 INFO  Job:1647 -  map 67% reduce 22%
2019-11-05 17:15:48 INFO  Job:1647 -  map 100% reduce 22%
2019-11-05 17:15:50 INFO  Job:1647 -  map 100% reduce 100%
2019-11-05 17:15:51 INFO  Job:1658 - Job job_1572974048799_0001 completed successfully
2019-11-05 17:15:52 INFO  Job:1665 - Counters: 55
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=1051369
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=215
		O3FS: Number of read operations=16
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=9
	Job Counters 
		Failed map tasks=4
		Launched map tasks=7
		Launched reduce tasks=1
		Other local map tasks=4
		Rack-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=58998
		Total time spent by all reduces in occupied slots (ms)=37456
		Total time spent by all map tasks (ms)=29499
		Total time spent by all reduce tasks (ms)=18728
		Total vcore-milliseconds taken by all map tasks=29499
		Total vcore-milliseconds taken by all reduce tasks=18728
		Total megabyte-milliseconds taken by all map tasks=60413952
		Total megabyte-milliseconds taken by all reduce tasks=38354944
	Map-Reduce Framework
		Map input records=3
		Map output records=6
		Map output bytes=54
		Map output materialized bytes=84
		Input split bytes=435
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=84
		Reduce input records=6
		Reduce output records=0
		Spilled Records=12
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=722
		CPU time spent (ms)=17360
		Physical memory (bytes) snapshot=2107150336
		Virtual memory (bytes) snapshot=14947983360
		Total committed heap usage (bytes)=6593445888
		Peak Map Physical memory (bytes)=519651328
		Peak Map Virtual memory (bytes)=3758403584
		Peak Reduce Physical memory (bytes)=553783296
		Peak Reduce Virtual memory (bytes)=3731980288
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=97
Job Finished in 50.181 seconds
2019-11-05 17:15:52 ERROR XceiverClientGrpc:335 - Failed to execute command cmdType: GetBlock
traceID: ""
containerID: 3
datanodeUuid: "e175d03f-a4e4-4755-9ca7-ecf84858191b"
getBlock {
  blockID {
    containerID: 3
    localID: 103086433852325899
    blockCommitSequenceId: 161
  }
}
encodedToken: "VAoGaGFkb29wEiJjb25JRDogMyBsb2NJRDogMTAzMDg2NDMzODUyMzI1ODk5GO-13I3kLSIRMTMzMjA4Mzc5NTUzMzg0NTgoASgCKAMoBDCAgICAAY4BAElo6WlcWvBeKdsW_raQwQO4z-OzM3-JWoYqXV9w4taAKgRXnCsATjhUQIjl6bqgpV4PJeB-HvfY5Mi_Y251MyccXBkK7MTPWXZ29oQ8Iia2CljQQ40G7kUSy7HtmvMGLWaUVNcm7S1x1GRffK8g2qmtwKAB4IgZ0VWPcSBxiJI3b56OcxJU84XCvAGv2_ZVHLZuQ_aKY7J3CaAuTCltESOTh4MZWQ9Q4zmu7y7W7nif4HeNMMRLX6BOY3-SfpLJ5JoPVeFaBU87bxKLpy2bW5K3VqUpx8Yr9EGbJcb1zd6lQbXjcQ3SXu8uMkmFgkRmfeaSDhpxM3g4nCi5OwEeqdgQSEREU19CTE9DS19UT0tFTiJjb25JRDogMyBsb2NJRDogMTAzMDg2NDMzODUyMzI1ODk5"
 on datanode e175d03f-a4e4-4755-9ca7-ecf84858191b
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAUTHENTICATED: Fail to find any token (empty or null.)
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:323)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:52)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1962)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1923)
	at org.apache.hadoop.io.SequenceFile$Reader.&lt;init&gt;(SequenceFile.java:1872)
	at org.apache.hadoop.io.SequenceFile$Reader.&lt;init&gt;(SequenceFile.java:1886)
	at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:319)
	at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:360)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:368)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAUTHENTICATED: Fail to find any token (empty or null.)
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:526)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:52)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1962)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1923)
	at org.apache.hadoop.io.SequenceFile$Reader.&lt;init&gt;(SequenceFile.java:1872)
	at org.apache.hadoop.io.SequenceFile$Reader.&lt;init&gt;(SequenceFile.java:1886)
	at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:319)
	at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:360)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:368)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)</msg>
<status status="PASS" endtime="20191105 17:15:52.906" starttime="20191105 17:15:52.904"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191105 17:15:52.906" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<msg timestamp="20191105 17:15:52.907" level="FAIL">255 != 0</msg>
<status status="FAIL" endtime="20191105 17:15:52.907" starttime="20191105 17:15:52.906"></status>
</kw>
<status status="FAIL" endtime="20191105 17:15:52.907" starttime="20191105 17:14:56.695"></status>
</kw>
<timeout value="4 minutes"></timeout>
<status status="FAIL" endtime="20191105 17:15:52.908" critical="yes" starttime="20191105 17:14:56.694">255 != 0</status>
</test>
<test id="s1-t2" name="Execute WordCount">
<kw name="Generate Random String" library="String">
<doc>Generates a string with a desired ``length`` from the given ``chars``.</doc>
<arguments>
<arg>2</arg>
<arg>[NUMBERS]</arg>
</arguments>
<assign>
<var>${random}</var>
</assign>
<msg timestamp="20191105 17:15:52.911" level="INFO">${random} = 89</msg>
<status status="PASS" endtime="20191105 17:15:52.911" starttime="20191105 17:15:52.910"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-${hadoop.version}.jar wordcount o3fs://bucket1.vol1/key1 o3fs://bucket1.vol1/key1-${random}.count</arg>
</arguments>
<assign>
<var>${output}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191105 17:15:52.916" level="INFO">Running command 'yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar wordcount o3fs://bucket1.vol1/key1 o3fs://bucket1.vol1/key1-89.count 2&gt;&amp;1'.</msg>
<msg timestamp="20191105 17:16:38.672" level="INFO">${rc} = 0</msg>
<msg timestamp="20191105 17:16:38.672" level="INFO">${output} = 2019-11-05 17:15:55 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.19.0.6:8032
2019-11-05 17:15:55 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.19.0.3:10200
201...</msg>
<status status="PASS" endtime="20191105 17:16:38.672" starttime="20191105 17:15:52.913"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191105 17:16:38.674" level="INFO">2019-11-05 17:15:55 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.19.0.6:8032
2019-11-05 17:15:55 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.19.0.3:10200
2019-11-05 17:15:55 INFO  KMSClientProvider:1041 - New token created: (Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572974155902, maxDate=1573578955902, sequenceNumber=2, masterKeyId=2))
2019-11-05 17:15:55 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: OzoneToken, Service: 172.19.0.10:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1572974155788, maxDate=1573578955788, sequenceNumber=2, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null)
2019-11-05 17:15:55 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572974155902, maxDate=1573578955902, sequenceNumber=2, masterKeyId=2)
2019-11-05 17:15:55 INFO  JobSubmissionFiles:156 - Permissions on staging directory /user/hadoop/.staging are incorrect: rwxrwxrwx. Fixing permissions to correct value rwx------
2019-11-05 17:15:56 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-05 17:15:56 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-11-05 17:15:56 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
2019-11-05 17:15:57 INFO  FileInputFormat:292 - Total input files to process : 1
2019-11-05 17:15:57 INFO  JobSubmitter:202 - number of splits:1
2019-11-05 17:15:57 INFO  deprecation:1394 - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2019-11-05 17:15:58 INFO  JobSubmitter:298 - Submitting tokens for job: job_1572974048799_0002
2019-11-05 17:15:58 INFO  JobSubmitter:299 - Executing with tokens: [Kind: OzoneToken, Service: 172.19.0.10:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1572974155788, maxDate=1573578955788, sequenceNumber=2, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null), Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572974155902, maxDate=1573578955902, sequenceNumber=2, masterKeyId=2)]
2019-11-05 17:15:58 INFO  Configuration:2752 - resource-types.xml not found
2019-11-05 17:15:58 INFO  ResourceUtils:419 - Unable to find 'resource-types.xml'.
2019-11-05 17:15:58 INFO  TimelineClientImpl:129 - Timeline service address: jhs:8188
2019-11-05 17:15:59 INFO  YarnClientImpl:311 - Submitted application application_1572974048799_0002
2019-11-05 17:15:59 INFO  Job:1574 - The url to track the job: http://rm:8088/proxy/application_1572974048799_0002/
2019-11-05 17:15:59 INFO  Job:1619 - Running job: job_1572974048799_0002
2019-11-05 17:16:09 INFO  Job:1640 - Job job_1572974048799_0002 running in uber mode : false
2019-11-05 17:16:09 INFO  Job:1647 -  map 0% reduce 0%
2019-11-05 17:16:16 INFO  Job:1686 - Task Id : attempt_1572974048799_0002_m_000000_1000, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-05 17:16:22 INFO  Job:1686 - Task Id : attempt_1572974048799_0002_m_000000_1001, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:52)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:218)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:176)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:192)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:568)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-05 17:16:29 INFO  Job:1647 -  map 100% reduce 0%
2019-11-05 17:16:36 INFO  Job:1647 -  map 100% reduce 100%
2019-11-05 17:16:38 INFO  Job:1658 - Job job_1572974048799_0002 completed successfully
2019-11-05 17:16:38 INFO  Job:1665 - Counters: 55
	File System Counters
		FILE: Number of bytes read=15067
		FILE: Number of bytes written=555015
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=11886
		O3FS: Number of read operations=11
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=4
	Job Counters 
		Failed map tasks=2
		Launched map tasks=3
		Launched reduce tasks=1
		Other local map tasks=2
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=26746
		Total time spent by all reduces in occupied slots (ms)=9628
		Total time spent by all map tasks (ms)=13373
		Total time spent by all reduce tasks (ms)=4814
		Total vcore-milliseconds taken by all map tasks=13373
		Total vcore-milliseconds taken by all reduce tasks=4814
		Total megabyte-milliseconds taken by all map tasks=27387904
		Total megabyte-milliseconds taken by all reduce tasks=9859072
	Map-Reduce Framework
		Map input records=443
		Map output records=1884
		Map output bytes=24122
		Map output materialized bytes=15067
		Input split bytes=89
		Combine input records=1884
		Combine output records=801
		Reduce input groups=801
		Reduce shuffle bytes=15067
		Reduce input records=801
		Reduce output records=801
		Spilled Records=1602
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=569
		CPU time spent (ms)=12110
		Physical memory (bytes) snapshot=1101168640
		Virtual memory (bytes) snapshot=7447375872
		Total committed heap usage (bytes)=3287285760
		Peak Map Physical memory (bytes)=521269248
		Peak Map Virtual memory (bytes)=3710185472
		Peak Reduce Physical memory (bytes)=579899392
		Peak Reduce Virtual memory (bytes)=3737190400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=11886</msg>
<status status="PASS" endtime="20191105 17:16:38.674" starttime="20191105 17:16:38.673"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191105 17:16:38.675" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<status status="PASS" endtime="20191105 17:16:38.675" starttime="20191105 17:16:38.674"></status>
</kw>
<msg timestamp="20191105 17:16:38.676" level="INFO">${output} = 2019-11-05 17:15:55 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.19.0.6:8032
2019-11-05 17:15:55 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.19.0.3:10200
201...</msg>
<status status="PASS" endtime="20191105 17:16:38.676" starttime="20191105 17:15:52.912"></status>
</kw>
<kw name="Should Contain" library="BuiltIn">
<doc>Fails if ``container`` does not contain ``item`` one or more times.</doc>
<arguments>
<arg>${output}</arg>
<arg>completed successfully</arg>
</arguments>
<status status="PASS" endtime="20191105 17:16:38.677" starttime="20191105 17:16:38.676"></status>
</kw>
<timeout value="4 minutes"></timeout>
<status status="PASS" endtime="20191105 17:16:38.677" critical="yes" starttime="20191105 17:15:52.908"></status>
</test>
<doc>Execute MR jobs</doc>
<status status="FAIL" endtime="20191105 17:16:38.678" starttime="20191105 17:14:56.643"></status>
</suite>
<statistics>
<total>
<stat fail="1" pass="1">Critical Tests</stat>
<stat fail="1" pass="1">All Tests</stat>
</total>
<tag>
</tag>
<suite>
<stat fail="1" id="s1" name="ozonesecure-mr-mapreduce" pass="1">ozonesecure-mr-mapreduce</stat>
</suite>
</statistics>
<errors>
</errors>
</robot>
