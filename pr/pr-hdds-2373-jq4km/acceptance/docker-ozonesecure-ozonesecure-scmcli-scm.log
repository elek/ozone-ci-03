Attaching to ozonesecure_om_1, ozonesecure_kms_1, ozonesecure_datanode_1, ozonesecure_datanode_3, ozonesecure_datanode_2, ozonesecure_scm_1, ozonesecure_recon_1, ozonesecure_s3g_1, ozonesecure_kdc_1
om_1        | Sleeping for 5 seconds
kms_1       | Sleeping for 5 seconds
om_1        | Setting up kerberos!!
om_1        | KDC ISSUER_SERVER => kdc:8081
kms_1       | Setting up kerberos!!
om_1        | Sleeping for 5 seconds
kms_1       | KDC ISSUER_SERVER => kdc:8081
om_1        | Got 200, KDC service ready!!
kms_1       | /opt/starter.sh: line 66: SLEEP_SECONDS: command not found
datanode_1  | Sleeping for 5 seconds
om_1        | Download dn/om@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
kms_1       | Sleeping for  seconds
datanode_3  | Sleeping for 5 seconds
datanode_1  | Setting up kerberos!!
recon_1     | Sleeping for 5 seconds
kms_1       | Got 200, KDC service ready!!
datanode_1  | KDC ISSUER_SERVER => kdc:8081
datanode_3  | Setting up kerberos!!
om_1        | --2019-10-28 19:29:31--  http://kdc:8081/keytab/om/dn
recon_1     | Waiting for the service om:9874
scm_1       | Sleeping for 5 seconds
kms_1       | Download dn/6045f1ad9083@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_1  | Sleeping for 5 seconds
datanode_3  | KDC ISSUER_SERVER => kdc:8081
om_1        | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Setting up kerberos!!
scm_1       | Setting up kerberos!!
kms_1       | --2019-10-28 19:29:32--  http://kdc:8081/keytab/6045f1ad9083/dn
datanode_1  | Got 200, KDC service ready!!
datanode_3  | Sleeping for 5 seconds
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | KDC ISSUER_SERVER => kdc:8081
scm_1       | KDC ISSUER_SERVER => kdc:8081
datanode_2  | Sleeping for 5 seconds
kms_1       | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Issuer is listening on : 8081krb5kdc: starting...
datanode_1  | Download dn/62d67d27c24f@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_3  | Got 200, KDC service ready!!
om_1        | HTTP request sent, awaiting response... 200 OK
recon_1     | Sleeping for 5 seconds
scm_1       | Sleeping for 5 seconds
datanode_2  | Setting up kerberos!!
s3g_1       | Sleeping for 5 seconds
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | --2019-10-28 19:29:31--  http://kdc:8081/keytab/62d67d27c24f/dn
kdc_1       | kadmind: starting...
datanode_3  | Download dn/c004515c1151@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
om_1        | Length: 138 [application/octet-stream]
recon_1     | Got 200, KDC service ready!!
scm_1       | Got 200, KDC service ready!!
datanode_2  | KDC ISSUER_SERVER => kdc:8081
s3g_1       | Setting up kerberos!!
kms_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | otp: Loaded
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | --2019-10-28 19:29:32--  http://kdc:8081/keytab/c004515c1151/dn
om_1        | Saving to: '/etc/security/keytabs/dn.keytab'
recon_1     | Download dn/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
scm_1       | Download dn/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | Sleeping for 5 seconds
s3g_1       | KDC ISSUER_SERVER => kdc:8081
kms_1       | Length: 158 [application/octet-stream]
kdc_1       | Oct 28 19:29:20 kdc krb5kdc[9](info): setting up network...
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
recon_1     | --2019-10-28 19:29:55--  http://kdc:8081/keytab/recon/dn
om_1        | 
scm_1       | --2019-10-28 19:29:31--  http://kdc:8081/keytab/scm/dn
datanode_2  | Got 200, KDC service ready!!
s3g_1       | Sleeping for 5 seconds
kms_1       | Saving to: '/etc/security/keytabs/dn.keytab'
kdc_1       | krb5kdc: setsockopt(9,IPV6_V6ONLY,1) worked
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | Resolving kdc (kdc)... 172.18.0.2
om_1        |      0K                                                       100% 10.7M=0s
scm_1       | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Download dn/6440263c42ed@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
s3g_1       | Got 200, KDC service ready!!
kms_1       | 
kdc_1       | krb5kdc: setsockopt(11,IPV6_V6ONLY,1) worked
datanode_1  | Length: 158 [application/octet-stream]
datanode_3  | HTTP request sent, awaiting response... 200 OK
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | 
datanode_2  | --2019-10-28 19:29:31--  http://kdc:8081/keytab/6440263c42ed/dn
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | Download dn/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
kdc_1       | Oct 28 19:29:20 kdc krb5kdc[9](info): set up 4 sockets
kms_1       |      0K                                                       100% 15.5M=0s
datanode_1  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_3  | Length: 158 [application/octet-stream]
recon_1     | HTTP request sent, awaiting response... 200 OK
om_1        | 2019-10-28 19:29:31 (10.7 MB/s) - '/etc/security/keytabs/dn.keytab' saved [138/138]
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
scm_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | --2019-10-28 19:29:31--  http://kdc:8081/keytab/s3g/dn
kdc_1       | Oct 28 19:29:20 kdc krb5kdc[9](info): commencing operation
kms_1       | 
datanode_1  | 
datanode_3  | Saving to: '/etc/security/keytabs/dn.keytab'
recon_1     | Length: 144 [application/octet-stream]
om_1        | 
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | Length: 140 [application/octet-stream]
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Oct 28 19:29:02 546d963b16d5 kadmin.local[1](info): No dictionary file specified, continuing without one.
kms_1       | 2019-10-28 19:29:33 (15.5 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_1  |      0K                                                       100% 15.4M=0s
datanode_3  | 
recon_1     | Saving to: '/etc/security/keytabs/dn.keytab'
om_1        | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_2  | HTTP request sent, awaiting response... 200 OK
scm_1       | Saving to: '/etc/security/keytabs/dn.keytab'
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kdc_1       | Oct 28 19:29:04 bf0fa7e42ed3 kadmin.local[1](info): No dictionary file specified, continuing without one.
kms_1       | 
datanode_1  | 
datanode_3  |      0K                                                       100% 13.6M=0s
recon_1     | 
om_1        | KVNO Timestamp         Principal
datanode_2  | Length: 158 [application/octet-stream]
scm_1       | 
s3g_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 28 19:29:24 kdc kadmind[15](info): No dictionary file specified, continuing without one.
kms_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_1  | 2019-10-28 19:29:31 (15.4 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_3  | 
recon_1     |      0K                                                       100% 12.8M=0s
om_1        | ---- ----------------- --------------------------------------------------------
datanode_2  | Saving to: '/etc/security/keytabs/dn.keytab'
s3g_1       | Length: 140 [application/octet-stream]
scm_1       |      0K                                                       100% 18.5M=0s
kdc_1       | Oct 28 19:29:24 kdc kadmind[15](info): setting up network...
kms_1       | KVNO Timestamp         Principal
datanode_1  | 
datanode_3  | 2019-10-28 19:29:33 (13.6 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
recon_1     | 
om_1        |    2 10/28/19 19:29:31 dn/om@EXAMPLE.COM
datanode_2  | 
s3g_1       | Saving to: '/etc/security/keytabs/dn.keytab'
scm_1       | 
kms_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | kadmind: setsockopt(9,IPV6_V6ONLY,1) worked
datanode_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_3  | 
recon_1     | 2019-10-28 19:29:55 (12.8 MB/s) - '/etc/security/keytabs/dn.keytab' saved [144/144]
om_1        |    2 10/28/19 19:29:31 dn/om@EXAMPLE.COM
datanode_2  |      0K                                                       100% 12.2M=0s
s3g_1       | 
scm_1       | 2019-10-28 19:29:31 (18.5 MB/s) - '/etc/security/keytabs/dn.keytab' saved [140/140]
kdc_1       | kadmind: setsockopt(11,IPV6_V6ONLY,1) worked
kms_1       |    2 10/28/19 19:29:33 dn/6045f1ad9083@EXAMPLE.COM
datanode_1  | KVNO Timestamp         Principal
datanode_3  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
recon_1     | 
om_1        | Download om/om@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_2  | 
s3g_1       |      0K                                                       100% 19.5M=0s
scm_1       | 
kdc_1       | kadmind: setsockopt(13,IPV6_V6ONLY,1) worked
kms_1       |    2 10/28/19 19:29:33 dn/6045f1ad9083@EXAMPLE.COM
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_3  | KVNO Timestamp         Principal
recon_1     | Keytab name: FILE:/etc/security/keytabs/dn.keytab
om_1        | --2019-10-28 19:29:31--  http://kdc:8081/keytab/om/om
datanode_2  | 2019-10-28 19:29:31 (12.2 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
s3g_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
kdc_1       | Oct 28 19:29:24 kdc kadmind[15](info): set up 6 sockets
kms_1       | Download om/6045f1ad9083@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_1  |    2 10/28/19 19:29:31 dn/62d67d27c24f@EXAMPLE.COM
datanode_3  | ---- ----------------- --------------------------------------------------------
recon_1     | KVNO Timestamp         Principal
om_1        | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | 
s3g_1       | 2019-10-28 19:29:31 (19.5 MB/s) - '/etc/security/keytabs/dn.keytab' saved [140/140]
scm_1       | KVNO Timestamp         Principal
kdc_1       | Oct 28 19:29:24 kdc kadmind[15](info): Seeding random number generator
kms_1       | --2019-10-28 19:29:33--  http://kdc:8081/keytab/6045f1ad9083/om
datanode_1  |    2 10/28/19 19:29:31 dn/62d67d27c24f@EXAMPLE.COM
datanode_3  |    2 10/28/19 19:29:33 dn/c004515c1151@EXAMPLE.COM
recon_1     | ---- ----------------- --------------------------------------------------------
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
s3g_1       | 
kdc_1       | Oct 28 19:29:24 kdc kadmind[15](info): starting
scm_1       | ---- ----------------- --------------------------------------------------------
kms_1       | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Download om/62d67d27c24f@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_3  |    2 10/28/19 19:29:33 dn/c004515c1151@EXAMPLE.COM
recon_1     |    2 10/28/19 19:29:55 dn/recon@EXAMPLE.COM
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_2  | KVNO Timestamp         Principal
s3g_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
kdc_1       | Generiting keytab
scm_1       |    2 10/28/19 19:29:31 dn/scm@EXAMPLE.COM
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | --2019-10-28 19:29:31--  http://kdc:8081/keytab/62d67d27c24f/om
datanode_3  | Download om/c004515c1151@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
recon_1     |    2 10/28/19 19:29:55 dn/recon@EXAMPLE.COM
om_1        | Length: 138 [application/octet-stream]
datanode_2  | ---- ----------------- --------------------------------------------------------
s3g_1       | KVNO Timestamp         Principal
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       |    2 10/28/19 19:29:31 dn/scm@EXAMPLE.COM
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | --2019-10-28 19:29:33--  http://kdc:8081/keytab/c004515c1151/om
recon_1     | Download om/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_2  |    2 10/28/19 19:29:31 dn/6440263c42ed@EXAMPLE.COM
s3g_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
scm_1       | Download om/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
kms_1       | Length: 158 [application/octet-stream]
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
om_1        | Saving to: '/etc/security/keytabs/om.keytab'
recon_1     | --2019-10-28 19:29:55--  http://kdc:8081/keytab/recon/om
datanode_2  |    2 10/28/19 19:29:31 dn/6440263c42ed@EXAMPLE.COM
s3g_1       |    2 10/28/19 19:29:31 dn/s3g@EXAMPLE.COM
kdc_1       | Principal "test/test@EXAMPLE.COM" created.
scm_1       | --2019-10-28 19:29:31--  http://kdc:8081/keytab/scm/om
kms_1       | Saving to: '/etc/security/keytabs/om.keytab'
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | 
recon_1     | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Download om/6440263c42ed@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
s3g_1       |    2 10/28/19 19:29:31 dn/s3g@EXAMPLE.COM
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | Resolving kdc (kdc)... 172.18.0.2
kms_1       | 
datanode_1  | Length: 158 [application/octet-stream]
datanode_3  | HTTP request sent, awaiting response... 200 OK
om_1        |      0K                                                       100% 10.9M=0s
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | --2019-10-28 19:29:31--  http://kdc:8081/keytab/6440263c42ed/om
s3g_1       | Download om/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | Saving to: '/etc/security/keytabs/om.keytab'
om_1        | 
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
recon_1     | HTTP request sent, awaiting response... 200 OK
kms_1       |      0K                                                       100% 17.9M=0s
datanode_3  | Length: 158 [application/octet-stream]
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | --2019-10-28 19:29:31--  http://kdc:8081/keytab/s3g/om
scm_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  | 
om_1        | 2019-10-28 19:29:33 (10.9 MB/s) - '/etc/security/keytabs/om.keytab' saved [138/138]
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kms_1       | 
recon_1     | Length: 144 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/om.keytab'
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Length: 140 [application/octet-stream]
datanode_1  |      0K                                                       100% 11.5M=0s
om_1        | 
kdc_1       | Generiting keytab
kms_1       | 2019-10-28 19:29:34 (17.9 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
recon_1     | Saving to: '/etc/security/keytabs/om.keytab'
datanode_3  | 
datanode_2  | HTTP request sent, awaiting response... 200 OK
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | Saving to: '/etc/security/keytabs/om.keytab'
om_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 
kms_1       | 
recon_1     | 
datanode_3  |      0K                                                       100% 15.6M=0s
datanode_2  | Length: 158 [application/octet-stream]
s3g_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | 
om_1        | KVNO Timestamp         Principal
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-28 19:29:32 (11.5 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
recon_1     |      0K                                                       100% 15.2M=0s
datanode_3  | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_2  | Saving to: '/etc/security/keytabs/om.keytab'
s3g_1       | Length: 140 [application/octet-stream]
scm_1       |      0K                                                       100% 10.7M=0s
om_1        | ---- ----------------- --------------------------------------------------------
kdc_1       | add_principal: Principal or policy already exists while creating "test/test@EXAMPLE.COM".
datanode_1  | 
recon_1     | 
datanode_3  | 2019-10-28 19:29:34 (15.6 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
kms_1       | KVNO Timestamp         Principal
datanode_2  | 
s3g_1       | Saving to: '/etc/security/keytabs/om.keytab'
scm_1       | 
om_1        |    2 10/28/19 19:29:33 om/om@EXAMPLE.COM
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | Keytab name: FILE:/etc/security/keytabs/om.keytab
recon_1     | 2019-10-28 19:29:55 (15.2 MB/s) - '/etc/security/keytabs/om.keytab' saved [144/144]
datanode_3  | 
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_2  |      0K                                                       100% 14.8M=0s
s3g_1       | 
scm_1       | 2019-10-28 19:29:32 (10.7 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
om_1        |    2 10/28/19 19:29:33 om/om@EXAMPLE.COM
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 3, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
datanode_1  | KVNO Timestamp         Principal
recon_1     | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_2  | 
s3g_1       |      0K                                                       100% 7.28M=0s
om_1        | Download scm/om@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
scm_1       | 
kms_1       |    2 10/28/19 19:29:34 om/6045f1ad9083@EXAMPLE.COM
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 3, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
datanode_1  | ---- ----------------- --------------------------------------------------------
recon_1     | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_2  | 2019-10-28 19:29:32 (14.8 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
s3g_1       | 
om_1        | --2019-10-28 19:29:33--  http://kdc:8081/keytab/om/scm
scm_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
kms_1       |    2 10/28/19 19:29:34 om/6045f1ad9083@EXAMPLE.COM
kdc_1       | Generiting keytab
datanode_1  |    2 10/28/19 19:29:32 om/62d67d27c24f@EXAMPLE.COM
recon_1     | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_2  | 
s3g_1       | 2019-10-28 19:29:33 (7.28 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
om_1        | Resolving kdc (kdc)... 172.18.0.2
scm_1       | KVNO Timestamp         Principal
kms_1       | Download scm/6045f1ad9083@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_1  |    2 10/28/19 19:29:32 om/62d67d27c24f@EXAMPLE.COM
recon_1     | ---- ----------------- --------------------------------------------------------
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  |    2 10/28/19 19:29:34 om/c004515c1151@EXAMPLE.COM
datanode_2  | Keytab name: FILE:/etc/security/keytabs/om.keytab
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | 
scm_1       | ---- ----------------- --------------------------------------------------------
kms_1       | --2019-10-28 19:29:34--  http://kdc:8081/keytab/6045f1ad9083/scm
datanode_1  | Download scm/62d67d27c24f@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
recon_1     |    2 10/28/19 19:29:55 om/recon@EXAMPLE.COM
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
datanode_3  |    2 10/28/19 19:29:34 om/c004515c1151@EXAMPLE.COM
datanode_2  | KVNO Timestamp         Principal
om_1        | HTTP request sent, awaiting response... 200 OK
s3g_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
scm_1       |    2 10/28/19 19:29:32 om/scm@EXAMPLE.COM
kms_1       | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | --2019-10-28 19:29:32--  http://kdc:8081/keytab/62d67d27c24f/scm
kdc_1       | add_principal: Principal or policy already exists while creating "test/test@EXAMPLE.COM".
recon_1     |    2 10/28/19 19:29:55 om/recon@EXAMPLE.COM
datanode_3  | Download scm/c004515c1151@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_2  | ---- ----------------- --------------------------------------------------------
om_1        | Length: 140 [application/octet-stream]
s3g_1       | KVNO Timestamp         Principal
scm_1       |    2 10/28/19 19:29:32 om/scm@EXAMPLE.COM
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | Download scm/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_3  | --2019-10-28 19:29:34--  http://kdc:8081/keytab/c004515c1151/scm
datanode_2  |    2 10/28/19 19:29:32 om/6440263c42ed@EXAMPLE.COM
om_1        | Saving to: '/etc/security/keytabs/scm.keytab'
s3g_1       | ---- ----------------- --------------------------------------------------------
scm_1       | Download scm/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 4, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
recon_1     | --2019-10-28 19:29:55--  http://kdc:8081/keytab/recon/scm
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  |    2 10/28/19 19:29:32 om/6440263c42ed@EXAMPLE.COM
om_1        | 
s3g_1       |    2 10/28/19 19:29:33 om/s3g@EXAMPLE.COM
scm_1       | --2019-10-28 19:29:32--  http://kdc:8081/keytab/scm/scm
kms_1       | Length: 160 [application/octet-stream]
datanode_1  | HTTP request sent, awaiting response... 200 OK
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 4, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
recon_1     | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | Download scm/6440263c42ed@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
om_1        |      0K                                                       100% 18.1M=0s
s3g_1       |    2 10/28/19 19:29:33 om/s3g@EXAMPLE.COM
scm_1       | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_1  | Length: 160 [application/octet-stream]
kdc_1       | Generiting keytab
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | --2019-10-28 19:29:32--  http://kdc:8081/keytab/6440263c42ed/scm
datanode_3  | HTTP request sent, awaiting response... 200 OK
om_1        | 
s3g_1       | Download scm/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | 
datanode_1  | Saving to: '/etc/security/keytabs/scm.keytab'
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | Length: 160 [application/octet-stream]
om_1        | 2019-10-28 19:29:34 (18.1 MB/s) - '/etc/security/keytabs/scm.keytab' saved [140/140]
s3g_1       | --2019-10-28 19:29:33--  http://kdc:8081/keytab/s3g/scm
scm_1       | HTTP request sent, awaiting response... 200 OK
kms_1       |      0K                                                       100% 18.2M=0s
datanode_1  | 
kdc_1       | WARNING: no policy specified for dn/6440263c42ed@EXAMPLE.COM; defaulting to no policy
recon_1     | Length: 146 [application/octet-stream]
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Saving to: '/etc/security/keytabs/scm.keytab'
om_1        | 
scm_1       | Length: 142 [application/octet-stream]
datanode_1  |      0K                                                       100% 12.2M=0s
kms_1       | 
kdc_1       | Principal "dn/6440263c42ed@EXAMPLE.COM" created.
recon_1     | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_3  | 
om_1        | Keytab name: FILE:/etc/security/keytabs/scm.keytab
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Saving to: '/etc/security/keytabs/scm.keytab'
kms_1       | 2019-10-28 19:29:35 (18.2 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | 
datanode_1  | 
datanode_2  | Length: 160 [application/octet-stream]
datanode_3  |      0K                                                       100% 8.93M=0s
om_1        | KVNO Timestamp         Principal
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | 
kms_1       | 
kdc_1       | Entry for principal dn/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.6440263c42ed.keytab.
recon_1     |      0K                                                       100% 14.8M=0s
datanode_1  | 2019-10-28 19:29:33 (12.2 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
datanode_2  | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_3  | 
om_1        | ---- ----------------- --------------------------------------------------------
s3g_1       | HTTP request sent, awaiting response... 200 OK
scm_1       |      0K                                                       100% 10.6M=0s
kms_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
kdc_1       | Entry for principal dn/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.6440263c42ed.keytab.
recon_1     | 
datanode_1  | 
datanode_2  | 
datanode_3  | 2019-10-28 19:29:35 (8.93 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
om_1        |    2 10/28/19 19:29:34 scm/om@EXAMPLE.COM
s3g_1       | Length: 142 [application/octet-stream]
scm_1       | 
kms_1       | KVNO Timestamp         Principal
kms_1       | ---- ----------------- --------------------------------------------------------
kms_1       |    2 10/28/19 19:29:35 scm/6045f1ad9083@EXAMPLE.COM
kdc_1       | Generiting keytab
datanode_2  |      0K                                                       100% 15.4M=0s
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_1  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_1  | KVNO Timestamp         Principal
scm_1       | 2019-10-28 19:29:33 (10.6 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
kms_1       |    2 10/28/19 19:29:35 scm/6045f1ad9083@EXAMPLE.COM
kms_1       | Download HTTP/6045f1ad9083@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 
datanode_2  | 2019-10-28 19:29:33 (15.4 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
datanode_3  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
scm_1       | 
recon_1     | 2019-10-28 19:29:55 (14.8 MB/s) - '/etc/security/keytabs/scm.keytab' saved [146/146]
kms_1       | --2019-10-28 19:29:35--  http://kdc:8081/keytab/6045f1ad9083/HTTP
s3g_1       | Saving to: '/etc/security/keytabs/scm.keytab'
s3g_1       | 
kdc_1       | WARNING: no policy specified for dn/62d67d27c24f@EXAMPLE.COM; defaulting to no policy
om_1        |    2 10/28/19 19:29:34 scm/om@EXAMPLE.COM
datanode_2  | 
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 10/28/19 19:29:33 scm/62d67d27c24f@EXAMPLE.COM
scm_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
recon_1     | 
kms_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       |      0K                                                       100% 9.18M=0s
s3g_1       | 
kdc_1       | Principal "dn/62d67d27c24f@EXAMPLE.COM" created.
om_1        | Download HTTP/om@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_2  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_3  |    2 10/28/19 19:29:35 scm/c004515c1151@EXAMPLE.COM
datanode_1  |    2 10/28/19 19:29:33 scm/62d67d27c24f@EXAMPLE.COM
scm_1       | KVNO Timestamp         Principal
recon_1     | Keytab name: FILE:/etc/security/keytabs/scm.keytab
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | 2019-10-28 19:29:34 (9.18 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | --2019-10-28 19:29:34--  http://kdc:8081/keytab/om/HTTP
datanode_2  | KVNO Timestamp         Principal
datanode_3  |    2 10/28/19 19:29:35 scm/c004515c1151@EXAMPLE.COM
scm_1       | ---- ----------------- --------------------------------------------------------
kms_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | 
kdc_1       | Entry for principal dn/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.62d67d27c24f.keytab.
datanode_1  | Download HTTP/62d67d27c24f@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om_1        | Resolving kdc (kdc)... 172.18.0.2
recon_1     | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_3  | Download HTTP/c004515c1151@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1       |    2 10/28/19 19:29:33 scm/scm@EXAMPLE.COM
kms_1       | Length: 162 [application/octet-stream]
s3g_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
kdc_1       | Entry for principal dn/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.62d67d27c24f.keytab.
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_1  | --2019-10-28 19:29:33--  http://kdc:8081/keytab/62d67d27c24f/HTTP
datanode_2  |    2 10/28/19 19:29:33 scm/6440263c42ed@EXAMPLE.COM
scm_1       |    2 10/28/19 19:29:33 scm/scm@EXAMPLE.COM
datanode_3  | --2019-10-28 19:29:35--  http://kdc:8081/keytab/c004515c1151/HTTP
kms_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1       | KVNO Timestamp         Principal
kdc_1       | Generiting keytab
om_1        | HTTP request sent, awaiting response... 200 OK
recon_1     |    2 10/28/19 19:29:55 scm/recon@EXAMPLE.COM
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  |    2 10/28/19 19:29:33 scm/6440263c42ed@EXAMPLE.COM
scm_1       | Download HTTP/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
kms_1       | 
s3g_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | Length: 142 [application/octet-stream]
recon_1     |    2 10/28/19 19:29:55 scm/recon@EXAMPLE.COM
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | Download HTTP/6440263c42ed@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1       | --2019-10-28 19:29:33--  http://kdc:8081/keytab/scm/HTTP
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       |      0K                                                       100% 13.1M=0s
s3g_1       |    2 10/28/19 19:29:33 scm/s3g@EXAMPLE.COM
kdc_1       | WARNING: no policy specified for dn/scm@EXAMPLE.COM; defaulting to no policy
om_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
recon_1     | Download HTTP/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_2  | --2019-10-28 19:29:33--  http://kdc:8081/keytab/6440263c42ed/HTTP
scm_1       | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | HTTP request sent, awaiting response... 200 OK
kms_1       | 
kdc_1       | Principal "dn/scm@EXAMPLE.COM" created.
om_1        | 
recon_1     | --2019-10-28 19:29:55--  http://kdc:8081/keytab/recon/HTTP
s3g_1       |    2 10/28/19 19:29:33 scm/s3g@EXAMPLE.COM
datanode_1  | Length: 162 [application/octet-stream]
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Length: 162 [application/octet-stream]
kms_1       | 2019-10-28 19:29:36 (13.1 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        |      0K                                                       100% 6.79M=0s
scm_1       | HTTP request sent, awaiting response... 200 OK
datanode_3  | Saving to: '/etc/security/keytabs/HTTP.keytab'
kms_1       | 
kdc_1       | Entry for principal dn/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.scm.keytab.
s3g_1       | Download HTTP/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | 
datanode_2  | HTTP request sent, awaiting response... 200 OK
om_1        | 
scm_1       | Length: 144 [application/octet-stream]
datanode_3  | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
kdc_1       | Entry for principal dn/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.scm.keytab.
s3g_1       | --2019-10-28 19:29:34--  http://kdc:8081/keytab/s3g/HTTP
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_1  |      0K                                                       100% 13.5M=0s
datanode_2  | Length: 162 [application/octet-stream]
om_1        | 2019-10-28 19:29:35 (6.79 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [142/142]
scm_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_3  |      0K                                                       100% 13.7M=0s
kms_1       | KVNO Timestamp         Principal
kdc_1       | Generiting keytab
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Length: 148 [application/octet-stream]
datanode_1  | 
datanode_2  | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        | 
scm_1       | 
datanode_3  | 
kms_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_1  | 2019-10-28 19:29:34 (13.5 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_2  | 
om_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
scm_1       |      0K                                                       100% 10.6M=0s
kms_1       |    2 10/28/19 19:29:35 HTTP/6045f1ad9083@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:35 (13.7 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
kdc_1       | WARNING: no policy specified for dn/s3g@EXAMPLE.COM; defaulting to no policy
s3g_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | 
datanode_1  | 
datanode_2  |      0K                                                       100% 11.8M=0s
om_1        | KVNO Timestamp         Principal
scm_1       | 
kms_1       |    2 10/28/19 19:29:36 HTTP/6045f1ad9083@EXAMPLE.COM
datanode_3  | 
kdc_1       | Principal "dn/s3g@EXAMPLE.COM" created.
s3g_1       | Length: 144 [application/octet-stream]
datanode_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_2  | 
om_1        | ---- ----------------- --------------------------------------------------------
scm_1       | 2019-10-28 19:29:34 (10.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
kms_1       | Download testuser/6045f1ad9083@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
recon_1     |      0K                                                       100% 15.5M=0s
datanode_3  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_1  | KVNO Timestamp         Principal
datanode_2  | 2019-10-28 19:29:34 (11.8 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
om_1        |    2 10/28/19 19:29:35 HTTP/om@EXAMPLE.COM
scm_1       | 
recon_1     | 
datanode_3  | KVNO Timestamp         Principal
kms_1       | --2019-10-28 19:29:36--  http://kdc:8081/keytab/6045f1ad9083/testuser
s3g_1       | 
kdc_1       | Entry for principal dn/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.s3g.keytab.
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_2  | 
om_1        |    2 10/28/19 19:29:35 HTTP/om@EXAMPLE.COM
datanode_3  | ---- ----------------- --------------------------------------------------------
kms_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       |      0K                                                       100% 11.0M=0s
scm_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
kdc_1       | Entry for principal dn/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.s3g.keytab.
datanode_2  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_1  |    2 10/28/19 19:29:34 HTTP/62d67d27c24f@EXAMPLE.COM
om_1        | Download testuser/om@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
recon_1     | 2019-10-28 19:29:56 (15.5 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [148/148]
datanode_3  |    2 10/28/19 19:29:35 HTTP/c004515c1151@EXAMPLE.COM
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | 
kdc_1       | Generiting keytab
datanode_2  | KVNO Timestamp         Principal
scm_1       | KVNO Timestamp         Principal
datanode_1  |    2 10/28/19 19:29:34 HTTP/62d67d27c24f@EXAMPLE.COM
om_1        | --2019-10-28 19:29:35--  http://kdc:8081/keytab/om/testuser
recon_1     | 
datanode_3  |    2 10/28/19 19:29:35 HTTP/c004515c1151@EXAMPLE.COM
kms_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | 2019-10-28 19:29:34 (11.0 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | ---- ----------------- --------------------------------------------------------
scm_1       | ---- ----------------- --------------------------------------------------------
om_1        | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_1  | Download testuser/62d67d27c24f@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_3  | Download testuser/c004515c1151@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
kms_1       | Length: 170 [application/octet-stream]
s3g_1       | 
kdc_1       | WARNING: no policy specified for dn/om@EXAMPLE.COM; defaulting to no policy
datanode_2  |    2 10/28/19 19:29:34 HTTP/6440263c42ed@EXAMPLE.COM
scm_1       |    2 10/28/19 19:29:34 HTTP/scm@EXAMPLE.COM
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | KVNO Timestamp         Principal
datanode_1  | --2019-10-28 19:29:34--  http://kdc:8081/keytab/62d67d27c24f/testuser
datanode_3  | --2019-10-28 19:29:35--  http://kdc:8081/keytab/c004515c1151/testuser
kms_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
kdc_1       | Principal "dn/om@EXAMPLE.COM" created.
datanode_2  |    2 10/28/19 19:29:34 HTTP/6440263c42ed@EXAMPLE.COM
scm_1       |    2 10/28/19 19:29:34 HTTP/scm@EXAMPLE.COM
om_1        | HTTP request sent, awaiting response... 200 OK
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
kms_1       | 
s3g_1       | KVNO Timestamp         Principal
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | Download testuser/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
om_1        | Length: 150 [application/octet-stream]
recon_1     |    2 10/28/19 19:29:56 HTTP/recon@EXAMPLE.COM
datanode_2  | Download testuser/6440263c42ed@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | ---- ----------------- --------------------------------------------------------
kms_1       |      0K                                                       100% 13.0M=0s
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | --2019-10-28 19:29:34--  http://kdc:8081/keytab/scm/testuser
om_1        | Saving to: '/etc/security/keytabs/testuser.keytab'
recon_1     |    2 10/28/19 19:29:56 HTTP/recon@EXAMPLE.COM
datanode_2  | --2019-10-28 19:29:34--  http://kdc:8081/keytab/6440263c42ed/testuser
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_3  | HTTP request sent, awaiting response... 200 OK
s3g_1       |    2 10/28/19 19:29:34 HTTP/s3g@EXAMPLE.COM
kms_1       | 
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | Resolving kdc (kdc)... 172.18.0.2
om_1        | 
recon_1     | Download testuser/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Length: 170 [application/octet-stream]
datanode_3  | Length: 170 [application/octet-stream]
s3g_1       |    2 10/28/19 19:29:34 HTTP/s3g@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kms_1       | 2019-10-28 19:29:36 (13.0 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        |      0K                                                       100% 20.5M=0s
recon_1     | --2019-10-28 19:29:56--  http://kdc:8081/keytab/recon/testuser
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1       | Download testuser/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | Saving to: '/etc/security/keytabs/testuser.keytab'
kms_1       | 
scm_1       | HTTP request sent, awaiting response... 200 OK
om_1        | 
recon_1     | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_1  | 
s3g_1       | --2019-10-28 19:29:34--  http://kdc:8081/keytab/s3g/testuser
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
scm_1       | Length: 152 [application/octet-stream]
om_1        | 2019-10-28 19:29:35 (20.5 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [150/150]
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | Length: 170 [application/octet-stream]
datanode_1  |      0K                                                       100% 13.1M=0s
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  |      0K                                                       100% 13.7M=0s
kms_1       | KVNO Timestamp         Principal
scm_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
om_1        | 
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_2  | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_1  | 
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | 
kms_1       | ---- ----------------- --------------------------------------------------------
om_1        | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
recon_1     | Length: 156 [application/octet-stream]
datanode_2  | 
datanode_1  | 2019-10-28 19:29:35 (13.1 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
scm_1       | 
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | HTTP request sent, awaiting response... 200 OK
datanode_3  | 2019-10-28 19:29:36 (13.7 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
kms_1       |    2 10/28/19 19:29:36 testuser/6045f1ad9083@EXAMPLE.COM
om_1        | KVNO Timestamp         Principal
recon_1     | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_2  |      0K                                                       100% 9.47M=0s
datanode_1  | 
scm_1       |      0K                                                       100% 8.36M=0s
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 
kms_1       |    2 10/28/19 19:29:36 testuser/6045f1ad9083@EXAMPLE.COM
om_1        | ---- ----------------- --------------------------------------------------------
s3g_1       | Length: 152 [application/octet-stream]
recon_1     | 
datanode_2  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
scm_1       | 
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
kms_1       | Download testuser2/6045f1ad9083@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
om_1        |    2 10/28/19 19:29:35 testuser/om@EXAMPLE.COM
s3g_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
recon_1     |      0K                                                       100% 17.3M=0s
datanode_2  | 2019-10-28 19:29:35 (9.47 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
datanode_1  | KVNO Timestamp         Principal
scm_1       | 2019-10-28 19:29:35 (8.36 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | KVNO Timestamp         Principal
kms_1       | --2019-10-28 19:29:36--  http://kdc:8081/keytab/6045f1ad9083/testuser2
om_1        |    2 10/28/19 19:29:35 testuser/om@EXAMPLE.COM
s3g_1       | 
recon_1     | 
datanode_2  | 
datanode_1  | ---- ----------------- --------------------------------------------------------
scm_1       | 
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | ---- ----------------- --------------------------------------------------------
kms_1       | Resolving kdc (kdc)... 172.18.0.2
om_1        | Download testuser2/om@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
s3g_1       |      0K                                                       100% 13.8M=0s
recon_1     | 2019-10-28 19:29:56 (17.3 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [156/156]
datanode_1  |    2 10/28/19 19:29:35 testuser/62d67d27c24f@EXAMPLE.COM
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  |    2 10/28/19 19:29:36 testuser/c004515c1151@EXAMPLE.COM
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | --2019-10-28 19:29:35--  http://kdc:8081/keytab/om/testuser2
s3g_1       | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
recon_1     | 
scm_1       | KVNO Timestamp         Principal
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  |    2 10/28/19 19:29:36 testuser/c004515c1151@EXAMPLE.COM
kms_1       | HTTP request sent, awaiting response... 200 OK
om_1        | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | 2019-10-28 19:29:35 (13.8 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
datanode_2  | KVNO Timestamp         Principal
datanode_1  |    2 10/28/19 19:29:35 testuser/62d67d27c24f@EXAMPLE.COM
recon_1     | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | Download testuser2/c004515c1151@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
kms_1       | Length: 172 [application/octet-stream]
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | 
datanode_2  | ---- ----------------- --------------------------------------------------------
recon_1     | KVNO Timestamp         Principal
datanode_1  | Download testuser2/62d67d27c24f@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | --2019-10-28 19:29:36--  http://kdc:8081/keytab/c004515c1151/testuser2
kms_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_2  |    2 10/28/19 19:29:35 testuser/6440263c42ed@EXAMPLE.COM
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_1  | --2019-10-28 19:29:35--  http://kdc:8081/keytab/62d67d27c24f/testuser2
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
kms_1       | 
om_1        | Length: 152 [application/octet-stream]
datanode_2  |    2 10/28/19 19:29:35 testuser/6440263c42ed@EXAMPLE.COM
s3g_1       | KVNO Timestamp         Principal
scm_1       |    2 10/28/19 19:29:35 testuser/scm@EXAMPLE.COM
recon_1     |    2 10/28/19 19:29:56 testuser/recon@EXAMPLE.COM
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       |      0K                                                       100% 2.17M=0s
om_1        | Saving to: '/etc/security/keytabs/testuser2.keytab'
s3g_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | Download testuser2/6440263c42ed@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       |    2 10/28/19 19:29:35 testuser/scm@EXAMPLE.COM
recon_1     |    2 10/28/19 19:29:56 testuser/recon@EXAMPLE.COM
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | HTTP request sent, awaiting response... 200 OK
kms_1       | 
om_1        | 
datanode_2  | --2019-10-28 19:29:35--  http://kdc:8081/keytab/6440263c42ed/testuser2
s3g_1       |    2 10/28/19 19:29:35 testuser/s3g@EXAMPLE.COM
scm_1       | Download testuser2/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
recon_1     | Download testuser2/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_1  | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kms_1       | 2019-10-28 19:29:37 (2.17 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
datanode_3  | Length: 172 [application/octet-stream]
om_1        |      0K                                                       100% 6.45M=0s
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
scm_1       | --2019-10-28 19:29:35--  http://kdc:8081/keytab/scm/testuser2
s3g_1       |    2 10/28/19 19:29:35 testuser/s3g@EXAMPLE.COM
recon_1     | --2019-10-28 19:29:56--  http://kdc:8081/keytab/recon/testuser2
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | Length: 172 [application/octet-stream]
kms_1       | 
datanode_3  | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | 
scm_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Download testuser2/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
recon_1     | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | Saving to: '/etc/security/keytabs/testuser2.keytab'
kms_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_3  | 
datanode_2  | HTTP request sent, awaiting response... 200 OK
om_1        | 2019-10-28 19:29:36 (6.45 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [152/152]
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | --2019-10-28 19:29:35--  http://kdc:8081/keytab/s3g/testuser2
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | 
kms_1       | KVNO Timestamp         Principal
datanode_3  |      0K                                                       100% 15.2M=0s
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | Length: 172 [application/octet-stream]
om_1        | 
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
recon_1     | HTTP request sent, awaiting response... 200 OK
scm_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  |      0K                                                       100% 14.4M=0s
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_3  | 
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | Saving to: '/etc/security/keytabs/testuser2.keytab'
om_1        | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | Length: 158 [application/octet-stream]
scm_1       | Length: 154 [application/octet-stream]
datanode_1  | 
kms_1       |    2 10/28/19 19:29:37 testuser2/6045f1ad9083@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:37 (15.2 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 
om_1        | KVNO Timestamp         Principal
s3g_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | Saving to: '/etc/security/keytabs/testuser2.keytab'
scm_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
kms_1       |    2 10/28/19 19:29:37 testuser2/6045f1ad9083@EXAMPLE.COM
datanode_3  | 
datanode_1  | 2019-10-28 19:29:36 (14.4 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  |      0K                                                       100% 10.7M=0s
s3g_1       | Length: 154 [application/octet-stream]
om_1        | ---- ----------------- --------------------------------------------------------
recon_1     | 
scm_1       | 
kms_1       | Download s3g/6045f1ad9083@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_3  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_1  | 
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 
s3g_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
om_1        |    2 10/28/19 19:29:36 testuser2/om@EXAMPLE.COM
recon_1     |      0K                                                       100% 12.7M=0s
scm_1       |      0K                                                       100% 11.2M=0s
kms_1       | --2019-10-28 19:29:37--  http://kdc:8081/keytab/6045f1ad9083/s3g
datanode_3  | KVNO Timestamp         Principal
datanode_1  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-28 19:29:36 (10.7 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
s3g_1       | 
om_1        |    2 10/28/19 19:29:36 testuser2/om@EXAMPLE.COM
recon_1     | 
scm_1       | 
kms_1       | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_1  | KVNO Timestamp         Principal
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 
s3g_1       |      0K                                                       100% 12.3M=0s
om_1        | Download s3g/om@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
recon_1     | 2019-10-28 19:29:56 (12.7 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [158/158]
scm_1       | 2019-10-28 19:29:36 (11.2 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
datanode_3  |    2 10/28/19 19:29:37 testuser2/c004515c1151@EXAMPLE.COM
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | ---- ----------------- --------------------------------------------------------
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
s3g_1       | 
om_1        | --2019-10-28 19:29:36--  http://kdc:8081/keytab/om/s3g
recon_1     | 
scm_1       | 
datanode_3  |    2 10/28/19 19:29:37 testuser2/c004515c1151@EXAMPLE.COM
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  |    2 10/28/19 19:29:36 testuser2/62d67d27c24f@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | KVNO Timestamp         Principal
s3g_1       | 2019-10-28 19:29:36 (12.3 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
om_1        | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_3  | Download s3g/c004515c1151@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kms_1       | Length: 160 [application/octet-stream]
datanode_1  |    2 10/28/19 19:29:36 testuser2/62d67d27c24f@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | ---- ----------------- --------------------------------------------------------
s3g_1       | 
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | KVNO Timestamp         Principal
scm_1       | KVNO Timestamp         Principal
datanode_3  | --2019-10-28 19:29:37--  http://kdc:8081/keytab/c004515c1151/s3g
kms_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_1  | Download s3g/62d67d27c24f@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  |    2 10/28/19 19:29:36 testuser2/6440263c42ed@EXAMPLE.COM
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
om_1        | HTTP request sent, awaiting response... 200 OK
recon_1     | ---- ----------------- --------------------------------------------------------
scm_1       | ---- ----------------- --------------------------------------------------------
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | --2019-10-28 19:29:36--  http://kdc:8081/keytab/62d67d27c24f/s3g
kms_1       | 
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  |    2 10/28/19 19:29:36 testuser2/6440263c42ed@EXAMPLE.COM
s3g_1       | KVNO Timestamp         Principal
om_1        | Length: 140 [application/octet-stream]
recon_1     |    2 10/28/19 19:29:56 testuser2/recon@EXAMPLE.COM
scm_1       |    2 10/28/19 19:29:36 testuser2/scm@EXAMPLE.COM
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
kms_1       |      0K                                                       100% 14.9M=0s
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | Download s3g/6440263c42ed@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
s3g_1       | ---- ----------------- --------------------------------------------------------
om_1        | Saving to: '/etc/security/keytabs/s3g.keytab'
recon_1     |    2 10/28/19 19:29:56 testuser2/recon@EXAMPLE.COM
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | 
scm_1       |    2 10/28/19 19:29:36 testuser2/scm@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | --2019-10-28 19:29:36--  http://kdc:8081/keytab/6440263c42ed/s3g
s3g_1       |    2 10/28/19 19:29:36 testuser2/s3g@EXAMPLE.COM
om_1        | 
datanode_3  | Length: 160 [application/octet-stream]
recon_1     | Download s3g/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_1  | HTTP request sent, awaiting response... 200 OK
kms_1       | 2019-10-28 19:29:38 (14.9 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
scm_1       | Download s3g/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
s3g_1       |    2 10/28/19 19:29:36 testuser2/s3g@EXAMPLE.COM
om_1        |      0K                                                       100% 12.9M=0s
datanode_3  | Saving to: '/etc/security/keytabs/s3g.keytab'
recon_1     | --2019-10-28 19:29:56--  http://kdc:8081/keytab/recon/s3g
kms_1       | 
datanode_1  | Length: 160 [application/octet-stream]
scm_1       | --2019-10-28 19:29:36--  http://kdc:8081/keytab/scm/s3g
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | Download s3g/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 
datanode_3  | 
recon_1     | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_1  | Saving to: '/etc/security/keytabs/s3g.keytab'
scm_1       | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | HTTP request sent, awaiting response... 200 OK
s3g_1       | --2019-10-28 19:29:36--  http://kdc:8081/keytab/s3g/s3g
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:29:37 (12.9 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [140/140]
datanode_3  |      0K                                                       100% 14.8M=0s
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | KVNO Timestamp         Principal
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | 
datanode_2  | Length: 160 [application/octet-stream]
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 
datanode_3  | 
recon_1     | HTTP request sent, awaiting response... 200 OK
kms_1       | ---- ----------------- --------------------------------------------------------
scm_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  |      0K                                                       100% 17.2M=0s
datanode_2  | Saving to: '/etc/security/keytabs/s3g.keytab'
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
om_1        | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_3  | 2019-10-28 19:29:37 (14.8 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
recon_1     | Length: 146 [application/octet-stream]
kms_1       |    2 10/28/19 19:29:38 s3g/6045f1ad9083@EXAMPLE.COM
scm_1       | Length: 142 [application/octet-stream]
datanode_1  | 
datanode_2  | 
s3g_1       | HTTP request sent, awaiting response... 200 OK
om_1        | KVNO Timestamp         Principal
datanode_3  | 
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
recon_1     | Saving to: '/etc/security/keytabs/s3g.keytab'
kms_1       |    2 10/28/19 19:29:38 s3g/6045f1ad9083@EXAMPLE.COM
scm_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_1  | 2019-10-28 19:29:37 (17.2 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
datanode_2  |      0K                                                       100% 9.16M=0s
s3g_1       | Length: 142 [application/octet-stream]
om_1        | ---- ----------------- --------------------------------------------------------
datanode_3  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 
kms_1       | # Licensed to the Apache Software Foundation (ASF) under one or more
scm_1       | 
datanode_1  | 
datanode_2  | 
s3g_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
om_1        |    2 10/28/19 19:29:37 s3g/om@EXAMPLE.COM
datanode_3  | KVNO Timestamp         Principal
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, Principal or policy already exists, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     |      0K                                                       100% 13.3M=0s
kms_1       | # contributor license agreements.  See the NOTICE file distributed with
scm_1       |      0K                                                       100% 10.5M=0s
datanode_1  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_2  | 2019-10-28 19:29:36 (9.16 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
s3g_1       | 
om_1        |    2 10/28/19 19:29:37 s3g/om@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
datanode_3  | ---- ----------------- --------------------------------------------------------
recon_1     | 
kms_1       | # this work for additional information regarding copyright ownership.
scm_1       | 
datanode_1  | KVNO Timestamp         Principal
datanode_2  | 
s3g_1       |      0K                                                       100% 10.3M=0s
om_1        | 2019-10-28 19:29:39,046 [main] INFO       - STARTUP_MSG: 
datanode_3  |    2 10/28/19 19:29:37 s3g/c004515c1151@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
recon_1     | 2019-10-28 19:29:56 (13.3 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [146/146]
kms_1       | # The ASF licenses this file to You under the Apache License, Version 2.0
scm_1       | 2019-10-28 19:29:37 (10.5 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_2  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
s3g_1       | 
om_1        | /************************************************************
datanode_3  |    2 10/28/19 19:29:37 s3g/c004515c1151@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 
kms_1       | # (the "License"); you may not use this file except in compliance with
scm_1       | 
datanode_1  |    2 10/28/19 19:29:36 s3g/62d67d27c24f@EXAMPLE.COM
datanode_2  | KVNO Timestamp         Principal
om_1        | STARTUP_MSG: Starting OzoneManager
s3g_1       | 2019-10-28 19:29:37 (10.3 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
datanode_3  | 2019-10-28 19:29:39,762 [main] INFO       - STARTUP_MSG: 
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kms_1       | # the License.  You may obtain a copy of the License at
scm_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_1  |    2 10/28/19 19:29:36 s3g/62d67d27c24f@EXAMPLE.COM
datanode_2  | ---- ----------------- --------------------------------------------------------
om_1        | STARTUP_MSG:   host = om/172.18.0.10
s3g_1       | 
datanode_3  | /************************************************************
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
recon_1     | KVNO Timestamp         Principal
kms_1       | #
scm_1       | KVNO Timestamp         Principal
datanode_1  | 2019-10-28 19:29:37,989 [main] INFO       - STARTUP_MSG: 
datanode_2  |    2 10/28/19 19:29:36 s3g/6440263c42ed@EXAMPLE.COM
s3g_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
om_1        | STARTUP_MSG:   args = [--init]
recon_1     | ---- ----------------- --------------------------------------------------------
kms_1       | #     http://www.apache.org/licenses/LICENSE-2.0
scm_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | /************************************************************
datanode_2  |    2 10/28/19 19:29:36 s3g/6440263c42ed@EXAMPLE.COM
s3g_1       | KVNO Timestamp         Principal
datanode_3  | STARTUP_MSG:   host = c004515c1151/172.18.0.7
om_1        | STARTUP_MSG:   version = 3.2.0
kms_1       | #
scm_1       |    2 10/28/19 19:29:37 s3g/scm@EXAMPLE.COM
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
recon_1     |    2 10/28/19 19:29:56 s3g/recon@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:37,838 [main] INFO       - STARTUP_MSG: 
datanode_3  | STARTUP_MSG:   args = []
s3g_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | # Unless required by applicable law or agreed to in writing, software
scm_1       |    2 10/28/19 19:29:37 s3g/scm@EXAMPLE.COM
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   host = 62d67d27c24f/172.18.0.8
recon_1     |    2 10/28/19 19:29:56 s3g/recon@EXAMPLE.COM
datanode_3  | STARTUP_MSG:   version = 3.2.0
s3g_1       |    2 10/28/19 19:29:37 s3g/s3g@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, Principal or policy already exists, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | # distributed under the License is distributed on an "AS IS" BASIS,
scm_1       | 2019-10-28 19:29:38,363 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | STARTUP_MSG:   args = []
datanode_2  | /************************************************************
recon_1     | WARNING: An illegal reflective access operation has occurred
s3g_1       |    2 10/28/19 19:29:37 s3g/s3g@EXAMPLE.COM
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
kms_1       | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
scm_1       | /************************************************************
om_1        | STARTUP_MSG:   java = 11.0.3
datanode_1  | STARTUP_MSG:   version = 3.2.0
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
s3g_1       | WARNING: An illegal reflective access operation has occurred
kms_1       | # See the License for the specific language governing permissions and
scm_1       | STARTUP_MSG: Starting StorageContainerManager
om_1        | ************************************************************/
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   host = 6440263c42ed/172.18.0.6
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | STARTUP_MSG:   java = 11.0.3
s3g_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
kms_1       | # limitations under the License.
om_1        | 2019-10-28 19:29:39,062 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   host = scm/172.18.0.5
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3  | ************************************************************/
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
kms_1       | 
om_1        | 2019-10-28 19:29:40,226 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.10:9862
datanode_2  | STARTUP_MSG:   version = 3.2.0
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
scm_1       | STARTUP_MSG:   args = [--init]
datanode_1  | STARTUP_MSG:   java = 11.0.3
datanode_3  | 2019-10-28 19:29:39,785 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | 2019-10-28 19:29:40,227 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
recon_1     | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kms_1       | [logging]
scm_1       | STARTUP_MSG:   version = 3.2.0
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_3  | 2019-10-28 19:29:40,203 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2019-10-28 19:29:57,705 [main] INFO       - rest([/api/*]).packages(org.apache.hadoop.ozone.recon.api)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       |  default = FILE:/var/log/krb5libs.log
datanode_3  | 2019-10-28 19:29:40,452 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | ************************************************************/
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
s3g_1       | 2019-10-28 19:29:38,534 INFO hdfs.DFSUtil: Starting web server as: HTTP/s3g@EXAMPLE.COM
recon_1     | 2019-10-28 19:29:57,924 [main] INFO       - Initializing Recon server...
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       |  kdc = FILE:/var/log/krb5kdc.log
datanode_3  | 2019-10-28 19:29:40,452 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2  | STARTUP_MSG:   java = 11.0.3
datanode_1  | 2019-10-28 19:29:38,613 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
s3g_1       | 2019-10-28 19:29:38,535 INFO hdfs.DFSUtil: Starting Web-server for s3gateway at: http://0.0.0.0:9878
recon_1     | 2019-10-28 19:29:58,093 [main] ERROR      - Error during initializing Recon server.
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
kms_1       |  admin_server = FILE:/var/log/kadmind.log
scm_1       | STARTUP_MSG:   java = 11.0.3
datanode_3  | 2019-10-28 19:29:40,667 [main] INFO       - HddsDatanodeService host:c004515c1151 ip:172.18.0.7
datanode_2  | ************************************************************/
datanode_1  | 2019-10-28 19:29:38,877 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | java.sql.SQLException: path to '//data/metadata/recon/ozone_recon_sqlite.db': '/data/metadata' does not exist
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | ************************************************************/
kms_1       | 
s3g_1       | 2019-10-28 19:29:38,577 INFO util.log: Logging initialized @1239ms
datanode_3  | 2019-10-28 19:29:40,970 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_2  | 2019-10-28 19:29:37,854 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | WARNING: All illegal access operations will be denied in a future release
datanode_1  | 2019-10-28 19:29:39,071 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 	at org.sqlite.SQLiteConnection.open(SQLiteConnection.java:215)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:29:38,374 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
kms_1       | [libdefaults]
datanode_3  | WARNING: An illegal reflective access operation has occurred
datanode_2  | 2019-10-28 19:29:38,101 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2019-10-28 19:29:40,513 INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
s3g_1       | 2019-10-28 19:29:38,706 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2019-10-28 19:29:39,072 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
recon_1     | 	at org.sqlite.SQLiteConnection.<init>(SQLiteConnection.java:61)
scm_1       | 2019-10-28 19:29:38,602 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       |  dns_canonicalize_hostname = false
datanode_3  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
datanode_2  | 2019-10-28 19:29:38,233 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2019-10-28 19:29:40,513 [main] INFO       - Ozone Manager login successful.
s3g_1       | 2019-10-28 19:29:38,732 INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
datanode_1  | 2019-10-28 19:29:39,367 [main] INFO       - HddsDatanodeService host:62d67d27c24f ip:172.18.0.8
recon_1     | 	at org.sqlite.jdbc3.JDBC3Connection.<init>(JDBC3Connection.java:28)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
kms_1       |  dns_lookup_realm = false
scm_1       | SCM initialization succeeded.Current cluster id for sd=/data/metadata/scm;cid=CID-3f296440-b871-48c1-acbd-fb06c21acfc1
datanode_3  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_2  | 2019-10-28 19:29:38,233 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
om_1        | 2019-10-28 19:29:40,518 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 2019-10-28 19:29:38,741 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2019-10-28 19:29:39,739 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
recon_1     | 	at org.sqlite.jdbc4.JDBC4Connection.<init>(JDBC4Connection.java:21)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kms_1       |  ticket_lifetime = 24h
scm_1       | 2019-10-28 19:29:38,749 INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_3  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  | 2019-10-28 19:29:38,673 [main] INFO       - HddsDatanodeService host:6440263c42ed ip:172.18.0.6
om_1        | 2019-10-28 19:29:41,806 INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1       | 2019-10-28 19:29:38,743 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
datanode_1  | WARNING: An illegal reflective access operation has occurred
recon_1     | 	at org.sqlite.JDBC.createConnection(JDBC.java:116)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       |  renew_lifetime = 7d
scm_1       | /************************************************************
datanode_3  | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2019-10-28 19:29:38,979 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
om_1        | 2019-10-28 19:29:42,808 INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1       | 2019-10-28 19:29:38,743 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
recon_1     | 	at org.sqlite.SQLiteDataSource.getConnection(SQLiteDataSource.java:410)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       |  forwardable = true
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.5
datanode_3  | 2019-10-28 19:29:41,211 INFO security.UserGroupInformation: Login successful for user dn/c004515c1151@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
om_1        | 2019-10-28 19:29:43,809 INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2  | WARNING: An illegal reflective access operation has occurred
s3g_1       | 2019-10-28 19:29:38,743 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 	at org.sqlite.SQLiteDataSource.getConnection(SQLiteDataSource.java:398)
datanode_1  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
kms_1       |  rdns = false
scm_1       | ************************************************************/
datanode_3  | 2019-10-28 19:29:41,211 [main] INFO       - Hdds Datanode login successful.
om_1        | 2019-10-28 19:29:44,191 [main] INFO       - Initializing secure OzoneManager.
datanode_2  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
recon_1     | 	at org.hadoop.ozone.recon.schema.StatsSchemaDefinition.initializeSchema(StatsSchemaDefinition.java:44)
datanode_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 2019-10-28 19:29:38,761 [main] INFO       - Starting Ozone S3 gateway
kms_1       |  default_realm = EXAMPLE.COM
scm_1       | 2019-10-28 19:29:40,078 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_3  | 2019-10-28 19:29:41,212 [main] INFO       - Initializing secure Datanode.
om_1        | 2019-10-28 19:29:44,666 ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_2  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:78)
datanode_1  | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-28 19:29:38,771 INFO http.HttpServer2: Jetty bound to port 9878
kms_1       | 
scm_1       | /************************************************************
om_1        | 2019-10-28 19:29:44,666 INFO client.OMCertificateClient: Certificate client init case: 0
datanode_3  | 2019-10-28 19:29:41,212 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_2  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:41)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-28 19:29:38,772 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_1  | 2019-10-28 19:29:40,053 [main] INFO       - Hdds Datanode login successful.
kms_1       | [realms]
scm_1       | STARTUP_MSG: Starting StorageContainerManager
om_1        | 2019-10-28 19:29:44,666 INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_3  | 2019-10-28 19:29:41,212 INFO client.DNCertificateClient: Certificate client init case: 0
datanode_2  | WARNING: All illegal access operations will be denied in a future release
recon_1     | 	at picocli.CommandLine.execute(CommandLine.java:1173)
s3g_1       | 2019-10-28 19:29:38,813 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2019-10-28 19:29:40,053 INFO security.UserGroupInformation: Login successful for user dn/62d67d27c24f@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
scm_1       | STARTUP_MSG:   host = scm/172.18.0.5
kms_1       |  EXAMPLE.COM = {
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:29:45,057 [main] INFO       - Init response: GETCERT
datanode_2  | 2019-10-28 19:29:39,311 INFO security.UserGroupInformation: Login successful for user dn/6440263c42ed@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
s3g_1       | 2019-10-28 19:29:38,826 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
recon_1     | 	at picocli.CommandLine.access$800(CommandLine.java:141)
datanode_3  | 2019-10-28 19:29:41,214 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_1  | 2019-10-28 19:29:40,054 [main] INFO       - Initializing secure Datanode.
kms_1       |   kdc = kdc
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | STARTUP_MSG:   args = []
om_1        | 2019-10-28 19:29:45,087 [main] INFO       - Adding ip:172.18.0.10,host:om
datanode_2  | 2019-10-28 19:29:39,311 [main] INFO       - Hdds Datanode login successful.
s3g_1       | 2019-10-28 19:29:38,873 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61710c6{/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367)
datanode_3  | 2019-10-28 19:29:41,614 [main] INFO       - Init response: GETCERT
datanode_1  | 2019-10-28 19:29:40,054 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
kms_1       |   admin_server = kdc
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:29:45,088 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
datanode_2  | 2019-10-28 19:29:39,311 [main] INFO       - Initializing secure Datanode.
s3g_1       | 2019-10-28 19:29:38,874 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5f9edf14{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | STARTUP_MSG:   version = 3.2.0
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335)
datanode_3  | 2019-10-28 19:29:41,654 [main] INFO       - Adding ip:172.18.0.7,host:c004515c1151
datanode_1  | 2019-10-28 19:29:40,054 INFO client.DNCertificateClient: Certificate client init case: 0
kms_1       |  }
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:29:45,095 [main] INFO       - Creating csr for OM->dns:om,ip:172.18.0.10,scmId:fc49795a-ffa1-4d49-bd6c-474754bf6216,clusterId:CID-3f296440-b871-48c1-acbd-fb06c21acfc1,subject:root@om
datanode_2  | 2019-10-28 19:29:39,312 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
recon_1     | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243)
datanode_3  | 2019-10-28 19:29:41,655 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
datanode_1  | 2019-10-28 19:29:40,055 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
kms_1       | 
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:29:45,221 [main] INFO       - OzoneManager ports added:[name: "RPC"
datanode_2  | 2019-10-28 19:29:39,312 INFO client.DNCertificateClient: Certificate client init case: 0
s3g_1       | 2019-10-28 19:29:41,067 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
recon_1     | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526)
datanode_3  | 2019-10-28 19:29:41,661 [main] INFO       - Creating csr for DN-> subject:root@c004515c1151
datanode_1  | 2019-10-28 19:29:40,570 [main] INFO       - Init response: GETCERT
kms_1       | [domain_realm]
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | value: 9862
datanode_2  | 2019-10-28 19:29:39,313 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
s3g_1       | Oct 28, 2019 7:29:41 PM org.glassfish.jersey.internal.Errors logErrors
scm_1       | STARTUP_MSG:   java = 11.0.3
recon_1     | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465)
datanode_3  | 2019-10-28 19:29:42,857 INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-28 19:29:40,581 [main] INFO       - Adding ip:172.18.0.8,host:62d67d27c24f
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       |  .example.com = EXAMPLE.COM
om_1        | ]
datanode_2  | 2019-10-28 19:29:39,963 [main] INFO       - Init response: GETCERT
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
scm_1       | ************************************************************/
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65)
datanode_1  | 2019-10-28 19:29:40,581 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
om_1        | 2019-10-28 19:29:45,306 [main] INFO       - Successfully stored SCM signed certificate.
datanode_2  | 2019-10-28 19:29:39,977 [main] INFO       - Adding ip:172.18.0.6,host:6440263c42ed
datanode_3  | 2019-10-28 19:29:44,332 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
s3g_1       | 
scm_1       | 2019-10-28 19:29:40,086 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56)
datanode_1  | 2019-10-28 19:29:40,586 [main] INFO       - Creating csr for DN-> subject:root@62d67d27c24f
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
kms_1       | WARNING: /opt/hadoop/logs does not exist. Creating.
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-3f296440-b871-48c1-acbd-fb06c21acfc1
datanode_2  | 2019-10-28 19:29:39,980 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
datanode_3  | 2019-10-28 19:29:44,537 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
s3g_1       | 2019-10-28 19:29:41,935 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6af5b246{/,file:///tmp/jetty-0.0.0.0-9878-s3gateway-_-any-16342006876655930008.dir/webapp/,AVAILABLE}{/s3gateway}
scm_1       | 2019-10-28 19:29:40,364 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:52)
datanode_1  | 2019-10-28 19:29:41,811 INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kms_1       | Oct 28, 2019 7:29:40 PM com.sun.jersey.api.core.PackagesResourceConfig init
om_1        | 2019-10-28 19:29:45,378 [shutdown-hook-0] INFO       - SHUTDOWN_MSG: 
datanode_2  | 2019-10-28 19:29:39,991 [main] INFO       - Creating csr for DN-> subject:root@6440263c42ed
datanode_3  | 2019-10-28 19:29:44,540 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
s3g_1       | 2019-10-28 19:29:41,941 INFO server.AbstractConnector: Started ServerConnector@1a1ccaaf{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
scm_1       | WARNING: An illegal reflective access operation has occurred
recon_1     | 2019-10-28 19:29:58,096 [main] INFO       - Stopping Recon server
datanode_1  | 2019-10-28 19:29:42,812 INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | INFO: Scanning for root resource and provider classes in the packages:
om_1        | /************************************************************
datanode_2  | 2019-10-28 19:29:41,217 INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-28 19:29:44,551 [main] INFO       - Scheduling a check for /data/hdds/hdds
s3g_1       | 2019-10-28 19:29:41,941 INFO server.Server: Started @4606ms
scm_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
recon_1     | java.lang.NullPointerException
datanode_1  | 2019-10-28 19:29:44,487 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       |   org.apache.hadoop.crypto.key.kms.server
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.18.0.10
datanode_2  | 2019-10-28 19:29:42,218 INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-10-28 19:29:44,578 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
s3g_1       | 2019-10-28 19:29:41,944 INFO server.BaseHttpServer: HTTP server of S3GATEWAY is listening at http://0.0.0.0:9878
scm_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.stop(ReconServer.java:115)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
kms_1       | Oct 28, 2019 7:29:41 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
datanode_1  | 2019-10-28 19:29:44,558 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
om_1        | ************************************************************/
datanode_2  | 2019-10-28 19:29:44,482 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
s3g_1       | 2019-10-28 19:36:47,752 [qtp262445056-111] INFO       - Location is /bucket-test123
datanode_3  | 2019-10-28 19:29:45,045 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:100)
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kms_1       | INFO: Root resource classes found:
datanode_1  | 2019-10-28 19:29:44,561 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
om_1        | 2019-10-28 19:29:46,325 [main] INFO       - STARTUP_MSG: 
datanode_2  | 2019-10-28 19:29:44,567 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
s3g_1       | 2019-10-28 19:36:51,260 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-28 19:29:45,071 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
scm_1       | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMS
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:41)
datanode_1  | 2019-10-28 19:29:44,571 [main] INFO       - Scheduling a check for /data/hdds/hdds
om_1        | /************************************************************
datanode_2  | 2019-10-28 19:29:44,569 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
s3g_1       | 20191028T193651Z
datanode_3  | 2019-10-28 19:29:45,138 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
scm_1       | 2019-10-28 19:29:40,675 INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | Oct 28, 2019 7:29:41 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
recon_1     | 	at picocli.CommandLine.execute(CommandLine.java:1173)
datanode_1  | 2019-10-28 19:29:44,596 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
om_1        | STARTUP_MSG: Starting OzoneManager
datanode_2  | 2019-10-28 19:29:44,578 [main] INFO       - Scheduling a check for /data/hdds/hdds
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_3  | 2019-10-28 19:29:45,139 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
scm_1       | 2019-10-28 19:29:40,675 INFO server.StorageContainerManager: SCM login successful.
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
kms_1       | INFO: Provider classes found:
recon_1     | 	at picocli.CommandLine.access$800(CommandLine.java:141)
datanode_1  | 2019-10-28 19:29:45,014 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | STARTUP_MSG:   host = om/172.18.0.10
datanode_2  | 2019-10-28 19:29:44,596 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-28 19:29:45,140 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-28 19:29:40,677 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367)
datanode_1  | 2019-10-28 19:29:45,051 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2019-10-28 19:29:44,969 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | STARTUP_MSG:   args = []
s3g_1       | 2019-10-28 19:36:51,270 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-28 19:29:45,141 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1       | 2019-10-28 19:29:40,706 INFO util.log: Logging initialized @1781ms
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-28 19:29:45,113 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335)
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
datanode_2  | 2019-10-28 19:29:44,995 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om_1        | STARTUP_MSG:   version = 3.2.0
s3g_1       | 20191028T193651Z
datanode_3  | 2019-10-28 19:29:45,141 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-28 19:29:40,814 INFO db.DBStoreBuilder: using custom profile for table: deletedBlocks
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-28 19:29:45,114 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
recon_1     | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243)
datanode_2  | 2019-10-28 19:29:45,059 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_3  | 2019-10-28 19:29:45,295 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2019-10-28 19:29:40,814 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedBlocks
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
datanode_1  | 2019-10-28 19:29:45,115 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526)
datanode_2  | 2019-10-28 19:29:45,060 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_3  | 2019-10-28 19:29:45,378 INFO hdfs.DFSUtil: Starting web server as: HTTP/c004515c1151@EXAMPLE.COM
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kms_1       | Oct 28, 2019 7:29:41 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
scm_1       | 2019-10-28 19:29:40,814 INFO db.DBStoreBuilder: using custom profile for table: validCerts
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
kdc_1       | Entry for principal dn/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.om.keytab.
datanode_1  | 2019-10-28 19:29:45,116 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
recon_1     | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465)
datanode_2  | 2019-10-28 19:29:45,062 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-28 19:29:45,378 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
s3g_1       | 2019-10-28 19:36:51,271 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kms_1       | INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
scm_1       | 2019-10-28 19:29:40,814 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:validCerts
datanode_1  | 2019-10-28 19:29:45,117 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
kdc_1       | Entry for principal dn/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.om.keytab.
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65)
datanode_2  | 2019-10-28 19:29:45,062 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_3  | 2019-10-28 19:29:45,406 INFO util.log: Logging initialized @6624ms
s3g_1       | 20191028T193651Z
scm_1       | 2019-10-28 19:29:40,815 INFO db.DBStoreBuilder: using custom profile for table: revokedCerts
kdc_1       | Generiting keytab
om_1        | STARTUP_MSG:   java = 11.0.3
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56)
datanode_2  | 2019-10-28 19:29:45,063 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_3  | 2019-10-28 19:29:45,489 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 20191028/us-west-1/s3/aws4_request
scm_1       | 2019-10-28 19:29:40,815 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:revokedCerts
datanode_1  | 2019-10-28 19:29:45,260 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-28 19:29:45,341 INFO hdfs.DFSUtil: Starting web server as: HTTP/62d67d27c24f@EXAMPLE.COM
om_1        | ************************************************************/
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:52)
datanode_2  | 2019-10-28 19:29:45,220 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-28 19:29:45,492 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
scm_1       | 2019-10-28 19:29:40,824 INFO db.DBStoreBuilder: using custom profile for table: default
kdc_1       | WARNING: no policy specified for om/6440263c42ed@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-28 19:29:45,341 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
om_1        | 2019-10-28 19:29:46,337 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2019-10-28 19:29:45,298 INFO hdfs.DFSUtil: Starting web server as: HTTP/6440263c42ed@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:45,499 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2019-10-28 19:36:51,276 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-28 19:29:40,824 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
kdc_1       | Principal "om/6440263c42ed@EXAMPLE.COM" created.
om_1        | 2019-10-28 19:29:47,267 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.10:9862
datanode_1  | 2019-10-28 19:29:45,368 INFO util.log: Logging initialized @8178ms
datanode_2  | 2019-10-28 19:29:45,298 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2019-10-28 19:29:45,502 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
s3g_1       | 20191028T193651Z
scm_1       | 2019-10-28 19:29:40,825 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-28 19:29:47,268 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
datanode_1  | 2019-10-28 19:29:45,449 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-10-28 19:29:45,507 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_2  | 2019-10-28 19:29:45,318 INFO util.log: Logging initialized @8290ms
s3g_1       | 20191028/us-west-1/s3/aws4_request
scm_1       | 2019-10-28 19:29:42,057 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
kdc_1       | Entry for principal om/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.6440263c42ed.keytab.
om_1        | 2019-10-28 19:29:47,273 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-28 19:29:45,452 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2019-10-28 19:29:45,507 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2019-10-28 19:29:45,402 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-28 19:29:42,080 INFO ipc.Server: Starting Socket Reader #1 for port 9961
datanode_1  | 2019-10-28 19:29:45,458 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2019-10-28 19:29:45,527 INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2019-10-28 19:29:45,405 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
kdc_1       | Entry for principal om/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.6440263c42ed.keytab.
s3g_1       | 2019-10-28 19:36:51,276 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-28 19:29:42,148 INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@4a1c0752
om_1        | WARNING: An illegal reflective access operation has occurred
datanode_1  | 2019-10-28 19:29:45,459 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3  | 2019-10-28 19:29:45,528 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2  | 2019-10-28 19:29:45,412 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
s3g_1       | 20191028T193651Z
scm_1       | 2019-10-28 19:29:42,149 INFO net.NodeSchemaLoader: Loading network topology layer schema file
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
kdc_1       | Generiting keytab
datanode_1  | 2019-10-28 19:29:45,459 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2019-10-28 19:29:45,413 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
s3g_1       | 20191028/us-west-1/s3/aws4_request
scm_1       | 2019-10-28 19:29:42,211 INFO node.SCMNodeManager: Entering startup safe mode.
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-28 19:29:45,558 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-10-28 19:29:45,414 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
scm_1       | 2019-10-28 19:29:42,313 INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
kdc_1       | WARNING: no policy specified for om/62d67d27c24f@EXAMPLE.COM; defaulting to no policy
datanode_3  | 2019-10-28 19:29:45,560 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/c004515c1151@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:45,459 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_2  | 2019-10-28 19:29:45,414 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1       | 2019-10-28 19:36:51,285 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Principal "om/62d67d27c24f@EXAMPLE.COM" created.
scm_1       | 2019-10-28 19:29:42,324 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-28 19:29:45,481 INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2019-10-28 19:29:45,567 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1c628f6a{/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 20191028T193651Z
om_1        | 2019-10-28 19:29:47,458 INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:29:42,695 INFO pipeline.SCMPipelineManager: No pipeline exists in current db
datanode_2  | 2019-10-28 19:29:45,433 INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2019-10-28 19:29:45,483 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_3  | 2019-10-28 19:29:45,569 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1e12a5a6{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2019-10-28 19:29:47,459 [main] INFO       - Ozone Manager login successful.
kdc_1       | Entry for principal om/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.62d67d27c24f.keytab.
scm_1       | 2019-10-28 19:29:42,698 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2019-10-28 19:29:45,434 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_1  | 2019-10-28 19:29:45,512 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-28 19:29:45,643 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/c004515c1151@EXAMPLE.COM
kdc_1       | Entry for principal om/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.62d67d27c24f.keytab.
scm_1       | 2019-10-28 19:29:42,822 WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
om_1        | 2019-10-28 19:29:47,459 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-28 19:29:45,513 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/62d67d27c24f@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:45,461 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-10-28 19:29:45,647 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7cff3f1d{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-4374467664925495606.dir/webapp/,AVAILABLE}{/hddsDatanode}
kdc_1       | Generiting keytab
scm_1       | 2019-10-28 19:29:43,186 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2019-10-28 19:29:48,252 INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
datanode_1  | 2019-10-28 19:29:45,516 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7bee8621{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2019-10-28 19:29:45,463 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/6440263c42ed@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:45,652 INFO server.AbstractConnector: Started ServerConnector@5f08fe00{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
s3g_1       | 2019-10-28 19:36:51,285 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:29:43,187 INFO ipc.Server: Starting Socket Reader #1 for port 9861
om_1        | 2019-10-28 19:29:48,370 INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
datanode_1  | 2019-10-28 19:29:45,516 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10a18e3e{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2019-10-28 19:29:45,465 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@51d0ec6f{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2019-10-28 19:29:45,652 INFO server.Server: Started @6869ms
kdc_1       | WARNING: no policy specified for om/scm@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-28 19:29:43,232 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | 20191028T193651Z
om_1        | 2019-10-28 19:29:48,374 INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/11489940697318319.crt.
datanode_1  | 2019-10-28 19:29:45,579 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/62d67d27c24f@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:45,466 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64ae105d{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2019-10-28 19:29:45,654 INFO impl.MetricsSinkAdapter: Sink prometheus started
kdc_1       | Principal "om/scm@EXAMPLE.COM" created.
scm_1       | 2019-10-28 19:29:43,233 INFO ipc.Server: Starting Socket Reader #1 for port 9863
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:29:48,396 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-28 19:29:45,583 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@510689af{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-8678684060982159073.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_2  | 2019-10-28 19:29:45,521 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/6440263c42ed@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:45,654 INFO impl.MetricsSystemImpl: Registered sink prometheus
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:29:43,273 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
om_1        | 2019-10-28 19:29:48,419 INFO util.log: Logging initialized @2873ms
datanode_2  | 2019-10-28 19:29:45,525 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3daf03d8{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-8388479719876910234.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_1  | 2019-10-28 19:29:45,588 INFO server.AbstractConnector: Started ServerConnector@9df564f{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2019-10-28 19:29:45,656 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
kdc_1       | Entry for principal om/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.scm.keytab.
scm_1       | 2019-10-28 19:29:43,274 INFO ipc.Server: Starting Socket Reader #1 for port 9860
s3g_1       | 2019-10-28 19:36:51,292 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:29:48,498 INFO db.DBStoreBuilder: using custom profile for table: userTable
datanode_2  | 2019-10-28 19:29:45,530 INFO server.AbstractConnector: Started ServerConnector@377949f1{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2019-10-28 19:29:45,588 INFO server.Server: Started @8398ms
datanode_3  | 2019-10-28 19:29:45,669 INFO util.JvmPauseMonitor: Starting JVM pause monitor
kdc_1       | Entry for principal om/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.scm.keytab.
scm_1       | 2019-10-28 19:29:43,333 INFO hdfs.DFSUtil: Starting web server as: HTTP/scm@EXAMPLE.COM
s3g_1       | 20191028T193651Z
om_1        | 2019-10-28 19:29:48,498 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:userTable
datanode_1  | 2019-10-28 19:29:45,590 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2019-10-28 19:29:47,780 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
kdc_1       | Generiting keytab
scm_1       | 2019-10-28 19:29:43,333 INFO hdfs.DFSUtil: Starting Web-server for scm at: http://0.0.0.0:9876
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_2  | 2019-10-28 19:29:45,531 INFO server.Server: Started @8502ms
om_1        | 2019-10-28 19:29:48,498 INFO db.DBStoreBuilder: using custom profile for table: volumeTable
datanode_1  | 2019-10-28 19:29:45,590 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2019-10-28 19:29:47,782 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:29:43,443 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-10-28 19:29:45,535 INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:29:48,498 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:volumeTable
scm_1       | 2019-10-28 19:29:43,455 INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
kdc_1       | WARNING: no policy specified for om/s3g@EXAMPLE.COM; defaulting to no policy
datanode_3  | 2019-10-28 19:29:47,782 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 3951fc6b-1099-4c08-a0e2-d476327ac902 at port 9858
datanode_2  | 2019-10-28 19:29:45,535 INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1       | 2019-10-28 19:36:51,293 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:29:48,498 INFO db.DBStoreBuilder: using custom profile for table: bucketTable
datanode_1  | 2019-10-28 19:29:45,592 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
scm_1       | 2019-10-28 19:29:43,462 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
kdc_1       | Principal "om/s3g@EXAMPLE.COM" created.
datanode_2  | 2019-10-28 19:29:45,537 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
s3g_1       | 20191028T193651Z
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:bucketTable
datanode_1  | 2019-10-28 19:29:45,606 INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2019-10-28 19:29:43,464 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
datanode_2  | 2019-10-28 19:29:45,575 INFO util.JvmPauseMonitor: Starting JVM pause monitor
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-28 19:29:47,804 INFO impl.RaftServerProxy: 3951fc6b-1099-4c08-a0e2-d476327ac902: start RPC server
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: using custom profile for table: keyTable
datanode_1  | 2019-10-28 19:29:47,736 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
scm_1       | 2019-10-28 19:29:43,464 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
datanode_3  | 2019-10-28 19:29:48,008 INFO server.GrpcService: 3951fc6b-1099-4c08-a0e2-d476327ac902: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2019-10-28 19:29:47,702 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:keyTable
scm_1       | 2019-10-28 19:29:43,464 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:51,430 INFO impl.RaftServerProxy: 3951fc6b-1099-4c08-a0e2-d476327ac902: addNew group-594C50D4FCDD:[3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858] returns group-594C50D4FCDD:java.util.concurrent.CompletableFuture@b977cba[Not completed]
s3g_1       | 2019-10-28 19:36:51,298 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: using custom profile for table: deletedTable
datanode_1  | 2019-10-28 19:29:47,738 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
datanode_2  | 2019-10-28 19:29:47,704 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
scm_1       | 2019-10-28 19:29:43,490 INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-28 19:29:51,450 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902: new RaftServerImpl for group-594C50D4FCDD:[3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858] with ContainerStateMachine:uninitialized
s3g_1       | 20191028T193651Z
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedTable
datanode_2  | 2019-10-28 19:29:47,704 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis d32c1418-808c-4a84-ba8b-0f5d833bb07e at port 9858
scm_1       | 2019-10-28 19:29:43,562 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2019-10-28 19:29:47,738 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 601f4edf-2014-4c3a-a9c7-36f37e72f2ae at port 9858
kdc_1       | Oct 28 19:29:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290971, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:51,452 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: using custom profile for table: openKeyTable
datanode_2  | 2019-10-28 19:29:47,722 INFO impl.RaftServerProxy: d32c1418-808c-4a84-ba8b-0f5d833bb07e: start RPC server
scm_1       | 2019-10-28 19:29:43,600 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2019-10-28 19:29:47,756 INFO impl.RaftServerProxy: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: start RPC server
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-28 19:29:51,453 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
datanode_2  | 2019-10-28 19:29:47,909 INFO server.GrpcService: d32c1418-808c-4a84-ba8b-0f5d833bb07e: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:openKeyTable
scm_1       | 2019-10-28 19:29:43,600 INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290972, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:47,947 INFO server.GrpcService: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
s3g_1       | 2019-10-28 19:36:51,298 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-28 19:29:50,479 INFO impl.RaftServerProxy: d32c1418-808c-4a84-ba8b-0f5d833bb07e: addNew group-7F06C71867A2:[d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858] returns group-7F06C71867A2:java.util.concurrent.CompletableFuture@99a8481[Not completed]
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: using custom profile for table: s3Table
scm_1       | 2019-10-28 19:29:43,788 INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
datanode_3  | 2019-10-28 19:29:51,453 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-28 19:29:50,989 INFO impl.RaftServerProxy: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: addNew group-51FFEE81891F:[601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858] returns group-51FFEE81891F:java.util.concurrent.CompletableFuture@ffcc9fd[Not completed]
datanode_2  | 2019-10-28 19:29:50,493 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e: new RaftServerImpl for group-7F06C71867A2:[d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858] with ContainerStateMachine:uninitialized
om_1        | 2019-10-28 19:29:48,499 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3Table
s3g_1       | 20191028T193651Z
scm_1       | 2019-10-28 19:29:43,788 INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2019-10-28 19:29:51,454 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290972, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:51,015 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: new RaftServerImpl for group-51FFEE81891F:[601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2019-10-28 19:29:50,494 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2019-10-28 19:29:48,500 INFO db.DBStoreBuilder: using custom profile for table: multipartInfoTable
s3g_1       | 20191028/us-west-1/s3/aws4_request
scm_1       | 2019-10-28 19:29:43,789 INFO ipc.Server: IPC Server listener on 9860: starting
datanode_3  | 2019-10-28 19:29:51,454 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-28 19:29:51,016 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2019-10-28 19:29:50,495 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2019-10-28 19:29:48,500 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:multipartInfoTable
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
scm_1       | 2019-10-28 19:29:43,792 INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_3  | 2019-10-28 19:29:51,462 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD: ConfigurationManager, init=-1: [3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858], old=null, confs=<EMPTY_MAP>
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290972, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:51,017 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2019-10-28 19:29:50,495 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
om_1        | 2019-10-28 19:29:48,500 INFO db.DBStoreBuilder: using custom profile for table: dTokenTable
scm_1       | 2019-10-28 19:29:43,792 INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
s3g_1       | 2019-10-28 19:36:51,303 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-28 19:29:51,463 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-28 19:29:51,017 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_2  | 2019-10-28 19:29:50,495 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om_1        | 2019-10-28 19:29:48,500 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:dTokenTable
scm_1       | 2019-10-28 19:29:43,793 INFO ipc.Server: IPC Server Responder: starting
s3g_1       | 20191028T193651Z
datanode_3  | 2019-10-28 19:29:51,468 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2019-10-28 19:29:51,018 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290972, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:50,496 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | 2019-10-28 19:29:48,500 INFO db.DBStoreBuilder: using custom profile for table: s3SecretTable
scm_1       | 2019-10-28 19:29:43,793 INFO ipc.Server: IPC Server listener on 9863: starting
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_3  | 2019-10-28 19:29:51,470 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b0c791db-d9e9-4992-8cb6-594c50d4fcdd does not exist. Creating ...
datanode_1  | 2019-10-28 19:29:51,018 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-28 19:29:50,501 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2: ConfigurationManager, init=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858], old=null, confs=<EMPTY_MAP>
om_1        | 2019-10-28 19:29:48,500 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3SecretTable
scm_1       | 2019-10-28 19:29:43,795 INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-10-28 19:29:51,489 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b0c791db-d9e9-4992-8cb6-594c50d4fcdd/in_use.lock acquired by nodename 7@c004515c1151
datanode_1  | 2019-10-28 19:29:51,026 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F: ConfigurationManager, init=-1: [601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2019-10-28 19:29:50,502 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2019-10-28 19:29:48,500 INFO db.DBStoreBuilder: using custom profile for table: prefixTable
scm_1       | 2019-10-28 19:29:43,795 INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290972, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 2019-10-28 19:36:51,303 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-28 19:29:51,504 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b0c791db-d9e9-4992-8cb6-594c50d4fcdd has been successfully formatted.
datanode_1  | 2019-10-28 19:29:51,026 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2019-10-28 19:29:50,505 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2019-10-28 19:29:48,500 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:prefixTable
scm_1       | 2019-10-28 19:29:43,796 INFO ipc.Server: IPC Server Responder: starting
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 20191028T193651Z
datanode_3  | 2019-10-28 19:29:51,506 [pool-9-thread-1] INFO       - group-594C50D4FCDD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2019-10-28 19:29:51,031 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2019-10-28 19:29:50,507 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a409670b-5cb9-4114-805a-7f06c71867a2 does not exist. Creating ...
om_1        | 2019-10-28 19:29:48,509 INFO db.DBStoreBuilder: using custom profile for table: default
scm_1       | 2019-10-28 19:29:43,796 INFO ipc.Server: IPC Server listener on 9861: starting
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_3  | 2019-10-28 19:29:51,507 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 2019-10-28 19:29:51,033 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/db3468a0-d8f5-455d-9ccf-51ffee81891f does not exist. Creating ...
datanode_2  | 2019-10-28 19:29:50,548 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a409670b-5cb9-4114-805a-7f06c71867a2/in_use.lock acquired by nodename 7@6440263c42ed
om_1        | 2019-10-28 19:29:48,509 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
kdc_1       | Oct 28 19:29:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290972, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:29:43,798 INFO server.SCMClientProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
datanode_3  | 2019-10-28 19:29:51,509 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2019-10-28 19:29:51,064 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/db3468a0-d8f5-455d-9ccf-51ffee81891f/in_use.lock acquired by nodename 7@62d67d27c24f
datanode_2  | 2019-10-28 19:29:50,564 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a409670b-5cb9-4114-805a-7f06c71867a2 has been successfully formatted.
om_1        | 2019-10-28 19:29:48,510 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
s3g_1       | 2019-10-28 19:36:51,308 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-28 19:29:51,513 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2019-10-28 19:29:51,081 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/db3468a0-d8f5-455d-9ccf-51ffee81891f has been successfully formatted.
datanode_2  | 2019-10-28 19:29:50,569 [pool-9-thread-1] INFO       - group-7F06C71867A2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | 2019-10-28 19:29:43,799 INFO ipc.Server: IPC Server Responder: starting
om_1        | 2019-10-28 19:29:49,049 INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-28 19:29:51,513 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-10-28 19:29:51,085 [pool-9-thread-1] INFO       - group-51FFEE81891F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | 2019-10-28 19:29:43,799 INFO ipc.Server: IPC Server listener on 9961: starting
om_1        | 2019-10-28 19:29:49,052 [main] INFO       - Loaded 0 tokens
datanode_2  | 2019-10-28 19:29:50,570 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-28 19:29:51,514 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2019-10-28 19:29:51,086 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
scm_1       | 2019-10-28 19:29:43,804 INFO http.HttpServer2: Jetty bound to port 9876
datanode_2  | 2019-10-28 19:29:50,573 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2019-10-28 19:29:49,053 [main] INFO       - Loading token state into token manager.
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-28 19:29:51,522 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2019-10-28 19:29:51,090 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2019-10-28 19:29:43,805 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2  | 2019-10-28 19:29:50,577 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2019-10-28 19:29:49,099 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | 2019-10-28 19:36:51,308 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-28 19:29:51,525 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-10-28 19:29:51,096 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2019-10-28 19:29:50,577 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2019-10-28 19:29:49,106 INFO ipc.Server: Starting Socket Reader #1 for port 9862
s3g_1       | 20191028T193651Z
scm_1       | 2019-10-28 19:29:43,874 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-28 19:29:51,530 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2019-10-28 19:29:51,096 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2019-10-28 19:29:50,579 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:29:49,170 [main] INFO       - OzoneManager RPC server is listening at om/172.18.0.10:9862
scm_1       | 2019-10-28 19:29:43,876 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-28 19:29:51,534 INFO segmented.SegmentedRaftLogWorker: new 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b0c791db-d9e9-4992-8cb6-594c50d4fcdd
datanode_1  | 2019-10-28 19:29:51,099 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-28 19:29:50,586 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
om_1        | 2019-10-28 19:29:49,276 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2019-10-28 19:29:43,883 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6949e948{/logs,file:///var/log/hadoop/,AVAILABLE}
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](info): closing down fd 18
datanode_1  | 2019-10-28 19:29:51,109 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2019-10-28 19:29:51,534 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-10-28 19:29:50,589 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
s3g_1       | 2019-10-28 19:36:51,313 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:29:49,323 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2019-10-28 19:29:43,884 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@176555c{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
kdc_1       | Oct 28 19:29:31 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-28 19:29:51,112 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-10-28 19:29:51,534 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-10-28 19:29:50,593 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 2019-10-28 19:29:49,323 INFO impl.MetricsSystemImpl: OzoneManager metrics system started
scm_1       | 2019-10-28 19:29:43,988 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:51,117 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028T193651Z
datanode_3  | 2019-10-28 19:29:51,535 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-28 19:29:50,598 INFO segmented.SegmentedRaftLogWorker: new d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a409670b-5cb9-4114-805a-7f06c71867a2
om_1        | 2019-10-28 19:29:49,351 [main] INFO       - Reading keypair and certificate from file system.
datanode_1  | 2019-10-28 19:29:51,121 INFO segmented.SegmentedRaftLogWorker: new 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/db3468a0-d8f5-455d-9ccf-51ffee81891f
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_3  | 2019-10-28 19:29:51,536 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2019-10-28 19:29:50,598 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2019-10-28 19:29:51,121 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-28 19:29:43,992 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@575cabf0{/,file:///tmp/jetty-0.0.0.0-9876-scm-_-any-5611986953002749732.dir/webapp/,AVAILABLE}{/scm}
om_1        | 2019-10-28 19:29:49,364 [main] INFO       - Starting OM block token secret manager
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-28 19:29:51,536 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2  | 2019-10-28 19:29:50,598 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2019-10-28 19:29:51,122 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
s3g_1       | 2019-10-28 19:36:51,313 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-28 19:29:43,998 INFO server.AbstractConnector: Started ServerConnector@376bccef{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
om_1        | 2019-10-28 19:29:49,364 [main] INFO       - Updating the current master key for generating tokens
datanode_3  | 2019-10-28 19:29:51,536 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2019-10-28 19:29:51,123 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-28 19:29:50,599 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191028T193651Z
scm_1       | 2019-10-28 19:29:43,998 INFO server.Server: Started @5073ms
om_1        | 2019-10-28 19:29:49,365 [main] INFO       - Starting OM delegation token secret manager
datanode_1  | 2019-10-28 19:29:51,123 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2019-10-28 19:29:50,600 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-28 19:29:51,537 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
s3g_1       | 20191028/us-west-1/s3/aws4_request
scm_1       | 2019-10-28 19:29:44,000 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:29:49,365 [main] INFO       - Updating the current master key for generating tokens
datanode_1  | 2019-10-28 19:29:51,123 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2  | 2019-10-28 19:29:50,600 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-28 19:29:51,537 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
scm_1       | 2019-10-28 19:29:44,001 INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2019-10-28 19:29:49,366 [Thread[Thread-11,5,main]] INFO       - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
datanode_1  | 2019-10-28 19:29:51,123 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2019-10-28 19:29:50,600 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-28 19:29:51,537 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
s3g_1       | 2019-10-28 19:36:51,321 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-28 19:29:44,001 INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2019-10-28 19:29:49,392 INFO ipc.Server: IPC Server listener on 9862: starting
datanode_1  | 2019-10-28 19:29:51,124 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2019-10-28 19:29:50,601 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-28 19:29:51,544 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
s3g_1       | 20191028T193651Z
scm_1       | 2019-10-28 19:29:44,003 INFO server.BaseHttpServer: HTTP server of SCM is listening at http://0.0.0.0:9876
om_1        | 2019-10-28 19:29:49,393 INFO ipc.Server: IPC Server Responder: starting
datanode_2  | 2019-10-28 19:29:50,601 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2019-10-28 19:29:51,124 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2019-10-28 19:29:51,548 INFO segmented.SegmentedRaftLogWorker: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:29:49,426 INFO hdfs.DFSUtil: Starting web server as: HTTP/om@EXAMPLE.COM
scm_1       | 2019-10-28 19:29:44,005 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-28 19:29:50,601 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2019-10-28 19:29:51,125 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2019-10-28 19:29:51,552 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:29:44,007 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
datanode_2  | 2019-10-28 19:29:50,608 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
om_1        | 2019-10-28 19:29:49,426 INFO hdfs.DFSUtil: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
datanode_1  | 2019-10-28 19:29:51,132 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-10-28 19:29:51,552 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:29:44,010 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-28 19:36:51,321 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-28 19:29:50,612 INFO segmented.SegmentedRaftLogWorker: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2019-10-28 19:29:49,547 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2019-10-28 19:29:51,135 INFO segmented.SegmentedRaftLogWorker: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2019-10-28 19:29:51,552 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:29:44,012 INFO util.JvmPauseMonitor: Starting JVM pause monitor
s3g_1       | 20191028T193651Z
datanode_2  | 2019-10-28 19:29:50,618 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2019-10-28 19:29:49,551 INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_1  | 2019-10-28 19:29:51,139 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2019-10-28 19:29:51,553 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:29:44,020 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_2  | 2019-10-28 19:29:50,619 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 2019-10-28 19:29:49,558 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2019-10-28 19:29:51,139 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2019-10-28 19:29:51,570 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:29:44,020 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
datanode_2  | 2019-10-28 19:29:50,620 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2019-10-28 19:29:51,140 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2019-10-28 19:29:51,572 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
scm_1       | 2019-10-28 19:29:44,022 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](info): closing down fd 18
s3g_1       | 2019-10-28 19:36:51,329 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-28 19:29:50,621 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2019-10-28 19:29:51,140 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2019-10-28 19:29:51,573 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD: start as a follower, conf=-1: [3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858], old=null
om_1        | 2019-10-28 19:29:49,560 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
scm_1       | 2019-10-28 19:29:44,022 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191028T193651Z
datanode_2  | 2019-10-28 19:29:50,637 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-10-28 19:29:51,155 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-10-28 19:29:51,574 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2019-10-28 19:29:49,560 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1       | 2019-10-28 19:29:44,159 INFO server.SCMClientProtocolServer: Processing CSR for dn c004515c1151, UUID: 3951fc6b-1099-4c08-a0e2-d476327ac902
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028/us-west-1/s3/aws4_request
datanode_2  | 2019-10-28 19:29:50,639 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-10-28 19:29:51,156 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-10-28 19:29:51,575 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: start FollowerState
om_1        | 2019-10-28 19:29:49,561 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1       | 2019-10-28 19:29:44,159 INFO server.SCMClientProtocolServer: Processing CSR for dn 6440263c42ed, UUID: d32c1418-808c-4a84-ba8b-0f5d833bb07e
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-28 19:29:50,640 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2: start as a follower, conf=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858], old=null
datanode_1  | 2019-10-28 19:29:51,158 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F: start as a follower, conf=-1: [601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
datanode_3  | 2019-10-28 19:29:51,580 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-594C50D4FCDD,id=3951fc6b-1099-4c08-a0e2-d476327ac902
om_1        | 2019-10-28 19:29:49,581 INFO http.HttpServer2: Jetty bound to port 9874
scm_1       | 2019-10-28 19:29:44,253 INFO server.SCMClientProtocolServer: Processing CSR for dn 62d67d27c24f, UUID: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae
s3g_1       | 2019-10-28 19:36:51,329 [qtp262445056-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-28 19:29:50,641 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2019-10-28 19:29:51,159 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2019-10-28 19:29:51,582 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1        | 2019-10-28 19:29:49,582 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
scm_1       | 2019-10-28 19:29:45,263 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-28 19:36:51,331 [qtp262445056-27] ERROR      - Couldn't create RpcClient protocol exception: 
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-28 19:29:50,642 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: start FollowerState
datanode_1  | 2019-10-28 19:29:51,160 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: start FollowerState
datanode_3  | 2019-10-28 19:29:51,670 INFO impl.RaftServerProxy: 3951fc6b-1099-4c08-a0e2-d476327ac902: addNew group-153A6F1916DD:[d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858] returns group-153A6F1916DD:java.util.concurrent.CompletableFuture@7f051171[Not completed]
om_1        | 2019-10-28 19:29:49,616 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2019-10-28 19:29:45,269 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-28 19:29:51,164 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-51FFEE81891F,id=601f4edf-2014-4c3a-a9c7-36f37e72f2ae
datanode_2  | 2019-10-28 19:29:50,647 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7F06C71867A2,id=d32c1418-808c-4a84-ba8b-0f5d833bb07e
datanode_3  | 2019-10-28 19:29:51,674 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902: new RaftServerImpl for group-153A6F1916DD:[d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858] with ContainerStateMachine:uninitialized
om_1        | 2019-10-28 19:29:49,618 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
scm_1       | 2019-10-28 19:29:45,272 INFO server.SCMClientProtocolServer: Processing CSR for om om, UUID: 04356d59-9e6d-4b5a-8395-14f9b361e055
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-28 19:29:51,165 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2  | 2019-10-28 19:29:50,648 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-10-28 19:29:51,674 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 2019-10-28 19:29:47,602 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:29:49,621 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64b70f41{/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](info): closing down fd 18
datanode_1  | 2019-10-28 19:29:51,697 INFO impl.RaftServerProxy: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: addNew group-153A6F1916DD:[d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858] returns group-153A6F1916DD:java.util.concurrent.CompletableFuture@61bcc4d7[Not completed]
datanode_2  | 2019-10-28 19:29:51,682 INFO impl.RaftServerProxy: d32c1418-808c-4a84-ba8b-0f5d833bb07e: addNew group-153A6F1916DD:[d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858] returns group-153A6F1916DD:java.util.concurrent.CompletableFuture@7c315d61[Not completed]
scm_1       | 2019-10-28 19:29:47,605 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-28 19:29:51,674 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2019-10-28 19:29:49,622 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@67f63d26{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:32 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-28 19:29:51,700 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: new RaftServerImpl for group-153A6F1916DD:[d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858] with ContainerStateMachine:uninitialized
scm_1       | 2019-10-28 19:29:47,632 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:29:51,674 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-28 19:29:49,703 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:51,686 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e: new RaftServerImpl for group-153A6F1916DD:[d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858] with ContainerStateMachine:uninitialized
kdc_1       | Entry for principal om/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.s3g.keytab.
scm_1       | 2019-10-28 19:29:47,634 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-28 19:29:51,700 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2019-10-28 19:29:51,674 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-28 19:29:49,709 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5921b93c{/,file:///tmp/jetty-0.0.0.0-9874-ozoneManager-_-any-586228290282543834.dir/webapp/,AVAILABLE}{/ozoneManager}
kdc_1       | Entry for principal om/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.s3g.keytab.
datanode_2  | 2019-10-28 19:29:51,686 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 2019-10-28 19:29:47,698 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,700 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2019-10-28 19:29:51,674 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-28 19:29:49,732 INFO server.AbstractConnector: Started ServerConnector@70324ee7{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
kdc_1       | Generiting keytab
datanode_2  | 2019-10-28 19:29:51,686 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2019-10-28 19:29:47,700 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3  | 2019-10-28 19:29:51,675 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: ConfigurationManager, init=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null, confs=<EMPTY_MAP>
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-28 19:29:49,733 INFO server.Server: Started @4187ms
datanode_2  | 2019-10-28 19:29:51,686 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
scm_1       | 2019-10-28 19:29:47,838 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2019-10-28 19:29:51,675 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | WARNING: no policy specified for om/om@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-28 19:29:49,737 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2019-10-28 19:29:51,686 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1       | 2019-10-28 19:29:47,860 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_1  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-28 19:29:51,675 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:29:49,737 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2019-10-28 19:29:51,687 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-28 19:29:51,701 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD: ConfigurationManager, init=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null, confs=<EMPTY_MAP>
scm_1       | 2019-10-28 19:29:49,602 INFO net.NetworkTopology: Added a new node: /default-rack/d32c1418-808c-4a84-ba8b-0f5d833bb07e
kdc_1       | Principal "om/om@EXAMPLE.COM" created.
datanode_3  | 2019-10-28 19:29:51,675 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd does not exist. Creating ...
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-28 19:29:49,739 INFO server.BaseHttpServer: HTTP server of OZONEMANAGER is listening at http://0.0.0.0:9874
datanode_2  | 2019-10-28 19:29:51,687 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD: ConfigurationManager, init=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null, confs=<EMPTY_MAP>
scm_1       | 2019-10-28 19:29:49,603 INFO node.SCMNodeManager: Registered Data node : d32c1418-808c-4a84-ba8b-0f5d833bb07e{ip: 172.18.0.6, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11489939640278576}
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-28 19:29:51,689 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd/in_use.lock acquired by nodename 7@c004515c1151
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:30:07,020 INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-28 19:29:51,687 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2019-10-28 19:29:49,606 INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_3  | 2019-10-28 19:29:51,694 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd has been successfully formatted.
om_1        | 2019-10-28 19:30:07,039 INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-28 19:29:51,687 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 2019-10-28 19:29:49,607 INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
datanode_3  | 2019-10-28 19:29:51,694 [pool-9-thread-1] INFO       - group-153A6F1916DD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om_1        | 2019-10-28 19:30:08,381 [IPC Server handler 0 on 9862] INFO       - created volume:vol-0-96143 for user:HTTP/scm@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:51,688 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd does not exist. Creating ...
datanode_1  | 2019-10-28 19:29:51,701 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd does not exist. Creating ...
scm_1       | 2019-10-28 19:29:49,608 INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
kdc_1       | Generiting keytab
datanode_3  | 2019-10-28 19:29:51,695 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1        | 2019-10-28 19:30:08,458 [IPC Server handler 4 on 9862] INFO       - created volume:vol-1-52457 for user:HTTP/scm@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:51,691 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd/in_use.lock acquired by nodename 7@6440263c42ed
datanode_1  | 2019-10-28 19:29:51,715 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd/in_use.lock acquired by nodename 7@62d67d27c24f
scm_1       | 2019-10-28 19:29:49,630 INFO net.NetworkTopology: Added a new node: /default-rack/601f4edf-2014-4c3a-a9c7-36f37e72f2ae
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-28 19:29:51,695 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2019-10-28 19:29:51,697 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd has been successfully formatted.
om_1        | 2019-10-28 19:30:08,481 [IPC Server handler 3 on 9862] INFO       - created volume:vol-2-54208 for user:HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
datanode_1  | 2019-10-28 19:29:51,740 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd has been successfully formatted.
scm_1       | 2019-10-28 19:29:49,630 INFO node.SCMNodeManager: Registered Data node : 601f4edf-2014-4c3a-a9c7-36f37e72f2ae{ip: 172.18.0.8, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11489939677031469}
kdc_1       | WARNING: no policy specified for dn/c004515c1151@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-10-28 19:29:51,698 [pool-9-thread-1] INFO       - group-153A6F1916DD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2019-10-28 19:29:51,695 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-28 19:30:08,504 [IPC Server handler 5 on 9862] INFO       - created volume:vol-3-16716 for user:HTTP/scm@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:51,740 [pool-9-thread-1] INFO       - group-153A6F1916DD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | 2019-10-28 19:29:49,690 INFO net.NetworkTopology: Added a new node: /default-rack/3951fc6b-1099-4c08-a0e2-d476327ac902
kdc_1       | Principal "dn/c004515c1151@EXAMPLE.COM" created.
datanode_2  | 2019-10-28 19:29:51,698 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_3  | 2019-10-28 19:29:51,695 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-28 19:30:08,527 [IPC Server handler 6 on 9862] INFO       - created volume:vol-4-37219 for user:HTTP/scm@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:51,741 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
scm_1       | 2019-10-28 19:29:49,690 INFO node.SCMNodeManager: Registered Data node : 3951fc6b-1099-4c08-a0e2-d476327ac902{ip: 172.18.0.7, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 11489939640278882}
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:51,698 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2019-10-28 19:29:51,695 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-28 19:30:25,748 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,741 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2019-10-28 19:29:50,739 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a409670b-5cb9-4114-805a-7f06c71867a2, Nodes: d32c1418-808c-4a84-ba8b-0f5d833bb07e{ip: 172.18.0.6, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
kdc_1       | Entry for principal dn/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.c004515c1151.keytab.
datanode_2  | 2019-10-28 19:29:51,698 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2019-10-28 19:29:51,695 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:30:25,760 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:51,741 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2019-10-28 19:29:51,208 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: db3468a0-d8f5-455d-9ccf-51ffee81891f, Nodes: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae{ip: 172.18.0.8, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
kdc_1       | Entry for principal dn/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.c004515c1151.keytab.
datanode_2  | 2019-10-28 19:29:51,698 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-28 19:29:51,695 INFO segmented.SegmentedRaftLogWorker: new 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-28 19:30:28,451 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,741 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-28 19:29:51,633 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b0c791db-d9e9-4992-8cb6-594c50d4fcdd, Nodes: 3951fc6b-1099-4c08-a0e2-d476327ac902{ip: 172.18.0.7, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
kdc_1       | Generiting keytab
datanode_2  | 2019-10-28 19:29:51,698 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-10-28 19:29:51,695 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-28 19:30:28,464 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:51,741 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-28 19:29:51,752 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 8437c7a8-fe72-4bd4-9393-153a6f1916dd, Nodes: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae{ip: 172.18.0.8, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}3951fc6b-1099-4c08-a0e2-d476327ac902{ip: 172.18.0.7, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}d32c1418-808c-4a84-ba8b-0f5d833bb07e{ip: 172.18.0.6, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:51,699 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-28 19:30:29,204 [IPC Server handler 11 on 9862] INFO       - created volume:97133-rpcwoport for user:testuser/scm@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:51,741 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 2019-10-28 19:30:07,462 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for dn/6045f1ad9083@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-10-28 19:29:51,699 INFO segmented.SegmentedRaftLogWorker: new d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        | 2019-10-28 19:30:31,179 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,742 INFO segmented.SegmentedRaftLogWorker: new 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd
scm_1       | 2019-10-28 19:30:07,466 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
kdc_1       | Principal "dn/6045f1ad9083@EXAMPLE.COM" created.
datanode_2  | 2019-10-28 19:29:51,699 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:30:31,192 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:51,742 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
scm_1       | 2019-10-28 19:30:09,421 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:51,699 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:30:33,798 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,742 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1       | 2019-10-28 19:30:09,425 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Entry for principal dn/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.6045f1ad9083.keytab.
datanode_2  | 2019-10-28 19:29:51,699 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-28 19:30:33,808 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:51,742 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-28 19:30:10,799 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal dn/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.6045f1ad9083.keytab.
datanode_2  | 2019-10-28 19:29:51,699 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-28 19:30:36,225 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,742 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 2019-10-28 19:30:10,804 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Generiting keytab
datanode_2  | 2019-10-28 19:29:51,699 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-28 19:30:36,234 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:30:10,947 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,742 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:51,699 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-28 19:30:38,877 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:30:10,948 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,742 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
kdc_1       | WARNING: no policy specified for scm/6440263c42ed@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-10-28 19:29:51,699 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2019-10-28 19:29:51,696 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-28 19:30:38,887 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:30:10,952 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
datanode_1  | 2019-10-28 19:29:51,742 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
kdc_1       | Principal "scm/6440263c42ed@EXAMPLE.COM" created.
datanode_2  | 2019-10-28 19:29:51,700 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2019-10-28 19:29:51,697 INFO segmented.SegmentedRaftLogWorker: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-28 19:30:41,344 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:30:10,952 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
datanode_1  | 2019-10-28 19:29:51,743 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:51,700 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2019-10-28 19:29:51,697 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2019-10-28 19:30:41,356 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
scm_1       | 2019-10-28 19:30:11,082 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,743 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
kdc_1       | Entry for principal scm/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.6440263c42ed.keytab.
datanode_2  | 2019-10-28 19:29:51,700 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-10-28 19:29:51,697 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 2019-10-28 19:30:43,962 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
scm_1       | 2019-10-28 19:30:11,086 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-28 19:29:51,743 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
kdc_1       | Entry for principal scm/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.6440263c42ed.keytab.
datanode_2  | 2019-10-28 19:29:51,700 INFO segmented.SegmentedRaftLogWorker: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2019-10-28 19:29:51,697 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 2019-10-28 19:30:43,974 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm_1       | 2019-10-28 19:30:11,184 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,743 INFO segmented.SegmentedRaftLogWorker: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1       | Generiting keytab
datanode_2  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2019-10-28 19:29:51,697 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2019-10-28 19:30:46,560 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm_1       | 2019-10-28 19:30:11,184 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,744 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 2019-10-28 19:30:46,574 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2019-10-28 19:30:11,187 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-28 19:29:51,698 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-10-28 19:29:51,744 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
kdc_1       | WARNING: no policy specified for scm/62d67d27c24f@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 2019-10-28 19:30:49,307 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2019-10-28 19:30:11,187 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-28 19:29:51,698 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-10-28 19:29:51,744 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
kdc_1       | Principal "scm/62d67d27c24f@EXAMPLE.COM" created.
datanode_2  | 2019-10-28 19:29:51,701 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2019-10-28 19:30:49,320 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
scm_1       | 2019-10-28 19:30:25,776 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:29:51,698 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: start as a follower, conf=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
datanode_1  | 2019-10-28 19:29:51,744 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:51,701 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1        | 2019-10-28 19:30:53,813 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
scm_1       | 2019-10-28 19:30:25,779 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
datanode_1  | 2019-10-28 19:29:51,744 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-10-28 19:29:51,698 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: changes role from      null to FOLLOWER at term 0 for startAsFollower
kdc_1       | Entry for principal scm/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.62d67d27c24f.keytab.
datanode_2  | 2019-10-28 19:29:51,701 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1        | 2019-10-28 19:30:53,826 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
scm_1       | 2019-10-28 19:30:41,823 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,744 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-10-28 19:29:51,698 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: start FollowerState
kdc_1       | Entry for principal scm/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.62d67d27c24f.keytab.
datanode_2  | 2019-10-28 19:29:51,702 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD: start as a follower, conf=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
om_1        | 2019-10-28 19:30:57,951 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
scm_1       | 2019-10-28 19:30:41,825 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,745 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD: start as a follower, conf=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
datanode_3  | 2019-10-28 19:29:51,699 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-153A6F1916DD,id=3951fc6b-1099-4c08-a0e2-d476327ac902
kdc_1       | Generiting keytab
datanode_2  | 2019-10-28 19:29:51,702 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2019-10-28 19:30:57,963 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
scm_1       | 2019-10-28 19:30:41,826 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:51,745 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2019-10-28 19:29:51,699 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:51,702 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: start FollowerState
om_1        | 2019-10-28 19:31:00,717 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
scm_1       | 2019-10-28 19:30:41,827 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-28 19:29:51,745 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: start FollowerState
datanode_3  | 2019-10-28 19:29:56,674 INFO impl.FollowerState: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD-FollowerState: change to CANDIDATE, lastRpcTime:5099ms, electionTimeout:5098ms
kdc_1       | WARNING: no policy specified for scm/scm@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-10-28 19:29:51,703 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-153A6F1916DD,id=d32c1418-808c-4a84-ba8b-0f5d833bb07e
om_1        | 2019-10-28 19:31:00,730 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
scm_1       | 2019-10-28 19:30:41,829 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-28 19:29:51,745 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-153A6F1916DD,id=601f4edf-2014-4c3a-a9c7-36f37e72f2ae
datanode_3  | 2019-10-28 19:29:56,675 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: shutdown FollowerState
kdc_1       | Principal "scm/scm@EXAMPLE.COM" created.
datanode_2  | 2019-10-28 19:29:51,703 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1        | 2019-10-28 19:31:03,418 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
scm_1       | 2019-10-28 19:30:41,830 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-28 19:29:51,745 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-10-28 19:29:56,676 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-28 19:29:55,719 INFO impl.FollowerState: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2-FollowerState: change to CANDIDATE, lastRpcTime:5077ms, electionTimeout:5076ms
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
scm_1       | 2019-10-28 19:30:49,986 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:31:03,429 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:56,270 INFO impl.FollowerState: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F-FollowerState: change to CANDIDATE, lastRpcTime:5111ms, electionTimeout:5110ms
datanode_3  | 2019-10-28 19:29:56,679 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: start LeaderElection
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-28 19:29:55,720 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: shutdown FollowerState
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
scm_1       | 2019-10-28 19:30:49,988 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-28 19:31:06,243 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:56,272 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: shutdown FollowerState
datanode_3  | 2019-10-28 19:29:56,696 INFO impl.LeaderElection: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD-LeaderElection1: begin an election at term 1 for -1: [3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858], old=null
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:55,721 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
scm_1       | 2019-10-28 19:31:11,820 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:31:06,253 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:56,273 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2019-10-28 19:29:56,697 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: shutdown LeaderElection
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-28 19:29:55,725 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: start LeaderElection
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
scm_1       | 2019-10-28 19:31:11,820 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:31:08,946 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:56,277 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: start LeaderElection
datanode_3  | 2019-10-28 19:29:56,698 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-28 19:29:55,748 INFO impl.LeaderElection: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2-LeaderElection1: begin an election at term 1 for -1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858], old=null
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
scm_1       | 2019-10-28 19:31:11,822 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:31:08,959 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:56,293 INFO impl.LeaderElection: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F-LeaderElection1: begin an election at term 1 for -1: [601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
datanode_3  | 2019-10-28 19:29:56,699 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD: change Leader from null to 3951fc6b-1099-4c08-a0e2-d476327ac902 at term 1 for becomeLeader, leader elected after 5192ms
datanode_2  | 2019-10-28 19:29:55,750 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: shutdown LeaderElection
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
scm_1       | 2019-10-28 19:31:11,822 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:31:11,526 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:56,294 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: shutdown LeaderElection
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-28 19:29:56,704 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2019-10-28 19:29:55,750 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
scm_1       | 2019-10-28 19:31:11,824 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:31:11,537 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:56,294 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:56,704 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2019-10-28 19:29:55,751 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2: change Leader from null to d32c1418-808c-4a84-ba8b-0f5d833bb07e at term 1 for becomeLeader, leader elected after 5181ms
scm_1       | 2019-10-28 19:31:11,825 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-28 19:31:14,380 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:56,294 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F: change Leader from null to 601f4edf-2014-4c3a-a9c7-36f37e72f2ae at term 1 for becomeLeader, leader elected after 5208ms
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-28 19:29:56,709 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2019-10-28 19:31:41,820 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
datanode_2  | 2019-10-28 19:29:55,755 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2019-10-28 19:31:14,390 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:56,298 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-28 19:29:56,715 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1       | 2019-10-28 19:31:41,822 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-28 19:29:55,756 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2019-10-28 19:31:16,971 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:56,298 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:31:41,824 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-28 19:29:55,759 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-28 19:31:16,983 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:29:56,301 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:31:41,825 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-28 19:29:55,765 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_3  | 2019-10-28 19:29:56,715 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-28 19:31:17,617 [IPC Server handler 7 on 9862] INFO       - created volume:97133-rpcwoport2 for user:testuser/scm@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:56,306 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:31:41,828 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-28 19:29:55,765 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:31:19,597 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:29:56,716 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2019-10-28 19:29:56,306 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:31:41,829 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-28 19:29:55,766 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-28 19:31:19,608 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:29:56,727 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: start LeaderState
datanode_1  | 2019-10-28 19:29:56,306 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:31:49,431 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-28 19:29:55,774 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: start LeaderState
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-28 19:31:22,386 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:29:56,741 INFO impl.FollowerState: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-FollowerState: change to CANDIDATE, lastRpcTime:5042ms, electionTimeout:5042ms
datanode_1  | 2019-10-28 19:29:56,312 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: start LeaderState
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:31:49,434 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_2  | 2019-10-28 19:29:55,792 INFO segmented.SegmentedRaftLogWorker: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:31:22,398 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:29:56,741 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: shutdown FollowerState
datanode_1  | 2019-10-28 19:29:56,329 INFO segmented.SegmentedRaftLogWorker: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F-SegmentedRaftLogWorker: Starting segment from index:0
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:31:49,443 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
datanode_2  | 2019-10-28 19:29:55,800 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2: set configuration 0: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858], old=null at 0
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-28 19:31:24,953 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:56,338 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F: set configuration 0: [601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null at 0
datanode_3  | 2019-10-28 19:29:56,741 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:31:49,443 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103041666252079229 bcsId: 0
datanode_2  | 2019-10-28 19:29:55,926 INFO segmented.SegmentedRaftLogWorker: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-7F06C71867A2-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a409670b-5cb9-4114-805a-7f06c71867a2/current/log_inprogress_0
om_1        | 2019-10-28 19:31:24,964 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
datanode_1  | 2019-10-28 19:29:56,434 INFO segmented.SegmentedRaftLogWorker: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-51FFEE81891F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/db3468a0-d8f5-455d-9ccf-51ffee81891f/current/log_inprogress_0
datanode_3  | 2019-10-28 19:29:56,742 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: start LeaderElection
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:32:02,125 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-28 19:29:56,836 INFO impl.FollowerState: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-FollowerState: change to CANDIDATE, lastRpcTime:5134ms, electionTimeout:5134ms
om_1        | 2019-10-28 19:31:27,521 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:29:56,757 INFO segmented.SegmentedRaftLogWorker: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2019-10-28 19:29:56,831 INFO impl.FollowerState: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-FollowerState: change to CANDIDATE, lastRpcTime:5086ms, electionTimeout:5086ms
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
scm_1       | 2019-10-28 19:32:02,128 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_2  | 2019-10-28 19:29:56,837 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: shutdown FollowerState
om_1        | 2019-10-28 19:31:27,531 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:29:56,769 INFO impl.LeaderElection: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-LeaderElection2: begin an election at term 1 for -1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
datanode_1  | 2019-10-28 19:29:56,832 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: shutdown FollowerState
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
datanode_2  | 2019-10-28 19:29:56,837 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2019-10-28 19:31:30,269 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:29:56,771 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD: set configuration 0: [3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858], old=null at 0
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:56,832 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | 2019-10-28 19:32:11,818 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
datanode_2  | 2019-10-28 19:29:56,837 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: start LeaderElection
om_1        | 2019-10-28 19:31:30,282 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:29:56,924 INFO segmented.SegmentedRaftLogWorker: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-594C50D4FCDD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b0c791db-d9e9-4992-8cb6-594c50d4fcdd/current/log_inprogress_0
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-28 19:29:56,832 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: start LeaderElection
scm_1       | 2019-10-28 19:32:11,821 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
datanode_2  | 2019-10-28 19:29:56,861 INFO impl.LeaderElection: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-LeaderElection2: begin an election at term 1 for -1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
om_1        | 2019-10-28 19:31:32,940 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:29:56,962 INFO impl.LeaderElection: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-LeaderElection2: Election REJECTED; received 2 response(s) [3951fc6b-1099-4c08-a0e2-d476327ac902<-d32c1418-808c-4a84-ba8b-0f5d833bb07e#0:FAIL-t1, 3951fc6b-1099-4c08-a0e2-d476327ac902<-601f4edf-2014-4c3a-a9c7-36f37e72f2ae#0:FAIL-t1] and 0 exception(s); 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD:t1, leader=null, voted=3951fc6b-1099-4c08-a0e2-d476327ac902, raftlog=3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:56,861 INFO impl.LeaderElection: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-LeaderElection2: begin an election at term 1 for -1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
scm_1       | 2019-10-28 19:32:11,821 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
datanode_2  | 2019-10-28 19:29:57,039 INFO impl.LeaderElection: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-LeaderElection2: Election REJECTED; received 2 response(s) [d32c1418-808c-4a84-ba8b-0f5d833bb07e<-3951fc6b-1099-4c08-a0e2-d476327ac902#0:FAIL-t1, d32c1418-808c-4a84-ba8b-0f5d833bb07e<-601f4edf-2014-4c3a-a9c7-36f37e72f2ae#0:FAIL-t1] and 0 exception(s); d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD:t1, leader=null, voted=d32c1418-808c-4a84-ba8b-0f5d833bb07e, raftlog=d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
om_1        | 2019-10-28 19:31:32,954 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:29:56,963 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-28 19:29:57,039 INFO impl.LeaderElection: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-LeaderElection2: Election REJECTED; received 2 response(s) [601f4edf-2014-4c3a-a9c7-36f37e72f2ae<-d32c1418-808c-4a84-ba8b-0f5d833bb07e#0:FAIL-t1, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae<-3951fc6b-1099-4c08-a0e2-d476327ac902#0:FAIL-t1] and 0 exception(s); 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD:t1, leader=null, voted=601f4edf-2014-4c3a-a9c7-36f37e72f2ae, raftlog=601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
scm_1       | 2019-10-28 19:32:11,826 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
datanode_2  | 2019-10-28 19:29:57,040 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
om_1        | 2019-10-28 19:31:35,549 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:29:56,963 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: shutdown LeaderElection
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-28 19:29:57,041 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
scm_1       | 2019-10-28 19:32:11,832 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
datanode_2  | 2019-10-28 19:29:57,041 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: shutdown LeaderElection
om_1        | 2019-10-28 19:31:35,560 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:29:56,964 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: start FollowerState
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
scm_1       | 2019-10-28 19:32:11,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-28 19:29:57,041 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: shutdown LeaderElection
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
datanode_2  | 2019-10-28 19:29:57,041 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: start FollowerState
om_1        | 2019-10-28 19:31:38,404 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:30:01,976 INFO impl.FollowerState: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-FollowerState: change to CANDIDATE, lastRpcTime:5011ms, electionTimeout:5011ms
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
scm_1       | 2019-10-28 19:32:41,820 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:29:57,041 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: start FollowerState
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
datanode_2  | 2019-10-28 19:30:02,022 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:3951fc6b-1099-4c08-a0e2-d476327ac902
om_1        | 2019-10-28 19:31:38,416 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:30:01,976 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: shutdown FollowerState
kdc_1       | Generiting keytab
scm_1       | 2019-10-28 19:32:41,821 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:30:02,023 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:3951fc6b-1099-4c08-a0e2-d476327ac902
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
datanode_2  | 2019-10-28 19:30:02,023 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: shutdown FollowerState
om_1        | 2019-10-28 19:31:41,146 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:30:01,976 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:32:41,822 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:30:02,023 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: shutdown FollowerState
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
datanode_2  | 2019-10-28 19:30:02,023 INFO impl.FollowerState: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
om_1        | 2019-10-28 19:31:41,158 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:30:01,977 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: start LeaderElection
datanode_3  | 2019-10-28 19:30:02,003 INFO impl.LeaderElection: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-LeaderElection3: begin an election at term 2 for -1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
datanode_2  | 2019-10-28 19:30:02,023 INFO impl.RoleInfo: d32c1418-808c-4a84-ba8b-0f5d833bb07e: start FollowerState
om_1        | 2019-10-28 19:31:44,018 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:31:44,031 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:31:44,655 [IPC Server handler 5 on 9862] ERROR      - Add acl [user:superuser1:rwxy[ACCESS]] to path /97133-rpcwoport2/bb1 failed, because acl already exist
om_1        | 2019-10-28 19:31:46,695 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:31:46,706 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:31:49,440 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-28 19:30:02,111 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD: change Leader from null to 3951fc6b-1099-4c08-a0e2-d476327ac902 at term 2 for appendEntries, leader elected after 10413ms
kdc_1       | WARNING: no policy specified for scm/s3g@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-28 19:31:49,453 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-28 19:30:02,047 INFO impl.LeaderElection: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-LeaderElection3: Election PASSED; received 1 response(s) [3951fc6b-1099-4c08-a0e2-d476327ac902<-d32c1418-808c-4a84-ba8b-0f5d833bb07e#0:OK-t2] and 0 exception(s); 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD:t2, leader=null, voted=3951fc6b-1099-4c08-a0e2-d476327ac902, raftlog=3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null
datanode_1  | 2019-10-28 19:30:02,023 INFO impl.RoleInfo: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae: start FollowerState
scm_1       | 2019-10-28 19:32:41,825 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-28 19:30:02,135 INFO impl.RaftServerImpl: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD: set configuration 0: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null at 0
kdc_1       | Principal "scm/s3g@EXAMPLE.COM" created.
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
datanode_3  | 2019-10-28 19:30:02,047 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: shutdown LeaderElection
om_1        | 2019-10-28 19:31:52,069 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:30:02,023 INFO impl.FollowerState: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
scm_1       | 2019-10-28 19:32:41,826 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-28 19:30:02,135 INFO segmented.SegmentedRaftLogWorker: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 2019-10-28 19:31:52,083 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:30:02,112 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD: change Leader from null to 3951fc6b-1099-4c08-a0e2-d476327ac902 at term 2 for appendEntries, leader elected after 10371ms
datanode_3  | 2019-10-28 19:30:02,048 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
kdc_1       | Entry for principal scm/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.s3g.keytab.
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
scm_1       | 2019-10-28 19:32:41,826 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 2019-10-28 19:30:02,181 INFO segmented.SegmentedRaftLogWorker: d32c1418-808c-4a84-ba8b-0f5d833bb07e@group-153A6F1916DD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd/current/log_inprogress_0
om_1        | 2019-10-28 19:31:54,889 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:30:02,135 INFO impl.RaftServerImpl: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD: set configuration 0: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null at 0
datanode_3  | 2019-10-28 19:30:02,048 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: change Leader from null to 3951fc6b-1099-4c08-a0e2-d476327ac902 at term 2 for becomeLeader, leader elected after 10353ms
kdc_1       | Entry for principal scm/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.s3g.keytab.
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
scm_1       | 2019-10-28 19:32:49,953 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-28 19:30:10,925 INFO client.DNCertificateClient: Getting certificate with certSerialId:11489940697318319.
om_1        | 2019-10-28 19:31:54,905 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:30:02,135 INFO segmented.SegmentedRaftLogWorker: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2019-10-28 19:30:02,048 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
kdc_1       | Generiting keytab
scm_1       | 2019-10-28 19:32:49,956 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_2  | 2019-10-28 19:37:12,838 [Datanode State Machine Thread - 0] ERROR      - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-28 19:31:57,580 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:30:02,181 INFO segmented.SegmentedRaftLogWorker: 601f4edf-2014-4c3a-a9c7-36f37e72f2ae@group-153A6F1916DD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd/current/log_inprogress_0
datanode_3  | 2019-10-28 19:30:02,048 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | java.net.SocketTimeoutException: Call From 6440263c42ed/172.18.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:39777 remote=scm/172.18.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
scm_1       | 2019-10-28 19:33:11,820 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:31:57,589 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-28 19:30:10,911 INFO client.DNCertificateClient: Getting certificate with certSerialId:11489940697318319.
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 2019-10-28 19:30:02,048 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
kdc_1       | WARNING: no policy specified for scm/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
scm_1       | 2019-10-28 19:33:11,821 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:32:01,469 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-28 19:37:12,838 [Datanode State Machine Thread - 0] ERROR      - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 2019-10-28 19:30:02,048 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
kdc_1       | Principal "scm/om@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
scm_1       | 2019-10-28 19:33:11,823 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:32:01,477 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | java.net.SocketTimeoutException: Call From 62d67d27c24f/172.18.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.8:36532 remote=scm/172.18.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 2019-10-28 19:30:02,048 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:33:11,823 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:32:05,689 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 2019-10-28 19:30:02,049 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-28 19:33:11,824 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:32:05,698 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_3  | 2019-10-28 19:30:02,051 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-28 19:33:11,828 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:32:08,431 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_3  | 2019-10-28 19:30:02,051 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
scm_1       | 2019-10-28 19:33:41,775 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-28 19:32:08,440 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_3  | 2019-10-28 19:30:02,051 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1       | 2019-10-28 19:33:41,778 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
om_1        | 2019-10-28 19:32:11,070 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_3  | 2019-10-28 19:30:02,053 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2019-10-28 19:33:41,828 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
om_1        | 2019-10-28 19:32:11,084 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_3  | 2019-10-28 19:30:02,054 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-28 19:33:41,829 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-28 19:32:13,900 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3  | 2019-10-28 19:30:02,054 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2019-10-28 19:33:41,829 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-28 19:32:13,910 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_3  | 2019-10-28 19:30:02,055 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
scm_1       | 2019-10-28 19:33:41,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-28 19:32:16,776 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_2  | 	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
datanode_3  | 2019-10-28 19:30:02,055 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1       | 2019-10-28 19:33:41,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-28 19:32:16,786 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3  | 2019-10-28 19:30:02,056 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-28 19:33:41,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-28 19:32:19,412 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
datanode_3  | 2019-10-28 19:30:02,056 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1       | 2019-10-28 19:33:49,482 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-28 19:32:19,422 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:143)
datanode_3  | 2019-10-28 19:30:02,056 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2019-10-28 19:33:49,483 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103041674114302079 bcsId: 0
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-28 19:32:22,076 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
scm_1       | 2019-10-28 19:34:11,812 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-28 19:30:02,056 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-28 19:32:22,090 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 2019-10-28 19:34:11,815 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-28 19:30:02,056 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-28 19:32:24,817 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:143)
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 2019-10-28 19:30:02,058 INFO impl.RoleInfo: 3951fc6b-1099-4c08-a0e2-d476327ac902: start LeaderState
scm_1       | 2019-10-28 19:34:11,827 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-28 19:32:24,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 2019-10-28 19:30:02,058 INFO segmented.SegmentedRaftLogWorker: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2019-10-28 19:34:11,828 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-10-28 19:32:27,462 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2019-10-28 19:34:11,830 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-28 19:30:02,059 INFO impl.RaftServerImpl: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD: set configuration 0: [d32c1418-808c-4a84-ba8b-0f5d833bb07e:172.18.0.6:9858, 3951fc6b-1099-4c08-a0e2-d476327ac902:172.18.0.7:9858, 601f4edf-2014-4c3a-a9c7-36f37e72f2ae:172.18.0.8:9858], old=null at 0
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-28 19:32:27,472 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 2019-10-28 19:34:11,833 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-28 19:32:28,142 [IPC Server handler 17 on 9862] INFO       - created volume:97133-rpcwport for user:testuser/scm@EXAMPLE.COM
datanode_3  | 2019-10-28 19:30:02,104 INFO segmented.SegmentedRaftLogWorker: 3951fc6b-1099-4c08-a0e2-d476327ac902@group-153A6F1916DD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8437c7a8-fe72-4bd4-9393-153a6f1916dd/current/log_inprogress_0
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 2019-10-28 19:34:41,820 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-28 19:32:30,053 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_3  | 2019-10-28 19:30:10,776 INFO client.DNCertificateClient: Getting certificate with certSerialId:11489940697318319.
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2019-10-28 19:34:41,820 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:39777 remote=scm/172.18.0.5:9861]
om_1        | 2019-10-28 19:32:30,062 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 2019-10-28 19:30:51,801 WARN client.GrpcClientProtocolService: 3-UnorderedRequestStreamObserver3: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
scm_1       | 2019-10-28 19:34:41,821 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:32:32,751 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-28 19:30:51,801 WARN client.GrpcClientProtocolService: 2-OrderedRequestStreamObserver2: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
scm_1       | 2019-10-28 19:34:41,823 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:32:32,762 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.8:36532 remote=scm/172.18.0.5:9861]
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-28 19:32:03,897 WARN client.GrpcClientProtocolService: 4-OrderedRequestStreamObserver4: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
scm_1       | 2019-10-28 19:34:41,824 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:32:35,464 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-28 19:32:03,898 WARN client.GrpcClientProtocolService: 5-UnorderedRequestStreamObserver5: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
om_1        | 2019-10-28 19:32:35,480 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:34:41,825 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 2019-10-28 19:32:51,882 WARN client.GrpcClientProtocolService: 6-OrderedRequestStreamObserver6: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
om_1        | 2019-10-28 19:32:38,346 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:34:49,510 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 2019-10-28 19:32:51,884 WARN client.GrpcClientProtocolService: 7-UnorderedRequestStreamObserver7: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
om_1        | 2019-10-28 19:32:38,356 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:34:49,512 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 2019-10-28 19:33:43,676 WARN client.GrpcClientProtocolService: 9-UnorderedRequestStreamObserver9: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
om_1        | 2019-10-28 19:32:41,098 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:34:49,513 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:290)
datanode_3  | 2019-10-28 19:33:43,676 WARN client.GrpcClientProtocolService: 8-OrderedRequestStreamObserver8: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
om_1        | 2019-10-28 19:32:41,111 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:34:49,513 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103041677510508672 bcsId: 0
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 	at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:290)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)
datanode_3  | 2019-10-28 19:35:13,149 WARN client.GrpcClientProtocolService: 10-OrderedRequestStreamObserver10: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
om_1        | 2019-10-28 19:32:43,825 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:34:49,615 INFO container.ReplicationManager: Starting Replication Monitor Thread.
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
datanode_2  | 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149)
datanode_3  | 2019-10-28 19:37:12,838 [Datanode State Machine Thread - 0] ERROR      - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
om_1        | 2019-10-28 19:32:43,837 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:34:49,626 INFO container.ReplicationManager: Replication Monitor Thread took 9 milliseconds for processing 3 containers.
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
datanode_1  | 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | java.net.SocketTimeoutException: Call From c004515c1151/172.18.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:37869 remote=scm/172.18.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
om_1        | 2019-10-28 19:32:46,449 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:35:11,436 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 2019-10-28 19:32:46,462 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:35:11,439 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
om_1        | 2019-10-28 19:32:49,221 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm_1       | 2019-10-28 19:35:11,820 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
om_1        | 2019-10-28 19:32:49,236 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm_1       | 2019-10-28 19:35:11,821 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
om_1        | 2019-10-28 19:32:53,720 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm_1       | 2019-10-28 19:35:11,821 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
om_1        | 2019-10-28 19:32:53,729 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:35:11,823 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
om_1        | 2019-10-28 19:32:57,793 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:35:11,825 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
om_1        | 2019-10-28 19:32:57,803 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:35:11,826 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-28 19:33:00,482 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
scm_1       | 2019-10-28 19:35:41,814 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-28 19:33:00,491 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:35:41,814 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-28 19:33:03,001 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:35:41,818 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:33:03,013 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
scm_1       | 2019-10-28 19:35:41,818 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-28 19:33:05,606 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
scm_1       | 2019-10-28 19:35:41,821 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:33:05,617 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
scm_1       | 2019-10-28 19:35:41,823 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
om_1        | 2019-10-28 19:33:08,176 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
scm_1       | 2019-10-28 19:36:11,843 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
om_1        | 2019-10-28 19:33:08,189 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
scm_1       | 2019-10-28 19:36:11,845 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:143)
om_1        | 2019-10-28 19:33:10,885 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
scm_1       | 2019-10-28 19:36:11,846 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
om_1        | 2019-10-28 19:33:10,896 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
scm_1       | 2019-10-28 19:36:11,850 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        | 2019-10-28 19:33:13,514 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2019-10-28 19:36:11,851 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om_1        | 2019-10-28 19:33:13,528 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | Oct 28, 2019 7:36:51 PM org.glassfish.jersey.internal.Errors logErrors
scm_1       | 2019-10-28 19:36:11,852 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:33:16,290 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
scm_1       | 2019-10-28 19:36:41,824 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | MultiException stack 1 of 1
scm_1       | 2019-10-28 19:36:41,829 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:33:16,303 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | javax.enterprise.inject.CreationException
scm_1       | 2019-10-28 19:36:41,830 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:33:19,037 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm_1       | 2019-10-28 19:36:41,831 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:33:19,047 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:37869 remote=scm/172.18.0.5:9861]
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:36:41,833 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:33:19,812 [IPC Server handler 14 on 9862] INFO       - created volume:97133-rpcwoscheme for user:testuser/scm@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:36:41,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:33:21,712 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:36:43,205 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:33:21,724 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:36:43,207 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2019-10-28 19:33:24,534 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
kdc_1       | Oct 28 19:29:33 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:37:01,737 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:33:24,544 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:290)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:37:01,740 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2019-10-28 19:33:27,358 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:37:11,825 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:33:27,369 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:37:11,826 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:33:30,205 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:37:11,827 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:33:30,214 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:37:11,830 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:33:32,839 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
kdc_1       | Entry for principal scm/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.om.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-10-28 19:33:32,854 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:37:11,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
kdc_1       | Entry for principal scm/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.om.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-28 19:33:35,636 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:37:11,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-28 19:33:35,647 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:37:13,230 WARN ipc.Server: IPC Server handler 5 on 9861, call Call#21 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.6:39777: output error
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:33:38,338 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:37:13,230 WARN ipc.Server: IPC Server handler 6 on 9861, call Call#21 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.7:37869: output error
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
kdc_1       | WARNING: no policy specified for om/c004515c1151@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-28 19:33:38,350 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:37:13,230 WARN ipc.Server: IPC Server handler 7 on 9861, call Call#21 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.8:36532: output error
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
kdc_1       | Principal "om/c004515c1151@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-28 19:33:41,042 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:37:13,233 INFO ipc.Server: IPC Server handler 5 on 9861 caught an exception
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:33:41,054 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | java.nio.channels.AsynchronousCloseException
datanode_3  | 2019-10-28 19:39:06,311 WARN client.GrpcClientProtocolService: 24-OrderedRequestStreamObserver24: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Entry for principal om/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.c004515c1151.keytab.
om_1        | 2019-10-28 19:33:45,634 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_3  | 2019-10-28 19:39:06,313 WARN client.GrpcClientProtocolService: 25-UnorderedRequestStreamObserver25: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Entry for principal om/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.c004515c1151.keytab.
om_1        | 2019-10-28 19:33:45,646 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 2019-10-28 19:33:49,864 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
om_1        | 2019-10-28 19:33:49,874 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
om_1        | 2019-10-28 19:33:52,625 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for om/6045f1ad9083@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
om_1        | 2019-10-28 19:33:52,637 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Principal "om/6045f1ad9083@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
om_1        | 2019-10-28 19:33:55,290 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-28 19:33:55,301 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
kdc_1       | Entry for principal om/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.6045f1ad9083.keytab.
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
om_1        | 2019-10-28 19:33:57,978 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
kdc_1       | Entry for principal om/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.6045f1ad9083.keytab.
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
om_1        | 2019-10-28 19:33:57,992 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Generiting keytab
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
om_1        | 2019-10-28 19:34:00,629 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
om_1        | 2019-10-28 19:34:00,645 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | WARNING: no policy specified for HTTP/6440263c42ed@EXAMPLE.COM; defaulting to no policy
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 2019-10-28 19:34:03,408 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Principal "HTTP/6440263c42ed@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-28 19:34:03,421 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
kdc_1       | Entry for principal HTTP/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.6440263c42ed.keytab.
om_1        | 2019-10-28 19:34:06,077 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
kdc_1       | Entry for principal HTTP/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.6440263c42ed.keytab.
om_1        | 2019-10-28 19:34:06,089 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-28 19:34:12,357 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-10-28 19:34:12,371 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:37:13,233 INFO ipc.Server: IPC Server handler 6 on 9861 caught an exception
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-28 19:34:13,039 [IPC Server handler 4 on 9862] INFO       - created volume:fstest62 for user:testuser/scm@EXAMPLE.COM
kdc_1       | WARNING: no policy specified for HTTP/62d67d27c24f@EXAMPLE.COM; defaulting to no policy
scm_1       | java.nio.channels.AsynchronousCloseException
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-28 19:34:15,041 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "HTTP/62d67d27c24f@EXAMPLE.COM" created.
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-28 19:34:15,053 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-28 19:34:15,770 [IPC Server handler 0 on 9862] INFO       - created volume:fstest262 for user:testuser/scm@EXAMPLE.COM
kdc_1       | Entry for principal HTTP/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.62d67d27c24f.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-10-28 19:34:17,802 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.62d67d27c24f.keytab.
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-28 19:34:17,815 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Generiting keytab
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-28 19:34:20,513 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-28 19:34:20,525 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | WARNING: no policy specified for HTTP/scm@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-10-28 19:34:23,227 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "HTTP/scm@EXAMPLE.COM" created.
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-28 19:34:23,238 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-28 19:34:26,172 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
om_1        | 2019-10-28 19:34:26,185 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290973, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 2019-10-28 19:34:28,752 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-28 19:34:28,767 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 2019-10-28 19:34:29,564 [IPC Server handler 15 on 9862] INFO       - created volume:fstest362 for user:testuser/scm@EXAMPLE.COM
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 2019-10-28 19:34:31,527 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-10-28 19:34:31,540 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
scm_1       | 2019-10-28 19:37:13,233 INFO ipc.Server: IPC Server handler 7 on 9861 caught an exception
om_1        | 2019-10-28 19:34:34,313 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
scm_1       | java.nio.channels.AsynchronousCloseException
om_1        | 2019-10-28 19:34:34,325 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
om_1        | 2019-10-28 19:34:36,993 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-28 19:34:37,005 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-28 19:34:39,511 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-28 19:34:39,523 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-28 19:34:42,143 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-28 19:34:42,152 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-28 19:34:44,839 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-28 19:34:44,850 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-28 19:34:47,324 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-28 19:34:47,336 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-28 19:34:49,897 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-28 19:34:49,907 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-28 19:34:52,573 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-28 19:34:52,585 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-28 19:34:55,245 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:37:31,542 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-28 19:34:55,256 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:37:31,543 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-28 19:34:55,986 [IPC Server handler 7 on 9862] ERROR      - Add acl [user:superuser1:rwxy[ACCESS]] to path /fstest362/bk1 failed, because acl already exist
scm_1       | 2019-10-28 19:37:41,829 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:34:58,003 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
scm_1       | 2019-10-28 19:37:41,829 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-28 19:34:58,017 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Generiting keytab
scm_1       | 2019-10-28 19:37:41,829 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:35:00,604 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:37:41,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 2019-10-28 19:35:00,615 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:37:41,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | WARNING: no policy specified for HTTP/s3g@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-28 19:35:03,161 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:37:41,833 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Principal "HTTP/s3g@EXAMPLE.COM" created.
om_1        | 2019-10-28 19:35:03,170 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2019-10-28 19:37:57,261 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-28 19:35:05,839 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
scm_1       | 2019-10-28 19:37:57,263 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
om_1        | 2019-10-28 19:35:05,850 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
scm_1       | 2019-10-28 19:38:11,823 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
scm_1       | 2019-10-28 19:38:11,828 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
om_1        | 2019-10-28 19:35:08,359 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
scm_1       | 2019-10-28 19:38:11,831 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-28 19:35:08,371 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
scm_1       | 2019-10-28 19:38:11,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:35:10,787 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for HTTP/om@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-28 19:38:11,837 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-28 19:35:10,800 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Principal "HTTP/om@EXAMPLE.COM" created.
scm_1       | 2019-10-28 19:38:11,843 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-28 19:35:14,971 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:38:22,901 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 2019-10-28 19:35:14,981 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:38:22,903 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-28 19:35:17,523 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:38:37,289 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:35:17,534 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:38:37,291 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-28 19:35:20,144 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:38:41,833 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:35:20,159 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:38:41,835 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:35:22,747 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
scm_1       | 2019-10-28 19:38:41,836 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:35:22,758 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:38:41,837 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-28 19:35:25,469 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:38:41,838 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
scm_1       | 2019-10-28 19:38:41,841 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:35:25,482 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
scm_1       | 2019-10-28 19:38:49,533 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
om_1        | 2019-10-28 19:35:28,185 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
scm_1       | 2019-10-28 19:38:49,533 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103041692568453250 bcsId: 0
om_1        | 2019-10-28 19:35:28,194 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
scm_1       | 2019-10-28 19:38:49,533 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103041693056696451 bcsId: 0
om_1        | 2019-10-28 19:35:30,696 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-28 19:35:30,705 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:35:33,405 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:38:49,533 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103041694253908100 bcsId: 0
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:35:33,417 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-10-28 19:35:36,118 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:39:11,822 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 2019-10-28 19:35:36,130 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:39:11,823 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-28 19:35:36,846 [IPC Server handler 3 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume
scm_1       | 2019-10-28 19:39:11,825 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-28 19:35:38,858 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:39:11,829 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-28 19:35:38,870 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:39:11,835 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:35:39,501 [IPC Server handler 17 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
scm_1       | 2019-10-28 19:39:11,839 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:35:41,461 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
scm_1       | 2019-10-28 19:39:41,820 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm_1       | 2019-10-28 19:39:41,822 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:35:41,473 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:39:41,823 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:35:42,111 [IPC Server handler 8 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm_1       | 2019-10-28 19:39:41,829 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:35:42,111 [IPC Server handler 8 on 9862] ERROR      - Add acl user:testuser2/scm@EXAMPLE.COM:xy[ACCESS] to volume fstest362 failed!
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2019-10-28 19:39:41,830 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | PERMISSION_DENIED org.apache.hadoop.ozone.om.exceptions.OMException: User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2019-10-28 19:39:41,833 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1628)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
scm_1       | 2019-10-28 19:39:49,627 INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 3 containers.
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:135)
s3g_1       | 	... 92 more
scm_1       | 2019-10-28 19:39:53,769 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.acl.OMVolumeAclRequest.validateAndUpdateCache(OMVolumeAclRequest.java:79)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:39:53,771 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:40:08,200 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028T193651Z
scm_1       | 2019-10-28 19:40:08,202 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:40:11,826 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:40:11,827 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:40:11,827 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:40:11,830 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 2019-10-28 19:40:11,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 2019-10-28 19:40:11,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 2019-10-28 19:40:41,718 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 2019-10-28 19:40:41,721 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 2019-10-28 19:40:41,825 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 2019-10-28 19:40:41,827 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 2019-10-28 19:40:41,828 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-28 19:35:44,076 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:40:41,828 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-28 19:35:44,087 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:40:41,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:40:41,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-28 19:35:46,639 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:40:49,550 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:35:46,653 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:40:49,550 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103041705031893133 bcsId: 0
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:41:11,831 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
kdc_1       | Oct 28 19:29:34 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-28 19:41:11,832 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:35:47,422 [IPC Server handler 15 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access volume
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-28 19:41:11,832 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:35:49,468 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:41:11,834 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:35:49,479 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-28 19:41:11,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:35:51,940 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2019-10-28 19:41:11,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:35:51,953 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2019-10-28 19:41:35,356 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
om_1        | 2019-10-28 19:35:54,511 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-28 19:35:54,520 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:41:35,357 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Generiting keytab
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
scm_1       | 2019-10-28 19:41:41,822 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:35:57,235 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
scm_1       | 2019-10-28 19:41:41,825 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:35:57,245 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | WARNING: no policy specified for scm/c004515c1151@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-28 19:41:41,825 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	... 101 more
om_1        | 2019-10-28 19:35:57,865 [IPC Server handler 4 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket
kdc_1       | Principal "scm/c004515c1151@EXAMPLE.COM" created.
scm_1       | 2019-10-28 19:41:41,826 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 
om_1        | 2019-10-28 19:36:00,002 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:41:41,828 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 
om_1        | 2019-10-28 19:36:00,013 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Entry for principal scm/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.c004515c1151.keytab.
s3g_1       | 2019-10-28 19:36:51,351 WARN servlet.ServletHandler: 
om_1        | 2019-10-28 19:36:02,799 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:41:41,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal scm/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.c004515c1151.keytab.
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-28 19:36:02,811 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Generiting keytab
scm_1       | 2019-10-28 19:41:49,580 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-28 19:36:05,758 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:41:49,580 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103041709252214936 bcsId: 0,conID: 1 locID: 103041709252411545 bcsId: 0,conID: 2 locID: 103041709251231895 bcsId: 0
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 
om_1        | 2019-10-28 19:36:05,770 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-28 19:41:49,581 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103041708546982037 bcsId: 0
kdc_1       | WARNING: no policy specified for scm/6045f1ad9083@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 2019-10-28 19:36:08,477 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-28 19:41:49,581 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103041708615532694 bcsId: 0
kdc_1       | Principal "scm/6045f1ad9083@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:42:11,823 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:36:08,491 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Entry for principal scm/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.6045f1ad9083.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
scm_1       | 2019-10-28 19:42:11,824 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:36:43,184 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal scm/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.6045f1ad9083.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
scm_1       | 2019-10-28 19:42:11,825 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:36:43,195 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Generiting keytab
om_1        | 2019-10-28 19:36:47,142 [Socket Reader #1 for port 9862] INFO       - 1098c7b735dc71415b4c001e15aa054d6c2034b6e9ee85ffc5546d2349b33416
scm_1       | 2019-10-28 19:42:11,826 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-28 19:36:47,146 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-28 19:36:47,160 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | WARNING: no policy specified for testuser/6440263c42ed@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-28 19:42:11,827 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-28 19:36:48,512 [Socket Reader #1 for port 9862] INFO       - 1098c7b735dc71415b4c001e15aa054d6c2034b6e9ee85ffc5546d2349b33416
kdc_1       | Principal "testuser/6440263c42ed@EXAMPLE.COM" created.
scm_1       | 2019-10-28 19:42:11,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:36:48,513 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:42:23,676 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-28 19:36:48,517 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Entry for principal testuser/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.6440263c42ed.keytab.
scm_1       | 2019-10-28 19:42:23,678 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:36:51,255 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal testuser/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.6440263c42ed.keytab.
scm_1       | 2019-10-28 19:42:41,821 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Generiting keytab
om_1        | 20191028T193651Z
scm_1       | 2019-10-28 19:42:41,822 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 20191028/us-west-1/s3/aws4_request
scm_1       | 2019-10-28 19:42:41,826 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
kdc_1       | WARNING: no policy specified for testuser/62d67d27c24f@EXAMPLE.COM; defaulting to no policy
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-28 19:42:41,827 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Principal "testuser/62d67d27c24f@EXAMPLE.COM" created.
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
scm_1       | 2019-10-28 19:42:41,830 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
scm_1       | 2019-10-28 19:42:41,833 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal testuser/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.62d67d27c24f.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
scm_1       | 2019-10-28 19:42:52,527 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal testuser/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.62d67d27c24f.keytab.
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
scm_1       | 2019-10-28 19:42:52,529 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Generiting keytab
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
scm_1       | 2019-10-28 19:43:07,856 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
scm_1       | 2019-10-28 19:43:07,858 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
kdc_1       | WARNING: no policy specified for testuser/scm@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Principal "testuser/scm@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
scm_1       | 2019-10-28 19:43:11,827 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
scm_1       | 2019-10-28 19:43:11,828 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
scm_1       | 2019-10-28 19:43:11,829 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
scm_1       | 2019-10-28 19:43:11,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
scm_1       | 2019-10-28 19:43:11,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | WARNING: no policy specified for testuser/s3g@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
scm_1       | 2019-10-28 19:43:11,834 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Principal "testuser/s3g@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
scm_1       | 2019-10-28 19:43:30,696 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
scm_1       | 2019-10-28 19:43:30,698 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
scm_1       | 2019-10-28 19:43:41,832 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
scm_1       | 2019-10-28 19:43:41,833 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
scm_1       | 2019-10-28 19:43:41,834 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Generiting keytab
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2019-10-28 19:43:41,835 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-28 19:43:41,837 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-28 19:36:51,257 WARN ipc.Server: Auth failed for 172.18.0.4:54246:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | WARNING: no policy specified for testuser/om@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-28 19:43:41,839 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 20191028T193651Z
s3g_1       | 
scm_1       | 2019-10-28 19:43:49,598 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 5 blocks
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Principal "testuser/om@EXAMPLE.COM" created.
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
scm_1       | 2019-10-28 19:43:49,599 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103041716105969829 bcsId: 0
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-28 19:36:51,269 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-28 19:43:49,600 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103041716154073254 bcsId: 0
kdc_1       | Entry for principal testuser/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.om.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 20191028T193651Z
scm_1       | 2019-10-28 19:43:49,600 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103041713604526242 bcsId: 0
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 20191028/us-west-1/s3/aws4_request
scm_1       | 2019-10-28 19:43:49,600 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103041714609127587 bcsId: 0
kdc_1       | Entry for principal testuser/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.om.keytab.
kdc_1       | Generiting keytab
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-28 19:43:49,601 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103041715167035556 bcsId: 0
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
scm_1       | 2019-10-28 19:44:11,849 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
scm_1       | 2019-10-28 19:44:11,859 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:44:11,863 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:44:11,865 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:44:11,869 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:29:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290974, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:44:11,877 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
scm_1       | 2019-10-28 19:44:41,826 INFO ipc.Server: Auth successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-28 19:44:41,827 INFO ipc.Server: Auth successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:44:41,829 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/62d67d27c24f@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:44:41,838 INFO ipc.Server: Auth successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
scm_1       | 2019-10-28 19:44:41,839 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6440263c42ed@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
scm_1       | 2019-10-28 19:44:41,843 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c004515c1151@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:44:49,628 INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 3 containers.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-28 19:44:55,512 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:44:55,523 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-28 19:36:51,270 WARN ipc.Server: Auth failed for 172.18.0.4:54248:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-28 19:44:55,734 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-28 19:44:55,738 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-28 19:36:51,275 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193651Z
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	... 33 more
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | WARNING: no policy specified for HTTP/c004515c1151@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Principal "HTTP/c004515c1151@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Entry for principal HTTP/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.c004515c1151.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Entry for principal HTTP/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.c004515c1151.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | WARNING: no policy specified for HTTP/6045f1ad9083@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:36:51,275 WARN ipc.Server: Auth failed for 172.18.0.4:54250:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Principal "HTTP/6045f1ad9083@EXAMPLE.COM" created.
om_1        | 20191028T193651Z
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Entry for principal HTTP/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.6045f1ad9083.keytab.
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | Entry for principal HTTP/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.6045f1ad9083.keytab.
om_1        | 2019-10-28 19:36:51,283 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191028T193651Z
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	... 60 more
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:36:51,284 WARN ipc.Server: Auth failed for 172.18.0.4:54252:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191028T193651Z
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:36:51,291 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191028T193651Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	... 92 more
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-28 19:36:51,292 WARN ipc.Server: Auth failed for 172.18.0.4:54254:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-28 19:36:51,297 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028T193651Z
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	... 101 more
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 2019-10-28 19:36:51,357 WARN server.HttpChannel: //s3g:9878/bucket-test123
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
kdc_1       | Oct 28 19:29:35 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | WARNING: no policy specified for testuser2/6440263c42ed@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Principal "testuser2/6440263c42ed@EXAMPLE.COM" created.
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-28 19:36:51,297 WARN ipc.Server: Auth failed for 172.18.0.4:54256:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 20191028T193651Z
kdc_1       | Entry for principal testuser2/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.6440263c42ed.keytab.
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Entry for principal testuser2/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.6440263c42ed.keytab.
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Generiting keytab
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-28 19:36:51,302 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 20191028T193651Z
s3g_1       | 
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
kdc_1       | WARNING: no policy specified for testuser2/62d67d27c24f@EXAMPLE.COM; defaulting to no policy
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
kdc_1       | Principal "testuser2/62d67d27c24f@EXAMPLE.COM" created.
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
kdc_1       | Entry for principal testuser2/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.62d67d27c24f.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Entry for principal testuser2/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.62d67d27c24f.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Generiting keytab
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | WARNING: no policy specified for testuser2/scm@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Principal "testuser2/scm@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Generiting keytab
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | WARNING: no policy specified for testuser2/s3g@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Principal "testuser2/s3g@EXAMPLE.COM" created.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Entry for principal testuser2/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.s3g.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Entry for principal testuser2/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.s3g.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | WARNING: no policy specified for testuser2/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Principal "testuser2/om@EXAMPLE.COM" created.
s3g_1       | 	... 13 more
om_1        | 2019-10-28 19:36:51,302 WARN ipc.Server: Auth failed for 172.18.0.4:54258:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 20191028T193651Z
kdc_1       | Entry for principal testuser2/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.om.keytab.
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Entry for principal testuser2/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.om.keytab.
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | WARNING: no policy specified for testuser/c004515c1151@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
kdc_1       | Principal "testuser/c004515c1151@EXAMPLE.COM" created.
om_1        | 2019-10-28 19:36:51,307 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 20191028T193651Z
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Entry for principal testuser/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.c004515c1151.keytab.
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
kdc_1       | Entry for principal testuser/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.c004515c1151.keytab.
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Generiting keytab
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | WARNING: no policy specified for testuser/6045f1ad9083@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Principal "testuser/6045f1ad9083@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Entry for principal testuser/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.6045f1ad9083.keytab.
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Entry for principal testuser/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.6045f1ad9083.keytab.
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | WARNING: no policy specified for s3g/6440263c42ed@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Principal "s3g/6440263c42ed@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Entry for principal s3g/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.6440263c42ed.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Entry for principal s3g/6440263c42ed@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.6440263c42ed.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	... 33 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:29:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290975, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-10-28 19:36:51,307 WARN ipc.Server: Auth failed for 172.18.0.4:54260:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191028T193651Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-28 19:36:51,312 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-28 19:36:51,312 WARN ipc.Server: Auth failed for 172.18.0.4:54262:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 20191028T193651Z
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-28 19:36:51,320 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191028T193651Z
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | WARNING: no policy specified for s3g/62d67d27c24f@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Principal "s3g/62d67d27c24f@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Entry for principal s3g/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.62d67d27c24f.keytab.
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
kdc_1       | Entry for principal s3g/62d67d27c24f@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.62d67d27c24f.keytab.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	... 60 more
kdc_1       | WARNING: no policy specified for s3g/scm@EXAMPLE.COM; defaulting to no policy
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
kdc_1       | Principal "s3g/scm@EXAMPLE.COM" created.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:36:51,320 WARN ipc.Server: Auth failed for 172.18.0.4:54264:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	... 92 more
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:36:51,327 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028T193651Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-28 19:36:51,328 WARN ipc.Server: Auth failed for 172.18.0.4:54266:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	... 101 more
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
s3g_1       | 2019-10-28 19:36:51,701 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191028T193651Z
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:36:51,700 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
s3g_1       | 2019-10-28 19:36:51,706 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191028T193651Z
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 2019-10-28 19:36:51,707 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 2019-10-28 19:36:51,711 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 2019-10-28 19:36:51,713 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/6440263c42ed@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 2019-10-28 19:36:51,717 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](info): closing down fd 18
s3g_1       | 2019-10-28 19:36:51,717 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:36:51,700 WARN ipc.Server: Auth failed for 172.18.0.4:54272:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191028T193651Z
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/62d67d27c24f@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:51,721 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191028T193651Z
om_1        | 2019-10-28 19:36:51,705 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal s3g/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.scm.keytab.
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 20191028T193651Z
kdc_1       | Entry for principal s3g/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.scm.keytab.
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 2019-10-28 19:36:51,722 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Generiting keytab
s3g_1       | 20191028T193651Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
kdc_1       | WARNING: no policy specified for s3g/s3g@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 2019-10-28 19:36:51,726 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Principal "s3g/s3g@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191028T193651Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 2019-10-28 19:36:51,726 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 20191028T193651Z
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 2019-10-28 19:36:51,731 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | WARNING: no policy specified for s3g/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Principal "s3g/om@EXAMPLE.COM" created.
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-10-28 19:36:51,731 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Entry for principal s3g/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.om.keytab.
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Entry for principal s3g/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.om.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-10-28 19:36:51,735 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | WARNING: no policy specified for testuser2/c004515c1151@EXAMPLE.COM; defaulting to no policy
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Principal "testuser2/c004515c1151@EXAMPLE.COM" created.
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:36:51,706 WARN ipc.Server: Auth failed for 172.18.0.4:54274:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal testuser2/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.c004515c1151.keytab.
om_1        | 20191028T193651Z
s3g_1       | 2019-10-28 19:36:51,735 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal testuser2/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.c004515c1151.keytab.
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 20191028T193651Z
kdc_1       | Generiting keytab
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-28 19:36:51,710 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
kdc_1       | WARNING: no policy specified for testuser2/6045f1ad9083@EXAMPLE.COM; defaulting to no policy
om_1        | 20191028T193651Z
s3g_1       | 2019-10-28 19:36:51,740 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Principal "testuser2/6045f1ad9083@EXAMPLE.COM" created.
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 20191028T193651Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Entry for principal testuser2/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.6045f1ad9083.keytab.
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Entry for principal testuser2/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.6045f1ad9083.keytab.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 2019-10-28 19:36:51,741 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Generiting keytab
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | WARNING: no policy specified for s3g/c004515c1151@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
kdc_1       | Principal "s3g/c004515c1151@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 2019-10-28 19:36:51,744 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Entry for principal s3g/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.c004515c1151.keytab.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 20191028T193651Z
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Entry for principal s3g/c004515c1151@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.c004515c1151.keytab.
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Generiting keytab
s3g_1       | 2019-10-28 19:36:51,745 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290976, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 2019-10-28 19:36:51,749 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 2019-10-28 19:36:51,749 [qtp262445056-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 2019-10-28 19:36:51,750 [qtp262445056-27] ERROR      - Couldn't create RpcClient protocol exception: 
om_1        | 2019-10-28 19:36:51,711 WARN ipc.Server: Auth failed for 172.18.0.4:54276:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191028T193651Z
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-28 19:36:51,716 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
kdc_1       | Oct 28 19:29:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290977, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:36:51,716 WARN ipc.Server: Auth failed for 172.18.0.4:54278:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
om_1        | 20191028T193651Z
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:36:51,720 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028T193651Z
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-28 19:36:51,721 WARN ipc.Server: Auth failed for 172.18.0.4:54280:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-28 19:36:51,725 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/c004515c1151@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:29:37 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | WARNING: no policy specified for s3g/6045f1ad9083@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Principal "s3g/6045f1ad9083@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
kdc_1       | Oct 28 19:29:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290978, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:29:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
kdc_1       | Oct 28 19:29:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290978, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
kdc_1       | Entry for principal s3g/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.6045f1ad9083.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Entry for principal s3g/6045f1ad9083@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.6045f1ad9083.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:29:38 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:29:38 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:29:38 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:29:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:29:38 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:29:38 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/6045f1ad9083@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:29:38 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-28 19:36:51,725 WARN ipc.Server: Auth failed for 172.18.0.4:54282:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:39 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.6: ISSUE: authtime 1572290979, etypes {rep=18 tkt=18 ses=18}, dn/6440263c42ed@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 20191028T193651Z
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 28 19:29:39 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.8: ISSUE: authtime 1572290979, etypes {rep=18 tkt=18 ses=18}, dn/62d67d27c24f@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:40 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.10: ISSUE: authtime 1572290980, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Oct 28 19:29:40 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.5: ISSUE: authtime 1572290980, etypes {rep=18 tkt=18 ses=18}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-28 19:36:51,730 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:41 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.7: ISSUE: authtime 1572290981, etypes {rep=18 tkt=18 ses=18}, dn/c004515c1151@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290981, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290983, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:29:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1572290979, etypes {rep=18 tkt=18 ses=18}, dn/6440263c42ed@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Oct 28 19:29:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.7: ISSUE: authtime 1572290981, etypes {rep=18 tkt=18 ses=18}, dn/c004515c1151@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Oct 28 19:29:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572290979, etypes {rep=18 tkt=18 ses=18}, dn/62d67d27c24f@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572290980, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:29:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290986, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 28 19:29:46 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290986, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:29:47 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.10: ISSUE: authtime 1572290987, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572290987, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290988, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Oct 28 19:29:49 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290988, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 28 19:29:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290991, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:29:51 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572290991, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | WARNING: no policy specified for dn/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Principal "dn/recon@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Entry for principal dn/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-28 19:36:51,730 WARN ipc.Server: Auth failed for 172.18.0.4:54284:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal dn/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.recon.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 20191028T193651Z
kdc_1       | Generiting keytab
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | WARNING: no policy specified for om/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-28 19:36:51,734 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
kdc_1       | Principal "om/recon@EXAMPLE.COM" created.
om_1        | 20191028T193651Z
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290995, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290995, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290995, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290995, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Entry for principal om/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.recon.keytab.
s3g_1       | Oct 28, 2019 7:36:51 PM org.glassfish.jersey.internal.Errors logErrors
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Entry for principal om/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.recon.keytab.
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Generiting keytab
s3g_1       | MultiException stack 1 of 1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | WARNING: no policy specified for scm/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Principal "scm/recon@EXAMPLE.COM" created.
om_1        | 2019-10-28 19:36:51,734 WARN ipc.Server: Auth failed for 172.18.0.4:54286:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 20191028T193651Z
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Entry for principal scm/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.recon.keytab.
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Entry for principal scm/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.recon.keytab.
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | WARNING: no policy specified for HTTP/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
kdc_1       | Principal "HTTP/recon@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Generiting keytab
om_1        | 2019-10-28 19:36:51,738 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 20191028T193651Z
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | WARNING: no policy specified for testuser/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Principal "testuser/recon@EXAMPLE.COM" created.
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Entry for principal testuser/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.recon.keytab.
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Entry for principal testuser/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.recon.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | WARNING: no policy specified for testuser2/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | Principal "testuser2/recon@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
kdc_1       | Entry for principal testuser2/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.recon.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
kdc_1       | Entry for principal testuser2/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | WARNING: no policy specified for s3g/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Principal "s3g/recon@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Entry for principal s3g/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.recon.keytab.
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Entry for principal s3g/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-28 19:36:51,740 WARN ipc.Server: Auth failed for 172.18.0.4:54288:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-28 19:36:51,744 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028T193651Z
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](info): closing down fd 18
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 28 19:29:55 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-28 19:36:51,744 WARN ipc.Server: Auth failed for 172.18.0.4:54290:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-28 19:36:51,748 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191028T193651Z
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](info): closing down fd 18
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:29:56 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290995, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-28 19:36:51,748 WARN ipc.Server: Auth failed for 172.18.0.4:54292:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 20191028T193651Z
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290995, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 28 19:29:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290995, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290996, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290996, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-28 19:36:53,565 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290996, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191028T193653Z
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290996, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290996, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290996, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:29:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572290996, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 28 19:30:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291002, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 28 19:30:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291004, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 28 19:30:04 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291004, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 28 19:30:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291004, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:30:23 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:30:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 28 19:30:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	... 92 more
kdc_1       | Oct 28 19:30:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:30:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 28 19:30:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:30:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:30:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:30:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:30:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Oct 28 19:30:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Oct 28 19:30:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 28 19:30:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Oct 28 19:31:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,566 WARN ipc.Server: Auth failed for 172.18.0.4:54302:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:31:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:31:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Oct 28 19:31:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 28 19:31:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Oct 28 19:31:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291023, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,573 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Oct 28 19:31:15 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
kdc_1       | Oct 28 19:31:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:31:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:31:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:31:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 28 19:31:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:31:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:31:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:31:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291075, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:31:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 28 19:31:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 28 19:31:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 28 19:31:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	... 101 more
kdc_1       | Oct 28 19:31:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 
kdc_1       | Oct 28 19:31:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 
kdc_1       | Oct 28 19:31:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 2019-10-28 19:36:51,755 WARN servlet.ServletHandler: 
kdc_1       | Oct 28 19:31:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 28 19:31:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291096, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 28 19:31:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:32:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:32:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:32:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-28 19:36:53,574 WARN ipc.Server: Auth failed for 172.18.0.4:54304:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Oct 28 19:32:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
kdc_1       | Oct 28 19:32:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | Oct 28 19:32:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 28 19:32:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Oct 28 19:32:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291118, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,581 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:32:22 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 20191028T193653Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Oct 28 19:32:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Oct 28 19:32:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
kdc_1       | Oct 28 19:32:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Oct 28 19:32:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Oct 28 19:32:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Oct 28 19:32:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Oct 28 19:32:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
kdc_1       | Oct 28 19:32:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Oct 28 19:32:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
kdc_1       | Oct 28 19:32:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Oct 28 19:32:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:32:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:33:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
kdc_1       | Oct 28 19:33:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 28 19:33:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Oct 28 19:33:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Oct 28 19:33:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 28 19:33:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291142, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:33:14 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Oct 28 19:33:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 28 19:33:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 28 19:33:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 28 19:33:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 28 19:33:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,582 WARN ipc.Server: Auth failed for 172.18.0.4:54306:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 28 19:33:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:33:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:33:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 2019-10-28 19:36:53,591 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:33:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 20191028T193653Z
kdc_1       | Oct 28 19:33:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:33:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:33:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
kdc_1       | Oct 28 19:33:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
kdc_1       | Oct 28 19:33:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 28 19:33:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
kdc_1       | Oct 28 19:34:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Oct 28 19:34:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Oct 28 19:34:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291194, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Oct 28 19:34:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Oct 28 19:34:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:34:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:34:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:34:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
kdc_1       | Oct 28 19:34:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 28 19:34:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 28 19:34:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 28 19:34:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 28 19:34:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Oct 28 19:34:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Oct 28 19:34:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,591 WARN ipc.Server: Auth failed for 172.18.0.4:54308:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Oct 28 19:34:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Oct 28 19:34:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Oct 28 19:34:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Oct 28 19:34:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Oct 28 19:34:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:34:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	... 33 more
om_1        | 2019-10-28 19:36:53,598 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:34:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | Caused by: javax.enterprise.inject.CreationException
kdc_1       | Oct 28 19:35:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 20191028T193653Z
kdc_1       | Oct 28 19:35:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:35:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:35:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:35:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 28 19:35:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:35:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:35:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:35:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
kdc_1       | Oct 28 19:35:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
kdc_1       | Oct 28 19:35:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
kdc_1       | Oct 28 19:35:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
kdc_1       | Oct 28 19:35:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291250, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Oct 28 19:35:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291334, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:35:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291334, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:35:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291334, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:35:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291334, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:35:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291342, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 28 19:35:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291342, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:35:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291344, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:35:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291344, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:35:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291344, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Oct 28 19:35:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291344, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Oct 28 19:35:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291344, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:35:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291344, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-28 19:36:53,599 WARN ipc.Server: Auth failed for 172.18.0.4:54310:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:35:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291358, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 20191028T193653Z
kdc_1       | Oct 28 19:35:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291358, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:36:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291358, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:36:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291363, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
kdc_1       | Oct 28 19:36:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291363, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
kdc_1       | Oct 28 19:36:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291363, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
kdc_1       | Oct 28 19:36:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291369, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,604 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 28 19:36:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 28 19:36:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 28 19:37:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:37:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:37:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
kdc_1       | Oct 28 19:37:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
kdc_1       | Oct 28 19:37:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 28 19:37:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Oct 28 19:37:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
kdc_1       | Oct 28 19:37:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
kdc_1       | Oct 28 19:37:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
kdc_1       | Oct 28 19:37:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:37:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:37:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:37:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	... 60 more
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
kdc_1       | Oct 28 19:37:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Oct 28 19:37:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 28 19:37:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 28 19:37:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 28 19:38:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 28 19:38:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:38:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 28 19:38:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:38:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-28 19:36:53,605 WARN ipc.Server: Auth failed for 172.18.0.4:54312:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:38:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191028T193653Z
kdc_1       | Oct 28 19:38:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 28 19:38:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	... 92 more
kdc_1       | Oct 28 19:38:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,611 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:38:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 20191028T193651Z
kdc_1       | Oct 28 19:38:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:38:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:38:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
kdc_1       | Oct 28 19:38:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Oct 28 19:38:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Oct 28 19:38:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 28 19:38:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 28 19:38:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:38:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Oct 28 19:39:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 28 19:39:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Oct 28 19:39:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Oct 28 19:39:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
kdc_1       | Oct 28 19:39:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 28 19:39:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291591, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
kdc_1       | Oct 28 19:39:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291591, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
kdc_1       | Oct 28 19:39:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291598, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 28 19:40:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291598, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 28 19:40:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291613, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 28 19:40:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291613, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 28 19:40:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291620, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-28 19:36:53,611 WARN ipc.Server: Auth failed for 172.18.0.4:54314:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 20191028T193653Z
kdc_1       | Oct 28 19:40:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291620, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:40:27 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291627, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 28 19:40:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291627, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,617 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 28 19:40:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291634, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 	... 101 more
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 2019-10-28 19:36:51,757 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:40:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291634, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 28 19:40:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291644, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 28 19:40:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291644, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:40:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291654, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Oct 28 19:40:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291654, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
kdc_1       | Oct 28 19:41:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291662, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
kdc_1       | Oct 28 19:41:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291662, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
kdc_1       | Oct 28 19:41:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291670, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:41:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291670, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Oct 28 19:41:17 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291677, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Oct 28 19:41:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291677, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 28 19:41:23 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291683, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 28 19:41:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291683, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Oct 28 19:41:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291689, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 28 19:41:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291689, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 28 19:41:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291700, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 28 19:41:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291700, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 28 19:41:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291709, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 28 19:41:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291709, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 
kdc_1       | Oct 28 19:41:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291719, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 28 19:42:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291719, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 28 19:42:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291730, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
kdc_1       | Oct 28 19:42:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291730, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,618 WARN ipc.Server: Auth failed for 172.18.0.4:54316:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
kdc_1       | Oct 28 19:42:17 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291737, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
kdc_1       | Oct 28 19:42:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291737, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Oct 28 19:42:28 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291748, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Oct 28 19:42:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291748, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,623 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 20191028T193653Z
kdc_1       | Oct 28 19:42:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291754, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:42:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291754, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:42:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291760, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:42:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291760, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 28 19:42:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291766, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 28 19:42:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291766, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 28 19:42:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291775, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 28 19:42:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291775, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Oct 28 19:43:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291782, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 28 19:43:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291782, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 28 19:43:11 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291791, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Oct 28 19:43:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291791, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:43:19 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291799, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 28 19:43:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291799, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 28 19:43:25 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291805, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	... 13 more
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 28 19:43:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291805, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 28 19:43:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291815, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 28 19:43:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291815, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 
kdc_1       | Oct 28 19:43:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291823, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
kdc_1       | Oct 28 19:43:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291823, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
kdc_1       | Oct 28 19:43:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291829, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
kdc_1       | Oct 28 19:43:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291829, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 28 19:43:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291836, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 28 19:43:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291836, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,624 WARN ipc.Server: Auth failed for 172.18.0.4:54318:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 28 19:44:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291842, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191028T193653Z
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 20191028/us-west-1/s3/aws4_request
kdc_1       | Oct 28 19:44:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291842, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 28 19:44:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291849, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2019-10-28 19:36:53,629 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 20191028T193653Z
kdc_1       | Oct 28 19:44:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291849, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 28 19:44:15 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291855, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 28 19:44:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291855, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Oct 28 19:44:22 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291862, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:44:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291862, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:44:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291869, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 28 19:44:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291869, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
kdc_1       | Oct 28 19:44:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291875, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 28 19:44:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291875, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 28 19:44:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291882, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 28 19:44:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291882, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 28 19:44:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291887, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 28 19:44:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572291887, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Oct 28 19:44:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291891, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Oct 28 19:44:51 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.4: ISSUE: authtime 1572291891, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Oct 28 19:44:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572291401, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	... 33 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-10-28 19:36:53,630 WARN ipc.Server: Auth failed for 172.18.0.4:54320:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 20191028T193653Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-10-28 19:36:53,636 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 20191028T193653Z
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-28 19:36:53,636 WARN ipc.Server: Auth failed for 172.18.0.4:54322:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 20191028T193653Z
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-28 19:36:54,686 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193654Z
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	... 60 more
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	... 92 more
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 20191028T193651Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 5543a1016415ce5f47b50e70f2e39cc86e1fa3a5203c81dddf168aef8658f09e, signature=5f789edac8c7959ec70f0309cccb7f2bf3d9ccb25e7518afd44bfdfe7eec4ee6, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-28 19:36:54,687 WARN ipc.Server: Auth failed for 172.18.0.4:54330:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 20191028T193654Z
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-28 19:36:54,695 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193654Z
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	... 101 more
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 2019-10-28 19:36:53,567 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-28 19:36:54,696 WARN ipc.Server: Auth failed for 172.18.0.4:54332:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 20191028T193654Z
s3g_1       | 2019-10-28 19:36:53,575 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 20191028T193653Z
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:36:54,703 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 20191028T193654Z
s3g_1       | 2019-10-28 19:36:53,575 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 20191028T193653Z
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 2019-10-28 19:36:53,584 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:53,585 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 2019-10-28 19:36:53,592 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 2019-10-28 19:36:53,593 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-28 19:36:54,703 WARN ipc.Server: Auth failed for 172.18.0.4:54334:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 20191028T193654Z
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 2019-10-28 19:36:53,599 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 20191028T193653Z
om_1        | 2019-10-28 19:36:54,710 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 20191028T193654Z
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:53,600 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 20191028T193653Z
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 2019-10-28 19:36:53,606 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:53,606 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:53,612 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 2019-10-28 19:36:53,613 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
om_1        | 2019-10-28 19:36:54,711 WARN ipc.Server: Auth failed for 172.18.0.4:54336:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-10-28 19:36:53,619 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193653Z
om_1        | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 2019-10-28 19:36:53,619 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:36:54,718 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193653Z
om_1        | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:53,624 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 2019-10-28 19:36:53,625 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191028T193653Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 2019-10-28 19:36:53,631 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 20191028T193653Z
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 2019-10-28 19:36:53,631 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191028T193653Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 2019-10-28 19:36:53,637 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193653Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 2019-10-28 19:36:53,637 [qtp262445056-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 2019-10-28 19:36:53,638 [qtp262445056-27] ERROR      - Couldn't create RpcClient protocol exception: 
om_1        | 2019-10-28 19:36:54,718 WARN ipc.Server: Auth failed for 172.18.0.4:54338:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193654Z
s3g_1       | 20191028T193653Z
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:36:54,724 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 20191028T193654Z
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-28 19:36:54,725 WARN ipc.Server: Auth failed for 172.18.0.4:54340:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 20191028T193654Z
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-28 19:36:54,730 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 20191028T193654Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-28 19:36:54,732 WARN ipc.Server: Auth failed for 172.18.0.4:54342:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 20191028T193654Z
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:36:54,739 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 20191028T193654Z
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-28 19:36:54,739 WARN ipc.Server: Auth failed for 172.18.0.4:54344:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 20191028T193654Z
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-28 19:36:54,745 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 20191028T193654Z
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 2019-10-28 19:36:54,745 WARN ipc.Server: Auth failed for 172.18.0.4:54346:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 20191028T193654Z
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-28 19:36:54,750 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 20191028T193654Z
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | Oct 28, 2019 7:36:53 PM org.glassfish.jersey.internal.Errors logErrors
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-28 19:36:54,750 WARN ipc.Server: Auth failed for 172.18.0.4:54348:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193654Z
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | MultiException stack 1 of 1
om_1        | 2019-10-28 19:36:54,755 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 20191028T193654Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-28 19:36:54,755 WARN ipc.Server: Auth failed for 172.18.0.4:54350:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 20191028T193654Z
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-28 19:36:57,756 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 20191028T193657Z
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:36:57,757 WARN ipc.Server: Auth failed for 172.18.0.4:54376:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 20191028T193657Z
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-28 19:36:57,762 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193657Z
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-28 19:36:57,762 WARN ipc.Server: Auth failed for 172.18.0.4:54378:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191028T193657Z
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193653Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-28 19:36:57,768 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 20191028T193657Z
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-28 19:36:57,768 WARN ipc.Server: Auth failed for 172.18.0.4:54380:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193657Z
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-28 19:36:57,775 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
om_1        | 20191028T193657Z
s3g_1       | 
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:53,642 WARN servlet.ServletHandler: 
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-28 19:36:57,775 WARN ipc.Server: Auth failed for 172.18.0.4:54382:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 20191028T193657Z
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-28 19:36:57,781 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 20191028T193657Z
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-28 19:36:57,782 WARN ipc.Server: Auth failed for 172.18.0.4:54384:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 20191028T193657Z
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-28 19:36:57,787 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 20191028T193657Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-28 19:36:57,787 WARN ipc.Server: Auth failed for 172.18.0.4:54386:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193657Z
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	... 33 more
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:36:57,792 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 20191028T193657Z
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-28 19:36:57,792 WARN ipc.Server: Auth failed for 172.18.0.4:54388:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191028T193657Z
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-28 19:36:57,798 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 20191028T193657Z
s3g_1       | 	... 60 more
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	... 92 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:36:57,798 WARN ipc.Server: Auth failed for 172.18.0.4:54390:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193653Z
om_1        | 20191028T193657Z
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-28 19:36:57,803 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 20191028T193657Z
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-28 19:36:57,803 WARN ipc.Server: Auth failed for 172.18.0.4:54392:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 20191028T193657Z
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-28 19:36:57,808 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 20191028T193657Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	... 101 more
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 2019-10-28 19:36:53,644 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
om_1        | 2019-10-28 19:36:57,808 WARN ipc.Server: Auth failed for 172.18.0.4:54394:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 20191028T193657Z
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 20191028/us-west-1/s3/aws4_request
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-28 19:36:57,813 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 20191028T193657Z
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-28 19:36:57,814 WARN ipc.Server: Auth failed for 172.18.0.4:54396:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 20191028T193657Z
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 20191028/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-28 19:37:01,711 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-28 19:37:01,726 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-28 19:37:02,437 [IPC Server handler 13 on 9862] INFO       - created volume:fstest for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-28 19:37:04,584 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-28 19:37:04,597 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-28 19:37:05,401 [IPC Server handler 16 on 9862] INFO       - created volume:fstest2 for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-28 19:37:07,598 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-28 19:37:07,610 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-28 19:37:15,983 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-28 19:37:15,998 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-28 19:37:18,968 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-28 19:37:18,981 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-28 19:37:22,135 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:37:22,154 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 33 more
om_1        | 2019-10-28 19:37:25,192 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:37:25,213 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:37:27,828 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-10-28 19:37:27,840 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 2019-10-28 19:37:30,821 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 2019-10-28 19:37:30,837 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-10-28 19:37:35,228 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-28 19:37:35,242 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-28 19:37:38,264 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-10-28 19:37:38,286 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 2019-10-28 19:37:42,748 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-10-28 19:37:42,760 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-28 19:37:45,591 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:37:45,602 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 2019-10-28 19:37:48,223 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 2019-10-28 19:37:48,237 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-28 19:37:50,804 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-28 19:37:50,815 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-28 19:37:53,740 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-28 19:37:53,755 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:37:56,584 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-28 19:37:56,598 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-28 19:38:00,937 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:38:00,950 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-28 19:38:03,857 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-28 19:38:03,871 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-28 19:38:06,771 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-28 19:38:06,793 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:38:11,016 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-28 19:38:11,028 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-28 19:38:13,680 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-28 19:38:13,695 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-28 19:38:16,680 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-28 19:38:16,695 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:38:19,378 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:38:19,388 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193653Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 88652af0ee01da0e689e41a01ce6dcbc48db0ece9ce060b479a9a742fadbfdf3, signature=cb6b305e36ec5cc8c4b6d4c1b1e4e6d979b43d599fdc74f3eca7932ebeff9200, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-28 19:38:22,257 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-28 19:38:22,271 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:38:25,018 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-28 19:38:25,032 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-28 19:38:27,895 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:38:27,910 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-28 19:38:30,722 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:38:30,733 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:38:33,614 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:38:33,625 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:38:36,585 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-28 19:38:36,598 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:38:40,991 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-28 19:38:41,004 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-28 19:38:45,416 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-28 19:38:45,429 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-28 19:38:48,266 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-28 19:38:48,280 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:38:51,279 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-28 19:38:51,299 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 101 more
om_1        | 2019-10-28 19:38:54,131 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-28 19:36:54,688 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:38:54,143 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:38:59,553 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:38:59,565 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:39:03,800 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:39:03,811 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-28 19:36:54,696 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:39:08,497 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:39:08,506 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:39:11,323 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:39:11,333 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:39:14,117 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-28 19:36:54,697 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:39:14,130 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:39:18,319 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:54,704 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:39:18,329 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:39:53,749 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-28 19:36:54,705 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:39:53,759 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:39:57,039 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:54,711 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:39:57,041 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:54,712 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:39:57,045 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:54,719 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:40:00,986 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:40:00,999 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:40:08,139 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 2019-10-28 19:36:54,719 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:08,140 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:08,143 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:54,726 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:10,389 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:10,390 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:40:10,394 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-28 19:36:54,726 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:11,285 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:54,734 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:11,288 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:11,291 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:40:11,972 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 2019-10-28 19:36:54,734 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
om_1        | 2019-10-28 19:40:11,973 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-10-28 19:36:54,740 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:11,976 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:54,741 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:12,698 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:12,699 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
om_1        | 2019-10-28 19:40:12,702 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-28 19:36:54,746 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:15,339 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:40:15,349 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:40:18,615 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:40:18,616 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:18,622 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:19,370 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:40:19,370 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:40:19,373 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-28 19:36:54,746 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:19,380 [IPC Server handler 10 on 9862] ERROR      - S3Bucket Creation Failed for userName: 2724f42bcd3225359401cb62da89c51d, s3BucketName bucket-13182, VolumeName s32724f42bcd3225359401cb62da89c51d
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:22,109 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:22,122 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:40:25,306 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
om_1        | 2019-10-28 19:40:25,307 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-10-28 19:36:54,751 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:25,310 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:26,085 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:26,085 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:40:26,088 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:40:26,798 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 2019-10-28 19:36:54,751 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:26,799 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:26,802 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:29,506 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 2019-10-28 19:40:29,516 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-28 19:36:54,756 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:32,568 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:32,568 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:32,571 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:40:33,336 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:40:33,337 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:40:33,339 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-28 19:36:54,756 [qtp262445056-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 2019-10-28 19:40:36,058 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:40:36,070 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:40:39,431 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 2019-10-28 19:36:54,756 [qtp262445056-27] ERROR      - Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:40:39,432 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:40:39,434 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:40:40,165 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:40:40,166 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-28 19:40:40,168 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-28 19:40:40,857 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:40:40,858 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:40:40,860 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-28 19:40:41,659 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:40:41,660 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:40:41,664 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-28 19:40:43,005 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-28 19:40:43,005 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-28 19:40:43,010 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:40:46,001 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-28 19:40:46,011 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-28 19:40:49,217 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-28 19:40:49,218 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-28 19:40:49,221 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:40:50,070 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:40:50,071 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-28 19:40:50,073 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-28 19:40:51,138 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-28 19:40:51,139 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:40:51,142 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:40:52,004 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:40:52,005 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:40:52,008 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-28 19:40:52,786 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-28 19:40:52,787 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-28 19:40:52,790 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-28 19:40:55,918 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-28 19:40:55,927 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-28 19:40:59,193 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:40:59,194 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:40:59,196 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-28 19:40:59,871 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-28 19:40:59,871 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:40:59,873 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-28 19:41:00,736 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 2019-10-28 19:41:00,737 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 2019-10-28 19:41:00,739 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-28 19:41:01,553 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-28 19:41:01,554 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-28 19:41:01,557 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-28 19:41:01,582 [IPC Server handler 10 on 9862] ERROR      - MultipartUpload: /s32724f42bcd3225359401cb62da89c51d/bucket-97972/multipartKey2Part number: 1size 6 is less than minimum part size 5242880
om_1        | 2019-10-28 19:41:01,583 [IPC Server handler 10 on 9862] ERROR      - MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-97972
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-97972key: multipartKey2
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-10-28 19:41:04,325 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:41:04,336 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-28 19:41:07,488 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-28 19:41:07,489 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-28 19:41:07,492 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:41:08,179 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:41:08,180 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-10-28 19:41:08,182 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:41:09,138 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-10-28 19:41:09,138 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-28 19:41:09,141 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-28 19:41:10,031 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-28 19:41:10,031 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-28 19:41:10,033 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-28 19:41:10,051 [IPC Server handler 0 on 9862] ERROR      - MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-97972
om_1        | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-97972key: multipartKey3
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:195)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-28 19:41:12,715 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-28 19:41:12,728 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-28 19:41:15,987 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:41:15,988 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-28 19:41:15,991 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-10-28 19:41:16,637 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-28 19:41:16,637 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-28 19:41:16,639 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-28 19:41:19,409 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-28 19:41:19,421 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:41:22,518 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-28 19:41:22,519 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-28 19:41:22,521 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:41:22,533 [IPC Server handler 16 on 9862] ERROR      - Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-97972
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-97972key: multipartKey5
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:116)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-28 19:41:25,132 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 2019-10-28 19:41:25,147 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 2019-10-28 19:41:28,470 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 2019-10-28 19:41:28,471 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:28,474 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-28 19:41:28,493 [IPC Server handler 9 on 9862] ERROR      - ALLOCATE_KEY failed for Key: multipartKey in volume/bucket:s32724f42bcd3225359401cb62da89c51d/bucket-97972
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:471)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:423)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:182)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | Oct 28, 2019 7:36:54 PM org.glassfish.jersey.internal.Errors logErrors
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | MultiException stack 1 of 1
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-10-28 19:41:31,139 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:41:31,152 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-28 19:41:34,485 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-28 19:41:34,485 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-28 19:41:34,488 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 2019-10-28 19:41:35,308 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 2019-10-28 19:41:35,309 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 2019-10-28 19:41:35,312 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 2019-10-28 19:41:36,365 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-10-28 19:41:36,366 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-28 19:41:36,369 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:41:37,258 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:41:37,258 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:37,261 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:41:38,022 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:41:38,023 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:38,026 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-28 19:41:38,785 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:41:38,785 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:38,789 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-28 19:41:39,516 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:41:39,517 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:39,520 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:41:42,190 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:41:42,205 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 2019-10-28 19:41:45,903 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 2019-10-28 19:41:45,903 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-28 19:41:45,907 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-28 19:41:46,062 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-28 19:41:46,063 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-28 19:41:46,065 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-28 19:41:46,077 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:41:46,078 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-28 19:41:46,082 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-28 19:41:46,087 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:41:46,087 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-28 19:41:46,090 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:41:46,614 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:41:46,615 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-28 19:41:46,628 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-28 19:41:47,386 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-28 19:41:47,387 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-10-28 19:41:47,394 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-28 19:41:47,467 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:41:47,468 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:47,468 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:41:47,469 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:47,472 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-28 19:41:47,474 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-28 19:41:47,477 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-28 19:41:47,478 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:47,480 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:41:48,793 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:41:48,794 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:41:48,796 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-10-28 19:41:51,621 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-28 19:41:51,635 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-28 19:41:55,149 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-28 19:41:55,150 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-10-28 19:41:55,152 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-10-28 19:41:56,062 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-28 19:41:56,062 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-28 19:41:56,065 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-28 19:41:56,782 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-28 19:41:56,782 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-28 19:41:56,785 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-28 19:41:57,910 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-28 19:41:57,910 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-28 19:41:57,914 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-28 19:41:58,594 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-28 19:41:58,594 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-28 19:41:58,597 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-28 19:42:01,418 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-28 19:42:01,428 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-28 19:42:04,694 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-28 19:42:04,695 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-28 19:42:04,697 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-28 19:42:05,615 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-28 19:42:05,615 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:42:05,618 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-28 19:42:06,291 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:42:06,291 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 2019-10-28 19:42:06,295 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-28 19:42:07,433 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:07,433 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 2019-10-28 19:42:07,436 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-28 19:42:08,406 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-28 19:42:08,407 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-28 19:42:08,410 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 2019-10-28 19:42:09,129 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-10-28 19:42:09,129 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-28 19:42:09,132 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-28 19:42:12,126 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-28 19:42:12,137 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:15,269 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:15,270 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:42:15,273 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:15,954 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:15,955 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 2019-10-28 19:42:15,957 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:16,586 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:16,586 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:42:16,589 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 2019-10-28 19:42:19,394 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 2019-10-28 19:42:19,404 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-28 19:42:22,311 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 2019-10-28 19:42:22,311 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 2019-10-28 19:42:22,317 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-28 19:42:22,992 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-10-28 19:42:22,993 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 2019-10-28 19:42:22,995 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:23,647 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:23,648 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:42:23,649 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-28 19:42:24,508 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-28 19:42:24,508 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-28 19:42:24,511 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-28 19:42:25,199 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-28 19:42:25,199 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-28 19:42:25,202 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:42:26,032 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:26,033 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:42:26,037 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:42:26,623 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-28 19:42:26,624 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-28 19:42:26,626 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:27,400 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:27,401 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:42:27,403 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-28 19:42:29,978 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-28 19:42:29,987 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:42:33,290 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:42:33,290 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-28 19:42:33,293 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-28 19:42:33,897 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-28 19:42:33,898 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-28 19:42:33,901 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:36,497 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-28 19:42:36,508 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-28 19:42:39,677 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:42:39,678 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:42:39,680 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:42,404 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:42:42,418 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-28 19:42:45,673 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-28 19:42:45,674 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-28 19:42:45,676 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-28 19:42:48,366 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	... 101 more
om_1        | 2019-10-28 19:42:48,378 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 
om_1        | 2019-10-28 19:42:51,766 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:51,766 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:42:51,769 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:52,500 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:52,500 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:42:52,503 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:42:53,261 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:42:53,261 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:42:53,263 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 
om_1        | 2019-10-28 19:42:53,921 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 2019-10-28 19:36:54,762 WARN servlet.ServletHandler: 
om_1        | 2019-10-28 19:42:53,922 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-28 19:42:53,924 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-28 19:42:54,585 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 
om_1        | 2019-10-28 19:42:54,586 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 2019-10-28 19:42:54,593 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-10-28 19:42:57,282 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-28 19:42:57,291 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-28 19:43:00,537 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-28 19:43:00,538 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-28 19:43:00,540 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-28 19:43:01,210 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-28 19:43:01,210 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-28 19:43:01,213 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 2019-10-28 19:43:01,919 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 2019-10-28 19:43:01,919 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-28 19:43:01,922 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-28 19:43:04,565 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:43:04,577 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:07,829 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 2019-10-28 19:43:07,830 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 2019-10-28 19:43:07,832 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-28 19:43:08,537 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-28 19:43:08,537 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 2019-10-28 19:43:08,540 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 2019-10-28 19:43:09,165 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-10-28 19:43:09,166 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:43:09,168 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:09,756 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-28 19:43:09,756 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-28 19:43:09,759 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-28 19:43:10,404 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-28 19:43:10,405 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-28 19:43:10,408 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 2019-10-28 19:43:13,160 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 2019-10-28 19:43:13,171 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-28 19:43:16,354 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-28 19:43:16,355 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:43:16,357 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-28 19:43:17,193 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 
om_1        | 2019-10-28 19:43:17,193 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 2019-10-28 19:43:17,195 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:17,803 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-10-28 19:43:17,804 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-28 19:43:17,806 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-28 19:43:18,371 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-28 19:43:18,371 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-10-28 19:43:18,373 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:18,896 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-10-28 19:43:18,897 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-28 19:43:18,899 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-28 19:43:21,342 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-28 19:43:21,350 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:24,267 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-28 19:43:24,268 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-28 19:43:24,271 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-28 19:43:26,734 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:43:26,745 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-28 19:43:30,073 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:43:30,073 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:43:30,075 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-28 19:43:30,669 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-28 19:43:30,670 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-28 19:43:30,672 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-28 19:43:31,416 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-28 19:43:31,417 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 2019-10-28 19:43:31,419 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-10-28 19:43:32,211 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:43:32,211 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-28 19:43:32,214 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-28 19:43:32,924 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-10-28 19:43:32,925 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-28 19:43:32,927 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-28 19:43:33,655 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-28 19:43:33,655 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:43:33,658 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:34,333 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:43:34,334 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:43:34,336 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-28 19:43:36,950 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-28 19:43:36,961 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:40,132 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-28 19:43:40,132 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-28 19:43:40,135 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-28 19:43:40,780 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-28 19:43:40,780 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:43:40,783 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:41,568 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-28 19:43:41,568 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-28 19:43:41,571 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-28 19:43:42,243 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-28 19:43:42,244 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-28 19:43:42,246 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-28 19:43:42,907 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-28 19:43:42,908 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:43:42,910 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:45,597 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:43:45,607 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:48,744 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2019-10-28 19:43:48,744 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-28 19:43:48,747 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-28 19:43:51,411 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:43:51,423 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:54,599 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:43:54,600 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-28 19:43:54,603 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-28 19:43:55,335 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-28 19:43:55,336 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-28 19:43:55,338 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-28 19:43:55,903 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	... 60 more
om_1        | 2019-10-28 19:43:55,903 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:43:55,905 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:43:58,715 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:43:58,728 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-28 19:44:02,086 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:44:02,086 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:44:02,089 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:44:04,849 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-28 19:44:04,862 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-28 19:44:08,091 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-28 19:44:08,092 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-28 19:44:08,095 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-28 19:44:10,968 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:44:10,981 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:44:14,396 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:44:14,397 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:44:14,404 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-28 19:44:17,384 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	... 92 more
om_1        | 2019-10-28 19:44:17,393 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:44:20,634 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-28 19:44:20,634 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191028T193654Z
om_1        | 2019-10-28 19:44:20,638 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191028/us-west-1/s3/aws4_request
om_1        | 2019-10-28 19:44:21,411 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-28 19:44:21,412 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-28 19:44:21,417 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-28 19:44:24,219 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-28 19:44:24,231 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-28 19:44:27,458 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-28 19:44:27,458 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:44:27,461 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-28 19:44:28,180 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:44:28,180 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:44:28,183 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:44:30,948 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-28 19:44:30,959 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-28 19:44:34,097 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-28 19:44:34,098 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-28 19:44:34,100 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-28 19:44:34,734 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-28 19:44:34,734 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-28 19:44:34,737 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-28 19:44:37,236 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-28 19:44:37,248 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-28 19:44:40,288 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-28 19:44:40,288 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:44:40,290 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-28 19:44:40,828 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
om_1        | 2019-10-28 19:44:40,829 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-28 19:44:40,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:44:41,442 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-28 19:44:41,442 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-28 19:44:41,446 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-28 19:44:43,773 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-28 19:44:43,783 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-28 19:44:46,613 [Socket Reader #1 for port 9862] INFO       - 61f4ae93d8c5572c008e4a74f871feb9b40432de29fd992ae7776da21534b4fa
s3g_1       | 	... 101 more
s3g_1       | 2019-10-28 19:36:54,764 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 2019-10-28 19:44:46,613 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-28 19:44:46,615 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-28 19:44:49,006 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 
om_1        | 2019-10-28 19:44:49,017 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193654Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | a2a4990a819e029ae3da9142f6ee0a5e08a0b909de13278bbc5410a8bc9de5b7, signature=04c051fb48ab9a87f1d127ab53a6a34e4068d4f78ca7412cdc473b487a5d078b, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-28 19:36:57,758 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,763 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,763 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,769 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,769 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,776 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,776 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,782 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,783 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,788 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,788 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,793 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,793 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,799 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,799 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,804 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,804 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,809 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,809 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-28 19:36:57,814 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-28 19:36:57,815 [qtp262445056-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
s3g_1       | 2019-10-28 19:36:57,815 [qtp262445056-27] ERROR      - Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Oct 28, 2019 7:36:57 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2019-10-28 19:36:57,821 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-28 19:36:57,822 WARN server.HttpChannel: //s3g:9878/bucket-test123
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191028T193657Z
s3g_1       | 20191028/us-west-1/s3/aws4_request
s3g_1       | 1b842b82b1ea62b09fef0a1a49286474db5a9dee75f76afca5893d009fb205ed, signature=5e7cb96b95884bd2d8b2ccbc78d4ca0a99e01598624d612da089d8536cccf51a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-28 19:39:57,118 [qtp262445056-30] INFO       - Location is /bucket-46584
s3g_1       | 2019-10-28 19:40:08,674 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2019-10-28 19:40:08,735 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2019-10-28 19:40:08,735 INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2019-10-28 19:40:08,737 WARN impl.MetricsSystemImpl: Sink prometheus already exists!
s3g_1       | 2019-10-28 19:40:18,651 [qtp262445056-173] INFO       - Location is /bucket-13182
s3g_1       | 2019-10-28 19:40:19,398 [qtp262445056-176] INFO       - Location is /bucket-13182
s3g_1       | 2019-10-28 19:40:25,353 [qtp262445056-173] INFO       - Location is /bucket-48250
s3g_1       | 2019-10-28 19:40:26,855 [qtp262445056-173] ERROR      - Exception occurred in headBucket
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:103)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:81)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:250)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-10-28 19:40:32,618 [qtp262445056-176] INFO       - Location is /bucket-16547
s3g_1       | 2019-10-28 19:40:39,463 [qtp262445056-176] INFO       - Location is /bucket-97972
s3g_1       | 2019-10-28 19:40:41,697 [qtp262445056-173] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:40:43,041 [qtp262445056-176] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:40:50,105 [qtp262445056-176] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:40:51,176 [qtp262445056-173] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:40:59,900 [qtp262445056-173] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:00,768 [qtp262445056-176] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:01,596 [qtp262445056-173] ERROR      - Error in Complete Multipart Upload Request for bucket: bucket-97972, key: multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-97972key: multipartKey2
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1104)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.completeMultipartUpload(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:883)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:445)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:498)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-10-28 19:41:08,216 [qtp262445056-173] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:09,174 [qtp262445056-266] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:10,066 [qtp262445056-173] ERROR      - Error in Complete Multipart Upload Request for bucket: bucket-97972, key: multipartKey3
s3g_1       | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-97972key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1104)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.completeMultipartUpload(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:883)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:445)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:498)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-10-28 19:41:35,346 [qtp262445056-176] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:36,401 [qtp262445056-112] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:46,100 [qtp262445056-112] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:46,115 [qtp262445056-172] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:46,119 [qtp262445056-176] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:41:56,880 [qtp262445056-172] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=134, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=165, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=135, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=157, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=145, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=161, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=153, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=149, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=57, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=49, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=133, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 28, 2019 7:41:57 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=53, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2019-10-28 19:42:06,406 [qtp262445056-266] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:42:07,647 [qtp262445056-28] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-28 19:42:22,350 [qtp262445056-172] INFO       - Location is /bucket-00034
s3g_1       | 2019-10-28 19:42:23,021 [qtp262445056-172] INFO       - Location is /destbucket-24473
s3g_1       | 2019-10-28 19:42:51,793 [qtp262445056-307] INFO       - Location is /bucket-46274
s3g_1       | 2019-10-28 19:43:30,097 [qtp262445056-307] INFO       - Location is /bucket-30503
s3g_1       | 2019-10-28 19:43:40,172 [qtp262445056-307] INFO       - Location is /bucket-39681
s3g_1       | 2019-10-28 19:44:46,636 [qtp262445056-28] INFO       - Location is /bucket-69805
s3g_1       | 2019-10-28 19:44:51,526 [qtp262445056-415] ERROR      - Error: 
s3g_1       | java.lang.NullPointerException
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:78)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
