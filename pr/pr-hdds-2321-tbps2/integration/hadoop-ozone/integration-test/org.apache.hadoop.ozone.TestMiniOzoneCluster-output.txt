2019-11-02 05:56:10,352 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:10,461 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:10,465 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:10,490 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @886ms
2019-11-02 05:56:10,589 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-02 05:56:10,589 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-02 05:56:10,589 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-02 05:56:10,589 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-02 05:56:10,590 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-02 05:56:10,590 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-02 05:56:10,601 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-02 05:56:10,601 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-02 05:56:10,603 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-02 05:56:10,922 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@4100118a
2019-11-02 05:56:10,924 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-02 05:56:10,980 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-02 05:56:10,982 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-02 05:56:10,984 [Thread-0] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-02 05:56:11,048 [Thread-0] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-02 05:56:11,062 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:11,165 [Thread-0] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-02 05:56:11,169 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:11,309 [Thread-0] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-11-02 05:56:11,694 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-02 05:56:11,720 [Socket Reader #1 for port 40901] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40901
2019-11-02 05:56:11,892 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-02 05:56:11,893 [Socket Reader #1 for port 45026] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45026
2019-11-02 05:56:11,904 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-02 05:56:11,905 [Socket Reader #1 for port 45605] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45605
2019-11-02 05:56:11,951 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:11,967 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:11,968 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:11,969 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-02 05:56:11,969 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-02 05:56:11,969 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-02 05:56:11,970 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-02 05:56:11,970 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-02 05:56:11,970 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-02 05:56:11,971 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-02 05:56:11,971 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-02 05:56:11,971 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-02 05:56:12,177 [Thread-12] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@5564341f
2019-11-02 05:56:12,177 [Thread-12] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-02 05:56:12,183 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-02 05:56:12,184 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-02 05:56:12,184 [Thread-12] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-02 05:56:12,186 [Thread-12] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-02 05:56:12,187 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:12,255 [Thread-12] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-02 05:56:12,256 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-02 05:56:12,352 [Thread-12] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-02 05:56:12,354 [Thread-12] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-02 05:56:12,355 [Socket Reader #1 for port 40814] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40814
2019-11-02 05:56:12,357 [Thread-12] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-02 05:56:12,359 [Socket Reader #1 for port 45599] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45599
2019-11-02 05:56:12,360 [Thread-12] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-02 05:56:12,361 [Socket Reader #1 for port 42127] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42127
2019-11-02 05:56:12,515 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/read/malformed.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:173)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: Can't construct a java object for tag:yaml.org,2002:org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml; exception=No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
 in 'reader', line 1, column 1:
    malformed
    ^

	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:349)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:182)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:141)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:127)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:450)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
Caused by: org.yaml.snakeyaml.error.YAMLException: No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
	at org.yaml.snakeyaml.constructor.Constructor$ConstructScalar.construct(Constructor.java:396)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:345)
	... 36 more
2019-11-02 05:56:12,527 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/write/valid-proto.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: unacceptable character '' (0x12) special characters are not allowed
in "'reader'", position 38
	at org.yaml.snakeyaml.reader.StreamReader.checkPrintable(StreamReader.java:93)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:192)
	at org.yaml.snakeyaml.reader.StreamReader.<init>(StreamReader.java:60)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
2019-11-02 05:56:12,587 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-02 05:56:12,588 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds to VolumeSet
2019-11-02 05:56:12,597 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:12,613 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,100 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-02 05:56:13,128 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-02 05:56:13,193 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-02 05:56:13,198 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-02 05:56:13,199 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-02 05:56:13,200 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-02 05:56:13,201 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-02 05:56:13,202 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-02 05:56:13,356 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-02 05:56:13,423 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-02 05:56:13,423 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds to VolumeSet
2019-11-02 05:56:13,424 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,424 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,441 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-02 05:56:13,442 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-02 05:56:13,443 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-02 05:56:13,443 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-02 05:56:13,443 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-02 05:56:13,443 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-02 05:56:13,444 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-02 05:56:13,444 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-02 05:56:13,445 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-02 05:56:13,453 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-02 05:56:13,453 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds to VolumeSet
2019-11-02 05:56:13,453 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,454 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,471 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-02 05:56:13,472 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-02 05:56:13,472 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-02 05:56:13,472 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-02 05:56:13,472 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-02 05:56:13,473 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-02 05:56:13,473 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-02 05:56:13,473 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-02 05:56:13,474 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-02 05:56:13,571 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 264c5719-9187-4b24-9422-a1c2019853a1 is started using port 43223
2019-11-02 05:56:13,571 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 264c5719-9187-4b24-9422-a1c2019853a1 at port 0
2019-11-02 05:56:13,588 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 264c5719-9187-4b24-9422-a1c2019853a1: start RPC server
2019-11-02 05:56:13,590 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 264c5719-9187-4b24-9422-a1c2019853a1: GrpcService started, listening on 0.0.0.0/0.0.0.0:43912
2019-11-02 05:56:13,590 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis 264c5719-9187-4b24-9422-a1c2019853a1 is started using port 43912
2019-11-02 05:56:13,590 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc ee03a998-7c46-4cae-a323-9ae11d0cdc4e is started using port 45635
2019-11-02 05:56:13,591 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis ee03a998-7c46-4cae-a323-9ae11d0cdc4e at port 0
2019-11-02 05:56:13,599 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - ee03a998-7c46-4cae-a323-9ae11d0cdc4e: start RPC server
2019-11-02 05:56:13,600 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - ee03a998-7c46-4cae-a323-9ae11d0cdc4e: GrpcService started, listening on 0.0.0.0/0.0.0.0:33325
2019-11-02 05:56:13,600 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis ee03a998-7c46-4cae-a323-9ae11d0cdc4e is started using port 33325
2019-11-02 05:56:13,601 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 8d3b787e-96bd-47fb-89fa-7c60fb8549eb is started using port 37090
2019-11-02 05:56:13,601 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 8d3b787e-96bd-47fb-89fa-7c60fb8549eb at port 0
2019-11-02 05:56:13,609 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 8d3b787e-96bd-47fb-89fa-7c60fb8549eb: start RPC server
2019-11-02 05:56:13,609 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 8d3b787e-96bd-47fb-89fa-7c60fb8549eb: GrpcService started, listening on 0.0.0.0/0.0.0.0:37450
2019-11-02 05:56:13,610 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis 8d3b787e-96bd-47fb-89fa-7c60fb8549eb is started using port 37450
2019-11-02 05:56:13,611 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 264c5719-9187-4b24-9422-a1c2019853a1: close
2019-11-02 05:56:13,612 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 264c5719-9187-4b24-9422-a1c2019853a1: shutdown server with port 43912 now
2019-11-02 05:56:13,618 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 264c5719-9187-4b24-9422-a1c2019853a1: shutdown server with port 43912 successfully
2019-11-02 05:56:13,622 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - ee03a998-7c46-4cae-a323-9ae11d0cdc4e: close
2019-11-02 05:56:13,622 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - ee03a998-7c46-4cae-a323-9ae11d0cdc4e: shutdown server with port 33325 now
2019-11-02 05:56:13,623 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - ee03a998-7c46-4cae-a323-9ae11d0cdc4e: shutdown server with port 33325 successfully
2019-11-02 05:56:13,624 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 8d3b787e-96bd-47fb-89fa-7c60fb8549eb: close
2019-11-02 05:56:13,624 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 8d3b787e-96bd-47fb-89fa-7c60fb8549eb: shutdown server with port 37450 now
2019-11-02 05:56:13,625 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 8d3b787e-96bd-47fb-89fa-7c60fb8549eb: shutdown server with port 37450 successfully
2019-11-02 05:56:13,661 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-02 05:56:13,662 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-02 05:56:13,672 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-02 05:56:13,673 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-02 05:56:13,673 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-02 05:56:13,681 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-02 05:56:13,681 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-02 05:56:13,682 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-02 05:56:13,691 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-02 05:56:13,695 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26 : 8192 
2019-11-02 05:56:13,695 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-02 05:56:13,695 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds to VolumeSet
2019-11-02 05:56:13,695 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,696 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,708 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-02 05:56:13,709 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-02 05:56:13,709 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-02 05:56:13,709 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-02 05:56:13,710 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-02 05:56:13,710 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-02 05:56:13,710 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-02 05:56:13,710 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-02 05:56:13,711 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-02 05:56:13,714 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26 : 8192 
2019-11-02 05:56:13,714 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-02 05:56:13,715 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds to VolumeSet
2019-11-02 05:56:13,715 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,715 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,729 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-02 05:56:13,730 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-02 05:56:13,730 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-02 05:56:13,730 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-02 05:56:13,730 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-02 05:56:13,730 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-02 05:56:13,731 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-02 05:56:13,731 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-02 05:56:13,732 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-02 05:56:13,735 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26 : 8192 
2019-11-02 05:56:13,735 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-02 05:56:13,735 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds to VolumeSet
2019-11-02 05:56:13,735 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,736 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26/hdds
2019-11-02 05:56:13,751 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-02 05:56:13,752 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-02 05:56:13,752 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-02 05:56:13,752 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-02 05:56:13,752 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-02 05:56:13,753 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-02 05:56:13,753 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-02 05:56:13,753 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-02 05:56:13,754 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-02 05:56:13,755 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-02 05:56:13,755 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-02 05:56:13,768 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-02 05:56:13,768 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-02 05:56:13,768 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-02 05:56:13,780 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-02 05:56:13,780 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-02 05:56:13,781 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/lbm5vkKF26] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-02 05:56:13,792 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
