Attaching to ozoneperf_scm_1, ozoneperf_datanode_2, ozoneperf_grafana_1, ozoneperf_s3g_1, ozoneperf_datanode_3, ozoneperf_jaeger_1, ozoneperf_om_1, ozoneperf_datanode_1, ozoneperf_prometheus_1
scm_1         | 2019-11-13 21:57:27,909 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = 551fe321d7f7/172.19.0.10
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 3.2.0
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1         | STARTUP_MSG:   java = 11.0.3
scm_1         | ************************************************************/
scm_1         | 2019-11-13 21:57:27,916 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2019-11-13 21:57:27,951 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | SCM initialization succeeded.Current cluster id for sd=/data/metadata/scm;cid=CID-06b5b809-a0af-45e8-8e2e-00b1bf5bb949
scm_1         | 2019-11-13 21:57:28,720 INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
s3g_1         | 2019-11-13 21:57:20,994 INFO hdfs.DFSUtil: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1         | 2019-11-13 21:57:21,019 INFO util.log: Logging initialized @1026ms
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at 551fe321d7f7/172.19.0.10
s3g_1         | 2019-11-13 21:57:21,143 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | ************************************************************/
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Starting Grafana" logger=server version=6.4.4 commit=092e514 branch=HEAD compiled=2019-11-06T12:04:33+0000
s3g_1         | 2019-11-13 21:57:21,178 INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
jaeger_1      | 2019/11/13 21:57:21 maxprocs: Leaving GOMAXPROCS=32: CPU quota undefined
scm_1         | 2019-11-13 21:57:33,248 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_2    | 2019-11-13 21:57:22,784 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config loaded from" logger=settings file=/usr/share/grafana/conf/defaults.ini
s3g_1         | 2019-11-13 21:57:21,199 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
jaeger_1      | {"level":"info","ts":1573682241.8910217,"caller":"flags/service.go:115","msg":"Mounting metrics handler on admin server","route":"/metrics"}
scm_1         | /************************************************************
datanode_3    | 2019-11-13 21:57:20,771 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
om_1          | 2019-11-13 21:57:20,941 INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_2    | /************************************************************
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config loaded from" logger=settings file=/etc/grafana/grafana.ini
prometheus_1  | level=info ts=2019-11-13T21:57:19.655Z caller=main.go:296 msg="no time or size retention was set so using the default time retention" duration=15d
s3g_1         | 2019-11-13 21:57:21,210 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
jaeger_1      | {"level":"info","ts":1573682241.8913443,"caller":"flags/admin.go:108","msg":"Mounting health check on admin server","route":"/"}
scm_1         | STARTUP_MSG: Starting StorageContainerManager
datanode_3    | /************************************************************
datanode_2    | STARTUP_MSG: Starting HddsDatanodeService
om_1          | /************************************************************
datanode_1    | 2019-11-13 21:57:20,600 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.data=/var/lib/grafana"
prometheus_1  | level=info ts=2019-11-13T21:57:19.655Z caller=main.go:332 msg="Starting Prometheus" version="(version=2.14.0, branch=HEAD, revision=edeb7a44cbf745f1d8be4ea6f215e79e651bfe19)"
s3g_1         | 2019-11-13 21:57:21,210 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
jaeger_1      | {"level":"info","ts":1573682241.8914468,"caller":"flags/admin.go:114","msg":"Starting admin HTTP server","http-port":14269}
scm_1         | STARTUP_MSG:   host = 551fe321d7f7/172.19.0.10
datanode_3    | STARTUP_MSG: Starting HddsDatanodeService
datanode_2    | STARTUP_MSG:   host = 5932f82a666d/172.19.0.6
om_1          | STARTUP_MSG: Starting OzoneManager
datanode_1    | /************************************************************
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.logs=/var/log/grafana"
prometheus_1  | level=info ts=2019-11-13T21:57:19.655Z caller=main.go:333 build_context="(go=go1.13.4, user=root@df2327081015, date=20191111-14:27:12)"
s3g_1         | 2019-11-13 21:57:21,210 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
jaeger_1      | {"level":"info","ts":1573682241.891476,"caller":"flags/admin.go:100","msg":"Admin server started","http-port":14269,"health-status":"unavailable"}
scm_1         | STARTUP_MSG:   args = []
datanode_3    | STARTUP_MSG:   host = 04b2d59aad1f/172.19.0.8
om_1          | STARTUP_MSG:   host = f40fe122cc8a/172.19.0.7
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.plugins=/var/lib/grafana/plugins"
datanode_2    | STARTUP_MSG:   args = []
datanode_1    | STARTUP_MSG: Starting HddsDatanodeService
prometheus_1  | level=info ts=2019-11-13T21:57:19.655Z caller=main.go:334 host_details="(Linux 3.10.0-957.12.2.el7.x86_64 #1 SMP Tue May 14 21:24:32 UTC 2019 x86_64 f8ca66d4030d (none))"
s3g_1         | 2019-11-13 21:57:21,228 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
jaeger_1      | {"level":"info","ts":1573682241.9005194,"caller":"memory/factory.go:56","msg":"Memory storage initialized","configuration":{"MaxTraces":0}}
scm_1         | STARTUP_MSG:   version = 3.2.0
datanode_3    | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   args = [--init]
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.provisioning=/etc/grafana/provisioning"
datanode_2    | STARTUP_MSG:   version = 3.2.0
prometheus_1  | level=info ts=2019-11-13T21:57:19.655Z caller=main.go:335 fd_limits="(soft=1048576, hard=1048576)"
datanode_1    | STARTUP_MSG:   host = f5d92a2776ba/172.19.0.3
s3g_1         | 2019-11-13 21:57:21,229 INFO s3.Gateway: Starting Ozone S3 gateway
jaeger_1      | {"level":"info","ts":1573682241.9170754,"caller":"all-in-one/main.go:242","msg":"Starting jaeger-collector TChannel server","port":14267}
datanode_3    | STARTUP_MSG:   version = 3.2.0
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.log.mode=console"
om_1          | STARTUP_MSG:   version = 3.2.0
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
datanode_2    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
prometheus_1  | level=info ts=2019-11-13T21:57:19.655Z caller=main.go:336 vm_limits="(soft=unlimited, hard=unlimited)"
datanode_1    | STARTUP_MSG:   args = []
s3g_1         | 2019-11-13 21:57:21,238 INFO http.HttpServer2: Jetty bound to port 9878
datanode_3    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
jaeger_1      | {"level":"info","ts":1573682241.9172094,"caller":"grpcserver/grpc_server.go:64","msg":"Starting jaeger-collector gRPC server","grpc-port":"14250"}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_DATA=/var/lib/grafana"
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
datanode_2    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
prometheus_1  | level=info ts=2019-11-13T21:57:19.657Z caller=web.go:496 component=web msg="Start listening for connections" address=0.0.0.0:9090
datanode_1    | STARTUP_MSG:   version = 3.2.0
s3g_1         | 2019-11-13 21:57:21,240 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
jaeger_1      | {"level":"info","ts":1573682241.9172962,"caller":"all-in-one/main.go:260","msg":"Starting jaeger-collector HTTP server","http-port":14268}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_LOGS=/var/log/grafana"
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2    | STARTUP_MSG:   java = 11.0.3
prometheus_1  | level=info ts=2019-11-13T21:57:19.657Z caller=main.go:657 msg="Starting TSDB ..."
datanode_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
s3g_1         | 2019-11-13 21:57:21,286 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b919693{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3    | STARTUP_MSG:   java = 11.0.3
jaeger_1      | {"level":"info","ts":1573682241.9173207,"caller":"grpc/builder.go:65","msg":"Agent requested insecure grpc connection to collector(s)"}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_PLUGINS=/var/lib/grafana/plugins"
om_1          | STARTUP_MSG:   java = 11.0.3
datanode_2    | ************************************************************/
prometheus_1  | level=info ts=2019-11-13T21:57:19.661Z caller=head.go:535 component=tsdb msg="replaying WAL, this may take awhile"
datanode_1    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1         | STARTUP_MSG:   java = 11.0.3
s3g_1         | 2019-11-13 21:57:21,286 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6933b6c6{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
jaeger_1      | {"level":"info","ts":1573682241.9184988,"caller":"all-in-one/main.go:199","msg":"Starting agent"}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_PROVISIONING=/etc/grafana/provisioning"
om_1          | ************************************************************/
datanode_3    | ************************************************************/
datanode_2    | 2019-11-13 21:57:22,794 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
prometheus_1  | level=info ts=2019-11-13T21:57:19.662Z caller=head.go:583 component=tsdb msg="WAL segment loaded" segment=0 maxSegment=0
datanode_1    | STARTUP_MSG:   java = 11.0.3
scm_1         | ************************************************************/
s3g_1         | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
jaeger_1      | {"level":"info","ts":1573682241.918588,"caller":"querysvc/query_service.go:130","msg":"Archive storage not created","reason":"archive storage not supported"}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Path Home" logger=settings path=/usr/share/grafana
om_1          | 2019-11-13 21:57:20,951 INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3    | 2019-11-13 21:57:20,789 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
prometheus_1  | level=info ts=2019-11-13T21:57:19.663Z caller=main.go:672 fs_type=EXT4_SUPER_MAGIC
datanode_2    | 2019-11-13 21:57:23,098 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1    | ************************************************************/
scm_1         | 2019-11-13 21:57:33,255 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
jaeger_1      | {"level":"info","ts":1573682241.9186172,"caller":"all-in-one/main.go:342","msg":"Archive storage not initialized"}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Path Data" logger=settings path=/var/lib/grafana
s3g_1         | WARNING: An illegal reflective access operation has occurred
om_1          | 2019-11-13 21:57:21,872 INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.19.0.7:9862
datanode_3    | 2019-11-13 21:57:21,158 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
prometheus_1  | level=info ts=2019-11-13T21:57:19.663Z caller=main.go:673 msg="TSDB started"
scm_1         | 2019-11-13 21:57:33,326 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
jaeger_1      | {"level":"info","ts":1573682241.9186702,"caller":"app/agent.go:69","msg":"Starting jaeger-agent HTTP server","http-port":5778}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Path Logs" logger=settings path=/var/log/grafana
s3g_1         | WARNING: Illegal reflective access by org.jboss.classfilewriter.ClassFile$1 (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
om_1          | 2019-11-13 21:57:21,873 INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
datanode_1    | 2019-11-13 21:57:20,608 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2    | 2019-11-13 21:57:23,308 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3    | 2019-11-13 21:57:21,347 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
prometheus_1  | level=info ts=2019-11-13T21:57:19.663Z caller=main.go:743 msg="Loading configuration file" filename=/etc/prometheus.yml
scm_1         | 2019-11-13 21:57:33,341 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
jaeger_1      | {"level":"info","ts":1573682241.919325,"caller":"healthcheck/handler.go:128","msg":"Health Check state change","status":"ready"}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Path Plugins" logger=settings path=/var/lib/grafana/plugins
s3g_1         | WARNING: Please consider reporting this to the maintainers of org.jboss.classfilewriter.ClassFile$1
om_1          | 2019-11-13 21:57:21,877 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2    | 2019-11-13 21:57:23,308 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1    | 2019-11-13 21:57:20,923 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3    | 2019-11-13 21:57:21,348 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
prometheus_1  | level=info ts=2019-11-13T21:57:19.665Z caller=main.go:771 msg="Completed loading of configuration file" filename=/etc/prometheus.yml
scm_1         | 2019-11-13 21:57:33,375 INFO util.log: Logging initialized @978ms
jaeger_1      | {"level":"info","ts":1573682241.919356,"caller":"app/server.go:135","msg":"Starting CMUX server","port":16686}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Path Provisioning" logger=settings path=/etc/grafana/provisioning
om_1          | 2019-11-13 21:57:23,133 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-13 21:57:23,463 INFO ozone.HddsDatanodeService: HddsDatanodeService host:5932f82a666d ip:172.19.0.6
datanode_3    | 2019-11-13 21:57:21,474 INFO ozone.HddsDatanodeService: HddsDatanodeService host:04b2d59aad1f ip:172.19.0.8
s3g_1         | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_1    | 2019-11-13 21:57:21,101 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
prometheus_1  | level=info ts=2019-11-13T21:57:19.665Z caller=main.go:626 msg="Server is ready to receive web requests."
scm_1         | 2019-11-13 21:57:33,484 INFO db.DBStoreBuilder: using custom profile for table: deletedBlocks
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="App mode production" logger=settings
om_1          | 2019-11-13 21:57:24,134 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
jaeger_1      | {"level":"info","ts":1573682241.9193633,"caller":"app/server.go:125","msg":"Starting GRPC server","port":16686}
datanode_2    | 2019-11-13 21:57:23,503 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
datanode_3    | 2019-11-13 21:57:21,520 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
s3g_1         | WARNING: All illegal access operations will be denied in a future release
datanode_1    | 2019-11-13 21:57:21,101 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
scm_1         | 2019-11-13 21:57:33,485 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedBlocks
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Initializing SqlStore" logger=server
om_1          | 2019-11-13 21:57:25,135 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
jaeger_1      | {"level":"info","ts":1573682241.9193664,"caller":"app/server.go:112","msg":"Starting HTTP server","port":16686}
datanode_2    | 2019-11-13 21:57:23,505 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3    | 2019-11-13 21:57:21,521 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
s3g_1         | Nov 13, 2019 9:57:24 PM org.glassfish.jersey.internal.Errors logErrors
datanode_1    | 2019-11-13 21:57:21,274 INFO ozone.HddsDatanodeService: HddsDatanodeService host:f5d92a2776ba ip:172.19.0.3
scm_1         | 2019-11-13 21:57:33,485 INFO db.DBStoreBuilder: using custom profile for table: validCerts
om_1          | 2019-11-13 21:57:26,136 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
jaeger_1      | {"level":"info","ts":1573682241.955388,"caller":"all-in-one/main.go:298","msg":"Listening for Zipkin HTTP traffic","zipkin.http-port":9411}
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Connecting to DB" logger=sqlstore dbtype=sqlite3
datanode_3    | 2019-11-13 21:57:21,532 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
s3g_1         | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
datanode_1    | 2019-11-13 21:57:21,349 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
datanode_2    | 2019-11-13 21:57:23,512 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
scm_1         | 2019-11-13 21:57:33,485 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:validCerts
om_1          | 2019-11-13 21:57:27,137 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Starting DB migration" logger=migrator
datanode_3    | 2019-11-13 21:57:21,553 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
s3g_1         | 
datanode_1    | 2019-11-13 21:57:21,352 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2    | 2019-11-13 21:57:23,536 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
scm_1         | 2019-11-13 21:57:33,485 INFO db.DBStoreBuilder: using custom profile for table: revokedCerts
om_1          | 2019-11-13 21:57:28,137 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:26+0000 lvl=info msg="Executing migration" logger=migrator id="create migration_log table"
s3g_1         | 2019-11-13 21:57:24,111 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@77cb452c{/,file:///tmp/jetty-0.0.0.0-9878-s3gateway-_-any-14159561715529328462.dir/webapp/,AVAILABLE}{/s3gateway}
datanode_3    | 2019-11-13 21:57:22,746 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1    | 2019-11-13 21:57:21,362 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2    | 2019-11-13 21:57:24,391 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1          | 2019-11-13 21:57:29,138 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:33,485 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:revokedCerts
grafana_1     | t=2019-11-13T21:57:36+0000 lvl=info msg="Executing migration" logger=migrator id="create user table"
s3g_1         | 2019-11-13 21:57:24,116 INFO server.AbstractConnector: Started ServerConnector@3ba1308d{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
datanode_3    | 2019-11-13 21:57:22,779 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1    | 2019-11-13 21:57:21,390 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2    | 2019-11-13 21:57:24,425 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om_1          | 2019-11-13 21:57:30,139 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:33,496 INFO db.DBStoreBuilder: using custom profile for table: default
grafana_1     | t=2019-11-13T21:57:41+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user.login"
s3g_1         | 2019-11-13 21:57:24,117 INFO server.Server: Started @4126ms
datanode_3    | 2019-11-13 21:57:22,959 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_1    | 2019-11-13 21:57:22,397 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2    | 2019-11-13 21:57:24,531 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
om_1          | 2019-11-13 21:57:31,141 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:33,496 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user.email"
s3g_1         | 2019-11-13 21:57:24,119 INFO server.BaseHttpServer: HTTP server of S3GATEWAY is listening at http://0.0.0.0:9878
datanode_3    | 2019-11-13 21:57:22,959 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_1    | 2019-11-13 21:57:22,435 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2    | 2019-11-13 21:57:24,532 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
om_1          | 2019-11-13 21:57:32,142 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:33,498 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_user_login - v1"
datanode_3    | 2019-11-13 21:57:22,961 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1    | 2019-11-13 21:57:22,605 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_2    | 2019-11-13 21:57:24,549 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1          | 2019-11-13 21:57:32,146 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
scm_1         | 2019-11-13 21:57:45,641 INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@1b266842
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_user_email - v1"
datanode_3    | 2019-11-13 21:57:22,962 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_1    | 2019-11-13 21:57:22,606 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_2    | 2019-11-13 21:57:24,549 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1          | 2019-11-13 21:57:38,149 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:45,642 INFO net.NodeSchemaLoader: Loading network topology layer schema file
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table user to user_v1 - v1"
datanode_3    | 2019-11-13 21:57:22,962 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_2    | 2019-11-13 21:57:24,550 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1    | 2019-11-13 21:57:22,608 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1          | 2019-11-13 21:57:39,150 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:45,719 INFO node.SCMNodeManager: Entering startup safe mode.
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="create user table v2"
datanode_3    | 2019-11-13 21:57:23,141 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2    | 2019-11-13 21:57:24,679 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1    | 2019-11-13 21:57:22,609 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1          | 2019-11-13 21:57:40,151 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:45,826 INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_user_login - v2"
datanode_3    | 2019-11-13 21:57:23,357 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2    | 2019-11-13 21:57:24,815 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1    | 2019-11-13 21:57:22,609 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om_1          | 2019-11-13 21:57:41,153 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:45,843 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_user_email - v2"
datanode_3    | 2019-11-13 21:57:23,385 INFO util.log: Logging initialized @3315ms
datanode_2    | 2019-11-13 21:57:24,835 INFO util.log: Logging initialized @2823ms
datanode_1    | 2019-11-13 21:57:22,750 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1          | 2019-11-13 21:57:42,154 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:46,090 INFO pipeline.SCMPipelineManager: No pipeline exists in current db
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="copy data_source v1 to v2"
datanode_1    | 2019-11-13 21:57:22,921 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2    | 2019-11-13 21:57:24,908 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table user_v1"
om_1          | 2019-11-13 21:57:43,155 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:23,483 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2019-11-13 21:57:46,092 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2    | 2019-11-13 21:57:24,911 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="Add column help_flags1 to user table"
datanode_1    | 2019-11-13 21:57:22,950 INFO util.log: Logging initialized @3049ms
om_1          | 2019-11-13 21:57:44,157 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:23,486 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
scm_1         | 2019-11-13 21:57:46,284 WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
datanode_2    | 2019-11-13 21:57:24,917 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
grafana_1     | t=2019-11-13T21:57:45+0000 lvl=info msg="Executing migration" logger=migrator id="Update user table charset"
datanode_1    | 2019-11-13 21:57:23,061 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2019-11-13 21:57:45,158 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:23,494 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
scm_1         | 2019-11-13 21:57:46,826 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="Add last_seen_at column to user"
datanode_2    | 2019-11-13 21:57:24,918 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1    | 2019-11-13 21:57:23,065 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
om_1          | 2019-11-13 21:57:46,159 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:23,496 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
scm_1         | 2019-11-13 21:57:46,849 INFO ipc.Server: Starting Socket Reader #1 for port 9861
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="Add missing user data"
datanode_2    | 2019-11-13 21:57:24,918 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1    | 2019-11-13 21:57:23,076 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
om_1          | 2019-11-13 21:57:47,160 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:23,496 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2019-11-13 21:57:46,882 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="Add is_disabled column to user"
datanode_2    | 2019-11-13 21:57:24,918 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1    | 2019-11-13 21:57:23,079 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-06b5b809-a0af-45e8-8e2e-00b1bf5bb949
datanode_3    | 2019-11-13 21:57:23,496 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2019-11-13 21:57:46,883 INFO ipc.Server: Starting Socket Reader #1 for port 9863
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create temp user table v1-7"
datanode_2    | 2019-11-13 21:57:24,936 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1    | 2019-11-13 21:57:23,079 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2019-11-13 21:57:47,717 INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
datanode_3    | 2019-11-13 21:57:23,516 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2019-11-13 21:57:46,894 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_email - v1-7"
datanode_2    | 2019-11-13 21:57:24,943 INFO http.HttpServer2: Jetty bound to port 9882
datanode_1    | 2019-11-13 21:57:23,079 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | /************************************************************
datanode_3    | 2019-11-13 21:57:23,524 INFO http.HttpServer2: Jetty bound to port 9882
scm_1         | 2019-11-13 21:57:46,894 INFO ipc.Server: Starting Socket Reader #1 for port 9860
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_org_id - v1-7"
datanode_2    | 2019-11-13 21:57:24,944 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_1    | 2019-11-13 21:57:23,111 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at f40fe122cc8a/172.19.0.7
datanode_3    | 2019-11-13 21:57:23,525 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
scm_1         | 2019-11-13 21:57:46,918 INFO hdfs.DFSUtil: Starting Web-server for scm at: http://0.0.0.0:9876
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_code - v1-7"
datanode_2    | 2019-11-13 21:57:24,979 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@22a736d7{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1    | 2019-11-13 21:57:23,121 INFO http.HttpServer2: Jetty bound to port 9882
datanode_3    | 2019-11-13 21:57:23,551 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@35c12c7a{/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2019-11-13 21:57:47,122 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_status - v1-7"
datanode_2    | 2019-11-13 21:57:24,980 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@66273da0{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | ************************************************************/
datanode_1    | 2019-11-13 21:57:23,123 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3    | 2019-11-13 21:57:23,552 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@17f2dd85{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2019-11-13 21:57:47,137 INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="Update temp_user table charset"
datanode_2    | 2019-11-13 21:57:25,066 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1ab5f08a{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-13838599683462054725.dir/webapp/,AVAILABLE}{/hddsDatanode}
om_1          | 2019-11-13 21:57:48,834 INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_1    | 2019-11-13 21:57:23,161 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4a734c04{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3    | 2019-11-13 21:57:23,623 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@173a6728{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-11603945050686964985.dir/webapp/,AVAILABLE}{/hddsDatanode}
scm_1         | 2019-11-13 21:57:47,144 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create star table"
datanode_2    | 2019-11-13 21:57:25,073 INFO server.AbstractConnector: Started ServerConnector@1e9469b8{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
om_1          | /************************************************************
datanode_1    | 2019-11-13 21:57:23,162 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ac86d6a{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2019-11-13 21:57:47,146 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index star.user_id_dashboard_id"
datanode_3    | 2019-11-13 21:57:23,631 INFO server.AbstractConnector: Started ServerConnector@146ebb83{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2    | 2019-11-13 21:57:25,073 INFO server.Server: Started @3061ms
om_1          | STARTUP_MSG: Starting OzoneManager
datanode_1    | 2019-11-13 21:57:23,256 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@29149030{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-1553825456525987773.dir/webapp/,AVAILABLE}{/hddsDatanode}
scm_1         | 2019-11-13 21:57:47,147 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create org table v1"
datanode_3    | 2019-11-13 21:57:23,632 INFO server.Server: Started @3561ms
datanode_2    | 2019-11-13 21:57:25,077 INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | STARTUP_MSG:   host = f40fe122cc8a/172.19.0.7
datanode_1    | 2019-11-13 21:57:23,264 INFO server.AbstractConnector: Started ServerConnector@2dbd2221{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
scm_1         | 2019-11-13 21:57:47,147 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_org_name - v1"
datanode_3    | 2019-11-13 21:57:23,637 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2    | 2019-11-13 21:57:25,077 INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | STARTUP_MSG:   args = []
datanode_1    | 2019-11-13 21:57:23,265 INFO server.Server: Started @3364ms
scm_1         | 2019-11-13 21:57:47,166 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create org_user table v1"
datanode_3    | 2019-11-13 21:57:23,637 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2    | 2019-11-13 21:57:25,079 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
om_1          | STARTUP_MSG:   version = 3.2.0
scm_1         | 2019-11-13 21:57:47,172 INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_org_user_org_id - v1"
datanode_1    | 2019-11-13 21:57:23,270 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3    | 2019-11-13 21:57:23,639 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_2    | 2019-11-13 21:57:25,092 INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2019-11-13 21:57:47,235 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_org_user_org_id_user_id - v1"
datanode_1    | 2019-11-13 21:57:23,270 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3    | 2019-11-13 21:57:23,654 INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
datanode_2    | 2019-11-13 21:57:25,218 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
scm_1         | 2019-11-13 21:57:47,272 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1    | 2019-11-13 21:57:23,273 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="Update org table charset"
datanode_3    | 2019-11-13 21:57:23,827 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2    | 2019-11-13 21:57:28,145 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1         | 2019-11-13 21:57:47,272 INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
datanode_1    | 2019-11-13 21:57:23,289 INFO util.JvmPauseMonitor: Starting JVM pause monitor
grafana_1     | t=2019-11-13T21:57:46+0000 lvl=info msg="Executing migration" logger=migrator id="Update org_user table charset"
datanode_3    | 2019-11-13 21:57:26,722 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-13 21:57:29,146 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | STARTUP_MSG:   java = 11.0.3
scm_1         | 2019-11-13 21:57:47,488 INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
datanode_1    | 2019-11-13 21:57:23,442 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="Migrate all Read Only Viewers to Viewers"
datanode_3    | 2019-11-13 21:57:27,723 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-13 21:57:30,147 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,489 INFO ipc.Server: IPC Server Responder: starting
datanode_1    | 2019-11-13 21:57:26,363 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard table"
datanode_3    | 2019-11-13 21:57:28,724 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | ************************************************************/
datanode_2    | 2019-11-13 21:57:31,148 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,489 INFO ipc.Server: IPC Server listener on 9860: starting
datanode_1    | 2019-11-13 21:57:27,365 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard.account_id"
datanode_3    | 2019-11-13 21:57:29,725 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:48,841 INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2    | 2019-11-13 21:57:32,149 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,492 INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_1    | 2019-11-13 21:57:28,366 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_account_id_slug"
datanode_3    | 2019-11-13 21:57:30,726 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:49,631 INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.19.0.7:9862
datanode_2    | 2019-11-13 21:57:33,150 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,493 INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
datanode_1    | 2019-11-13 21:57:29,367 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_tag table"
datanode_3    | 2019-11-13 21:57:31,727 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:49,632 INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
datanode_2    | 2019-11-13 21:57:34,151 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,493 INFO ipc.Server: IPC Server Responder: starting
datanode_1    | 2019-11-13 21:57:30,368 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_tag.dasboard_id_term"
datanode_3    | 2019-11-13 21:57:32,728 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:49,636 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2019-11-13 21:57:47,494 INFO ipc.Server: IPC Server listener on 9863: starting
datanode_2    | 2019-11-13 21:57:35,152 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-13 21:57:31,369 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_dashboard_tag_dashboard_id_term - v1"
datanode_3    | 2019-11-13 21:57:33,729 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:49,645 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2019-11-13 21:57:47,496 INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
datanode_2    | 2019-11-13 21:57:36,153 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table dashboard to dashboard_v1 - v1"
datanode_3    | 2019-11-13 21:57:34,731 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,469 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2019-11-13 21:57:47,496 INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
datanode_2    | 2019-11-13 21:57:37,154 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-13 21:57:32,371 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard v2"
datanode_3    | 2019-11-13 21:57:35,732 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,497 INFO ipc.Server: IPC Server Responder: starting
datanode_2    | 2019-11-13 21:57:38,155 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,505 INFO util.log: Logging initialized @2483ms
datanode_1    | 2019-11-13 21:57:33,372 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_org_id - v2"
datanode_3    | 2019-11-13 21:57:36,733 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,497 INFO ipc.Server: IPC Server listener on 9861: starting
datanode_2    | 2019-11-13 21:57:39,156 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,646 INFO db.DBStoreBuilder: using custom profile for table: userTable
datanode_1    | 2019-11-13 21:57:34,373 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_org_id_slug - v2"
datanode_3    | 2019-11-13 21:57:37,734 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,502 INFO http.HttpServer2: Jetty bound to port 9876
datanode_2    | 2019-11-13 21:57:40,157 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,646 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:userTable
datanode_1    | 2019-11-13 21:57:35,374 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="copy dashboard v1 to v2"
datanode_3    | 2019-11-13 21:57:38,735 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,504 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2    | 2019-11-13 21:57:41,158 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,646 INFO db.DBStoreBuilder: using custom profile for table: volumeTable
datanode_1    | 2019-11-13 21:57:36,375 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="drop table dashboard_v1"
datanode_3    | 2019-11-13 21:57:39,737 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,550 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6818d900{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2    | 2019-11-13 21:57:42,160 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,646 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:volumeTable
datanode_1    | 2019-11-13 21:57:37,376 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:40,738 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard.data to mediumtext v1"
scm_1         | 2019-11-13 21:57:47,551 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3b36e000{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2019-11-13 21:57:50,646 INFO db.DBStoreBuilder: using custom profile for table: bucketTable
datanode_1    | 2019-11-13 21:57:38,377 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:41,739 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="Add column updated_by in dashboard - v2"
datanode_2    | 2019-11-13 21:57:43,161 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,679 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@59f93db8{/,file:///tmp/jetty-0.0.0.0-9876-scm-_-any-10733978254136930995.dir/webapp/,AVAILABLE}{/scm}
om_1          | 2019-11-13 21:57:50,646 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:bucketTable
datanode_1    | 2019-11-13 21:57:39,378 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="Add column created_by in dashboard - v2"
datanode_2    | 2019-11-13 21:57:44,162 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,646 INFO db.DBStoreBuilder: using custom profile for table: keyTable
datanode_1    | 2019-11-13 21:57:40,379 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,684 INFO server.AbstractConnector: Started ServerConnector@60783105{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="Add column gnetId in dashboard"
datanode_2    | 2019-11-13 21:57:45,163 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,647 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:keyTable
scm_1         | 2019-11-13 21:57:47,684 INFO server.Server: Started @15286ms
datanode_1    | 2019-11-13 21:57:41,380 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:42,740 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for gnetId in dashboard"
datanode_2    | 2019-11-13 21:57:46,164 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,647 INFO db.DBStoreBuilder: using custom profile for table: deletedTable
scm_1         | 2019-11-13 21:57:47,690 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1    | 2019-11-13 21:57:42,381 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:43,741 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="Add column plugin_id in dashboard"
datanode_2    | 2019-11-13 21:57:47,165 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-13 21:57:50,647 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedTable
datanode_1    | 2019-11-13 21:57:43,383 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:44,743 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,690 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2    | 2019-11-13 21:57:47,731 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
om_1          | 2019-11-13 21:57:50,647 INFO db.DBStoreBuilder: using custom profile for table: openKeyTable
datanode_3    | 2019-11-13 21:57:45,744 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:47+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for plugin_id in dashboard"
datanode_1    | 2019-11-13 21:57:44,384 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:47,692 INFO server.BaseHttpServer: HTTP server of SCM is listening at http://0.0.0.0:9876
datanode_2    | 2019-11-13 21:57:47,732 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
om_1          | 2019-11-13 21:57:50,647 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:openKeyTable
datanode_3    | 2019-11-13 21:57:46,745 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for dashboard_id in dashboard_tag"
datanode_1    | 2019-11-13 21:57:45,385 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-13 21:57:47,732 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10 at port 9858
scm_1         | 2019-11-13 21:57:47,697 INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2019-11-13 21:57:50,647 INFO db.DBStoreBuilder: using custom profile for table: s3Table
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard table charset"
datanode_1    | 2019-11-13 21:57:46,386 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:47,746 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-13 21:57:49,129 INFO net.NetworkTopology: Added a new node: /default-rack/3f125c43-e0c0-4016-b1c9-9c61c0fe5f10
om_1          | 2019-11-13 21:57:50,647 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3Table
datanode_2    | 2019-11-13 21:57:47,753 INFO impl.RaftServerProxy: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: start RPC server
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard_tag table charset"
datanode_1    | 2019-11-13 21:57:47,387 INFO ipc.Client: Retrying connect to server: scm/172.19.0.10:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-13 21:57:47,871 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
om_1          | 2019-11-13 21:57:50,648 INFO db.DBStoreBuilder: using custom profile for table: multipartInfoTable
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Add column folder_id in dashboard"
datanode_2    | 2019-11-13 21:57:47,966 INFO server.GrpcService: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
scm_1         | 2019-11-13 21:57:49,129 INFO node.SCMNodeManager: Registered Data node : 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10{ip: 172.19.0.6, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
datanode_1    | 2019-11-13 21:57:47,731 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3    | 2019-11-13 21:57:47,872 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
om_1          | 2019-11-13 21:57:50,648 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:multipartInfoTable
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Add column isFolder in dashboard"
datanode_2    | WARNING: An illegal reflective access operation has occurred
scm_1         | 2019-11-13 21:57:49,134 INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
datanode_1    | 2019-11-13 21:57:47,732 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3    | 2019-11-13 21:57:47,872 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 657ad21c-ec1e-4fe9-87b2-969df546c1d3 at port 9858
om_1          | 2019-11-13 21:57:50,648 INFO db.DBStoreBuilder: using custom profile for table: dTokenTable
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Add column has_acl in dashboard"
datanode_2    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
scm_1         | 2019-11-13 21:57:49,137 INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode_1    | 2019-11-13 21:57:47,732 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d13145d6-352e-4f4c-9fe8-9d9a20b76d13 at port 9858
datanode_3    | 2019-11-13 21:57:47,886 INFO impl.RaftServerProxy: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: start RPC server
om_1          | 2019-11-13 21:57:50,648 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:dTokenTable
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Add column uid in dashboard"
datanode_2    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
scm_1         | 2019-11-13 21:57:49,139 INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
datanode_1    | 2019-11-13 21:57:47,767 INFO impl.RaftServerProxy: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: start RPC server
datanode_3    | 2019-11-13 21:57:47,994 INFO server.GrpcService: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
om_1          | 2019-11-13 21:57:50,648 INFO db.DBStoreBuilder: using custom profile for table: s3SecretTable
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Update uid column values in dashboard"
scm_1         | 2019-11-13 21:57:49,320 INFO net.NetworkTopology: Added a new node: /default-rack/d13145d6-352e-4f4c-9fe8-9d9a20b76d13
datanode_2    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_1    | 2019-11-13 21:57:47,896 INFO server.GrpcService: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3    | WARNING: An illegal reflective access operation has occurred
om_1          | 2019-11-13 21:57:50,648 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3SecretTable
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index dashboard_org_id_uid"
scm_1         | 2019-11-13 21:57:49,321 INFO node.SCMNodeManager: Registered Data node : d13145d6-352e-4f4c-9fe8-9d9a20b76d13{ip: 172.19.0.3, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
datanode_2    | WARNING: All illegal access operations will be denied in a future release
datanode_1    | WARNING: An illegal reflective access operation has occurred
datanode_3    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
om_1          | 2019-11-13 21:57:50,649 INFO db.DBStoreBuilder: using custom profile for table: prefixTable
scm_1         | 2019-11-13 21:57:49,707 INFO net.NetworkTopology: Added a new node: /default-rack/657ad21c-ec1e-4fe9-87b2-969df546c1d3
datanode_2    | 2019-11-13 21:57:49,998 INFO impl.RaftServerProxy: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: addNew group-527DE9B1BBD8:[3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858] returns group-527DE9B1BBD8:java.util.concurrent.CompletableFuture@d8953ed[Not completed]
datanode_1    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
datanode_3    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Remove unique index org_id_slug"
scm_1         | 2019-11-13 21:57:49,708 INFO node.SCMNodeManager: Registered Data node : 657ad21c-ec1e-4fe9-87b2-969df546c1d3{ip: 172.19.0.8, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
om_1          | 2019-11-13 21:57:50,649 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:prefixTable
datanode_2    | 2019-11-13 21:57:50,013 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: new RaftServerImpl for group-527DE9B1BBD8:[3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858] with ContainerStateMachine:uninitialized
datanode_1    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
datanode_3    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard title length"
scm_1         | WARNING: An illegal reflective access operation has occurred
om_1          | 2019-11-13 21:57:50,659 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_2    | 2019-11-13 21:57:50,014 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index for dashboard_org_id_title_folder_id"
datanode_3    | WARNING: All illegal access operations will be denied in a future release
scm_1         | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
om_1          | 2019-11-13 21:57:50,659 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_1    | WARNING: All illegal access operations will be denied in a future release
datanode_2    | 2019-11-13 21:57:50,014 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_provisioning"
datanode_3    | 2019-11-13 21:57:51,065 INFO impl.RaftServerProxy: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: addNew group-5853C67F24D4:[657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858] returns group-5853C67F24D4:java.util.concurrent.CompletableFuture@18df7f29[Not completed]
scm_1         | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
om_1          | 2019-11-13 21:57:50,660 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_1    | 2019-11-13 21:57:50,562 INFO impl.RaftServerProxy: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: addNew group-D76FAA64F965:[d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858] returns group-D76FAA64F965:java.util.concurrent.CompletableFuture@30808200[Not completed]
datanode_2    | 2019-11-13 21:57:50,014 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table dashboard_provisioning to dashboard_provisioning_tmp_qwerty - v1"
scm_1         | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3    | 2019-11-13 21:57:51,084 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: new RaftServerImpl for group-5853C67F24D4:[657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858] with ContainerStateMachine:uninitialized
om_1          | 2019-11-13 21:57:51,488 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1    | 2019-11-13 21:57:50,577 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: new RaftServerImpl for group-D76FAA64F965:[d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858] with ContainerStateMachine:uninitialized
datanode_2    | 2019-11-13 21:57:50,015 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_provisioning v2"
scm_1         | WARNING: All illegal access operations will be denied in a future release
datanode_3    | 2019-11-13 21:57:51,085 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1          | 2019-11-13 21:57:51,497 INFO ipc.Server: Starting Socket Reader #1 for port 9862
datanode_1    | 2019-11-13 21:57:50,578 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2    | 2019-11-13 21:57:50,015 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_provisioning_dashboard_id - v2"
scm_1         | 2019-11-13 21:57:50,295 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b3aeb8e9-15e5-4e19-baa0-527de9b1bbd8, Nodes: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10{ip: 172.19.0.6, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
datanode_3    | 2019-11-13 21:57:51,086 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1          | 2019-11-13 21:57:51,531 INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.19.0.7:9862
datanode_1    | 2019-11-13 21:57:50,579 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_provisioning_dashboard_id_name - v2"
datanode_2    | 2019-11-13 21:57:50,020 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8: ConfigurationManager, init=-1: [3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858], old=null, confs=<EMPTY_MAP>
scm_1         | 2019-11-13 21:57:50,786 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d1b03ee0-a8c5-4fb6-80ed-d76faa64f965, Nodes: d13145d6-352e-4f4c-9fe8-9d9a20b76d13{ip: 172.19.0.3, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
datanode_3    | 2019-11-13 21:57:51,086 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
om_1          | 2019-11-13 21:57:51,602 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="copy dashboard_provisioning v1 to v2"
datanode_2    | 2019-11-13 21:57:50,021 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1    | 2019-11-13 21:57:50,579 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
scm_1         | 2019-11-13 21:57:51,322 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 00646862-42c3-4bd9-bad3-5853c67f24d4, Nodes: 657ad21c-ec1e-4fe9-87b2-969df546c1d3{ip: 172.19.0.8, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
datanode_3    | 2019-11-13 21:57:51,086 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om_1          | 2019-11-13 21:57:51,643 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2    | 2019-11-13 21:57:50,025 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="drop dashboard_provisioning_tmp_qwerty"
scm_1         | 2019-11-13 21:57:51,437 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 93a6264a-3166-42f4-882e-354aba9331b7, Nodes: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10{ip: 172.19.0.6, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}d13145d6-352e-4f4c-9fe8-9d9a20b76d13{ip: 172.19.0.3, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}657ad21c-ec1e-4fe9-87b2-969df546c1d3{ip: 172.19.0.8, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED]
datanode_3    | 2019-11-13 21:57:51,087 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1    | 2019-11-13 21:57:50,579 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om_1          | 2019-11-13 21:57:51,643 INFO impl.MetricsSystemImpl: OzoneManager metrics system started
datanode_2    | 2019-11-13 21:57:50,026 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b3aeb8e9-15e5-4e19-baa0-527de9b1bbd8 does not exist. Creating ...
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Add check_sum column"
scm_1         | 2019-11-13 21:57:55,351 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b3aeb8e9-15e5-4e19-baa0-527de9b1bbd8, Nodes: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10{ip: 172.19.0.6, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN] moved to OPEN state
datanode_3    | 2019-11-13 21:57:51,093 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4: ConfigurationManager, init=-1: [657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_1    | 2019-11-13 21:57:50,580 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1          | 2019-11-13 21:57:51,679 INFO ipc.Server: IPC Server Responder: starting
datanode_2    | 2019-11-13 21:57:50,066 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b3aeb8e9-15e5-4e19-baa0-527de9b1bbd8/in_use.lock acquired by nodename 7@5932f82a666d
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="create data_source table"
scm_1         | 2019-11-13 21:57:55,916 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d1b03ee0-a8c5-4fb6-80ed-d76faa64f965, Nodes: d13145d6-352e-4f4c-9fe8-9d9a20b76d13{ip: 172.19.0.3, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN] moved to OPEN state
datanode_3    | 2019-11-13 21:57:51,093 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1    | 2019-11-13 21:57:50,585 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965: ConfigurationManager, init=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858], old=null, confs=<EMPTY_MAP>
om_1          | 2019-11-13 21:57:51,679 INFO ipc.Server: IPC Server listener on 9862: starting
datanode_2    | 2019-11-13 21:57:50,101 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b3aeb8e9-15e5-4e19-baa0-527de9b1bbd8 has been successfully formatted.
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="add index data_source.account_id"
scm_1         | 2019-11-13 21:57:56,550 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 00646862-42c3-4bd9-bad3-5853c67f24d4, Nodes: 657ad21c-ec1e-4fe9-87b2-969df546c1d3{ip: 172.19.0.8, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN] moved to OPEN state
datanode_3    | 2019-11-13 21:57:51,098 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1    | 2019-11-13 21:57:50,585 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1          | 2019-11-13 21:57:51,709 INFO hdfs.DFSUtil: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
datanode_2    | 2019-11-13 21:57:50,106 INFO ratis.ContainerStateMachine: group-527DE9B1BBD8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index data_source.account_id_name"
scm_1         | 2019-11-13 21:57:56,595 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 93a6264a-3166-42f4-882e-354aba9331b7, Nodes: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10{ip: 172.19.0.6, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}d13145d6-352e-4f4c-9fe8-9d9a20b76d13{ip: 172.19.0.3, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}657ad21c-ec1e-4fe9-87b2-969df546c1d3{ip: 172.19.0.8, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN] moved to OPEN state
datanode_3    | 2019-11-13 21:57:51,100 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/00646862-42c3-4bd9-bad3-5853c67f24d4 does not exist. Creating ...
datanode_1    | 2019-11-13 21:57:50,590 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1          | 2019-11-13 21:57:51,847 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2    | 2019-11-13 21:57:50,106 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_data_source_account_id - v1"
datanode_3    | 2019-11-13 21:57:51,123 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/00646862-42c3-4bd9-bad3-5853c67f24d4/in_use.lock acquired by nodename 7@04b2d59aad1f
datanode_1    | 2019-11-13 21:57:50,591 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d1b03ee0-a8c5-4fb6-80ed-d76faa64f965 does not exist. Creating ...
om_1          | 2019-11-13 21:57:51,851 INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_2    | 2019-11-13 21:57:50,110 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_data_source_account_id_name - v1"
datanode_1    | 2019-11-13 21:57:50,624 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d1b03ee0-a8c5-4fb6-80ed-d76faa64f965/in_use.lock acquired by nodename 7@f5d92a2776ba
om_1          | 2019-11-13 21:57:51,860 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1    | 2019-11-13 21:57:50,639 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d1b03ee0-a8c5-4fb6-80ed-d76faa64f965 has been successfully formatted.
datanode_3    | 2019-11-13 21:57:51,137 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/00646862-42c3-4bd9-bad3-5853c67f24d4 has been successfully formatted.
datanode_2    | 2019-11-13 21:57:50,115 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table data_source to data_source_v1 - v1"
om_1          | 2019-11-13 21:57:51,863 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
datanode_1    | 2019-11-13 21:57:50,643 INFO ratis.ContainerStateMachine: group-D76FAA64F965: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3    | 2019-11-13 21:57:51,141 INFO ratis.ContainerStateMachine: group-5853C67F24D4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2    | 2019-11-13 21:57:50,116 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="create data_source table v2"
om_1          | 2019-11-13 21:57:51,863 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1    | 2019-11-13 21:57:50,643 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_3    | 2019-11-13 21:57:51,141 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_2    | 2019-11-13 21:57:50,118 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_data_source_org_id - v2"
om_1          | 2019-11-13 21:57:51,863 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1    | 2019-11-13 21:57:50,646 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3    | 2019-11-13 21:57:51,144 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_data_source_org_id_name - v2"
om_1          | 2019-11-13 21:57:51,886 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1    | 2019-11-13 21:57:50,649 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3    | 2019-11-13 21:57:51,147 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2    | 2019-11-13 21:57:50,124 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="copy data_source v1 to v2"
om_1          | 2019-11-13 21:57:51,888 INFO http.HttpServer2: Jetty bound to port 9874
datanode_1    | 2019-11-13 21:57:50,650 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2    | 2019-11-13 21:57:50,128 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-13 21:57:51,147 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-13T21:57:48+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table data_source_v1 #2"
om_1          | 2019-11-13 21:57:51,889 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_1    | 2019-11-13 21:57:50,651 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2    | 2019-11-13 21:57:50,133 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Add column with_credentials"
datanode_3    | 2019-11-13 21:57:51,149 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1          | 2019-11-13 21:57:51,920 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4a2929a4{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1    | 2019-11-13 21:57:50,655 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Add secure json data column"
datanode_2    | 2019-11-13 21:57:50,139 INFO segmented.SegmentedRaftLogWorker: new 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b3aeb8e9-15e5-4e19-baa0-527de9b1bbd8
datanode_3    | 2019-11-13 21:57:51,153 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1          | 2019-11-13 21:57:51,921 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@529c2a9a{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1    | 2019-11-13 21:57:50,658 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Update data_source table charset"
datanode_2    | 2019-11-13 21:57:50,139 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3    | 2019-11-13 21:57:51,156 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1          | 2019-11-13 21:57:52,012 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2538bc06{/,file:///tmp/jetty-0.0.0.0-9874-ozoneManager-_-any-4074260243935423923.dir/webapp/,AVAILABLE}{/ozoneManager}
datanode_1    | 2019-11-13 21:57:50,662 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Update initial version to 1"
datanode_2    | 2019-11-13 21:57:50,140 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3    | 2019-11-13 21:57:51,160 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1          | 2019-11-13 21:57:52,017 INFO server.AbstractConnector: Started ServerConnector@4317850d{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
datanode_1    | 2019-11-13 21:57:50,668 INFO segmented.SegmentedRaftLogWorker: new d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d1b03ee0-a8c5-4fb6-80ed-d76faa64f965
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Add read_only data column"
datanode_2    | 2019-11-13 21:57:50,141 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3    | 2019-11-13 21:57:51,164 INFO segmented.SegmentedRaftLogWorker: new 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/00646862-42c3-4bd9-bad3-5853c67f24d4
om_1          | 2019-11-13 21:57:52,017 INFO server.Server: Started @3995ms
datanode_1    | 2019-11-13 21:57:50,669 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Migrate logging ds to loki ds"
datanode_2    | 2019-11-13 21:57:50,142 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3    | 2019-11-13 21:57:51,165 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
om_1          | 2019-11-13 21:57:52,021 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1    | 2019-11-13 21:57:50,669 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Update json_data with nulls"
datanode_2    | 2019-11-13 21:57:50,142 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3    | 2019-11-13 21:57:51,165 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
om_1          | 2019-11-13 21:57:52,021 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1    | 2019-11-13 21:57:50,671 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create api_key table"
datanode_2    | 2019-11-13 21:57:50,142 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3    | 2019-11-13 21:57:51,166 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1          | 2019-11-13 21:57:52,023 INFO server.BaseHttpServer: HTTP server of OZONEMANAGER is listening at http://0.0.0.0:9874
datanode_1    | 2019-11-13 21:57:50,671 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.account_id"
datanode_2    | 2019-11-13 21:57:50,143 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3    | 2019-11-13 21:57:51,166 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1          | 2019-11-13 21:58:04,596 INFO volume.OMVolumeCreateRequest: created volume:vol-0-80493 for user:hadoop
datanode_1    | 2019-11-13 21:57:50,672 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.key"
datanode_2    | 2019-11-13 21:57:50,143 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1          | 2019-11-13 21:58:04,640 INFO volume.OMVolumeCreateRequest: created volume:vol-1-38214 for user:hadoop
datanode_3    | 2019-11-13 21:57:51,166 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_1    | 2019-11-13 21:57:50,672 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.account_id_name"
datanode_2    | 2019-11-13 21:57:50,144 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1          | 2019-11-13 21:58:04,672 INFO volume.OMVolumeCreateRequest: created volume:vol-2-71576 for user:hadoop
datanode_3    | 2019-11-13 21:57:51,167 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_api_key_account_id - v1"
datanode_2    | 2019-11-13 21:57:50,153 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1    | 2019-11-13 21:57:50,673 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3    | 2019-11-13 21:57:51,167 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2    | 2019-11-13 21:57:50,158 INFO segmented.SegmentedRaftLogWorker: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_api_key_key - v1"
datanode_1    | 2019-11-13 21:57:50,673 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1          | 2019-11-13 21:58:04,695 INFO volume.OMVolumeCreateRequest: created volume:vol-3-54155 for user:hadoop
datanode_3    | 2019-11-13 21:57:51,167 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_api_key_account_id_name - v1"
datanode_2    | 2019-11-13 21:57:50,163 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1    | 2019-11-13 21:57:50,674 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3    | 2019-11-13 21:57:51,168 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table api_key to api_key_v1 - v1"
datanode_2    | 2019-11-13 21:57:50,164 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1          | 2019-11-13 21:58:04,726 INFO volume.OMVolumeCreateRequest: created volume:vol-4-45158 for user:hadoop
datanode_3    | 2019-11-13 21:57:51,174 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create api_key table v2"
datanode_2    | 2019-11-13 21:57:50,164 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1    | 2019-11-13 21:57:50,684 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3    | 2019-11-13 21:57:51,246 INFO segmented.SegmentedRaftLogWorker: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_api_key_org_id - v2"
datanode_1    | 2019-11-13 21:57:50,689 INFO segmented.SegmentedRaftLogWorker: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3    | 2019-11-13 21:57:51,250 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2    | 2019-11-13 21:57:50,165 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_api_key_key - v2"
datanode_3    | 2019-11-13 21:57:51,251 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1    | 2019-11-13 21:57:50,693 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2    | 2019-11-13 21:57:50,186 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_api_key_org_id_name - v2"
datanode_2    | 2019-11-13 21:57:50,189 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-13 21:57:50,694 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3    | 2019-11-13 21:57:51,251 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="copy api_key v1 to v2"
datanode_2    | 2019-11-13 21:57:50,190 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8: start as a follower, conf=-1: [3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858], old=null
datanode_1    | 2019-11-13 21:57:50,695 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3    | 2019-11-13 21:57:51,252 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table api_key_v1"
datanode_2    | 2019-11-13 21:57:50,192 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1    | 2019-11-13 21:57:50,695 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3    | 2019-11-13 21:57:51,268 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Update api_key table charset"
datanode_2    | 2019-11-13 21:57:50,193 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: start FollowerState
datanode_1    | 2019-11-13 21:57:50,715 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-13 21:57:51,269 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="Add expires to api_key table"
datanode_2    | 2019-11-13 21:57:50,197 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-527DE9B1BBD8,id=3f125c43-e0c0-4016-b1c9-9c61c0fe5f10
datanode_1    | 2019-11-13 21:57:50,717 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-13 21:57:51,271 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4: start as a follower, conf=-1: [657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_snapshot table v4"
datanode_2    | 2019-11-13 21:57:50,199 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-13 21:57:50,719 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965: start as a follower, conf=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858], old=null
datanode_3    | 2019-11-13 21:57:51,272 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4: changes role from      null to FOLLOWER at term 0 for startAsFollower
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="drop table dashboard_snapshot_v4 #1"
datanode_2    | 2019-11-13 21:57:51,368 INFO impl.RaftServerProxy: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: addNew group-354ABA9331B7:[d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858] returns group-354ABA9331B7:java.util.concurrent.CompletableFuture@3215f9fd[Not completed]
datanode_1    | 2019-11-13 21:57:50,720 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3    | 2019-11-13 21:57:51,273 INFO impl.RoleInfo: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: start FollowerState
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_snapshot table v5 #2"
datanode_2    | 2019-11-13 21:57:51,371 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: new RaftServerImpl for group-354ABA9331B7:[d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858] with ContainerStateMachine:uninitialized
datanode_1    | 2019-11-13 21:57:50,721 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: start FollowerState
datanode_3    | 2019-11-13 21:57:51,276 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5853C67F24D4,id=657ad21c-ec1e-4fe9-87b2-969df546c1d3
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_snapshot_key - v5"
datanode_2    | 2019-11-13 21:57:51,371 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1    | 2019-11-13 21:57:50,725 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D76FAA64F965,id=d13145d6-352e-4f4c-9fe8-9d9a20b76d13
datanode_3    | 2019-11-13 21:57:51,278 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-13T21:57:49+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_snapshot_delete_key - v5"
datanode_2    | 2019-11-13 21:57:51,371 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1    | 2019-11-13 21:57:50,726 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-13 21:57:51,381 INFO impl.RaftServerProxy: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: addNew group-354ABA9331B7:[d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858] returns group-354ABA9331B7:java.util.concurrent.CompletableFuture@2d310297[Not completed]
datanode_2    | 2019-11-13 21:57:51,371 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_snapshot_user_id - v5"
datanode_1    | 2019-11-13 21:57:51,353 INFO impl.RaftServerProxy: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: addNew group-354ABA9331B7:[d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858] returns group-354ABA9331B7:java.util.concurrent.CompletableFuture@65fe859a[Not completed]
datanode_3    | 2019-11-13 21:57:51,384 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: new RaftServerImpl for group-354ABA9331B7:[d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858] with ContainerStateMachine:uninitialized
datanode_2    | 2019-11-13 21:57:51,371 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard_snapshot to mediumtext v2"
datanode_3    | 2019-11-13 21:57:51,384 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2    | 2019-11-13 21:57:51,371 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3    | 2019-11-13 21:57:51,384 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard_snapshot table charset"
datanode_1    | 2019-11-13 21:57:51,356 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: new RaftServerImpl for group-354ABA9331B7:[d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858] with ContainerStateMachine:uninitialized
datanode_2    | 2019-11-13 21:57:51,372 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7: ConfigurationManager, init=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_3    | 2019-11-13 21:57:51,384 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="Add column external_delete_url to dashboard_snapshots table"
datanode_1    | 2019-11-13 21:57:51,356 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2    | 2019-11-13 21:57:51,372 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3    | 2019-11-13 21:57:51,384 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="create quota table v1"
datanode_1    | 2019-11-13 21:57:51,356 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2    | 2019-11-13 21:57:51,372 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3    | 2019-11-13 21:57:51,385 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_quota_org_id_user_id_target - v1"
datanode_1    | 2019-11-13 21:57:51,356 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_2    | 2019-11-13 21:57:51,372 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7 does not exist. Creating ...
datanode_3    | 2019-11-13 21:57:51,385 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7: ConfigurationManager, init=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null, confs=<EMPTY_MAP>
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="Update quota table charset"
datanode_1    | 2019-11-13 21:57:51,357 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2    | 2019-11-13 21:57:51,384 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7/in_use.lock acquired by nodename 7@5932f82a666d
datanode_3    | 2019-11-13 21:57:51,385 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="create plugin_setting table"
datanode_1    | 2019-11-13 21:57:51,357 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2    | 2019-11-13 21:57:51,402 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7 has been successfully formatted.
datanode_3    | 2019-11-13 21:57:51,385 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_plugin_setting_org_id_plugin_id - v1"
datanode_1    | 2019-11-13 21:57:51,357 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7: ConfigurationManager, init=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_2    | 2019-11-13 21:57:51,402 INFO ratis.ContainerStateMachine: group-354ABA9331B7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3    | 2019-11-13 21:57:51,386 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7 does not exist. Creating ...
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="Add column plugin_version to plugin_settings"
datanode_1    | 2019-11-13 21:57:51,357 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2    | 2019-11-13 21:57:51,402 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="Update plugin_setting table charset"
datanode_3    | 2019-11-13 21:57:51,402 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7/in_use.lock acquired by nodename 7@04b2d59aad1f
datanode_1    | 2019-11-13 21:57:51,357 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2    | 2019-11-13 21:57:51,403 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="create session table"
datanode_3    | 2019-11-13 21:57:51,417 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7 has been successfully formatted.
datanode_2    | 2019-11-13 21:57:51,403 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1    | 2019-11-13 21:57:51,357 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7 does not exist. Creating ...
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table playlist table"
datanode_3    | 2019-11-13 21:57:51,417 INFO ratis.ContainerStateMachine: group-354ABA9331B7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2    | 2019-11-13 21:57:51,403 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1    | 2019-11-13 21:57:51,370 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7/in_use.lock acquired by nodename 7@f5d92a2776ba
grafana_1     | t=2019-11-13T21:57:50+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table playlist_item table"
datanode_3    | 2019-11-13 21:57:51,418 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_2    | 2019-11-13 21:57:51,403 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1    | 2019-11-13 21:57:51,384 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7 has been successfully formatted.
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="create playlist table v2"
datanode_3    | 2019-11-13 21:57:51,418 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2    | 2019-11-13 21:57:51,404 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1    | 2019-11-13 21:57:51,385 INFO ratis.ContainerStateMachine: group-354ABA9331B7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="create playlist item table v2"
datanode_3    | 2019-11-13 21:57:51,418 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2    | 2019-11-13 21:57:51,404 INFO segmented.SegmentedRaftLogWorker: new 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7
datanode_1    | 2019-11-13 21:57:51,385 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Update playlist table charset"
datanode_3    | 2019-11-13 21:57:51,418 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2    | 2019-11-13 21:57:51,404 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1    | 2019-11-13 21:57:51,385 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Update playlist_item table charset"
datanode_3    | 2019-11-13 21:57:51,418 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2    | 2019-11-13 21:57:51,404 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1    | 2019-11-13 21:57:51,385 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="drop preferences table v2"
datanode_3    | 2019-11-13 21:57:51,418 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2    | 2019-11-13 21:57:51,404 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1    | 2019-11-13 21:57:51,385 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="drop preferences table v3"
datanode_3    | 2019-11-13 21:57:51,418 INFO segmented.SegmentedRaftLogWorker: new 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7
datanode_2    | 2019-11-13 21:57:51,404 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1    | 2019-11-13 21:57:51,385 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="create preferences table v3"
datanode_3    | 2019-11-13 21:57:51,418 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2    | 2019-11-13 21:57:51,404 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Update preferences table charset"
datanode_3    | 2019-11-13 21:57:51,418 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1    | 2019-11-13 21:57:51,386 INFO segmented.SegmentedRaftLogWorker: new d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7
datanode_2    | 2019-11-13 21:57:51,404 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Add column team_id in preferences"
datanode_3    | 2019-11-13 21:57:51,419 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2    | 2019-11-13 21:57:51,405 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Update team_id column values in preferences"
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2    | 2019-11-13 21:57:51,405 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="create alert table v1"
datanode_3    | 2019-11-13 21:57:51,419 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2    | 2019-11-13 21:57:51,405 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert org_id & id "
datanode_3    | 2019-11-13 21:57:51,419 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2    | 2019-11-13 21:57:51,405 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert state"
datanode_3    | 2019-11-13 21:57:51,419 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2    | 2019-11-13 21:57:51,416 INFO segmented.SegmentedRaftLogWorker: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert dashboard_id"
datanode_3    | 2019-11-13 21:57:51,419 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2    | 2019-11-13 21:57:51,416 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Create alert_rule_tag table v1"
datanode_3    | 2019-11-13 21:57:51,419 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2    | 2019-11-13 21:57:51,416 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index alert_rule_tag.alert_id_tag_id"
datanode_3    | 2019-11-13 21:57:51,419 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2    | 2019-11-13 21:57:51,416 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="create alert_notification table v1"
datanode_3    | 2019-11-13 21:57:51,419 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2    | 2019-11-13 21:57:51,416 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Add column is_default"
datanode_2    | 2019-11-13 21:57:51,417 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-13 21:57:51,386 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3    | 2019-11-13 21:57:51,419 INFO segmented.SegmentedRaftLogWorker: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Add column frequency"
datanode_2    | 2019-11-13 21:57:51,417 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-13 21:57:51,387 INFO segmented.SegmentedRaftLogWorker: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3    | 2019-11-13 21:57:51,420 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Add column send_reminder"
datanode_2    | 2019-11-13 21:57:51,417 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7: start as a follower, conf=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
datanode_1    | 2019-11-13 21:57:51,387 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3    | 2019-11-13 21:57:51,420 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Add column disable_resolve_message"
datanode_2    | 2019-11-13 21:57:51,417 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1    | 2019-11-13 21:57:51,387 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3    | 2019-11-13 21:57:51,420 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert_notification org_id & name"
datanode_1    | 2019-11-13 21:57:51,387 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2    | 2019-11-13 21:57:51,417 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: start FollowerState
datanode_3    | 2019-11-13 21:57:51,420 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1    | 2019-11-13 21:57:51,387 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2    | 2019-11-13 21:57:51,418 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-354ABA9331B7,id=3f125c43-e0c0-4016-b1c9-9c61c0fe5f10
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert table charset"
datanode_3    | 2019-11-13 21:57:51,420 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-13 21:57:51,388 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert_notification table charset"
datanode_3    | 2019-11-13 21:57:51,421 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-13 21:57:51,418 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-13 21:57:51,388 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-13T21:57:51+0000 lvl=info msg="Executing migration" logger=migrator id="create notification_journal table v1"
datanode_3    | 2019-11-13 21:57:51,421 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7: start as a follower, conf=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
datanode_1    | 2019-11-13 21:57:51,388 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7: start as a follower, conf=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
datanode_2    | 2019-11-13 21:57:55,238 INFO impl.FollowerState: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8-FollowerState: change to CANDIDATE, lastRpcTime:5046ms, electionTimeout:5045ms
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="add index notification_journal org_id & alert_id & notifier_id"
datanode_3    | 2019-11-13 21:57:51,421 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1    | 2019-11-13 21:57:51,388 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2    | 2019-11-13 21:57:55,242 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: shutdown FollowerState
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="drop alert_notification_journal"
datanode_3    | 2019-11-13 21:57:51,421 INFO impl.RoleInfo: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: start FollowerState
datanode_1    | 2019-11-13 21:57:51,388 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: start FollowerState
datanode_2    | 2019-11-13 21:57:55,243 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="create alert_notification_state table v1"
datanode_3    | 2019-11-13 21:57:51,421 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-354ABA9331B7,id=657ad21c-ec1e-4fe9-87b2-969df546c1d3
datanode_1    | 2019-11-13 21:57:51,389 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-354ABA9331B7,id=d13145d6-352e-4f4c-9fe8-9d9a20b76d13
datanode_2    | 2019-11-13 21:57:55,246 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: start LeaderElection
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert_notification_state org_id & alert_id & notifier_id"
datanode_3    | 2019-11-13 21:57:51,422 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-13 21:57:51,389 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-13 21:57:55,270 INFO impl.LeaderElection: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8-LeaderElection1: begin an election at term 1 for -1: [3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858], old=null
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Add for to alert table"
datanode_1    | 2019-11-13 21:57:55,815 INFO impl.FollowerState: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965-FollowerState: change to CANDIDATE, lastRpcTime:5094ms, electionTimeout:5093ms
datanode_3    | 2019-11-13 21:57:56,429 INFO impl.FollowerState: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4-FollowerState: change to CANDIDATE, lastRpcTime:5156ms, electionTimeout:5156ms
datanode_2    | 2019-11-13 21:57:55,272 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: shutdown LeaderElection
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Add column uid in alert_notification"
datanode_1    | 2019-11-13 21:57:55,817 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: shutdown FollowerState
datanode_3    | 2019-11-13 21:57:56,431 INFO impl.RoleInfo: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: shutdown FollowerState
datanode_2    | 2019-11-13 21:57:55,272 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Update uid column values in alert_notification"
datanode_1    | 2019-11-13 21:57:55,817 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3    | 2019-11-13 21:57:56,431 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index alert_notification_org_id_uid"
datanode_1    | 2019-11-13 21:57:55,821 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: start LeaderElection
datanode_2    | 2019-11-13 21:57:55,272 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-527DE9B1BBD8 with new leaderId: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10
datanode_3    | 2019-11-13 21:57:56,433 INFO impl.RoleInfo: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: start LeaderElection
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Remove unique index org_id_name"
datanode_1    | 2019-11-13 21:57:55,836 INFO impl.LeaderElection: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965-LeaderElection1: begin an election at term 1 for -1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858], old=null
datanode_2    | 2019-11-13 21:57:55,278 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8: change Leader from null to 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10 at term 1 for becomeLeader, leader elected after 5166ms
datanode_3    | 2019-11-13 21:57:56,457 INFO impl.LeaderElection: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4-LeaderElection1: begin an election at term 1 for -1: [657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old annotation table v4"
datanode_1    | 2019-11-13 21:57:55,837 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: shutdown LeaderElection
datanode_2    | 2019-11-13 21:57:55,282 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3    | 2019-11-13 21:57:56,458 INFO impl.RoleInfo: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: shutdown LeaderElection
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="create annotation table v5"
datanode_1    | 2019-11-13 21:57:55,838 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2    | 2019-11-13 21:57:55,282 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3    | 2019-11-13 21:57:56,459 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 0 v3"
datanode_1    | 2019-11-13 21:57:55,838 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D76FAA64F965 with new leaderId: d13145d6-352e-4f4c-9fe8-9d9a20b76d13
datanode_2    | 2019-11-13 21:57:55,284 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 1 v3"
datanode_3    | 2019-11-13 21:57:56,459 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5853C67F24D4 with new leaderId: 657ad21c-ec1e-4fe9-87b2-969df546c1d3
datanode_1    | 2019-11-13 21:57:55,845 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965: change Leader from null to d13145d6-352e-4f4c-9fe8-9d9a20b76d13 at term 1 for becomeLeader, leader elected after 5195ms
datanode_2    | 2019-11-13 21:57:55,288 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 2 v3"
datanode_3    | 2019-11-13 21:57:56,464 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4: change Leader from null to 657ad21c-ec1e-4fe9-87b2-969df546c1d3 at term 1 for becomeLeader, leader elected after 5318ms
datanode_1    | 2019-11-13 21:57:55,849 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2    | 2019-11-13 21:57:55,288 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 3 v3"
datanode_3    | 2019-11-13 21:57:56,467 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1    | 2019-11-13 21:57:55,849 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2    | 2019-11-13 21:57:55,289 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 4 v3"
datanode_3    | 2019-11-13 21:57:56,467 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1    | 2019-11-13 21:57:55,854 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Update annotation table charset"
datanode_2    | 2019-11-13 21:57:55,296 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: start LeaderState
datanode_3    | 2019-11-13 21:57:56,470 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_1    | 2019-11-13 21:57:55,859 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Add column region_id to annotation table"
datanode_2    | 2019-11-13 21:57:55,315 INFO segmented.SegmentedRaftLogWorker: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3    | 2019-11-13 21:57:56,476 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Drop category_id index"
datanode_1    | 2019-11-13 21:57:55,859 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2    | 2019-11-13 21:57:55,326 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8: set configuration 0: [3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858], old=null at 0
datanode_3    | 2019-11-13 21:57:56,476 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Add column tags to annotation table"
datanode_1    | 2019-11-13 21:57:55,861 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2    | 2019-11-13 21:57:55,473 INFO segmented.SegmentedRaftLogWorker: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-527DE9B1BBD8-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b3aeb8e9-15e5-4e19-baa0-527de9b1bbd8/current/log_inprogress_0
datanode_3    | 2019-11-13 21:57:56,477 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Create annotation_tag table v2"
datanode_1    | 2019-11-13 21:57:55,869 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: start LeaderState
datanode_3    | 2019-11-13 21:57:56,485 INFO impl.RoleInfo: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: start LeaderState
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index annotation_tag.annotation_id_tag_id"
datanode_2    | 2019-11-13 21:57:56,547 INFO impl.FollowerState: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7-FollowerState: change to CANDIDATE, lastRpcTime:5130ms, electionTimeout:5130ms
datanode_3    | 2019-11-13 21:57:56,504 INFO segmented.SegmentedRaftLogWorker: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-13 21:57:55,891 INFO segmented.SegmentedRaftLogWorker: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2    | 2019-11-13 21:57:56,548 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: shutdown FollowerState
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert annotations and set TEXT to empty"
datanode_3    | 2019-11-13 21:57:56,517 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4: set configuration 0: [657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null at 0
datanode_1    | 2019-11-13 21:57:55,903 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965: set configuration 0: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858], old=null at 0
datanode_2    | 2019-11-13 21:57:56,549 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
grafana_1     | t=2019-11-13T21:57:52+0000 lvl=info msg="Executing migration" logger=migrator id="Add created time to annotation table"
datanode_3    | 2019-11-13 21:57:56,557 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:d13145d6-352e-4f4c-9fe8-9d9a20b76d13
datanode_1    | 2019-11-13 21:57:56,023 INFO segmented.SegmentedRaftLogWorker: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-D76FAA64F965-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d1b03ee0-a8c5-4fb6-80ed-d76faa64f965/current/log_inprogress_0
datanode_2    | 2019-11-13 21:57:56,549 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: start LeaderElection
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Add updated time to annotation table"
datanode_3    | 2019-11-13 21:57:56,557 INFO impl.RoleInfo: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: shutdown FollowerState
datanode_1    | 2019-11-13 21:57:56,401 INFO impl.FollowerState: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-FollowerState: change to CANDIDATE, lastRpcTime:5012ms, electionTimeout:5012ms
datanode_2    | 2019-11-13 21:57:56,567 INFO impl.LeaderElection: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7-LeaderElection2: begin an election at term 1 for -1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for created in annotation table"
datanode_3    | 2019-11-13 21:57:56,557 INFO impl.RoleInfo: 657ad21c-ec1e-4fe9-87b2-969df546c1d3: start FollowerState
datanode_1    | 2019-11-13 21:57:56,401 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: shutdown FollowerState
datanode_2    | 2019-11-13 21:57:56,663 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
datanode_1    | 2019-11-13 21:57:56,401 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2    | 2019-11-13 21:57:56,663 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: shutdown LeaderElection
datanode_1    | 2019-11-13 21:57:56,402 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: start LeaderElection
datanode_2    | 2019-11-13 21:57:56,663 INFO impl.RoleInfo: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10: start FollowerState
datanode_2    | 2019-11-13 21:57:56,663 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-354ABA9331B7 with new leaderId: d13145d6-352e-4f4c-9fe8-9d9a20b76d13
datanode_2    | 2019-11-13 21:57:56,663 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7: change Leader from null to d13145d6-352e-4f4c-9fe8-9d9a20b76d13 at term 1 for appendEntries, leader elected after 5261ms
datanode_2    | 2019-11-13 21:57:56,694 INFO impl.RaftServerImpl: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7: set configuration 0: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null at 0
datanode_1    | 2019-11-13 21:57:56,417 INFO impl.LeaderElection: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-LeaderElection2: begin an election at term 1 for -1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
datanode_3    | 2019-11-13 21:57:56,557 INFO impl.FollowerState: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for updated in annotation table"
datanode_2    | 2019-11-13 21:57:56,695 INFO segmented.SegmentedRaftLogWorker: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-13 21:57:56,590 INFO impl.LeaderElection: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-LeaderElection2: Election PASSED; received 2 response(s) [d13145d6-352e-4f4c-9fe8-9d9a20b76d13<-3f125c43-e0c0-4016-b1c9-9c61c0fe5f10#0:FAIL-t1, d13145d6-352e-4f4c-9fe8-9d9a20b76d13<-657ad21c-ec1e-4fe9-87b2-969df546c1d3#0:OK-t1] and 0 exception(s); d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7:t1, leader=null, voted=d13145d6-352e-4f4c-9fe8-9d9a20b76d13, raftlog=d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
datanode_3    | 2019-11-13 21:57:56,634 INFO segmented.SegmentedRaftLogWorker: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-5853C67F24D4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/00646862-42c3-4bd9-bad3-5853c67f24d4/current/log_inprogress_0
datanode_2    | 2019-11-13 21:57:56,725 INFO impl.LeaderElection: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7-LeaderElection2: Election REJECTED; received 1 response(s) [3f125c43-e0c0-4016-b1c9-9c61c0fe5f10<-657ad21c-ec1e-4fe9-87b2-969df546c1d3#0:FAIL-t1] and 0 exception(s); 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7:t1, leader=d13145d6-352e-4f4c-9fe8-9d9a20b76d13, voted=3f125c43-e0c0-4016-b1c9-9c61c0fe5f10, raftlog=3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=0: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null
datanode_1    | 2019-11-13 21:57:56,591 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: shutdown LeaderElection
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Convert existing annotations from seconds to milliseconds"
datanode_3    | 2019-11-13 21:57:56,661 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-354ABA9331B7 with new leaderId: d13145d6-352e-4f4c-9fe8-9d9a20b76d13
datanode_2    | 2019-11-13 21:57:56,740 INFO segmented.SegmentedRaftLogWorker: 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10@group-354ABA9331B7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7/current/log_inprogress_0
datanode_1    | 2019-11-13 21:57:56,591 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Add epoch_end column"
datanode_3    | 2019-11-13 21:57:56,661 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7: change Leader from null to d13145d6-352e-4f4c-9fe8-9d9a20b76d13 at term 1 for appendEntries, leader elected after 5243ms
datanode_1    | 2019-11-13 21:57:56,591 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-354ABA9331B7 with new leaderId: d13145d6-352e-4f4c-9fe8-9d9a20b76d13
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for epoch_end"
datanode_3    | 2019-11-13 21:57:56,687 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7: set configuration 0: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null at 0
datanode_1    | 2019-11-13 21:57:56,592 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7: change Leader from null to d13145d6-352e-4f4c-9fe8-9d9a20b76d13 at term 1 for becomeLeader, leader elected after 5206ms
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Make epoch_end the same as epoch"
datanode_3    | 2019-11-13 21:57:56,687 INFO segmented.SegmentedRaftLogWorker: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-13 21:57:56,592 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Move region to single row"
datanode_3    | 2019-11-13 21:57:56,715 INFO impl.RaftServerImpl: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7- FOLLOWER: Withhold vote from candidate 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10 with term 1. State: leader=d13145d6-352e-4f4c-9fe8-9d9a20b76d13, term=1, lastRpcElapsed=30ms
datanode_1    | 2019-11-13 21:57:56,592 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="create test_data table"
datanode_3    | 2019-11-13 21:57:56,740 INFO segmented.SegmentedRaftLogWorker: 657ad21c-ec1e-4fe9-87b2-969df546c1d3@group-354ABA9331B7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7/current/log_inprogress_0
datanode_1    | 2019-11-13 21:57:56,592 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_version table v1"
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard_version.dashboard_id"
datanode_1    | 2019-11-13 21:57:56,592 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_1    | 2019-11-13 21:57:56,592 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_version.dashboard_id and dashboard_version.version"
datanode_1    | 2019-11-13 21:57:56,592 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Set dashboard version to 1 where 0"
datanode_1    | 2019-11-13 21:57:56,597 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="save existing dashboard data in dashboard_version table v1"
datanode_1    | 2019-11-13 21:57:56,597 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard_version.data to mediumtext v1"
datanode_1    | 2019-11-13 21:57:56,598 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="create team table"
datanode_1    | 2019-11-13 21:57:56,601 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add index team.org_id"
datanode_1    | 2019-11-13 21:57:56,601 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1    | 2019-11-13 21:57:56,601 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index team_org_id_name"
datanode_1    | 2019-11-13 21:57:56,602 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="create team member table"
datanode_1    | 2019-11-13 21:57:56,603 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add index team_member.org_id"
datanode_1    | 2019-11-13 21:57:56,604 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index team_member_org_id_team_id_user_id"
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Add column email to team table"
datanode_1    | 2019-11-13 21:57:56,604 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Add column external to team_member table"
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="Add column permission to team_member table"
datanode_1    | 2019-11-13 21:57:56,604 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard acl table"
datanode_1    | 2019-11-13 21:57:56,604 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard_acl_dashboard_id"
datanode_1    | 2019-11-13 21:57:56,604 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_acl_dashboard_id_user_id"
datanode_1    | 2019-11-13 21:57:56,606 INFO impl.RoleInfo: d13145d6-352e-4f4c-9fe8-9d9a20b76d13: start LeaderState
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_acl_dashboard_id_team_id"
datanode_1    | 2019-11-13 21:57:56,607 INFO segmented.SegmentedRaftLogWorker: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-SegmentedRaftLogWorker: Starting segment from index:0
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="save default acl rules in dashboard_acl table"
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="create tag table"
grafana_1     | t=2019-11-13T21:57:53+0000 lvl=info msg="Executing migration" logger=migrator id="add index tag.key_value"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="create login attempt table"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="add index login_attempt.username"
datanode_1    | 2019-11-13 21:57:56,608 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7: set configuration 0: [d13145d6-352e-4f4c-9fe8-9d9a20b76d13:172.19.0.3:9858, 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10:172.19.0.6:9858, 657ad21c-ec1e-4fe9-87b2-969df546c1d3:172.19.0.8:9858], old=null at 0
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_login_attempt_username - v1"
datanode_1    | 2019-11-13 21:57:56,636 INFO segmented.SegmentedRaftLogWorker: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/93a6264a-3166-42f4-882e-354aba9331b7/current/log_inprogress_0
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table login_attempt to login_attempt_tmp_qwerty - v1"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="create login_attempt v2"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_login_attempt_username - v2"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="copy login_attempt v1 to v2"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="drop login_attempt_tmp_qwerty"
datanode_1    | 2019-11-13 21:57:56,724 INFO impl.RaftServerImpl: d13145d6-352e-4f4c-9fe8-9d9a20b76d13@group-354ABA9331B7-   LEADER: Withhold vote from candidate 3f125c43-e0c0-4016-b1c9-9c61c0fe5f10 with term 1. State: leader=d13145d6-352e-4f4c-9fe8-9d9a20b76d13, term=1, lastRpcElapsed=null
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="create user auth table"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_user_auth_auth_module_auth_id - v1"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="alter user_auth.auth_id to length 190"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth access token to user_auth"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth refresh token to user_auth"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth token type to user_auth"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth expiry to user_auth"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add index to user_id column in user_auth"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="create server_lock table"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="add index server_lock.operation_uid"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="create user auth token table"
grafana_1     | t=2019-11-13T21:57:54+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user_auth_token.auth_token"
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user_auth_token.prev_auth_token"
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Executing migration" logger=migrator id="create cache_data table"
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index cache_data.cache_key"
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Created default admin" logger=sqlstore user=admin
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing HTTPServer" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing InternalMetricsService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing RemoteCache" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing QuotaService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing ServerLockService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing UserAuthTokenService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing PluginManager" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Starting plugin search" logger=plugins
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing RenderingService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing AlertEngine" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing DatasourceCacheService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing HooksService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing LoginService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing SearchService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing TracingService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing UsageStatsService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing CleanUpService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing NotificationService" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing provisioningServiceImpl" logger=server
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=warn msg="[Deprecated] the datasource provisioning config is outdated. please upgrade" logger=provisioning.datasources filename=/etc/grafana/provisioning/datasources/datasources.yml
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="inserting datasource from configuration " logger=provisioning.datasources name=Prometheus
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=eror msg="Can't read alert notification provisioning files from directory" logger=provisioning.notifiers path=/etc/grafana/provisioning/notifiers error="open /etc/grafana/provisioning/notifiers: no such file or directory"
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=warn msg="[Deprecated] the dashboard provisioning config is outdated. please upgrade" logger=provisioning.dashboard filename=/etc/grafana/provisioning/dashboards/dashboards.yml
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=warn msg="[Deprecated] The folder property is deprecated. Please use path instead." logger=provisioning.dashboard type=file name=default
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Backend rendering via phantomJS" logger=rendering
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=warn msg="phantomJS is deprecated and will be removed in a future release. You should consider migrating from phantomJS to grafana-image-renderer plugin." logger=rendering
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="Initializing Stream Manager"
grafana_1     | t=2019-11-13T21:57:55+0000 lvl=info msg="HTTP Server Listen" logger=http.server address=0.0.0.0:3000 protocol=http subUrl= socket=
