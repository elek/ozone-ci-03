2019-11-12 16:43:54,061 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:54,208 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:54,213 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:54,257 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @882ms
2019-11-12 16:43:54,360 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-12 16:43:54,360 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-12 16:43:54,360 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-12 16:43:54,360 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-12 16:43:54,361 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-12 16:43:54,361 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-12 16:43:54,372 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-12 16:43:54,372 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-12 16:43:54,374 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-12 16:43:54,818 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@4e7593f5
2019-11-12 16:43:54,820 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-12 16:43:54,873 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-12 16:43:54,875 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-12 16:43:54,877 [Thread-0] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-12 16:43:54,947 [Thread-0] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-12 16:43:54,961 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:55,084 [Thread-0] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-12 16:43:55,087 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:55,349 [Thread-0] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-11-12 16:43:55,713 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:43:55,847 [Socket Reader #1 for port 34488] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34488
2019-11-12 16:43:55,882 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:43:55,883 [Socket Reader #1 for port 45890] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45890
2019-11-12 16:43:55,893 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:43:55,894 [Socket Reader #1 for port 39718] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39718
2019-11-12 16:43:55,919 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-12 16:43:56,067 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:43:56,075 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:43:56,084 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:43:56,087 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-12 16:43:56,088 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:43:56,088 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:43:56,118 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(764)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39718
2019-11-12 16:43:56,178 [Thread-0] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-12 16:43:56,193 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-12 16:43:56,193 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-12 16:43:56,456 [Thread-0] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:39718
2019-11-12 16:43:56,456 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:43:56,457 [IPC Server listener on 39718] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39718: starting
2019-11-12 16:43:56,460 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(774)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45890
2019-11-12 16:43:56,460 [Thread-0] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:45890
2019-11-12 16:43:56,461 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:43:56,461 [IPC Server listener on 45890] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45890: starting
2019-11-12 16:43:56,463 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(778)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:34488
2019-11-12 16:43:56,463 [Thread-0] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:34488
2019-11-12 16:43:56,464 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:43:56,464 [IPC Server listener on 34488] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34488: starting
2019-11-12 16:43:56,468 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37331
2019-11-12 16:43:56,470 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:43:56,508 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@585d2e09{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:43:56,509 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4476dfc1{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-12 16:43:56,942 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f907ee5{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-12 16:43:56,950 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@49ec53c3{HTTP/1.1,[http/1.1]}{0.0.0.0:37331}
2019-11-12 16:43:56,950 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @3576ms
2019-11-12 16:43:56,953 [Thread-0] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-11-12 16:43:56,953 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-11-12 16:43:56,955 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:37331
2019-11-12 16:43:56,964 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@eab9cba] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-12 16:43:56,969 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:57,086 [Thread-0] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-11-12 16:43:57,086 [Thread-0] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-11-12 16:43:57,088 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:57,089 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:57,733 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:43:57,741 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-12 16:43:57,741 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-12 16:43:57,741 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-12 16:43:57,742 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-12 16:43:57,742 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-12 16:43:57,742 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-12 16:43:57,742 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-12 16:43:57,742 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-12 16:43:57,743 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-12 16:43:57,743 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-12 16:43:57,743 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-12 16:43:57,743 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-12 16:43:57,744 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-12 16:43:57,744 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-12 16:43:57,744 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-12 16:43:57,744 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-12 16:43:57,744 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-12 16:43:57,745 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-12 16:43:57,745 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-12 16:43:57,745 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-12 16:43:57,745 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-12 16:43:57,745 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-12 16:43:57,746 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-12 16:43:57,746 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-12 16:43:57,746 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-12 16:43:58,769 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:43:58,770 [Socket Reader #1 for port 37842] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37842
2019-11-12 16:43:58,794 [Thread-0] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:37842
2019-11-12 16:43:58,795 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-12 16:43:58,804 [IPC Server listener on 37842] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37842: starting
2019-11-12 16:43:58,804 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:43:58,810 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-11-12 16:43:58,812 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:43:58,813 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:43:58,815 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:43:58,816 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-12 16:43:58,816 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:43:58,816 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:43:58,819 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38350
2019-11-12 16:43:58,819 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:43:58,821 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1bfa38ad{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:43:58,821 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@79800f24{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-12 16:43:58,826 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5ad639bd{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-12 16:43:58,827 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4e46532d{HTTP/1.1,[http/1.1]}{0.0.0.0:38350}
2019-11-12 16:43:58,827 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @5453ms
2019-11-12 16:43:58,828 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:43:58,829 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:38350
2019-11-12 16:43:59,082 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-12 16:43:59,128 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2462-m47mv-1978053924 ip:192.168.69.75
2019-11-12 16:43:59,160 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:43:59,161 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/containers/hdds to VolumeSet
2019-11-12 16:43:59,164 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/containers/hdds
2019-11-12 16:43:59,179 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/containers/hdds
2019-11-12 16:43:59,281 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:43:59,344 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:43:59,349 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:43:59,350 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:43:59,352 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:43:59,352 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:43:59,353 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:43:59,506 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis] (custom)
2019-11-12 16:43:59,549 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-12 16:43:59,550 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:43:59,551 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:43:59,552 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:43:59,553 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-12 16:43:59,553 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:43:59,553 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:43:59,554 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 32856
2019-11-12 16:43:59,554 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:43:59,556 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@132d0084{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:43:59,557 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a961a1f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-12 16:43:59,841 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2023fdd6{/,file:///tmp/jetty-0.0.0.0-32856-hddsDatanode-_-any-9185667443175832401.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-12 16:43:59,842 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7655096e{HTTP/1.1,[http/1.1]}{0.0.0.0:32856}
2019-11-12 16:43:59,842 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @6468ms
2019-11-12 16:43:59,842 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:43:59,844 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:32856
2019-11-12 16:43:59,845 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-12 16:43:59,847 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2462-m47mv-1978053924 ip:192.168.69.75
2019-11-12 16:43:59,852 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75bac37f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-12 16:43:59,857 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:43:59,858 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/containers/hdds to VolumeSet
2019-11-12 16:43:59,858 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/containers/hdds
2019-11-12 16:43:59,859 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/containers/hdds
2019-11-12 16:43:59,875 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:43:59,875 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:43:59,875 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:43:59,875 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:43:59,876 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:43:59,876 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:43:59,876 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:43:59,877 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis] (custom)
2019-11-12 16:43:59,880 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-12 16:43:59,883 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:43:59,883 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:43:59,886 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:43:59,887 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-12 16:43:59,887 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:43:59,887 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:43:59,889 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40554
2019-11-12 16:43:59,889 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:43:59,893 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@602c12e3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:43:59,894 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f07760c{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-12 16:43:59,945 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7e78caef{/,file:///tmp/jetty-0.0.0.0-40554-hddsDatanode-_-any-7096319602491476533.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-12 16:43:59,946 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@444aad14{HTTP/1.1,[http/1.1]}{0.0.0.0:40554}
2019-11-12 16:43:59,947 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @6573ms
2019-11-12 16:43:59,948 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:43:59,949 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40554
2019-11-12 16:43:59,949 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-12 16:43:59,953 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2462-m47mv-1978053924 ip:192.168.69.75
2019-11-12 16:43:59,953 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7296ce8b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-12 16:43:59,962 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:43:59,963 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/containers/hdds to VolumeSet
2019-11-12 16:43:59,963 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/containers/hdds
2019-11-12 16:43:59,964 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/containers/hdds
2019-11-12 16:43:59,967 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/meta/datanode.id
2019-11-12 16:43:59,971 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/meta/datanode.id
2019-11-12 16:43:59,983 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:43:59,984 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:43:59,984 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:43:59,984 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:43:59,984 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:43:59,985 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:43:59,985 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:43:59,985 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis] (custom)
2019-11-12 16:43:59,988 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-12 16:43:59,990 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:43:59,991 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:43:59,993 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:43:59,994 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-12 16:43:59,994 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:43:59,995 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:43:59,996 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45857
2019-11-12 16:43:59,996 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:43:59,999 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7dcbf61b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:44:00,000 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a2cfc3f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-12 16:44:00,048 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@52d9f2b5{/,file:///tmp/jetty-0.0.0.0-45857-hddsDatanode-_-any-3745030157329696545.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-12 16:44:00,049 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ae8031d{HTTP/1.1,[http/1.1]}{0.0.0.0:45857}
2019-11-12 16:44:00,049 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @6675ms
2019-11-12 16:44:00,050 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:44:00,051 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45857
2019-11-12 16:44:00,053 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-12 16:44:00,055 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61563bae] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-12 16:44:00,058 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/meta/datanode.id
2019-11-12 16:44:01,054 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-12 16:44:01,924 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:44:01,927 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:44:01,927 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 03521250-4df1-44d0-9869-ed41996226df at port 0
2019-11-12 16:44:01,952 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 03521250-4df1-44d0-9869-ed41996226df: start RPC server
2019-11-12 16:44:01,973 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:44:01,978 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:44:01,979 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis d3b46922-5ccf-46e2-ad93-9e0948e658be at port 0
2019-11-12 16:44:01,989 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: start RPC server
2019-11-12 16:44:02,054 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-12 16:44:02,078 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:44:02,079 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:44:02,079 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis a6f12895-5d59-493f-8d3a-db37b056f92e at port 0
2019-11-12 16:44:02,084 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 03521250-4df1-44d0-9869-ed41996226df: GrpcService started, listening on 0.0.0.0/0.0.0.0:33854
2019-11-12 16:44:02,084 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: GrpcService started, listening on 0.0.0.0/0.0.0.0:37029
2019-11-12 16:44:02,085 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis 03521250-4df1-44d0-9869-ed41996226df is started using port 33854
2019-11-12 16:44:02,086 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis d3b46922-5ccf-46e2-ad93-9e0948e658be is started using port 37029
2019-11-12 16:44:02,090 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 03521250-4df1-44d0-9869-ed41996226df is started using port 42533
2019-11-12 16:44:02,090 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc d3b46922-5ccf-46e2-ad93-9e0948e658be is started using port 36869
2019-11-12 16:44:02,094 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - a6f12895-5d59-493f-8d3a-db37b056f92e: start RPC server
2019-11-12 16:44:02,096 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - a6f12895-5d59-493f-8d3a-db37b056f92e: GrpcService started, listening on 0.0.0.0/0.0.0.0:36523
2019-11-12 16:44:02,096 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis a6f12895-5d59-493f-8d3a-db37b056f92e is started using port 36523
2019-11-12 16:44:02,098 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc a6f12895-5d59-493f-8d3a-db37b056f92e is started using port 38661
2019-11-12 16:44:03,055 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-12 16:44:03,889 [IPC Server handler 0 on 34488] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/03521250-4df1-44d0-9869-ed41996226df
2019-11-12 16:44:03,889 [IPC Server handler 0 on 34488] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : 03521250-4df1-44d0-9869-ed41996226df{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}
2019-11-12 16:44:03,893 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-11-12 16:44:03,893 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-11-12 16:44:03,893 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-11-12 16:44:03,956 [IPC Server handler 1 on 34488] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/d3b46922-5ccf-46e2-ad93-9e0948e658be
2019-11-12 16:44:03,957 [IPC Server handler 1 on 34488] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : d3b46922-5ccf-46e2-ad93-9e0948e658be{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}
2019-11-12 16:44:04,055 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-11-12 16:44:04,059 [IPC Server handler 3 on 34488] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/a6f12895-5d59-493f-8d3a-db37b056f92e
2019-11-12 16:44:04,059 [IPC Server handler 3 on 34488] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : a6f12895-5d59-493f-8d3a-db37b056f92e{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}
2019-11-12 16:44:04,435 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 03521250-4df1-44d0-9869-ed41996226df: addNew group-7E645C0A8B9A:[03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854] returns group-7E645C0A8B9A:java.util.concurrent.CompletableFuture@1da7094a[Not completed]
2019-11-12 16:44:04,449 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 03521250-4df1-44d0-9869-ed41996226df: new RaftServerImpl for group-7E645C0A8B9A:[03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854] with ContainerStateMachine:uninitialized
2019-11-12 16:44:04,452 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-12 16:44:04,453 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-12 16:44:04,453 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-12 16:44:04,454 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-12 16:44:04,455 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-12 16:44:04,464 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A: ConfigurationManager, init=-1: [03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null, confs=<EMPTY_MAP>
2019-11-12 16:44:04,464 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis] (custom)
2019-11-12 16:44:04,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-12 16:44:04,473 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis/b85fb340-9b6b-4a47-8f6c-7e645c0a8b9a does not exist. Creating ...
2019-11-12 16:44:05,051 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis/b85fb340-9b6b-4a47-8f6c-7e645c0a8b9a/in_use.lock acquired by nodename 23247@pr-hdds-2462-m47mv-1978053924
2019-11-12 16:44:05,056 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-11-12 16:44:05,066 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-11-12 16:44:05,073 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis/b85fb340-9b6b-4a47-8f6c-7e645c0a8b9a has been successfully formatted.
2019-11-12 16:44:05,076 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-11-12 16:44:05,077 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-11-12 16:44:05,077 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-11-12 16:44:05,077 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(221)) - group-7E645C0A8B9A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-12 16:44:05,078 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37842
2019-11-12 16:44:05,079 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-12 16:44:05,087 [IPC Server listener on 37842] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37842
2019-11-12 16:44:05,090 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:44:05,090 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-12 16:44:05,092 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-12 16:44:05,092 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-12 16:44:05,093 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-12 16:44:05,102 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-12 16:44:05,103 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:05,105 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,111 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-11-12 16:44:05,114 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,121 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-12 16:44:05,127 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis/b85fb340-9b6b-4a47-8f6c-7e645c0a8b9a
2019-11-12 16:44:05,128 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-12 16:44:05,128 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-12 16:44:05,130 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,130 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-12 16:44:05,131 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-12 16:44:05,132 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-12 16:44:05,133 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-12 16:44:05,133 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-12 16:44:05,134 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-12 16:44:05,147 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-12 16:44:05,152 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-12 16:44:05,156 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-12 16:44:05,157 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-12 16:44:05,158 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-12 16:44:05,158 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-12 16:44:05,175 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,177 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,179 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A: start as a follower, conf=-1: [03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null
2019-11-12 16:44:05,180 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-12 16:44:05,181 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 03521250-4df1-44d0-9869-ed41996226df: start FollowerState
2019-11-12 16:44:05,183 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7E645C0A8B9A,id=03521250-4df1-44d0-9869-ed41996226df
2019-11-12 16:44:05,184 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,244 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b85fb340-9b6b-4a47-8f6c-7e645c0a8b9a, Nodes: 03521250-4df1-44d0-9869-ed41996226df{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-11-12 16:44:05,262 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a6f12895-5d59-493f-8d3a-db37b056f92e: addNew group-C8030D6EE054:[a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523] returns group-C8030D6EE054:java.util.concurrent.CompletableFuture@7e01d07f[Not completed]
2019-11-12 16:44:05,278 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - a6f12895-5d59-493f-8d3a-db37b056f92e: new RaftServerImpl for group-C8030D6EE054:[a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523] with ContainerStateMachine:uninitialized
2019-11-12 16:44:05,279 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-12 16:44:05,280 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-12 16:44:05,280 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-12 16:44:05,280 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-12 16:44:05,280 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-12 16:44:05,280 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: ConfigurationManager, init=-1: [a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523], old=null, confs=<EMPTY_MAP>
2019-11-12 16:44:05,280 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis] (custom)
2019-11-12 16:44:05,280 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-12 16:44:05,281 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/9f5c8af6-9fa3-4126-a75c-c8030d6ee054 does not exist. Creating ...
2019-11-12 16:44:05,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5ad639bd{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-12 16:44:05,287 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4e46532d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-12 16:44:05,288 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@79800f24{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-12 16:44:05,289 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1bfa38ad{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:44:05,293 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-11-12 16:44:05,297 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/9f5c8af6-9fa3-4126-a75c-c8030d6ee054/in_use.lock acquired by nodename 23247@pr-hdds-2462-m47mv-1978053924
2019-11-12 16:44:05,314 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/9f5c8af6-9fa3-4126-a75c-c8030d6ee054 has been successfully formatted.
2019-11-12 16:44:05,314 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(221)) - group-C8030D6EE054: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-12 16:44:05,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-12 16:44:05,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-12 16:44:05,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-12 16:44:05,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:05,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,316 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-12 16:44:05,316 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/9f5c8af6-9fa3-4126-a75c-c8030d6ee054
2019-11-12 16:44:05,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-12 16:44:05,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-12 16:44:05,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-12 16:44:05,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-12 16:44:05,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-12 16:44:05,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-12 16:44:05,318 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-12 16:44:05,318 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-12 16:44:05,318 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-12 16:44:05,318 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-12 16:44:05,318 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-12 16:44:05,319 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-12 16:44:05,319 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-12 16:44:05,319 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-12 16:44:05,319 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,319 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,319 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: start as a follower, conf=-1: [a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523], old=null
2019-11-12 16:44:05,319 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-12 16:44:05,320 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6f12895-5d59-493f-8d3a-db37b056f92e: start FollowerState
2019-11-12 16:44:05,320 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C8030D6EE054,id=a6f12895-5d59-493f-8d3a-db37b056f92e
2019-11-12 16:44:05,321 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,330 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9f5c8af6-9fa3-4126-a75c-c8030d6ee054, Nodes: a6f12895-5d59-493f-8d3a-db37b056f92e{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-11-12 16:44:05,346 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: addNew group-A349FF189C57:[d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029] returns group-A349FF189C57:java.util.concurrent.CompletableFuture@61ab469[Not completed]
2019-11-12 16:44:05,358 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: new RaftServerImpl for group-A349FF189C57:[d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029] with ContainerStateMachine:uninitialized
2019-11-12 16:44:05,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-12 16:44:05,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-12 16:44:05,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-12 16:44:05,359 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-12 16:44:05,360 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-12 16:44:05,360 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57: ConfigurationManager, init=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029], old=null, confs=<EMPTY_MAP>
2019-11-12 16:44:05,360 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis] (custom)
2019-11-12 16:44:05,360 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-12 16:44:05,361 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis/1e6d10d3-4d56-4d72-b1d4-a349ff189c57 does not exist. Creating ...
2019-11-12 16:44:05,372 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis/1e6d10d3-4d56-4d72-b1d4-a349ff189c57/in_use.lock acquired by nodename 23247@pr-hdds-2462-m47mv-1978053924
2019-11-12 16:44:05,390 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis/1e6d10d3-4d56-4d72-b1d4-a349ff189c57 has been successfully formatted.
2019-11-12 16:44:05,390 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(221)) - group-A349FF189C57: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-12 16:44:05,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-12 16:44:05,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-12 16:44:05,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-12 16:44:05,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:05,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,391 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-12 16:44:05,392 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis/1e6d10d3-4d56-4d72-b1d4-a349ff189c57
2019-11-12 16:44:05,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-12 16:44:05,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-12 16:44:05,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-12 16:44:05,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-12 16:44:05,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-12 16:44:05,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-12 16:44:05,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-12 16:44:05,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-12 16:44:05,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-12 16:44:05,394 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-12 16:44:05,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-12 16:44:05,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-12 16:44:05,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-12 16:44:05,395 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-12 16:44:05,395 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,395 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,395 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57: start as a follower, conf=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029], old=null
2019-11-12 16:44:05,396 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-12 16:44:05,396 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: start FollowerState
2019-11-12 16:44:05,396 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A349FF189C57,id=d3b46922-5ccf-46e2-ad93-9e0948e658be
2019-11-12 16:44:05,396 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,406 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1e6d10d3-4d56-4d72-b1d4-a349ff189c57, Nodes: d3b46922-5ccf-46e2-ad93-9e0948e658be{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-11-12 16:44:05,433 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 03521250-4df1-44d0-9869-ed41996226df: addNew group-2B1021E60B25:[d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854] returns group-2B1021E60B25:java.util.concurrent.CompletableFuture@2bf78e66[Not completed]
2019-11-12 16:44:05,434 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: addNew group-2B1021E60B25:[d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854] returns group-2B1021E60B25:java.util.concurrent.CompletableFuture@7c5e5c9d[Not completed]
2019-11-12 16:44:05,435 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a6f12895-5d59-493f-8d3a-db37b056f92e: addNew group-2B1021E60B25:[d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854] returns group-2B1021E60B25:java.util.concurrent.CompletableFuture@308c7ae1[Not completed]
2019-11-12 16:44:05,436 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 03521250-4df1-44d0-9869-ed41996226df: new RaftServerImpl for group-2B1021E60B25:[d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854] with ContainerStateMachine:uninitialized
2019-11-12 16:44:05,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-12 16:44:05,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-12 16:44:05,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-12 16:44:05,436 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - a6f12895-5d59-493f-8d3a-db37b056f92e: new RaftServerImpl for group-2B1021E60B25:[d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854] with ContainerStateMachine:uninitialized
2019-11-12 16:44:05,436 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-12 16:44:05,436 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-12 16:44:05,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-12 16:44:05,437 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-12 16:44:05,437 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25: ConfigurationManager, init=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null, confs=<EMPTY_MAP>
2019-11-12 16:44:05,437 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-12 16:44:05,437 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-12 16:44:05,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis] (custom)
2019-11-12 16:44:05,437 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-12 16:44:05,437 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: new RaftServerImpl for group-2B1021E60B25:[d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854] with ContainerStateMachine:uninitialized
2019-11-12 16:44:05,437 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25: ConfigurationManager, init=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null, confs=<EMPTY_MAP>
2019-11-12 16:44:05,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-12 16:44:05,438 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis] (custom)
2019-11-12 16:44:05,438 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-12 16:44:05,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-12 16:44:05,438 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-12 16:44:05,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-12 16:44:05,438 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25 does not exist. Creating ...
2019-11-12 16:44:05,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-12 16:44:05,438 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25 does not exist. Creating ...
2019-11-12 16:44:05,438 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-12 16:44:05,439 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25: ConfigurationManager, init=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null, confs=<EMPTY_MAP>
2019-11-12 16:44:05,439 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis] (custom)
2019-11-12 16:44:05,439 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-12 16:44:05,439 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25 does not exist. Creating ...
2019-11-12 16:44:05,456 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25/in_use.lock acquired by nodename 23247@pr-hdds-2462-m47mv-1978053924
2019-11-12 16:44:05,456 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25/in_use.lock acquired by nodename 23247@pr-hdds-2462-m47mv-1978053924
2019-11-12 16:44:05,458 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25/in_use.lock acquired by nodename 23247@pr-hdds-2462-m47mv-1978053924
2019-11-12 16:44:05,473 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25 has been successfully formatted.
2019-11-12 16:44:05,473 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25 has been successfully formatted.
2019-11-12 16:44:05,473 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25 has been successfully formatted.
2019-11-12 16:44:05,474 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(221)) - group-2B1021E60B25: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-12 16:44:05,474 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(221)) - group-2B1021E60B25: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-12 16:44:05,474 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-12 16:44:05,474 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(221)) - group-2B1021E60B25: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-12 16:44:05,474 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-12 16:44:05,474 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-12 16:44:05,474 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-12 16:44:05,474 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-12 16:44:05,475 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:05,475 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-12 16:44:05,475 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,475 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-12 16:44:05,475 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-12 16:44:05,475 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-12 16:44:05,475 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25
2019-11-12 16:44:05,475 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-12 16:44:05,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-12 16:44:05,476 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:05,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-12 16:44:05,476 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:05,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,476 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-12 16:44:05,476 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-12 16:44:05,476 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-12 16:44:05,477 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-12 16:44:05,477 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-12 16:44:05,477 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-12 16:44:05,477 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25
2019-11-12 16:44:05,477 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-12 16:44:05,477 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25
2019-11-12 16:44:05,477 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-12 16:44:05,477 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-12 16:44:05,477 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-12 16:44:05,478 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-12 16:44:05,478 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-12 16:44:05,478 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-12 16:44:05,478 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,478 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:05,478 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-12 16:44:05,478 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-12 16:44:05,478 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-12 16:44:05,479 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-12 16:44:05,479 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-12 16:44:05,479 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-12 16:44:05,479 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-12 16:44:05,479 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-12 16:44:05,479 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-12 16:44:05,479 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-12 16:44:05,479 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-12 16:44:05,479 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,479 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-12 16:44:05,479 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,479 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-12 16:44:05,480 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-12 16:44:05,480 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25: start as a follower, conf=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null
2019-11-12 16:44:05,480 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-12 16:44:05,480 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-12 16:44:05,480 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-12 16:44:05,480 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: start FollowerState
2019-11-12 16:44:05,480 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-12 16:44:05,480 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-12 16:44:05,481 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-12 16:44:05,481 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2B1021E60B25,id=d3b46922-5ccf-46e2-ad93-9e0948e658be
2019-11-12 16:44:05,481 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-12 16:44:05,481 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-12 16:44:05,481 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,481 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-12 16:44:05,481 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-12 16:44:05,481 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-12 16:44:05,482 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-12 16:44:05,482 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-12 16:44:05,482 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-12 16:44:05,482 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,482 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-12 16:44:05,482 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,482 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-12 16:44:05,482 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25: start as a follower, conf=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null
2019-11-12 16:44:05,483 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,483 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-12 16:44:05,483 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,484 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6f12895-5d59-493f-8d3a-db37b056f92e: start FollowerState
2019-11-12 16:44:05,484 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25: start as a follower, conf=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null
2019-11-12 16:44:05,484 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-12 16:44:05,484 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2B1021E60B25,id=a6f12895-5d59-493f-8d3a-db37b056f92e
2019-11-12 16:44:05,484 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 03521250-4df1-44d0-9869-ed41996226df: start FollowerState
2019-11-12 16:44:05,484 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,485 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2B1021E60B25,id=03521250-4df1-44d0-9869-ed41996226df
2019-11-12 16:44:05,485 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:05,498 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3dc5b04f-d6d2-4bdd-a8fb-2b1021e60b25, Nodes: 03521250-4df1-44d0-9869-ed41996226df{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}a6f12895-5d59-493f-8d3a-db37b056f92e{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}d3b46922-5ccf-46e2-ad93-9e0948e658be{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-11-12 16:44:05,852 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-12 16:44:05,952 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-12 16:44:06,900 [Thread-179] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-11-12 16:44:06,903 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-11-12 16:44:10,296 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:44:10,296 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:44:10,297 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 03521250-4df1-44d0-9869-ed41996226df: close
2019-11-12 16:44:10,297 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: close
2019-11-12 16:44:10,300 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A: shutdown
2019-11-12 16:44:10,300 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57: shutdown
2019-11-12 16:44:10,300 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7E645C0A8B9A,id=03521250-4df1-44d0-9869-ed41996226df
2019-11-12 16:44:10,300 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A349FF189C57,id=d3b46922-5ccf-46e2-ad93-9e0948e658be
2019-11-12 16:44:10,300 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 03521250-4df1-44d0-9869-ed41996226df: shutdown FollowerState
2019-11-12 16:44:10,301 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: shutdown FollowerState
2019-11-12 16:44:10,301 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A-StateMachineUpdater: set stopIndex = -1
2019-11-12 16:44:10,301 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57-StateMachineUpdater: set stopIndex = -1
2019-11-12 16:44:10,301 [Thread-181] INFO  impl.FollowerState (FollowerState.java:run(120)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-12 16:44:10,306 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(120)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-12 16:44:10,310 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A: closes. applyIndex: -1
2019-11-12 16:44:10,310 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57: closes. applyIndex: -1
2019-11-12 16:44:10,314 [03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-12 16:44:10,314 [d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-12 16:44:10,315 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 03521250-4df1-44d0-9869-ed41996226df@group-7E645C0A8B9A-SegmentedRaftLogWorker close()
2019-11-12 16:44:10,315 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-A349FF189C57-SegmentedRaftLogWorker close()
2019-11-12 16:44:10,319 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25: shutdown
2019-11-12 16:44:10,319 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25: shutdown
2019-11-12 16:44:10,319 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2B1021E60B25,id=03521250-4df1-44d0-9869-ed41996226df
2019-11-12 16:44:10,319 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2B1021E60B25,id=d3b46922-5ccf-46e2-ad93-9e0948e658be
2019-11-12 16:44:10,320 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 03521250-4df1-44d0-9869-ed41996226df: shutdown FollowerState
2019-11-12 16:44:10,320 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: shutdown FollowerState
2019-11-12 16:44:10,322 [Thread-195] INFO  impl.FollowerState (FollowerState.java:run(120)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-12 16:44:10,324 [Thread-190] INFO  impl.FollowerState (FollowerState.java:run(120)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-12 16:44:10,320 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25-StateMachineUpdater: set stopIndex = -1
2019-11-12 16:44:10,326 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25: closes. applyIndex: -1
2019-11-12 16:44:10,323 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25-StateMachineUpdater: set stopIndex = -1
2019-11-12 16:44:10,327 [03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-12 16:44:10,327 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25: closes. applyIndex: -1
2019-11-12 16:44:10,327 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 03521250-4df1-44d0-9869-ed41996226df@group-2B1021E60B25-SegmentedRaftLogWorker close()
2019-11-12 16:44:10,328 [d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-12 16:44:10,330 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - d3b46922-5ccf-46e2-ad93-9e0948e658be@group-2B1021E60B25-SegmentedRaftLogWorker close()
2019-11-12 16:44:10,330 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 03521250-4df1-44d0-9869-ed41996226df: shutdown server with port 33854 now
2019-11-12 16:44:10,332 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: shutdown server with port 37029 now
2019-11-12 16:44:10,335 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 03521250-4df1-44d0-9869-ed41996226df: shutdown server with port 33854 successfully
2019-11-12 16:44:10,336 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - d3b46922-5ccf-46e2-ad93-9e0948e658be: shutdown server with port 37029 successfully
2019-11-12 16:44:10,342 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:44:10,353 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:44:10,372 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:44:10,376 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-12 16:44:10,379 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:44:10,379 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2023fdd6{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-12 16:44:10,382 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-12 16:44:10,383 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7655096e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-12 16:44:10,385 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7e78caef{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-12 16:44:10,385 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a961a1f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-12 16:44:10,386 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@132d0084{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:44:10,386 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@444aad14{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-12 16:44:10,387 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f07760c{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-12 16:44:10,388 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@602c12e3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:44:10,434 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(111)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-FollowerState: change to CANDIDATE, lastRpcTime:5114ms, electionTimeout:5113ms
2019-11-12 16:44:10,435 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a6f12895-5d59-493f-8d3a-db37b056f92e: shutdown FollowerState
2019-11-12 16:44:10,435 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-12 16:44:10,441 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6f12895-5d59-493f-8d3a-db37b056f92e: start LeaderElection
2019-11-12 16:44:10,483 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1: begin an election at term 1 for -1: [a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523], old=null
2019-11-12 16:44:10,485 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a6f12895-5d59-493f-8d3a-db37b056f92e: shutdown LeaderElection
2019-11-12 16:44:10,486 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-12 16:44:10,486 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: change Leader from null to a6f12895-5d59-493f-8d3a-db37b056f92e at term 1 for becomeLeader, leader elected after 5171ms
2019-11-12 16:44:10,494 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-12 16:44:10,494 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-12 16:44:10,499 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-12 16:44:10,504 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-12 16:44:10,504 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-12 16:44:10,506 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-12 16:44:10,515 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6f12895-5d59-493f-8d3a-db37b056f92e: start LeaderState
2019-11-12 16:44:10,535 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-12 16:44:10,549 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: set configuration 0: [a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523], old=null at 0
2019-11-12 16:44:10,639 [Thread-194] INFO  impl.FollowerState (FollowerState.java:run(111)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-FollowerState: change to CANDIDATE, lastRpcTime:5155ms, electionTimeout:5155ms
2019-11-12 16:44:10,640 [Thread-194] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a6f12895-5d59-493f-8d3a-db37b056f92e: shutdown FollowerState
2019-11-12 16:44:10,640 [Thread-194] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-12 16:44:10,640 [Thread-194] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6f12895-5d59-493f-8d3a-db37b056f92e: start LeaderElection
2019-11-12 16:44:10,666 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2: begin an election at term 1 for -1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null
2019-11-12 16:44:10,700 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/ratis/9f5c8af6-9fa3-4126-a75c-c8030d6ee054/current/log_inprogress_0
2019-11-12 16:44:10,702 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.69.75:37029
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-12 16:44:10,705 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.69.75:33854
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-12 16:44:10,708 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2: Election REJECTED; received 0 response(s) [] and 2 exception(s); a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25:t1, leader=null, voted=a6f12895-5d59-493f-8d3a-db37b056f92e, raftlog=a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d3b46922-5ccf-46e2-ad93-9e0948e658be:192.168.69.75:37029, a6f12895-5d59-493f-8d3a-db37b056f92e:192.168.69.75:36523, 03521250-4df1-44d0-9869-ed41996226df:192.168.69.75:33854], old=null
2019-11-12 16:44:10,708 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.69.75:37029
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-12 16:44:10,709 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 1: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.69.75:33854
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-12 16:44:10,710 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-11-12 16:44:10,710 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a6f12895-5d59-493f-8d3a-db37b056f92e: shutdown LeaderElection
2019-11-12 16:44:10,710 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6f12895-5d59-493f-8d3a-db37b056f92e: start FollowerState
2019-11-12 16:44:11,055 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-12 16:44:15,389 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:44:15,390 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - a6f12895-5d59-493f-8d3a-db37b056f92e: close
2019-11-12 16:44:15,390 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: shutdown
2019-11-12 16:44:15,391 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C8030D6EE054,id=a6f12895-5d59-493f-8d3a-db37b056f92e
2019-11-12 16:44:15,391 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a6f12895-5d59-493f-8d3a-db37b056f92e: shutdown LeaderState
2019-11-12 16:44:15,393 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-PendingRequests: sendNotLeaderResponses
2019-11-12 16:44:15,395 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-StateMachineUpdater: set stopIndex = 0
2019-11-12 16:44:15,396 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054: closes. applyIndex: 0
2019-11-12 16:44:15,396 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-12 16:44:15,397 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-C8030D6EE054-SegmentedRaftLogWorker close()
2019-11-12 16:44:15,398 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25: shutdown
2019-11-12 16:44:15,399 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2B1021E60B25,id=a6f12895-5d59-493f-8d3a-db37b056f92e
2019-11-12 16:44:15,399 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a6f12895-5d59-493f-8d3a-db37b056f92e: shutdown FollowerState
2019-11-12 16:44:15,399 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-StateMachineUpdater: set stopIndex = -1
2019-11-12 16:44:15,399 [Thread-204] INFO  impl.FollowerState (FollowerState.java:run(120)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-12 16:44:15,400 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25: closes. applyIndex: -1
2019-11-12 16:44:15,401 [a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-12 16:44:15,401 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - a6f12895-5d59-493f-8d3a-db37b056f92e@group-2B1021E60B25-SegmentedRaftLogWorker close()
2019-11-12 16:44:15,402 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - a6f12895-5d59-493f-8d3a-db37b056f92e: shutdown server with port 36523 now
2019-11-12 16:44:15,404 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - a6f12895-5d59-493f-8d3a-db37b056f92e: shutdown server with port 36523 successfully
2019-11-12 16:44:15,417 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-33aadb6f-5f2f-454f-8b4e-4bdf768a10cf/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:44:15,435 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:44:15,441 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-12 16:44:15,445 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@52d9f2b5{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-12 16:44:15,446 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ae8031d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-12 16:44:15,447 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a2cfc3f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-12 16:44:15,448 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7dcbf61b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:44:15,450 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-11-12 16:44:15,450 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(802)) - Stopping Replication Manager Service.
2019-11-12 16:44:15,451 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-11-12 16:44:15,451 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(809)) - Stopping Lease Manager of the command watchers
2019-11-12 16:44:15,451 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping datanode service RPC server
2019-11-12 16:44:15,451 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-12 16:44:15,452 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34488
2019-11-12 16:44:15,453 [IPC Server listener on 34488] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34488
2019-11-12 16:44:15,454 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:44:15,527 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-11-12 16:44:15,528 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping block service RPC server
2019-11-12 16:44:15,528 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-12 16:44:15,528 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45890
2019-11-12 16:44:15,529 [IPC Server listener on 45890] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45890
2019-11-12 16:44:15,530 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-12 16:44:15,530 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:44:15,531 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-11-12 16:44:15,531 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39718
2019-11-12 16:44:15,532 [IPC Server listener on 39718] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39718
2019-11-12 16:44:15,532 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping Storage Container Manager HTTP server.
2019-11-12 16:44:15,533 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:44:15,534 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2f907ee5{/,null,UNAVAILABLE}{/scm}
2019-11-12 16:44:15,535 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@49ec53c3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-12 16:44:15,536 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4476dfc1{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-12 16:44:15,536 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@585d2e09{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:44:15,538 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(849)) - Stopping Block Manager Service.
2019-11-12 16:44:15,538 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-12 16:44:15,539 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-12 16:44:15,540 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping SCM Event Queue.
2019-11-12 16:44:15,548 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping XceiverClientMetrics metrics system...
2019-11-12 16:44:15,552 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-11-12 16:44:15,552 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - XceiverClientMetrics metrics system stopped.
2019-11-12 16:44:15,588 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:15,614 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:15,615 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:15,615 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-12 16:44:15,616 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-12 16:44:15,616 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-12 16:44:15,616 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-12 16:44:15,616 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-12 16:44:15,617 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-12 16:44:15,617 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-12 16:44:15,617 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-12 16:44:15,617 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-12 16:44:15,921 [Thread-205] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@5d0835a0
2019-11-12 16:44:15,921 [Thread-205] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-12 16:44:15,928 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-12 16:44:15,929 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-12 16:44:15,929 [Thread-205] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-12 16:44:15,930 [Thread-205] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-12 16:44:15,931 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:16,063 [Thread-205] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-12 16:44:16,063 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:16,176 [Thread-205] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-12 16:44:16,177 [Thread-205] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:44:16,178 [Socket Reader #1 for port 37529] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37529
2019-11-12 16:44:16,181 [Thread-205] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:44:16,181 [Socket Reader #1 for port 38339] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38339
2019-11-12 16:44:16,183 [Thread-205] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:44:16,184 [Socket Reader #1 for port 43397] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43397
2019-11-12 16:44:16,186 [Thread-205] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-12 16:44:16,189 [Thread-205] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:44:16,190 [Thread-205] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:44:16,193 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:44:16,194 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-12 16:44:16,194 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:44:16,194 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:44:16,198 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:start(764)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43397
2019-11-12 16:44:16,201 [Thread-205] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-12 16:44:16,202 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-12 16:44:16,203 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-12 16:44:16,222 [Thread-205] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:44:16,232 [Thread-205] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:43397
2019-11-12 16:44:16,232 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:44:16,232 [IPC Server listener on 43397] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43397: starting
2019-11-12 16:44:16,235 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:start(774)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38339
2019-11-12 16:44:16,235 [Thread-205] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:38339
2019-11-12 16:44:16,236 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:44:16,236 [IPC Server listener on 38339] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38339: starting
2019-11-12 16:44:16,238 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:start(778)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:37529
2019-11-12 16:44:16,238 [Thread-205] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:37529
2019-11-12 16:44:16,239 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:44:16,239 [IPC Server listener on 37529] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37529: starting
2019-11-12 16:44:16,242 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33509
2019-11-12 16:44:16,242 [Thread-205] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:44:16,244 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5c35ee{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:44:16,245 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4b653a1e{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-12 16:44:16,250 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b89f617{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-12 16:44:16,251 [Thread-205] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@79b521d0{HTTP/1.1,[http/1.1]}{0.0.0.0:33509}
2019-11-12 16:44:16,251 [Thread-205] INFO  server.Server (Server.java:doStart(419)) - Started @22878ms
2019-11-12 16:44:16,251 [Thread-205] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:44:16,253 [Thread-205] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:33509
2019-11-12 16:44:16,253 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:16,253 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@48cddfcc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-12 16:44:16,280 [Thread-205] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-11-12 16:44:16,280 [Thread-205] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-11-12 16:44:16,281 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:16,282 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:16,293 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:44:16,294 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-12 16:44:16,294 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-12 16:44:16,294 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-12 16:44:16,294 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-12 16:44:16,295 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-12 16:44:16,295 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-12 16:44:16,295 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-12 16:44:16,295 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-12 16:44:16,295 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-12 16:44:16,296 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-12 16:44:16,296 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-12 16:44:16,296 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-12 16:44:16,296 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-12 16:44:16,296 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-12 16:44:16,297 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-12 16:44:16,297 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-12 16:44:16,297 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-12 16:44:16,297 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-12 16:44:16,298 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-12 16:44:16,298 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-12 16:44:16,298 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-12 16:44:16,298 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-12 16:44:16,298 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-12 16:44:16,298 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-12 16:44:16,299 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-12 16:44:17,110 [Thread-205] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:44:17,111 [Socket Reader #1 for port 45740] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45740
2019-11-12 16:44:17,127 [Thread-205] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45740
2019-11-12 16:44:17,127 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-12 16:44:17,129 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:44:17,129 [IPC Server listener on 45740] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45740: starting
2019-11-12 16:44:17,133 [Thread-205] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-11-12 16:44:17,135 [Thread-205] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:44:17,136 [Thread-205] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:44:17,140 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:44:17,141 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-12 16:44:17,141 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:44:17,141 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:44:17,143 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38715
2019-11-12 16:44:17,143 [Thread-205] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:44:17,145 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4361eafd{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:44:17,146 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d20c6b9{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-12 16:44:17,155 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6082e6bc{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-12 16:44:17,156 [Thread-205] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@716c961e{HTTP/1.1,[http/1.1]}{0.0.0.0:38715}
2019-11-12 16:44:17,156 [Thread-205] INFO  server.Server (Server.java:doStart(419)) - Started @23783ms
2019-11-12 16:44:17,157 [Thread-205] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:44:17,158 [Thread-205] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:38715
2019-11-12 16:44:17,164 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-12 16:44:17,166 [Thread-205] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2462-m47mv-1978053924 ip:192.168.69.75
2019-11-12 16:44:17,174 [Thread-205] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:44:17,174 [Thread-205] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers/hdds to VolumeSet
2019-11-12 16:44:17,174 [Thread-205] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers/hdds
2019-11-12 16:44:17,175 [Thread-205] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers/hdds
2019-11-12 16:44:17,188 [Thread-205] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:44:17,188 [Thread-205] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:44:17,188 [Thread-205] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:44:17,189 [Thread-205] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:44:17,189 [Thread-205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:17,189 [Thread-205] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:44:17,189 [Thread-205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:44:17,190 [Thread-205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis] (custom)
2019-11-12 16:44:17,191 [Thread-205] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-12 16:44:17,193 [Thread-205] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:44:17,193 [Thread-205] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:44:17,194 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:44:17,195 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-12 16:44:17,195 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:44:17,195 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:44:17,196 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35345
2019-11-12 16:44:17,196 [Thread-205] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:44:17,197 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d9d5114{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:44:17,198 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@476eb19f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-12 16:44:22,607 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27195dc7{/,file:///tmp/jetty-0.0.0.0-35345-hddsDatanode-_-any-5143335078941709747.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-12 16:44:22,608 [Thread-205] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6c46ea18{HTTP/1.1,[http/1.1]}{0.0.0.0:35345}
2019-11-12 16:44:22,609 [Thread-205] INFO  server.Server (Server.java:doStart(419)) - Started @29235ms
2019-11-12 16:44:22,609 [Thread-205] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:44:22,612 [Thread-205] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35345
2019-11-12 16:44:22,612 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:44:22,615 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@620aa1a4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-12 16:44:22,619 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/meta/datanode.id
2019-11-12 16:44:23,613 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:44:24,613 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:44:25,614 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:44:25,888 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:44:25,890 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:44:25,890 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 0
2019-11-12 16:44:25,899 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 013257cb-d561-4102-a451-38f910b8168a: start RPC server
2019-11-12 16:44:25,902 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 013257cb-d561-4102-a451-38f910b8168a: GrpcService started, listening on 0.0.0.0/0.0.0.0:37331
2019-11-12 16:44:25,903 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a is started using port 37331
2019-11-12 16:44:25,904 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 013257cb-d561-4102-a451-38f910b8168a is started using port 44270
2019-11-12 16:44:26,614 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:44:26,620 [IPC Server handler 1 on 37529] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/013257cb-d561-4102-a451-38f910b8168a
2019-11-12 16:44:26,620 [IPC Server handler 1 on 37529] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : 013257cb-d561-4102-a451-38f910b8168a{ip: 192.168.69.75, host: pr-hdds-2462-m47mv-1978053924, networkLocation: /default-rack, certSerialId: null}
2019-11-12 16:44:26,622 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-11-12 16:44:26,623 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-11-12 16:44:26,623 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-11-12 16:44:26,644 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 013257cb-d561-4102-a451-38f910b8168a: addNew group-14476F03424F:[013257cb-d561-4102-a451-38f910b8168a:192.168.69.75:37331] returns group-14476F03424F:java.util.concurrent.CompletableFuture@5306c15e[Not completed]
2019-11-12 16:44:26,647 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 013257cb-d561-4102-a451-38f910b8168a: new RaftServerImpl for group-14476F03424F:[013257cb-d561-4102-a451-38f910b8168a:192.168.69.75:37331] with ContainerStateMachine:uninitialized
2019-11-12 16:44:26,648 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-12 16:44:26,648 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-12 16:44:26,648 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-12 16:44:26,648 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-12 16:44:26,648 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-12 16:44:26,649 [pool-77-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 013257cb-d561-4102-a451-38f910b8168a@group-14476F03424F: ConfigurationManager, init=-1: [013257cb-d561-4102-a451-38f910b8168a:192.168.69.75:37331], old=null, confs=<EMPTY_MAP>
2019-11-12 16:44:26,649 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis] (custom)
2019-11-12 16:44:26,649 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-12 16:44:26,649 [pool-77-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f does not exist. Creating ...
2019-11-12 16:44:27,615 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-11-12 16:44:27,615 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(802)) - Stopping Replication Manager Service.
2019-11-12 16:44:27,615 [Thread-205] INFO  container.ReplicationManager (ReplicationManager.java:stop(209)) - Replication Monitor Thread is not running.
2019-11-12 16:44:27,615 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(809)) - Stopping Lease Manager of the command watchers
2019-11-12 16:44:27,615 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping datanode service RPC server
2019-11-12 16:44:27,616 [Thread-205] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-12 16:44:27,616 [Thread-205] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37529
2019-11-12 16:44:27,621 [IPC Server listener on 37529] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37529
2019-11-12 16:44:27,621 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:44:27,650 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-11-12 16:44:27,650 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping block service RPC server
2019-11-12 16:44:27,650 [Thread-205] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-12 16:44:27,650 [Thread-205] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38339
2019-11-12 16:44:27,652 [IPC Server listener on 38339] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38339
2019-11-12 16:44:27,652 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:44:27,652 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-12 16:44:27,653 [Thread-205] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-11-12 16:44:27,653 [Thread-205] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43397
2019-11-12 16:44:27,654 [IPC Server listener on 43397] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43397
2019-11-12 16:44:27,654 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping Storage Container Manager HTTP server.
2019-11-12 16:44:27,654 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:44:27,657 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b89f617{/,null,UNAVAILABLE}{/scm}
2019-11-12 16:44:27,657 [Thread-205] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@79b521d0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-12 16:44:27,658 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4b653a1e{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-12 16:44:27,658 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5c35ee{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:44:27,659 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(849)) - Stopping Block Manager Service.
2019-11-12 16:44:27,659 [Thread-205] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-12 16:44:27,659 [Thread-205] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-12 16:44:27,660 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping SCM Event Queue.
2019-11-12 16:44:27,670 [RATISCREATEPIPELINE1] ERROR client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:close(147)) - Unexpected exception while waiting for channel termination
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:277)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImpl.awaitTermination(ManagedChannelImpl.java:763)
	at org.apache.ratis.thirdparty.io.grpc.internal.ForwardingManagedChannel.awaitTermination(ForwardingManagedChannel.java:57)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.awaitTermination(ManagedChannelOrphanWrapper.java:70)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.close(GrpcClientProtocolClient.java:145)
	at org.apache.ratis.util.PeerProxyMap.closeProxy(PeerProxyMap.java:160)
	at org.apache.ratis.util.PeerProxyMap.lambda$resetProxy$2(PeerProxyMap.java:135)
	at java.util.Optional.ifPresent(Optional.java:159)
	at org.apache.ratis.util.PeerProxyMap.resetProxy(PeerProxyMap.java:135)
	at org.apache.ratis.util.PeerProxyMap.handleException(PeerProxyMap.java:141)
	at org.apache.ratis.client.impl.RaftClientRpcWithProxy.handleException(RaftClientRpcWithProxy.java:47)
	at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:372)
	at org.apache.ratis.client.impl.RaftClientImpl.handleIOException(RaftClientImpl.java:338)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:282)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:227)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
2019-11-12 16:44:27,672 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(237)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$185/155635747@17f9a911 for 013257cb-d561-4102-a451-38f910b8168a
java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Call was interrupted
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:76)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:198)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:233)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:227)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Call was interrupted
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:136)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2048)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$ThreadlessExecutor.waitAndDrain(ClientCalls.java:642)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:130)
	... 28 more
2019-11-12 16:44:27,674 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-11-12 16:44:27,678 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2019-11-12 16:44:28,616 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-12 16:44:29,629 [Thread-347] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-11-12 16:44:29,629 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-11-12 16:44:32,679 [Thread-205] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:44:37,493 [pool-77-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f/in_use.lock acquired by nodename 23247@pr-hdds-2462-m47mv-1978053924
2019-11-12 16:44:41,520 [pool-77-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f has been successfully formatted.
2019-11-12 16:44:41,520 [pool-77-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(221)) - group-14476F03424F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-12 16:44:41,521 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-12 16:44:41,521 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-12 16:44:41,521 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-12 16:44:41,521 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:41,521 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:41,522 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:41,522 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-12 16:44:41,522 [pool-77-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 013257cb-d561-4102-a451-38f910b8168a@group-14476F03424F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f
2019-11-12 16:44:41,522 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-12 16:44:41,522 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-12 16:44:41,522 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-12 16:44:41,523 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-12 16:44:41,523 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-12 16:44:41,523 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-12 16:44:41,523 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-12 16:44:41,523 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-12 16:44:41,523 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-12 16:44:41,524 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-12 16:44:41,524 [pool-77-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 013257cb-d561-4102-a451-38f910b8168a@group-14476F03424F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-12 16:44:41,525 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-12 16:44:41,525 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-12 16:44:41,525 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-12 16:44:41,525 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-12 16:44:41,525 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:41,526 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-12 16:44:41,526 [pool-77-thread-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 013257cb-d561-4102-a451-38f910b8168a: remove      null 013257cb-d561-4102-a451-38f910b8168a@group-14476F03424F:t0, leader=null, voted=null, raftlog=013257cb-d561-4102-a451-38f910b8168a@group-14476F03424F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [013257cb-d561-4102-a451-38f910b8168a:192.168.69.75:37331], old=null NEW
2019-11-12 16:44:41,527 [pool-77-thread-1] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(388)) - 013257cb-d561-4102-a451-38f910b8168a: Failed groupAdd* GroupManagementRequest:client-4D49C280C4A4->013257cb-d561-4102-a451-38f910b8168a@group-14476F03424F, cid=6, seq=0, RW, null, Add:group-14476F03424F:[013257cb-d561-4102-a451-38f910b8168a:192.168.69.75:37331]
java.util.concurrent.CompletionException: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@3aa2a75b rejected from java.util.concurrent.ThreadPoolExecutor@34654e7f[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:604)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1595)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@3aa2a75b rejected from java.util.concurrent.ThreadPoolExecutor@34654e7f[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668)
	at java.util.concurrent.CompletableFuture$UniCompletion.claim(CompletableFuture.java:529)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:599)
	... 6 more
2019-11-12 16:44:41,528 [Thread-205] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 013257cb-d561-4102-a451-38f910b8168a: close
2019-11-12 16:44:41,528 [Thread-205] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 013257cb-d561-4102-a451-38f910b8168a: shutdown server with port 37331 now
2019-11-12 16:44:41,530 [Thread-205] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 013257cb-d561-4102-a451-38f910b8168a: shutdown server with port 37331 successfully
2019-11-12 16:44:41,532 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:44:41,545 [Thread-205] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:44:41,547 [Thread-205] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-12 16:44:41,555 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27195dc7{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-12 16:44:41,556 [Thread-205] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6c46ea18{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-12 16:44:41,556 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@476eb19f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-12 16:44:41,557 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d9d5114{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:44:41,561 [Thread-205] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-hddsdatanode.properties,hadoop-metrics2.properties
2019-11-12 16:44:41,563 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-12 16:44:41,563 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - HddsDatanode metrics system started
2019-11-12 16:44:41,582 [Thread-205] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:44:41,619 [Thread-205] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2462-m47mv-1978053924 ip:192.168.69.75
2019-11-12 16:44:41,622 [Thread-205] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers : 4096 
2019-11-12 16:44:41,622 [Thread-205] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:44:41,622 [Thread-205] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers/hdds to VolumeSet
2019-11-12 16:44:41,623 [Thread-205] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers/hdds
2019-11-12 16:44:41,623 [Thread-205] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers/hdds
2019-11-12 16:44:41,639 [Thread-205] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:44:41,639 [Thread-205] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:44:41,639 [Thread-205] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 37331 (custom)
2019-11-12 16:44:41,639 [Thread-205] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:44:41,640 [Thread-205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:44:41,640 [Thread-205] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:44:41,640 [Thread-205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:44:41,640 [Thread-205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis] (custom)
2019-11-12 16:44:41,641 [Thread-205] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$null$0(191)) - 013257cb-d561-4102-a451-38f910b8168a: found a subdirectory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f
2019-11-12 16:44:41,642 [Thread-205] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 013257cb-d561-4102-a451-38f910b8168a: addNew group-14476F03424F:[] returns group-14476F03424F:java.util.concurrent.CompletableFuture@582fa655[Not completed]
2019-11-12 16:44:41,643 [Thread-205] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:35345
2019-11-12 16:44:41,645 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 013257cb-d561-4102-a451-38f910b8168a: new RaftServerImpl for group-14476F03424F:[] with ContainerStateMachine:uninitialized
2019-11-12 16:44:41,645 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-12 16:44:41,646 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-12 16:44:41,646 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-12 16:44:41,646 [Thread-205] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:44:41,646 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-12 16:44:41,646 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-12 16:44:41,646 [Thread-205] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:44:41,646 [pool-89-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 013257cb-d561-4102-a451-38f910b8168a@group-14476F03424F: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
2019-11-12 16:44:41,647 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis] (custom)
2019-11-12 16:44:41,647 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-12 16:44:41,648 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:44:41,648 [pool-89-thread-1] ERROR storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(331)) - It appears that another process has already locked the storage directory: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f
java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-12 16:44:41,649 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-12 16:44:41,649 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:44:41,649 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:44:41,649 [pool-89-thread-1] WARN  util.FileUtils (JavaUtils.java:attempt(166)) - FAILED "tryLock /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f/in_use.lock", attempt #1/5: java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked, sleep 1s and then retry.
java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	... 14 more
2019-11-12 16:44:41,650 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35345
2019-11-12 16:44:41,650 [Thread-205] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:44:41,652 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8669010{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:44:41,652 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d552eaa{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-12 16:44:41,683 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1144e107{/,file:///tmp/jetty-0.0.0.0-35345-hddsDatanode-_-any-3009490405797238666.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-12 16:44:41,686 [Thread-205] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a5516ce{HTTP/1.1,[http/1.1]}{0.0.0.0:35345}
2019-11-12 16:44:41,688 [Thread-205] INFO  server.Server (Server.java:doStart(419)) - Started @48314ms
2019-11-12 16:44:41,688 [Thread-205] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:44:41,689 [Thread-205] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35345
2019-11-12 16:44:41,693 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1cac6354] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-12 16:44:42,650 [pool-89-thread-1] ERROR storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(331)) - It appears that another process has already locked the storage directory: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f
java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-12 16:44:42,652 [pool-89-thread-1] WARN  util.FileUtils (JavaUtils.java:attempt(166)) - FAILED "tryLock /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f/in_use.lock", attempt #2/5: java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked, sleep 1s and then retry.
java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	... 14 more
2019-11-12 16:44:43,653 [pool-89-thread-1] ERROR storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(331)) - It appears that another process has already locked the storage directory: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f
java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-12 16:44:43,655 [pool-89-thread-1] WARN  util.FileUtils (JavaUtils.java:attempt(166)) - FAILED "tryLock /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f/in_use.lock", attempt #3/5: java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked, sleep 1s and then retry.
java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	... 14 more
2019-11-12 16:44:44,656 [pool-89-thread-1] ERROR storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(331)) - It appears that another process has already locked the storage directory: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f
java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-12 16:44:44,657 [pool-89-thread-1] WARN  util.FileUtils (JavaUtils.java:attempt(166)) - FAILED "tryLock /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f/in_use.lock", attempt #4/5: java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked, sleep 1s and then retry.
java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	... 14 more
2019-11-12 16:44:44,702 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:45,658 [pool-89-thread-1] ERROR storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(331)) - It appears that another process has already locked the storage directory: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f
java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-12 16:44:45,704 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:46,705 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:47,707 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:48,708 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:49,709 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:50,711 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:51,712 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:52,713 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:53,715 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:54,716 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:55,717 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:56,718 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:57,720 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:58,721 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:44:59,723 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:45:00,724 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:45:01,698 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(802)) - Stopping Replication Manager Service.
2019-11-12 16:45:01,698 [Thread-205] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-11-12 16:45:01,699 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(809)) - Stopping Lease Manager of the command watchers
2019-11-12 16:45:01,699 [Thread-205] ERROR server.StorageContainerManager (StorageContainerManager.java:stop(812)) - Lease Manager of the command watchers stop failed
2019-11-12 16:45:01,699 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping datanode service RPC server
2019-11-12 16:45:01,699 [Thread-205] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-12 16:45:01,699 [Thread-205] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37529
2019-11-12 16:45:01,700 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping block service RPC server
2019-11-12 16:45:01,700 [Thread-205] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-12 16:45:01,700 [Thread-205] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38339
2019-11-12 16:45:01,700 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-12 16:45:01,700 [Thread-205] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-11-12 16:45:01,700 [Thread-205] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43397
2019-11-12 16:45:01,700 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping Storage Container Manager HTTP server.
2019-11-12 16:45:01,700 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(849)) - Stopping Block Manager Service.
2019-11-12 16:45:01,701 [Thread-205] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-12 16:45:01,701 [Thread-205] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-12 16:45:01,701 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping SCM Event Queue.
2019-11-12 16:45:01,701 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-11-12 16:45:01,704 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2019-11-12 16:45:01,705 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:45:01,705 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:45:01,706 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-12 16:45:01,706 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-12 16:45:01,707 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-12 16:45:01,707 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-12 16:45:01,707 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-12 16:45:01,707 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-12 16:45:01,707 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-12 16:45:01,708 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-12 16:45:01,708 [Thread-205] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-12 16:45:01,725 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:45:01,870 [Thread-205] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@31fa4995
2019-11-12 16:45:01,870 [Thread-205] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-12 16:45:01,875 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-12 16:45:01,875 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-12 16:45:01,876 [Thread-205] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-12 16:45:01,877 [Thread-205] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-12 16:45:01,877 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:45:01,964 [Thread-205] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-12 16:45:01,964 [Thread-205] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-12 16:45:02,079 [Thread-205] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-12 16:45:02,080 [Thread-205] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:45:02,081 [Socket Reader #1 for port 37529] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37529
2019-11-12 16:45:02,083 [Thread-205] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:45:02,084 [Socket Reader #1 for port 38339] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38339
2019-11-12 16:45:02,086 [Thread-205] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-12 16:45:02,087 [Socket Reader #1 for port 43397] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43397
2019-11-12 16:45:02,090 [Thread-205] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:33509
2019-11-12 16:45:02,092 [Thread-205] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-12 16:45:02,093 [Thread-205] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-12 16:45:02,096 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 16:45:02,097 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-12 16:45:02,097 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 16:45:02,098 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 16:45:02,102 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:start(764)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43397
2019-11-12 16:45:02,105 [Thread-205] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-12 16:45:02,106 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-12 16:45:02,106 [Thread-205] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-12 16:45:02,211 [Thread-205] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:45:02,228 [Thread-205] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:43397
2019-11-12 16:45:02,229 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:45:02,229 [IPC Server listener on 43397] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43397: starting
2019-11-12 16:45:02,234 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:start(774)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38339
2019-11-12 16:45:02,234 [Thread-205] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:38339
2019-11-12 16:45:02,235 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:45:02,235 [IPC Server listener on 38339] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38339: starting
2019-11-12 16:45:02,240 [Thread-205] INFO  server.StorageContainerManager (StorageContainerManager.java:start(778)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:37529
2019-11-12 16:45:02,240 [Thread-205] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:37529
2019-11-12 16:45:02,241 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-12 16:45:02,241 [IPC Server listener on 37529] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37529: starting
2019-11-12 16:45:02,245 [Thread-205] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33509
2019-11-12 16:45:02,245 [Thread-205] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-12 16:45:02,248 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54b24fd0{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-12 16:45:02,249 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10908801{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-12 16:45:02,256 [Thread-205] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b27efb8{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-12 16:45:02,257 [Thread-205] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@48102307{HTTP/1.1,[http/1.1]}{0.0.0.0:33509}
2019-11-12 16:45:02,257 [Thread-205] INFO  server.Server (Server.java:doStart(419)) - Started @68884ms
2019-11-12 16:45:02,258 [Thread-205] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-12 16:45:02,259 [Thread-205] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:33509
2019-11-12 16:45:02,260 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:02,260 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20b04409] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-12 16:45:02,726 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37529. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-12 16:45:02,735 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,735 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,735 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,747 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:37529 for past 0 seconds.
java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	... 14 more
2019-11-12 16:45:02,752 [Datanode State Machine Thread - 1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,752 [Datanode State Machine Thread - 1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,752 [Datanode State Machine Thread - 1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,756 [Datanode State Machine Thread - 2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,756 [Datanode State Machine Thread - 2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,756 [Datanode State Machine Thread - 2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,759 [Datanode State Machine Thread - 3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,759 [Datanode State Machine Thread - 3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,759 [Datanode State Machine Thread - 3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,762 [Datanode State Machine Thread - 4] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,762 [Datanode State Machine Thread - 4] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,762 [Datanode State Machine Thread - 4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,769 [Datanode State Machine Thread - 5] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,769 [Datanode State Machine Thread - 5] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,769 [Datanode State Machine Thread - 5] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,772 [Datanode State Machine Thread - 6] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,772 [Datanode State Machine Thread - 6] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,772 [Datanode State Machine Thread - 6] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,775 [Datanode State Machine Thread - 7] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,775 [Datanode State Machine Thread - 7] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,776 [Datanode State Machine Thread - 7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,778 [Datanode State Machine Thread - 8] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,778 [Datanode State Machine Thread - 8] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,778 [Datanode State Machine Thread - 8] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:02,781 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:02,781 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:02,781 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:03,261 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:03,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:03,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:03,702 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:03,703 [Datanode State Machine Thread - 9] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:37529 for past 10 seconds.
java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	... 14 more
2019-11-12 16:45:04,261 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:05,262 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:05,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:05,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:05,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:06,262 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:07,263 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:07,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:07,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:07,702 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:08,263 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:09,264 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:09,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:09,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:09,703 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:10,264 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:11,265 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:11,701 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:11,701 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:11,702 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:12,265 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:13,266 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:13,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:13,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:13,703 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:14,267 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:15,267 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:15,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:15,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:15,703 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:16,268 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:17,268 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:17,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:17,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:17,705 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:18,268 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:19,269 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:19,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:19,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:19,703 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:20,269 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:21,270 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:21,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:21,702 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:21,702 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:22,270 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:23,271 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:23,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:23,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:23,703 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:23,703 [Datanode State Machine Thread - 9] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:37529 for past 20 seconds.
java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	... 14 more
2019-11-12 16:45:24,271 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:25,272 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:25,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:25,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:25,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:26,272 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:27,273 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:27,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:27,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:27,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:28,273 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:29,274 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:29,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:29,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:29,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:30,274 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:31,275 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:31,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:31,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:31,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:32,275 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:33,276 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:33,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:33,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:33,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:34,276 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:35,277 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:35,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:35,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:35,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:36,277 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:37,278 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:37,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:37,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:37,705 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:38,278 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:39,279 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:39,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:39,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:39,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:40,279 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:41,280 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:41,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:41,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:41,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:42,280 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:43,281 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:43,703 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:43,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:43,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:43,704 [Datanode State Machine Thread - 9] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:37529 for past 30 seconds.
java.io.IOException: Failed to lock storage /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/ratis/b930ab16-0c61-46c2-873c-14476f03424f. The directory is already locked
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:334)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lambda$lock$1(RaftStorageDirectory.java:292)
	at org.apache.ratis.util.JavaUtils.attempt(JavaUtils.java:160)
	at org.apache.ratis.util.FileUtils.attempt(FileUtils.java:40)
	at org.apache.ratis.server.storage.RaftStorageDirectory.lock(RaftStorageDirectory.java:292)
	at org.apache.ratis.server.storage.RaftStorageDirectory.analyzeStorage(RaftStorageDirectory.java:264)
	at org.apache.ratis.server.storage.RaftStorage.analyzeAndRecoverStorage(RaftStorage.java:100)
	at org.apache.ratis.server.storage.RaftStorage.<init>(RaftStorage.java:63)
	at org.apache.ratis.server.impl.ServerState.<init>(ServerState.java:109)
	at org.apache.ratis.server.impl.RaftServerImpl.<init>(RaftServerImpl.java:113)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$newRaftServerImpl$2(RaftServerProxy.java:208)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.OverlappingFileLockException
	at sun.nio.ch.SharedFileLockTable.checkList(FileLockTable.java:255)
	at sun.nio.ch.SharedFileLockTable.add(FileLockTable.java:152)
	at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1107)
	at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155)
	at org.apache.ratis.server.storage.RaftStorageDirectory.tryLock(RaftStorageDirectory.java:322)
	... 14 more
2019-11-12 16:45:44,281 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:45,282 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:45,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:45,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:45,705 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:46,282 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:47,283 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:47,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:47,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:47,705 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:48,284 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:49,284 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:49,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:49,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:49,705 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:50,285 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:51,285 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:51,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:51,704 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:51,704 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:52,286 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:53,286 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:53,706 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:53,706 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:53,706 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:54,287 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:55,287 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:55,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:55,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:55,705 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:56,288 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:57,288 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:57,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:57,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:57,705 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:45:58,289 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:59,289 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:45:59,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:45:59,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:45:59,706 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:46:00,290 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:46:01,290 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:46:01,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-12 16:46:01,705 [Datanode State Machine Thread - 9] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-12 16:46:01,705 [Datanode State Machine Thread - 9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 013257cb-d561-4102-a451-38f910b8168a at port 37331
2019-11-12 16:46:02,291 [Thread-205] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-12 16:46:02,312 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-11-12 16:46:02,313 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-11-12 16:46:02,313 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-11-12 16:46:02,314 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45740
2019-11-12 16:46:02,315 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-12 16:46:02,315 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:46:02,316 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-12 16:46:02,315 [IPC Server listener on 45740] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45740
2019-11-12 16:46:02,317 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-12 16:46:02,319 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6082e6bc{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-12 16:46:02,320 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@716c961e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-12 16:46:02,321 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d20c6b9{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-12 16:46:02,322 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4361eafd{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:46:03,351 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-11-12 16:46:03,703 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-12 16:46:08,352 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:46:08,354 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-28357eba-4b48-40c8-8ce4-11cfd640767c/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:46:08,370 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:46:08,372 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-12 16:46:08,374 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1144e107{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-12 16:46:08,375 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a5516ce{HTTP/1.1,[http/1.1]}{0.0.0.0:35345}
2019-11-12 16:46:08,376 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d552eaa{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-12 16:46:08,377 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8669010{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:46:08,377 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-11-12 16:46:08,378 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(802)) - Stopping Replication Manager Service.
2019-11-12 16:46:08,378 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(209)) - Replication Monitor Thread is not running.
2019-11-12 16:46:08,378 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(809)) - Stopping Lease Manager of the command watchers
2019-11-12 16:46:08,378 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping datanode service RPC server
2019-11-12 16:46:08,378 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-12 16:46:08,379 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37529
2019-11-12 16:46:08,380 [IPC Server listener on 37529] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37529
2019-11-12 16:46:08,381 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:46:08,391 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-11-12 16:46:08,392 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping block service RPC server
2019-11-12 16:46:08,393 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-12 16:46:08,393 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38339
2019-11-12 16:46:08,394 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-12 16:46:08,394 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:46:08,395 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-11-12 16:46:08,394 [IPC Server listener on 38339] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38339
2019-11-12 16:46:08,396 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43397
2019-11-12 16:46:08,397 [IPC Server listener on 43397] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43397
2019-11-12 16:46:08,397 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-12 16:46:08,397 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping Storage Container Manager HTTP server.
2019-11-12 16:46:08,399 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b27efb8{/,null,UNAVAILABLE}{/scm}
2019-11-12 16:46:08,400 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@48102307{HTTP/1.1,[http/1.1]}{0.0.0.0:33509}
2019-11-12 16:46:08,401 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10908801{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-12 16:46:08,401 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54b24fd0{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-12 16:46:08,402 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(849)) - Stopping Block Manager Service.
2019-11-12 16:46:08,402 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-12 16:46:08,402 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-12 16:46:08,403 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping SCM Event Queue.
2019-11-12 16:46:08,407 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2019-11-12 16:46:08,410 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2019-11-12 16:46:08,470 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/read/malformed.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:173)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: Can't construct a java object for tag:yaml.org,2002:org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml; exception=No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
 in 'reader', line 1, column 1:
    malformed
    ^

	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:349)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:182)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:141)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:127)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:450)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
Caused by: org.yaml.snakeyaml.error.YAMLException: No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
	at org.yaml.snakeyaml.constructor.Constructor$ConstructScalar.construct(Constructor.java:396)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:345)
	... 36 more
2019-11-12 16:46:08,473 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/write/valid-proto.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: unacceptable character '' (0x12) special characters are not allowed
in "'reader'", position 38
	at org.yaml.snakeyaml.reader.StreamReader.checkPrintable(StreamReader.java:93)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:192)
	at org.yaml.snakeyaml.reader.StreamReader.<init>(StreamReader.java:60)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
2019-11-12 16:46:08,497 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:46:08,498 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds to VolumeSet
2019-11-12 16:46:08,498 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,499 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,513 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-12 16:46:08,513 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:46:08,513 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:46:08,514 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:46:08,514 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:46:08,515 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:46:08,515 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:46:08,515 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:46:08,515 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-12 16:46:08,522 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:46:08,523 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds to VolumeSet
2019-11-12 16:46:08,523 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,523 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,534 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-12 16:46:08,535 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:46:08,535 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:46:08,535 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:46:08,535 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:46:08,535 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:46:08,535 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:46:08,536 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:46:08,536 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-12 16:46:08,542 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:46:08,542 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds to VolumeSet
2019-11-12 16:46:08,542 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,543 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,553 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-12 16:46:08,554 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:46:08,554 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:46:08,554 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:46:08,554 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:46:08,554 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:46:08,554 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:46:08,555 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:46:08,555 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-12 16:46:08,558 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 95fde5b7-5b6b-4863-a068-6714c14e6356 is started using port 46409
2019-11-12 16:46:08,558 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 95fde5b7-5b6b-4863-a068-6714c14e6356 at port 0
2019-11-12 16:46:08,565 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 95fde5b7-5b6b-4863-a068-6714c14e6356: start RPC server
2019-11-12 16:46:08,566 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 95fde5b7-5b6b-4863-a068-6714c14e6356: GrpcService started, listening on 0.0.0.0/0.0.0.0:38317
2019-11-12 16:46:08,566 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis 95fde5b7-5b6b-4863-a068-6714c14e6356 is started using port 38317
2019-11-12 16:46:08,567 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 95880bad-b089-4089-b4a7-c826212da666 is started using port 36422
2019-11-12 16:46:08,567 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 95880bad-b089-4089-b4a7-c826212da666 at port 0
2019-11-12 16:46:08,574 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 95880bad-b089-4089-b4a7-c826212da666: start RPC server
2019-11-12 16:46:08,575 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 95880bad-b089-4089-b4a7-c826212da666: GrpcService started, listening on 0.0.0.0/0.0.0.0:43915
2019-11-12 16:46:08,576 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis 95880bad-b089-4089-b4a7-c826212da666 is started using port 43915
2019-11-12 16:46:08,577 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc c6be5686-b5ef-48b1-b56e-2179ad38fdcf is started using port 32780
2019-11-12 16:46:08,577 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis c6be5686-b5ef-48b1-b56e-2179ad38fdcf at port 0
2019-11-12 16:46:08,583 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c6be5686-b5ef-48b1-b56e-2179ad38fdcf: start RPC server
2019-11-12 16:46:08,585 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - c6be5686-b5ef-48b1-b56e-2179ad38fdcf: GrpcService started, listening on 0.0.0.0/0.0.0.0:40685
2019-11-12 16:46:08,585 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis c6be5686-b5ef-48b1-b56e-2179ad38fdcf is started using port 40685
2019-11-12 16:46:08,585 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 95fde5b7-5b6b-4863-a068-6714c14e6356: close
2019-11-12 16:46:08,585 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 95fde5b7-5b6b-4863-a068-6714c14e6356: shutdown server with port 38317 now
2019-11-12 16:46:08,586 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 95fde5b7-5b6b-4863-a068-6714c14e6356: shutdown server with port 38317 successfully
2019-11-12 16:46:08,587 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 95880bad-b089-4089-b4a7-c826212da666: close
2019-11-12 16:46:08,587 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 95880bad-b089-4089-b4a7-c826212da666: shutdown server with port 43915 now
2019-11-12 16:46:08,587 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 95880bad-b089-4089-b4a7-c826212da666: shutdown server with port 43915 successfully
2019-11-12 16:46:08,588 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - c6be5686-b5ef-48b1-b56e-2179ad38fdcf: close
2019-11-12 16:46:08,588 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - c6be5686-b5ef-48b1-b56e-2179ad38fdcf: shutdown server with port 40685 now
2019-11-12 16:46:08,589 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - c6be5686-b5ef-48b1-b56e-2179ad38fdcf: shutdown server with port 40685 successfully
2019-11-12 16:46:08,598 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:46:08,599 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:46:08,612 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:46:08,612 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:46:08,612 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:46:08,624 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:46:08,624 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:46:08,624 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:46:08,635 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:46:08,637 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW : 8192 
2019-11-12 16:46:08,638 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:46:08,638 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds to VolumeSet
2019-11-12 16:46:08,638 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,639 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,652 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-12 16:46:08,652 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:46:08,653 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:46:08,653 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:46:08,653 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:46:08,653 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:46:08,654 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:46:08,654 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:46:08,654 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-12 16:46:08,657 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW : 8192 
2019-11-12 16:46:08,657 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:46:08,657 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds to VolumeSet
2019-11-12 16:46:08,657 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,658 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,671 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-12 16:46:08,672 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:46:08,672 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:46:08,672 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:46:08,672 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:46:08,672 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:46:08,673 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:46:08,673 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:46:08,673 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-12 16:46:08,675 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW : 8192 
2019-11-12 16:46:08,676 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-12 16:46:08,676 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds to VolumeSet
2019-11-12 16:46:08,676 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,676 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW/hdds
2019-11-12 16:46:08,688 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-12 16:46:08,688 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-12 16:46:08,689 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-12 16:46:08,689 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-12 16:46:08,689 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-12 16:46:08,689 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-12 16:46:08,689 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-12 16:46:08,689 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-12 16:46:08,690 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-12 16:46:08,690 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:46:08,691 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:46:08,700 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:46:08,701 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:46:08,701 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:46:08,710 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-12 16:46:08,710 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-12 16:46:08,711 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/VtBLyVGOuW] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-12 16:46:08,720 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
