2019-11-04 07:02:04,908 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:05,050 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:05,054 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:05,084 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @912ms
2019-11-04 07:02:05,181 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedBlocks
2019-11-04 07:02:05,181 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-04 07:02:05,182 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: validCerts
2019-11-04 07:02:05,182 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-04 07:02:05,182 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: revokedCerts
2019-11-04 07:02:05,182 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-04 07:02:05,193 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-11-04 07:02:05,194 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-04 07:02:05,195 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-11-04 07:02:05,512 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@2ec411df
2019-11-04 07:02:05,514 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-04 07:02:05,574 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-04 07:02:05,576 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-04 07:02:05,578 [Thread-0] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-04 07:02:05,637 [Thread-0] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-04 07:02:05,650 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:05,720 [Thread-0] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-04 07:02:05,722 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:05,857 [Thread-0] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-11-04 07:02:06,238 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-04 07:02:06,262 [Socket Reader #1 for port 38821] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38821
2019-11-04 07:02:06,412 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-04 07:02:06,413 [Socket Reader #1 for port 39469] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39469
2019-11-04 07:02:06,421 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-04 07:02:06,422 [Socket Reader #1 for port 37979] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37979
2019-11-04 07:02:06,445 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-04 07:02:06,627 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-04 07:02:06,635 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-04 07:02:06,643 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-04 07:02:06,645 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-04 07:02:06,646 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-04 07:02:06,646 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-04 07:02:06,678 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37979
2019-11-04 07:02:06,751 [Thread-0] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-04 07:02:06,766 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-04 07:02:06,766 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-04 07:02:07,028 [Thread-0] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:37979
2019-11-04 07:02:07,028 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-04 07:02:07,029 [IPC Server listener on 37979] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37979: starting
2019-11-04 07:02:07,032 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39469
2019-11-04 07:02:07,032 [Thread-0] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:39469
2019-11-04 07:02:07,033 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-04 07:02:07,033 [IPC Server listener on 39469] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39469: starting
2019-11-04 07:02:07,035 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(786)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:38821
2019-11-04 07:02:07,035 [Thread-0] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:38821
2019-11-04 07:02:07,036 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-04 07:02:07,036 [IPC Server listener on 38821] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38821: starting
2019-11-04 07:02:07,040 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40400
2019-11-04 07:02:07,042 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-04 07:02:07,078 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@644f0f13{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-04 07:02:07,079 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b66ca7a{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-04 07:02:07,111 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27d2bd53{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-04 07:02:07,116 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a6ceaf9{HTTP/1.1,[http/1.1]}{0.0.0.0:40400}
2019-11-04 07:02:07,117 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @2945ms
2019-11-04 07:02:07,119 [Thread-0] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-11-04 07:02:07,119 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-11-04 07:02:07,120 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:40400
2019-11-04 07:02:07,125 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6291ae04] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-04 07:02:07,128 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:07,253 [Thread-0] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-11-04 07:02:07,253 [Thread-0] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-11-04 07:02:07,255 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:07,256 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:07,882 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:07,896 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:07,911 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:07,911 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:07,912 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedBlocks
2019-11-04 07:02:07,912 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-04 07:02:07,912 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: validCerts
2019-11-04 07:02:07,912 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-04 07:02:07,913 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: revokedCerts
2019-11-04 07:02:07,913 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-04 07:02:07,913 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-11-04 07:02:07,913 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-04 07:02:07,913 [Thread-87] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-11-04 07:02:08,093 [Thread-87] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@4ca5c81
2019-11-04 07:02:08,093 [Thread-87] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-04 07:02:08,098 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-04 07:02:08,098 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-04 07:02:08,099 [Thread-87] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-04 07:02:08,101 [Thread-87] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-04 07:02:08,101 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:08,155 [Thread-87] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-04 07:02:08,155 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:08,221 [Thread-87] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-04 07:02:08,224 [Thread-87] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-04 07:02:08,226 [Socket Reader #1 for port 44239] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44239
2019-11-04 07:02:08,229 [Thread-87] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-04 07:02:08,230 [Socket Reader #1 for port 39663] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39663
2019-11-04 07:02:08,233 [Thread-87] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-04 07:02:08,234 [Socket Reader #1 for port 34547] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34547
2019-11-04 07:02:08,239 [Thread-87] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-04 07:02:08,241 [Thread-87] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-04 07:02:08,242 [Thread-87] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-04 07:02:08,246 [Thread-87] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-04 07:02:08,248 [Thread-87] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-04 07:02:08,248 [Thread-87] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-04 07:02:08,248 [Thread-87] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-04 07:02:08,264 [Thread-87] INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:34547
2019-11-04 07:02:08,264 [Thread-87] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2019-11-04 07:02:08,267 [Thread-87] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:34547
2019-11-04 07:02:08,268 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-04 07:02:08,268 [IPC Server listener on 34547] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34547: starting
2019-11-04 07:02:08,273 [Thread-87] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39663
2019-11-04 07:02:08,274 [Thread-87] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:39663
2019-11-04 07:02:08,274 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-04 07:02:08,275 [IPC Server listener on 39663] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39663: starting
2019-11-04 07:02:08,279 [Thread-87] INFO  server.StorageContainerManager (StorageContainerManager.java:start(786)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:44239
2019-11-04 07:02:08,279 [Thread-87] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:44239
2019-11-04 07:02:08,280 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-04 07:02:08,280 [IPC Server listener on 44239] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44239: starting
2019-11-04 07:02:08,284 [Thread-87] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39999
2019-11-04 07:02:08,285 [Thread-87] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-04 07:02:08,288 [Thread-87] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d44dcbf{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-04 07:02:08,288 [Thread-87] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@137662df{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-04 07:02:08,296 [Thread-87] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@132d935{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-04 07:02:08,297 [Thread-87] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2f87a0c9{HTTP/1.1,[http/1.1]}{0.0.0.0:39999}
2019-11-04 07:02:08,297 [Thread-87] INFO  server.Server (Server.java:doStart(419)) - Started @4125ms
2019-11-04 07:02:08,298 [Thread-87] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-04 07:02:08,299 [Thread-87] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:39999
2019-11-04 07:02:08,300 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:08,300 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@66b32c43] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-04 07:02:08,359 [Thread-87] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-11-04 07:02:08,359 [Thread-87] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-11-04 07:02:08,360 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:08,360 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:08,369 [Thread-87] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-04 07:02:08,513 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/read/malformed.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:173)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: Can't construct a java object for tag:yaml.org,2002:org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml; exception=No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
 in 'reader', line 1, column 1:
    malformed
    ^

	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:349)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:182)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:141)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:127)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:450)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
Caused by: org.yaml.snakeyaml.error.YAMLException: No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
	at org.yaml.snakeyaml.constructor.Constructor$ConstructScalar.construct(Constructor.java:396)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:345)
	... 36 more
2019-11-04 07:02:08,518 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/write/valid-proto.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: unacceptable character '' (0x12) special characters are not allowed
in "'reader'", position 38
	at org.yaml.snakeyaml.reader.StreamReader.checkPrintable(StreamReader.java:93)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:192)
	at org.yaml.snakeyaml.reader.StreamReader.<init>(StreamReader.java:60)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
2019-11-04 07:02:08,568 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-04 07:02:08,571 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds to VolumeSet
2019-11-04 07:02:08,576 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:08,723 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:08,829 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-04 07:02:08,855 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-04 07:02:08,913 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-04 07:02:08,917 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-04 07:02:08,918 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-04 07:02:08,919 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-04 07:02:08,920 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-04 07:02:08,921 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-04 07:02:09,065 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-04 07:02:09,121 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-04 07:02:09,121 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds to VolumeSet
2019-11-04 07:02:09,121 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,122 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,135 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-04 07:02:09,135 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-04 07:02:09,135 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-04 07:02:09,136 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-04 07:02:09,136 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-04 07:02:09,136 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-04 07:02:09,136 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-04 07:02:09,137 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-04 07:02:09,137 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-04 07:02:09,146 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-04 07:02:09,147 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds to VolumeSet
2019-11-04 07:02:09,147 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,147 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,159 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-04 07:02:09,160 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-04 07:02:09,160 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-04 07:02:09,160 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-04 07:02:09,160 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-04 07:02:09,161 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-04 07:02:09,161 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-04 07:02:09,161 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-04 07:02:09,162 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-04 07:02:09,288 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc ed4934b2-047c-46ff-ba3f-ca204a3ee757 is started using port 35719
2019-11-04 07:02:09,289 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis ed4934b2-047c-46ff-ba3f-ca204a3ee757 at port 0
2019-11-04 07:02:09,307 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - ed4934b2-047c-46ff-ba3f-ca204a3ee757: start RPC server
2019-11-04 07:02:09,311 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - ed4934b2-047c-46ff-ba3f-ca204a3ee757: GrpcService started, listening on 0.0.0.0/0.0.0.0:36419
2019-11-04 07:02:09,311 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis ed4934b2-047c-46ff-ba3f-ca204a3ee757 is started using port 36419
2019-11-04 07:02:09,313 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 1527416f-b7e9-4b0c-8fc3-cd94a6539615 is started using port 42354
2019-11-04 07:02:09,313 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 1527416f-b7e9-4b0c-8fc3-cd94a6539615 at port 0
2019-11-04 07:02:09,323 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 1527416f-b7e9-4b0c-8fc3-cd94a6539615: start RPC server
2019-11-04 07:02:09,325 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 1527416f-b7e9-4b0c-8fc3-cd94a6539615: GrpcService started, listening on 0.0.0.0/0.0.0.0:34649
2019-11-04 07:02:09,325 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 1527416f-b7e9-4b0c-8fc3-cd94a6539615 is started using port 34649
2019-11-04 07:02:09,329 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc acd69470-a043-4d15-b531-c585c42a2d67 is started using port 34078
2019-11-04 07:02:09,329 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis acd69470-a043-4d15-b531-c585c42a2d67 at port 0
2019-11-04 07:02:09,343 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - acd69470-a043-4d15-b531-c585c42a2d67: start RPC server
2019-11-04 07:02:09,349 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - acd69470-a043-4d15-b531-c585c42a2d67: GrpcService started, listening on 0.0.0.0/0.0.0.0:43289
2019-11-04 07:02:09,350 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis acd69470-a043-4d15-b531-c585c42a2d67 is started using port 43289
2019-11-04 07:02:09,352 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - ed4934b2-047c-46ff-ba3f-ca204a3ee757: close
2019-11-04 07:02:09,355 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - ed4934b2-047c-46ff-ba3f-ca204a3ee757: shutdown server with port 36419 now
2019-11-04 07:02:09,367 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - ed4934b2-047c-46ff-ba3f-ca204a3ee757: shutdown server with port 36419 successfully
2019-11-04 07:02:09,372 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 1527416f-b7e9-4b0c-8fc3-cd94a6539615: close
2019-11-04 07:02:09,373 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 1527416f-b7e9-4b0c-8fc3-cd94a6539615: shutdown server with port 34649 now
2019-11-04 07:02:09,373 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 1527416f-b7e9-4b0c-8fc3-cd94a6539615: shutdown server with port 34649 successfully
2019-11-04 07:02:09,379 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - acd69470-a043-4d15-b531-c585c42a2d67: close
2019-11-04 07:02:09,384 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - acd69470-a043-4d15-b531-c585c42a2d67: shutdown server with port 43289 now
2019-11-04 07:02:09,388 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - acd69470-a043-4d15-b531-c585c42a2d67: shutdown server with port 43289 successfully
2019-11-04 07:02:09,401 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-11-04 07:02:09,403 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-04 07:02:09,419 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-04 07:02:09,420 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-11-04 07:02:09,421 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-04 07:02:09,434 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-04 07:02:09,434 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-11-04 07:02:09,435 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-04 07:02:09,447 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-04 07:02:09,451 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K : 8192 
2019-11-04 07:02:09,452 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-04 07:02:09,452 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds to VolumeSet
2019-11-04 07:02:09,452 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,453 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,469 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-04 07:02:09,470 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-04 07:02:09,470 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-04 07:02:09,470 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-04 07:02:09,470 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-04 07:02:09,471 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-04 07:02:09,471 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-04 07:02:09,471 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-04 07:02:09,472 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-04 07:02:09,475 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K : 8192 
2019-11-04 07:02:09,476 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-04 07:02:09,476 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds to VolumeSet
2019-11-04 07:02:09,476 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,477 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,491 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-04 07:02:09,491 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-04 07:02:09,492 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-04 07:02:09,492 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-04 07:02:09,492 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-04 07:02:09,492 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-04 07:02:09,492 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-04 07:02:09,493 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-04 07:02:09,493 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-04 07:02:09,496 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K : 8192 
2019-11-04 07:02:09,496 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-04 07:02:09,497 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds to VolumeSet
2019-11-04 07:02:09,497 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,497 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K/hdds
2019-11-04 07:02:09,510 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-04 07:02:09,510 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-04 07:02:09,510 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-04 07:02:09,511 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-04 07:02:09,511 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-04 07:02:09,511 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-04 07:02:09,511 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-04 07:02:09,512 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-04 07:02:09,512 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-04 07:02:09,513 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-11-04 07:02:09,513 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-04 07:02:09,524 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-04 07:02:09,524 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-11-04 07:02:09,524 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-04 07:02:09,536 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-04 07:02:09,536 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-11-04 07:02:09,536 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/8IZ7RuDV4K] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-04 07:02:09,547 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
