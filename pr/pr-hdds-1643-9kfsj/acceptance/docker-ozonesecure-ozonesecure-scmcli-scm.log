Attaching to ozonesecure_datanode_3, ozonesecure_datanode_2, ozonesecure_scm_1, ozonesecure_kms_1, ozonesecure_datanode_1, ozonesecure_om_1, ozonesecure_recon_1, ozonesecure_kdc_1, ozonesecure_s3g_1
datanode_3  | Sleeping for 5 seconds
datanode_3  | Setting up kerberos!!
datanode_3  | KDC ISSUER_SERVER => kdc:8081
datanode_3  | Sleeping for 5 seconds
datanode_3  | Got 200, KDC service ready!!
datanode_2  | Sleeping for 5 seconds
datanode_3  | Download dn/f186250a45b8@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | Setting up kerberos!!
datanode_3  | --2019-10-30 05:53:37--  http://kdc:8081/keytab/f186250a45b8/dn
datanode_2  | KDC ISSUER_SERVER => kdc:8081
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | Sleeping for 5 seconds
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Got 200, KDC service ready!!
kms_1       | Sleeping for 5 seconds
scm_1       | Sleeping for 5 seconds
datanode_3  | Length: 158 [application/octet-stream]
datanode_2  | Download dn/e68c2c815db9@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
om_1        | Sleeping for 5 seconds
kms_1       | Setting up kerberos!!
scm_1       | Setting up kerberos!!
datanode_1  | Sleeping for 5 seconds
datanode_3  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_2  | --2019-10-30 05:53:37--  http://kdc:8081/keytab/e68c2c815db9/dn
om_1        | Setting up kerberos!!
kms_1       | KDC ISSUER_SERVER => kdc:8081
scm_1       | KDC ISSUER_SERVER => kdc:8081
datanode_1  | Setting up kerberos!!
kdc_1       | Issuer is listening on : 8081krb5kdc: starting...
recon_1     | Sleeping for 5 seconds
datanode_3  | 
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
om_1        | KDC ISSUER_SERVER => kdc:8081
kms_1       | Sleeping for  seconds
scm_1       | Sleeping for 5 seconds
datanode_1  | KDC ISSUER_SERVER => kdc:8081
kdc_1       | kadmind: starting...
recon_1     | Waiting for the service om:9874
datanode_3  |      0K                                                       100% 12.5M=0s
om_1        | Sleeping for 5 seconds
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kms_1       | /opt/starter.sh: line 66: SLEEP_SECONDS: command not found
scm_1       | Got 200, KDC service ready!!
datanode_1  | Sleeping for 5 seconds
kdc_1       | otp: Loaded
s3g_1       | Sleeping for 5 seconds
recon_1     | Setting up kerberos!!
datanode_3  | 
om_1        | Got 200, KDC service ready!!
datanode_2  | HTTP request sent, awaiting response... 200 OK
kms_1       | Got 200, KDC service ready!!
datanode_1  | Got 200, KDC service ready!!
scm_1       | Download dn/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
kdc_1       | Oct 30 05:53:26 kdc krb5kdc[9](info): setting up network...
s3g_1       | Setting up kerberos!!
recon_1     | KDC ISSUER_SERVER => kdc:8081
datanode_3  | 2019-10-30 05:53:38 (12.5 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
om_1        | Download dn/om@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | Length: 158 [application/octet-stream]
kms_1       | Download dn/c1df53cef837@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_1  | Download dn/5bae0ed04c34@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
scm_1       | --2019-10-30 05:53:37--  http://kdc:8081/keytab/scm/dn
kdc_1       | krb5kdc: setsockopt(9,IPV6_V6ONLY,1) worked
s3g_1       | KDC ISSUER_SERVER => kdc:8081
recon_1     | Sleeping for 5 seconds
datanode_3  | 
om_1        | --2019-10-30 05:53:38--  http://kdc:8081/keytab/om/dn
datanode_2  | Saving to: '/etc/security/keytabs/dn.keytab'
kms_1       | --2019-10-30 05:53:37--  http://kdc:8081/keytab/c1df53cef837/dn
datanode_1  | --2019-10-30 05:53:37--  http://kdc:8081/keytab/5bae0ed04c34/dn
scm_1       | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | krb5kdc: setsockopt(11,IPV6_V6ONLY,1) worked
s3g_1       | Sleeping for 5 seconds
recon_1     | Got 200, KDC service ready!!
datanode_3  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
om_1        | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | 
kms_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Oct 30 05:53:26 kdc krb5kdc[9](info): set up 4 sockets
s3g_1       | Got 200, KDC service ready!!
recon_1     | Download dn/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  |      0K                                                       100% 18.1M=0s
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  | KVNO Timestamp         Principal
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 30 05:53:26 kdc krb5kdc[9](info): commencing operation
s3g_1       | Download dn/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
recon_1     | --2019-10-30 05:54:04--  http://kdc:8081/keytab/recon/dn
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_2  | 
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_1  | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 140 [application/octet-stream]
kdc_1       | Oct 30 05:53:16 4d3d92ece176 kadmin.local[1](info): No dictionary file specified, continuing without one.
s3g_1       | --2019-10-30 05:53:37--  http://kdc:8081/keytab/s3g/dn
om_1        | Length: 138 [application/octet-stream]
recon_1     | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | 2019-10-30 05:53:37 (18.1 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
kms_1       | Length: 158 [application/octet-stream]
datanode_3  |    2 10/30/19 05:53:38 dn/f186250a45b8@EXAMPLE.COM
datanode_1  | Length: 158 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/dn.keytab'
kdc_1       | Oct 30 05:53:18 ca008cd8ee18 kadmin.local[1](info): No dictionary file specified, continuing without one.
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
om_1        | Saving to: '/etc/security/keytabs/dn.keytab'
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  | 
kms_1       | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_3  |    2 10/30/19 05:53:38 dn/f186250a45b8@EXAMPLE.COM
datanode_1  | Saving to: '/etc/security/keytabs/dn.keytab'
scm_1       | 
kdc_1       | Oct 30 05:53:31 kdc kadmind[15](info): No dictionary file specified, continuing without one.
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_2  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
om_1        | 
kms_1       | 
datanode_3  | Download om/f186250a45b8@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_1  | 
scm_1       |      0K                                                       100% 14.7M=0s
kdc_1       | Oct 30 05:53:31 kdc kadmind[15](info): setting up network...
recon_1     | Length: 144 [application/octet-stream]
s3g_1       | HTTP request sent, awaiting response... 200 OK
datanode_2  | KVNO Timestamp         Principal
om_1        |      0K                                                       100% 13.9M=0s
kms_1       |      0K                                                       100% 5.00M=0s
datanode_3  | --2019-10-30 05:53:38--  http://kdc:8081/keytab/f186250a45b8/om
datanode_1  |      0K                                                       100% 6.85M=0s
scm_1       | 
kdc_1       | kadmind: setsockopt(9,IPV6_V6ONLY,1) worked
recon_1     | Saving to: '/etc/security/keytabs/dn.keytab'
s3g_1       | Length: 140 [application/octet-stream]
datanode_2  | ---- ----------------- --------------------------------------------------------
om_1        | 
kms_1       | 
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | 
scm_1       | 2019-10-30 05:53:38 (14.7 MB/s) - '/etc/security/keytabs/dn.keytab' saved [140/140]
kdc_1       | kadmind: setsockopt(11,IPV6_V6ONLY,1) worked
recon_1     | 
s3g_1       | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_2  |    2 10/30/19 05:53:37 dn/e68c2c815db9@EXAMPLE.COM
om_1        | 2019-10-30 05:53:39 (13.9 MB/s) - '/etc/security/keytabs/dn.keytab' saved [138/138]
kms_1       | 2019-10-30 05:53:37 (5.00 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | 2019-10-30 05:53:37 (6.85 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
scm_1       | 
kdc_1       | kadmind: setsockopt(13,IPV6_V6ONLY,1) worked
recon_1     |      0K                                                       100% 8.45M=0s
s3g_1       | 
datanode_2  |    2 10/30/19 05:53:37 dn/e68c2c815db9@EXAMPLE.COM
om_1        | 
kms_1       | 
datanode_1  | 
datanode_3  | HTTP request sent, awaiting response... 200 OK
scm_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
kdc_1       | Oct 30 05:53:31 kdc kadmind[15](info): set up 6 sockets
recon_1     | 
s3g_1       |      0K                                                       100% 11.1M=0s
datanode_2  | Download om/e68c2c815db9@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om_1        | Keytab name: FILE:/etc/security/keytabs/dn.keytab
kms_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_3  | Length: 158 [application/octet-stream]
scm_1       | KVNO Timestamp         Principal
kdc_1       | Oct 30 05:53:32 kdc kadmind[15](info): Seeding random number generator
recon_1     | 2019-10-30 05:54:04 (8.45 MB/s) - '/etc/security/keytabs/dn.keytab' saved [144/144]
s3g_1       | 
datanode_2  | --2019-10-30 05:53:37--  http://kdc:8081/keytab/e68c2c815db9/om
om_1        | KVNO Timestamp         Principal
kms_1       | KVNO Timestamp         Principal
datanode_1  | KVNO Timestamp         Principal
datanode_3  | Saving to: '/etc/security/keytabs/om.keytab'
kdc_1       | Oct 30 05:53:32 kdc kadmind[15](info): starting
recon_1     | 
scm_1       | ---- ----------------- --------------------------------------------------------
s3g_1       | 2019-10-30 05:53:38 (11.1 MB/s) - '/etc/security/keytabs/dn.keytab' saved [140/140]
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
kms_1       | ---- ----------------- --------------------------------------------------------
om_1        | ---- ----------------- --------------------------------------------------------
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_3  | 
kdc_1       | Generiting keytab
recon_1     | Keytab name: FILE:/etc/security/keytabs/dn.keytab
scm_1       |    2 10/30/19 05:53:38 dn/scm@EXAMPLE.COM
s3g_1       | 
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kms_1       |    2 10/30/19 05:53:37 dn/c1df53cef837@EXAMPLE.COM
om_1        |    2 10/30/19 05:53:39 dn/om@EXAMPLE.COM
datanode_1  |    2 10/30/19 05:53:37 dn/5bae0ed04c34@EXAMPLE.COM
datanode_3  |      0K                                                       100% 13.4M=0s
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | KVNO Timestamp         Principal
scm_1       |    2 10/30/19 05:53:38 dn/scm@EXAMPLE.COM
s3g_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_2  | HTTP request sent, awaiting response... 200 OK
kms_1       |    2 10/30/19 05:53:37 dn/c1df53cef837@EXAMPLE.COM
om_1        |    2 10/30/19 05:53:39 dn/om@EXAMPLE.COM
datanode_1  |    2 10/30/19 05:53:37 dn/5bae0ed04c34@EXAMPLE.COM
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
datanode_3  | 
recon_1     | ---- ----------------- --------------------------------------------------------
scm_1       | Download om/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
s3g_1       | KVNO Timestamp         Principal
datanode_2  | Length: 158 [application/octet-stream]
kms_1       | Download om/c1df53cef837@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om_1        | Download om/om@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_1  | Download om/5bae0ed04c34@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
kdc_1       | Principal "test/test@EXAMPLE.COM" created.
datanode_3  | 2019-10-30 05:53:39 (13.4 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
recon_1     |    2 10/30/19 05:54:04 dn/recon@EXAMPLE.COM
s3g_1       | ---- ----------------- --------------------------------------------------------
scm_1       | --2019-10-30 05:53:38--  http://kdc:8081/keytab/scm/om
datanode_2  | Saving to: '/etc/security/keytabs/om.keytab'
kms_1       | --2019-10-30 05:53:37--  http://kdc:8081/keytab/c1df53cef837/om
om_1        | --2019-10-30 05:53:39--  http://kdc:8081/keytab/om/om
datanode_1  | --2019-10-30 05:53:37--  http://kdc:8081/keytab/5bae0ed04c34/om
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 
recon_1     |    2 10/30/19 05:54:04 dn/recon@EXAMPLE.COM
scm_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | 
kms_1       | Resolving kdc (kdc)... 172.18.0.3
s3g_1       |    2 10/30/19 05:53:38 dn/s3g@EXAMPLE.COM
om_1        | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
datanode_3  | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Download om/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  |      0K                                                       100% 16.6M=0s
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       |    2 10/30/19 05:53:38 dn/s3g@EXAMPLE.COM
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
datanode_3  | KVNO Timestamp         Principal
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | --2019-10-30 05:54:04--  http://kdc:8081/keytab/recon/om
scm_1       | HTTP request sent, awaiting response... 200 OK
datanode_2  | 
kms_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Download om/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
s3g_1       | --2019-10-30 05:53:38--  http://kdc:8081/keytab/s3g/om
kdc_1       | Generiting keytab
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_1  | HTTP request sent, awaiting response... 200 OK
recon_1     | Resolving kdc (kdc)... 172.18.0.3
scm_1       | Length: 140 [application/octet-stream]
datanode_2  | 2019-10-30 05:53:38 (16.6 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
kms_1       | Length: 158 [application/octet-stream]
om_1        | HTTP request sent, awaiting response... 200 OK
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  |    2 10/30/19 05:53:39 om/f186250a45b8@EXAMPLE.COM
datanode_1  | Length: 158 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/om.keytab'
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  | 
kms_1       | Saving to: '/etc/security/keytabs/om.keytab'
om_1        | Length: 138 [application/octet-stream]
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
datanode_3  |    2 10/30/19 05:53:39 om/f186250a45b8@EXAMPLE.COM
datanode_1  | Saving to: '/etc/security/keytabs/om.keytab'
scm_1       | 
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_2  | Keytab name: FILE:/etc/security/keytabs/om.keytab
kms_1       | 
om_1        | Saving to: '/etc/security/keytabs/om.keytab'
s3g_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | add_principal: Principal or policy already exists while creating "test/test@EXAMPLE.COM".
datanode_3  | Download scm/f186250a45b8@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_1  | 
scm_1       |      0K                                                       100% 11.1M=0s
recon_1     | Length: 144 [application/octet-stream]
datanode_2  | KVNO Timestamp         Principal
kms_1       |      0K                                                       100% 15.2M=0s
om_1        | 
s3g_1       | Length: 140 [application/octet-stream]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | --2019-10-30 05:53:39--  http://kdc:8081/keytab/f186250a45b8/scm
datanode_1  |      0K                                                       100% 21.8M=0s
scm_1       | 
recon_1     | Saving to: '/etc/security/keytabs/om.keytab'
datanode_2  | ---- ----------------- --------------------------------------------------------
kms_1       | 
om_1        |      0K                                                       100% 8.12M=0s
s3g_1       | Saving to: '/etc/security/keytabs/om.keytab'
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 3, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | 
scm_1       | 2019-10-30 05:53:39 (11.1 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
datanode_2  |    2 10/30/19 05:53:38 om/e68c2c815db9@EXAMPLE.COM
recon_1     | 
kms_1       | 2019-10-30 05:53:38 (15.2 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
om_1        | 
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 3, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
s3g_1       | 
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | 2019-10-30 05:53:38 (21.8 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
scm_1       | 
datanode_2  |    2 10/30/19 05:53:38 om/e68c2c815db9@EXAMPLE.COM
recon_1     |      0K                                                       100% 12.0M=0s
kms_1       | 
om_1        | 2019-10-30 05:53:40 (8.12 MB/s) - '/etc/security/keytabs/om.keytab' saved [138/138]
kdc_1       | Generiting keytab
s3g_1       |      0K                                                       100% 11.9M=0s
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_1  | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_2  | Download scm/e68c2c815db9@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
recon_1     | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
om_1        | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 
datanode_3  | Length: 160 [application/octet-stream]
datanode_1  | Keytab name: FILE:/etc/security/keytabs/om.keytab
scm_1       | KVNO Timestamp         Principal
datanode_2  | --2019-10-30 05:53:38--  http://kdc:8081/keytab/e68c2c815db9/scm
recon_1     | 2019-10-30 05:54:05 (12.0 MB/s) - '/etc/security/keytabs/om.keytab' saved [144/144]
om_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
kdc_1       | WARNING: no policy specified for dn/5bae0ed04c34@EXAMPLE.COM; defaulting to no policy
kms_1       | KVNO Timestamp         Principal
s3g_1       | 2019-10-30 05:53:40 (11.9 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
datanode_3  | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_1  | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
om_1        | KVNO Timestamp         Principal
recon_1     | 
kdc_1       | Principal "dn/5bae0ed04c34@EXAMPLE.COM" created.
kms_1       | ---- ----------------- --------------------------------------------------------
s3g_1       | 
datanode_3  | 
datanode_1  | ---- ----------------- --------------------------------------------------------
scm_1       |    2 10/30/19 05:53:39 om/scm@EXAMPLE.COM
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | ---- ----------------- --------------------------------------------------------
recon_1     | Keytab name: FILE:/etc/security/keytabs/om.keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       |    2 10/30/19 05:53:38 om/c1df53cef837@EXAMPLE.COM
s3g_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_3  |      0K                                                       100% 11.3M=0s
scm_1       |    2 10/30/19 05:53:39 om/scm@EXAMPLE.COM
datanode_2  | HTTP request sent, awaiting response... 200 OK
om_1        |    2 10/30/19 05:53:40 om/om@EXAMPLE.COM
recon_1     | KVNO Timestamp         Principal
kdc_1       | Entry for principal dn/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.5bae0ed04c34.keytab.
kms_1       |    2 10/30/19 05:53:38 om/c1df53cef837@EXAMPLE.COM
datanode_1  |    2 10/30/19 05:53:38 om/5bae0ed04c34@EXAMPLE.COM
s3g_1       | KVNO Timestamp         Principal
datanode_3  | 
scm_1       | Download scm/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_2  | Length: 160 [application/octet-stream]
om_1        |    2 10/30/19 05:53:40 om/om@EXAMPLE.COM
recon_1     | ---- ----------------- --------------------------------------------------------
kdc_1       | Entry for principal dn/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.5bae0ed04c34.keytab.
kms_1       | Download scm/c1df53cef837@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_1  |    2 10/30/19 05:53:38 om/5bae0ed04c34@EXAMPLE.COM
s3g_1       | ---- ----------------- --------------------------------------------------------
datanode_3  | 2019-10-30 05:53:40 (11.3 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
scm_1       | --2019-10-30 05:53:39--  http://kdc:8081/keytab/scm/scm
datanode_2  | Saving to: '/etc/security/keytabs/scm.keytab'
om_1        | Download scm/om@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
recon_1     |    2 10/30/19 05:54:05 om/recon@EXAMPLE.COM
kdc_1       | Generiting keytab
kms_1       | --2019-10-30 05:53:39--  http://kdc:8081/keytab/c1df53cef837/scm
datanode_1  | Download scm/5bae0ed04c34@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
s3g_1       |    2 10/30/19 05:53:39 om/s3g@EXAMPLE.COM
scm_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_3  | 
datanode_2  | 
om_1        | --2019-10-30 05:53:40--  http://kdc:8081/keytab/om/scm
recon_1     |    2 10/30/19 05:54:05 om/recon@EXAMPLE.COM
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | --2019-10-30 05:53:38--  http://kdc:8081/keytab/5bae0ed04c34/scm
s3g_1       |    2 10/30/19 05:53:39 om/s3g@EXAMPLE.COM
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_2  |      0K                                                       100% 12.1M=0s
om_1        | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Download scm/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
kdc_1       | WARNING: no policy specified for dn/e68c2c815db9@EXAMPLE.COM; defaulting to no policy
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | Download scm/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
scm_1       | HTTP request sent, awaiting response... 200 OK
datanode_3  | KVNO Timestamp         Principal
datanode_2  | 
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | --2019-10-30 05:54:05--  http://kdc:8081/keytab/recon/scm
kdc_1       | Principal "dn/e68c2c815db9@EXAMPLE.COM" created.
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | --2019-10-30 05:53:40--  http://kdc:8081/keytab/s3g/scm
scm_1       | Length: 142 [application/octet-stream]
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_2  | 2019-10-30 05:53:40 (12.1 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
om_1        | HTTP request sent, awaiting response... 200 OK
recon_1     | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | Length: 160 [application/octet-stream]
datanode_1  | HTTP request sent, awaiting response... 200 OK
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
scm_1       | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_3  |    2 10/30/19 05:53:40 scm/f186250a45b8@EXAMPLE.COM
datanode_2  | 
om_1        | Length: 140 [application/octet-stream]
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Entry for principal dn/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.e68c2c815db9.keytab.
kms_1       | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_1  | Length: 160 [application/octet-stream]
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       | 
datanode_3  |    2 10/30/19 05:53:40 scm/f186250a45b8@EXAMPLE.COM
datanode_2  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
om_1        | Saving to: '/etc/security/keytabs/scm.keytab'
recon_1     | HTTP request sent, awaiting response... 200 OK
kdc_1       | Entry for principal dn/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.e68c2c815db9.keytab.
datanode_1  | Saving to: '/etc/security/keytabs/scm.keytab'
kms_1       | 
s3g_1       | HTTP request sent, awaiting response... 200 OK
scm_1       |      0K                                                       100% 18.4M=0s
datanode_3  | Download HTTP/f186250a45b8@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_2  | KVNO Timestamp         Principal
om_1        | 
recon_1     | Length: 146 [application/octet-stream]
kdc_1       | Generiting keytab
datanode_1  | 
kms_1       |      0K                                                       100% 11.0M=0s
s3g_1       | Length: 142 [application/octet-stream]
scm_1       | 
datanode_3  | --2019-10-30 05:53:40--  http://kdc:8081/keytab/f186250a45b8/HTTP
datanode_2  | ---- ----------------- --------------------------------------------------------
om_1        |      0K                                                       100% 18.4M=0s
recon_1     | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_1  |      0K                                                       100% 21.2M=0s
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | 
s3g_1       | Saving to: '/etc/security/keytabs/scm.keytab'
scm_1       | 2019-10-30 05:53:41 (18.4 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
datanode_2  |    2 10/30/19 05:53:40 scm/e68c2c815db9@EXAMPLE.COM
om_1        | 
recon_1     | 
datanode_1  | 
kdc_1       | WARNING: no policy specified for dn/c1df53cef837@EXAMPLE.COM; defaulting to no policy
kms_1       | 2019-10-30 05:53:40 (11.0 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
s3g_1       | 
scm_1       | 
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  |    2 10/30/19 05:53:40 scm/e68c2c815db9@EXAMPLE.COM
om_1        | 2019-10-30 05:53:41 (18.4 MB/s) - '/etc/security/keytabs/scm.keytab' saved [140/140]
recon_1     |      0K                                                       100% 14.3M=0s
datanode_1  | 2019-10-30 05:53:39 (21.2 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
kdc_1       | Principal "dn/c1df53cef837@EXAMPLE.COM" created.
kms_1       | 
s3g_1       |      0K                                                       100% 21.8M=0s
scm_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Download HTTP/e68c2c815db9@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om_1        | 
recon_1     | 
datanode_1  | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
s3g_1       | 
scm_1       | KVNO Timestamp         Principal
datanode_3  | Length: 162 [application/octet-stream]
datanode_2  | --2019-10-30 05:53:40--  http://kdc:8081/keytab/e68c2c815db9/HTTP
om_1        | Keytab name: FILE:/etc/security/keytabs/scm.keytab
recon_1     | 2019-10-30 05:54:05 (14.3 MB/s) - '/etc/security/keytabs/scm.keytab' saved [146/146]
datanode_1  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kms_1       | KVNO Timestamp         Principal
s3g_1       | 2019-10-30 05:53:41 (21.8 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
scm_1       | ---- ----------------- --------------------------------------------------------
datanode_3  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
om_1        | KVNO Timestamp         Principal
recon_1     | 
datanode_1  | KVNO Timestamp         Principal
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kms_1       | ---- ----------------- --------------------------------------------------------
s3g_1       | 
scm_1       |    2 10/30/19 05:53:40 scm/scm@EXAMPLE.COM
datanode_3  | 
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | ---- ----------------- --------------------------------------------------------
recon_1     | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_1  | ---- ----------------- --------------------------------------------------------
kms_1       |    2 10/30/19 05:53:40 scm/c1df53cef837@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
scm_1       |    2 10/30/19 05:53:40 scm/scm@EXAMPLE.COM
datanode_3  |      0K                                                       100% 15.6M=0s
datanode_2  | HTTP request sent, awaiting response... 200 OK
om_1        |    2 10/30/19 05:53:41 scm/om@EXAMPLE.COM
recon_1     | KVNO Timestamp         Principal
datanode_1  |    2 10/30/19 05:53:39 scm/5bae0ed04c34@EXAMPLE.COM
kms_1       |    2 10/30/19 05:53:40 scm/c1df53cef837@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | Download HTTP/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
s3g_1       | KVNO Timestamp         Principal
datanode_3  | 
datanode_2  | Length: 162 [application/octet-stream]
om_1        |    2 10/30/19 05:53:41 scm/om@EXAMPLE.COM
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 10/30/19 05:53:39 scm/5bae0ed04c34@EXAMPLE.COM
kms_1       | Download HTTP/c1df53cef837@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | --2019-10-30 05:53:41--  http://kdc:8081/keytab/scm/HTTP
s3g_1       | ---- ----------------- --------------------------------------------------------
datanode_3  | 2019-10-30 05:53:42 (15.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_2  | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        | Download HTTP/om@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
recon_1     |    2 10/30/19 05:54:05 scm/recon@EXAMPLE.COM
datanode_1  | Download HTTP/5bae0ed04c34@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
kms_1       | --2019-10-30 05:53:40--  http://kdc:8081/keytab/c1df53cef837/HTTP
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | Resolving kdc (kdc)... 172.18.0.3
s3g_1       |    2 10/30/19 05:53:41 scm/s3g@EXAMPLE.COM
datanode_3  | 
datanode_2  | 
om_1        | --2019-10-30 05:53:41--  http://kdc:8081/keytab/om/HTTP
recon_1     |    2 10/30/19 05:54:05 scm/recon@EXAMPLE.COM
datanode_1  | --2019-10-30 05:53:39--  http://kdc:8081/keytab/5bae0ed04c34/HTTP
kms_1       | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       |    2 10/30/19 05:53:41 scm/s3g@EXAMPLE.COM
datanode_3  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_2  |      0K                                                       100% 19.1M=0s
om_1        | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Download HTTP/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Download HTTP/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_2  | 
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | --2019-10-30 05:54:05--  http://kdc:8081/keytab/recon/HTTP
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kms_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | Length: 144 [application/octet-stream]
s3g_1       | --2019-10-30 05:53:41--  http://kdc:8081/keytab/s3g/HTTP
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_2  | 2019-10-30 05:53:41 (19.1 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
om_1        | HTTP request sent, awaiting response... 200 OK
recon_1     | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | HTTP request sent, awaiting response... 200 OK
kms_1       | Length: 162 [application/octet-stream]
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_3  |    2 10/30/19 05:53:42 HTTP/f186250a45b8@EXAMPLE.COM
datanode_2  | 
om_1        | Length: 142 [application/octet-stream]
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | Length: 162 [application/octet-stream]
kms_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_3  |    2 10/30/19 05:53:42 HTTP/f186250a45b8@EXAMPLE.COM
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
kms_1       | 
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       |      0K                                                       100% 9.03M=0s
datanode_2  | KVNO Timestamp         Principal
datanode_3  | Download testuser/f186250a45b8@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
s3g_1       | HTTP request sent, awaiting response... 200 OK
om_1        | 
recon_1     | Length: 148 [application/octet-stream]
datanode_1  | 
kms_1       |      0K                                                       100% 21.4M=0s
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_3  | --2019-10-30 05:53:42--  http://kdc:8081/keytab/f186250a45b8/testuser
s3g_1       | Length: 144 [application/octet-stream]
om_1        |      0K                                                       100% 18.9M=0s
recon_1     | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_1  |      0K                                                       100% 11.3M=0s
kms_1       | 
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:53:42 (9.03 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
datanode_2  |    2 10/30/19 05:53:41 HTTP/e68c2c815db9@EXAMPLE.COM
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
om_1        | 
s3g_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
recon_1     | 
datanode_1  | 
kms_1       | 2019-10-30 05:53:41 (21.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 
datanode_2  |    2 10/30/19 05:53:41 HTTP/e68c2c815db9@EXAMPLE.COM
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | 2019-10-30 05:53:43 (18.9 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [142/142]
s3g_1       | 
recon_1     |      0K                                                       100% 13.4M=0s
datanode_1  | 2019-10-30 05:53:41 (11.3 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
kms_1       | 
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_2  | Download testuser/e68c2c815db9@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_3  | HTTP request sent, awaiting response... 200 OK
om_1        | 
s3g_1       |      0K                                                       100% 19.0M=0s
recon_1     | 
datanode_1  | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
scm_1       | KVNO Timestamp         Principal
datanode_2  | --2019-10-30 05:53:41--  http://kdc:8081/keytab/e68c2c815db9/testuser
datanode_3  | Length: 170 [application/octet-stream]
om_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
s3g_1       | 
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
recon_1     | 2019-10-30 05:54:05 (13.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [148/148]
datanode_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
kms_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
datanode_3  | Saving to: '/etc/security/keytabs/testuser.keytab'
om_1        | KVNO Timestamp         Principal
s3g_1       | 2019-10-30 05:53:42 (19.0 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
recon_1     | 
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | KVNO Timestamp         Principal
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  | 
om_1        | ---- ----------------- --------------------------------------------------------
s3g_1       | 
scm_1       |    2 10/30/19 05:53:42 HTTP/scm@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kms_1       |    2 10/30/19 05:53:41 HTTP/c1df53cef837@EXAMPLE.COM
datanode_1  | ---- ----------------- --------------------------------------------------------
recon_1     | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_3  |      0K                                                       100% 23.0M=0s
om_1        |    2 10/30/19 05:53:43 HTTP/om@EXAMPLE.COM
s3g_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
scm_1       |    2 10/30/19 05:53:42 HTTP/scm@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kms_1       |    2 10/30/19 05:53:41 HTTP/c1df53cef837@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  |    2 10/30/19 05:53:41 HTTP/5bae0ed04c34@EXAMPLE.COM
recon_1     | KVNO Timestamp         Principal
datanode_2  | Length: 170 [application/octet-stream]
datanode_3  | 
om_1        |    2 10/30/19 05:53:43 HTTP/om@EXAMPLE.COM
s3g_1       | KVNO Timestamp         Principal
scm_1       | Download testuser/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
kms_1       | Download testuser/c1df53cef837@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  |    2 10/30/19 05:53:41 HTTP/5bae0ed04c34@EXAMPLE.COM
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_2  | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_3  | 2019-10-30 05:53:43 (23.0 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
om_1        | Download testuser/om@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
s3g_1       | ---- ----------------- --------------------------------------------------------
scm_1       | --2019-10-30 05:53:42--  http://kdc:8081/keytab/scm/testuser
kms_1       | --2019-10-30 05:53:41--  http://kdc:8081/keytab/c1df53cef837/testuser
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | Download testuser/5bae0ed04c34@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
recon_1     |    2 10/30/19 05:54:05 HTTP/recon@EXAMPLE.COM
datanode_2  | 
datanode_3  | 
om_1        | --2019-10-30 05:53:43--  http://kdc:8081/keytab/om/testuser
s3g_1       |    2 10/30/19 05:53:42 HTTP/s3g@EXAMPLE.COM
scm_1       | Resolving kdc (kdc)... 172.18.0.3
kms_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | --2019-10-30 05:53:41--  http://kdc:8081/keytab/5bae0ed04c34/testuser
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
recon_1     |    2 10/30/19 05:54:05 HTTP/recon@EXAMPLE.COM
datanode_2  |      0K                                                       100% 13.5M=0s
datanode_3  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
om_1        | Resolving kdc (kdc)... 172.18.0.3
s3g_1       |    2 10/30/19 05:53:42 HTTP/s3g@EXAMPLE.COM
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
recon_1     | Download testuser/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_2  | 
datanode_3  | KVNO Timestamp         Principal
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | Download testuser/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
scm_1       | HTTP request sent, awaiting response... 200 OK
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | --2019-10-30 05:54:05--  http://kdc:8081/keytab/recon/testuser
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_2  | 2019-10-30 05:53:42 (13.5 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
om_1        | HTTP request sent, awaiting response... 200 OK
s3g_1       | --2019-10-30 05:53:42--  http://kdc:8081/keytab/s3g/testuser
scm_1       | Length: 152 [application/octet-stream]
kms_1       | Length: 170 [application/octet-stream]
datanode_1  | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  |    2 10/30/19 05:53:43 testuser/f186250a45b8@EXAMPLE.COM
datanode_2  | 
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Resolving kdc (kdc)... 172.18.0.3
om_1        | Length: 150 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_1  | Length: 170 [application/octet-stream]
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
datanode_3  |    2 10/30/19 05:53:43 testuser/f186250a45b8@EXAMPLE.COM
datanode_2  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | Saving to: '/etc/security/keytabs/testuser.keytab'
scm_1       | 
kms_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_1  | Saving to: '/etc/security/keytabs/testuser.keytab'
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | Download testuser2/f186250a45b8@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_2  | KVNO Timestamp         Principal
recon_1     | HTTP request sent, awaiting response... 200 OK
om_1        | 
kms_1       | 
scm_1       |      0K                                                       100% 15.4M=0s
datanode_1  | 
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | --2019-10-30 05:53:43--  http://kdc:8081/keytab/f186250a45b8/testuser2
s3g_1       | HTTP request sent, awaiting response... 200 OK
datanode_2  | ---- ----------------- --------------------------------------------------------
s3g_1       | Length: 152 [application/octet-stream]
kms_1       |      0K                                                       100% 16.8M=0s
om_1        |      0K                                                       100% 14.9M=0s
scm_1       | 
datanode_1  |      0K                                                       100% 20.0M=0s
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, Principal or policy already exists, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
recon_1     | Length: 156 [application/octet-stream]
datanode_2  |    2 10/30/19 05:53:42 testuser/e68c2c815db9@EXAMPLE.COM
s3g_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
kms_1       | 
om_1        | 
scm_1       | 2019-10-30 05:53:43 (15.4 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
datanode_1  | 
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
recon_1     | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_2  |    2 10/30/19 05:53:42 testuser/e68c2c815db9@EXAMPLE.COM
s3g_1       | 
kms_1       | 2019-10-30 05:53:42 (16.8 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
om_1        | 2019-10-30 05:53:44 (14.9 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [150/150]
scm_1       | 
datanode_1  | 2019-10-30 05:53:42 (20.0 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | HTTP request sent, awaiting response... 200 OK
recon_1     | 
datanode_2  | Download testuser2/e68c2c815db9@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
s3g_1       |      0K                                                       100% 22.2M=0s
kms_1       | 
om_1        | 
datanode_1  | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | Length: 172 [application/octet-stream]
recon_1     |      0K                                                       100% 14.3M=0s
datanode_2  | --2019-10-30 05:53:42--  http://kdc:8081/keytab/e68c2c815db9/testuser2
s3g_1       | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
om_1        | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
datanode_1  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
scm_1       | KVNO Timestamp         Principal
datanode_3  | Saving to: '/etc/security/keytabs/testuser2.keytab'
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | 
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | 2019-10-30 05:53:43 (22.2 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
kms_1       | KVNO Timestamp         Principal
om_1        | KVNO Timestamp         Principal
datanode_1  | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
datanode_3  | 
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
recon_1     | 2019-10-30 05:54:05 (14.3 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [156/156]
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
s3g_1       | 
kms_1       | ---- ----------------- --------------------------------------------------------
om_1        | ---- ----------------- --------------------------------------------------------
datanode_1  | ---- ----------------- --------------------------------------------------------
scm_1       |    2 10/30/19 05:53:43 testuser/scm@EXAMPLE.COM
datanode_3  |      0K                                                       100% 24.7M=0s
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
recon_1     | 
datanode_2  | HTTP request sent, awaiting response... 200 OK
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
kms_1       |    2 10/30/19 05:53:42 testuser/c1df53cef837@EXAMPLE.COM
om_1        |    2 10/30/19 05:53:44 testuser/om@EXAMPLE.COM
datanode_1  |    2 10/30/19 05:53:42 testuser/5bae0ed04c34@EXAMPLE.COM
scm_1       |    2 10/30/19 05:53:43 testuser/scm@EXAMPLE.COM
datanode_3  | 
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
datanode_2  | Length: 172 [application/octet-stream]
s3g_1       | KVNO Timestamp         Principal
kms_1       |    2 10/30/19 05:53:42 testuser/c1df53cef837@EXAMPLE.COM
om_1        |    2 10/30/19 05:53:44 testuser/om@EXAMPLE.COM
datanode_1  |    2 10/30/19 05:53:42 testuser/5bae0ed04c34@EXAMPLE.COM
scm_1       | Download testuser2/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_3  | 2019-10-30 05:53:44 (24.7 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | KVNO Timestamp         Principal
datanode_2  | Saving to: '/etc/security/keytabs/testuser2.keytab'
s3g_1       | ---- ----------------- --------------------------------------------------------
kms_1       | Download testuser2/c1df53cef837@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
om_1        | Download testuser2/om@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_1  | Download testuser2/5bae0ed04c34@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       | --2019-10-30 05:53:43--  http://kdc:8081/keytab/scm/testuser2
datanode_3  | 
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_2  | 
s3g_1       |    2 10/30/19 05:53:43 testuser/s3g@EXAMPLE.COM
kms_1       | --2019-10-30 05:53:42--  http://kdc:8081/keytab/c1df53cef837/testuser2
om_1        | --2019-10-30 05:53:44--  http://kdc:8081/keytab/om/testuser2
datanode_1  | --2019-10-30 05:53:42--  http://kdc:8081/keytab/5bae0ed04c34/testuser2
datanode_3  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
scm_1       | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
recon_1     |    2 10/30/19 05:54:05 testuser/recon@EXAMPLE.COM
datanode_2  |      0K                                                       100% 24.7M=0s
s3g_1       |    2 10/30/19 05:53:43 testuser/s3g@EXAMPLE.COM
om_1        | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
datanode_3  | KVNO Timestamp         Principal
kms_1       | Resolving kdc (kdc)... 172.18.0.3
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     |    2 10/30/19 05:54:05 testuser/recon@EXAMPLE.COM
datanode_2  | 
s3g_1       | Download testuser2/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  | ---- ----------------- --------------------------------------------------------
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | Download testuser2/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_2  | 2019-10-30 05:53:43 (24.7 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
s3g_1       | --2019-10-30 05:53:43--  http://kdc:8081/keytab/s3g/testuser2
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_3  |    2 10/30/19 05:53:44 testuser2/f186250a45b8@EXAMPLE.COM
kms_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 154 [application/octet-stream]
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
recon_1     | --2019-10-30 05:54:05--  http://kdc:8081/keytab/recon/testuser2
datanode_2  | 
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
om_1        | Length: 152 [application/octet-stream]
datanode_1  | Length: 172 [application/octet-stream]
datanode_3  |    2 10/30/19 05:53:44 testuser2/f186250a45b8@EXAMPLE.COM
kms_1       | Length: 172 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
recon_1     | Resolving kdc (kdc)... 172.18.0.3
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_1  | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_3  | Download s3g/f186250a45b8@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kms_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
scm_1       | 
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | KVNO Timestamp         Principal
s3g_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | 
datanode_3  | --2019-10-30 05:53:44--  http://kdc:8081/keytab/f186250a45b8/s3g
kms_1       | 
datanode_1  | 
scm_1       |      0K                                                       100% 13.1M=0s
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | ---- ----------------- --------------------------------------------------------
recon_1     | HTTP request sent, awaiting response... 200 OK
om_1        |      0K                                                       100% 15.0M=0s
datanode_1  |      0K                                                       100% 22.2M=0s
scm_1       | 
s3g_1       | Length: 154 [application/octet-stream]
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
kms_1       |      0K                                                       100% 25.0M=0s
datanode_3  | Resolving kdc (kdc)... 172.18.0.3
datanode_2  |    2 10/30/19 05:53:43 testuser2/e68c2c815db9@EXAMPLE.COM
recon_1     | Length: 158 [application/octet-stream]
om_1        | 
datanode_1  | 
scm_1       | 2019-10-30 05:53:44 (13.1 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
kms_1       | 
datanode_3  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  |    2 10/30/19 05:53:43 testuser2/e68c2c815db9@EXAMPLE.COM
recon_1     | Saving to: '/etc/security/keytabs/testuser2.keytab'
om_1        | 2019-10-30 05:53:45 (15.0 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [152/152]
datanode_1  | 2019-10-30 05:53:43 (22.2 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
scm_1       | 
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 
kms_1       | 2019-10-30 05:53:44 (25.0 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
datanode_2  | Download s3g/e68c2c815db9@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_3  | HTTP request sent, awaiting response... 200 OK
recon_1     | 
om_1        | 
datanode_1  | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       |      0K                                                       100% 16.6M=0s
kms_1       | 
datanode_2  | --2019-10-30 05:53:43--  http://kdc:8081/keytab/e68c2c815db9/s3g
datanode_3  | Length: 160 [application/octet-stream]
recon_1     |      0K                                                       100% 18.8M=0s
om_1        | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_1  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
scm_1       | KVNO Timestamp         Principal
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_2  | Resolving kdc (kdc)... 172.18.0.3
datanode_3  | Saving to: '/etc/security/keytabs/s3g.keytab'
recon_1     | 
om_1        | KVNO Timestamp         Principal
datanode_1  | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 2019-10-30 05:53:44 (16.6 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
kms_1       | KVNO Timestamp         Principal
datanode_2  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_3  | 
recon_1     | 2019-10-30 05:54:05 (18.8 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [158/158]
om_1        | ---- ----------------- --------------------------------------------------------
datanode_1  | ---- ----------------- --------------------------------------------------------
scm_1       |    2 10/30/19 05:53:44 testuser2/scm@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_3  |      0K                                                       100% 13.6M=0s
recon_1     | 
om_1        |    2 10/30/19 05:53:45 testuser2/om@EXAMPLE.COM
datanode_1  |    2 10/30/19 05:53:43 testuser2/5bae0ed04c34@EXAMPLE.COM
scm_1       |    2 10/30/19 05:53:44 testuser2/scm@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
kms_1       |    2 10/30/19 05:53:44 testuser2/c1df53cef837@EXAMPLE.COM
datanode_2  | Length: 160 [application/octet-stream]
datanode_3  | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
om_1        |    2 10/30/19 05:53:45 testuser2/om@EXAMPLE.COM
scm_1       | Download s3g/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_1  |    2 10/30/19 05:53:43 testuser2/5bae0ed04c34@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
s3g_1       | KVNO Timestamp         Principal
kms_1       |    2 10/30/19 05:53:44 testuser2/c1df53cef837@EXAMPLE.COM
datanode_2  | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_3  | 2019-10-30 05:53:45 (13.6 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
recon_1     | KVNO Timestamp         Principal
om_1        | Download s3g/om@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
scm_1       | --2019-10-30 05:53:44--  http://kdc:8081/keytab/scm/s3g
datanode_1  | Download s3g/5bae0ed04c34@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | ---- ----------------- --------------------------------------------------------
kms_1       | Download s3g/c1df53cef837@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_2  | 
datanode_3  | 
recon_1     | ---- ----------------- --------------------------------------------------------
om_1        | --2019-10-30 05:53:45--  http://kdc:8081/keytab/om/s3g
scm_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_1  | --2019-10-30 05:53:43--  http://kdc:8081/keytab/5bae0ed04c34/s3g
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       |    2 10/30/19 05:53:44 testuser2/s3g@EXAMPLE.COM
kms_1       | --2019-10-30 05:53:44--  http://kdc:8081/keytab/c1df53cef837/s3g
datanode_2  |      0K                                                       100% 13.6M=0s
datanode_3  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
recon_1     |    2 10/30/19 05:54:05 testuser2/recon@EXAMPLE.COM
om_1        | Resolving kdc (kdc)... 172.18.0.3
scm_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_1  | Resolving kdc (kdc)... 172.18.0.3
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       |    2 10/30/19 05:53:44 testuser2/s3g@EXAMPLE.COM
kms_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | 
datanode_3  | KVNO Timestamp         Principal
recon_1     |    2 10/30/19 05:54:05 testuser2/recon@EXAMPLE.COM
om_1        | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
datanode_1  | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
kdc_1       | Entry for principal dn/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.c1df53cef837.keytab.
s3g_1       | Download s3g/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kms_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  | 2019-10-30 05:53:45 (13.6 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
datanode_3  | ---- ----------------- --------------------------------------------------------
recon_1     | Download s3g/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
om_1        | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 142 [application/octet-stream]
datanode_1  | HTTP request sent, awaiting response... 200 OK
kdc_1       | Entry for principal dn/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.c1df53cef837.keytab.
s3g_1       | --2019-10-30 05:53:44--  http://kdc:8081/keytab/s3g/s3g
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_2  | 
datanode_3  |    2 10/30/19 05:53:45 s3g/f186250a45b8@EXAMPLE.COM
recon_1     | --2019-10-30 05:54:05--  http://kdc:8081/keytab/recon/s3g
om_1        | Length: 140 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_1  | Length: 160 [application/octet-stream]
kdc_1       | Generiting keytab
kms_1       | Length: 160 [application/octet-stream]
s3g_1       | Resolving kdc (kdc)... 172.18.0.3
datanode_2  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_3  |    2 10/30/19 05:53:45 s3g/f186250a45b8@EXAMPLE.COM
recon_1     | Resolving kdc (kdc)... 172.18.0.3
om_1        | Saving to: '/etc/security/keytabs/s3g.keytab'
scm_1       | 
datanode_1  | Saving to: '/etc/security/keytabs/s3g.keytab'
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
s3g_1       | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
datanode_2  | KVNO Timestamp         Principal
datanode_3  | 2019-10-30 05:53:46,691 [main] INFO       - STARTUP_MSG: 
recon_1     | Connecting to kdc (kdc)|172.18.0.3|:8081... connected.
om_1        | 
scm_1       |      0K                                                       100% 15.8M=0s
datanode_1  | 
kdc_1       | WARNING: no policy specified for dn/f186250a45b8@EXAMPLE.COM; defaulting to no policy
kms_1       | 
s3g_1       | HTTP request sent, awaiting response... 200 OK
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_3  | /************************************************************
recon_1     | HTTP request sent, awaiting response... 200 OK
om_1        |      0K                                                       100% 1.69M=0s
scm_1       | 
datanode_1  |      0K                                                       100% 23.6M=0s
kdc_1       | Principal "dn/f186250a45b8@EXAMPLE.COM" created.
kms_1       |      0K                                                       100% 16.0M=0s
s3g_1       | Length: 142 [application/octet-stream]
datanode_2  |    2 10/30/19 05:53:45 s3g/e68c2c815db9@EXAMPLE.COM
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
om_1        | 
scm_1       | 2019-10-30 05:53:45 (15.8 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
datanode_1  | 
recon_1     | Length: 146 [application/octet-stream]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | 
datanode_2  |    2 10/30/19 05:53:45 s3g/e68c2c815db9@EXAMPLE.COM
datanode_3  | STARTUP_MSG:   host = f186250a45b8/172.18.0.10
s3g_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
om_1        | 2019-10-30 05:53:46 (1.69 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [140/140]
scm_1       | 
datanode_1  | 2019-10-30 05:53:44 (23.6 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
recon_1     | Saving to: '/etc/security/keytabs/s3g.keytab'
kdc_1       | Entry for principal dn/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.f186250a45b8.keytab.
kms_1       | 2019-10-30 05:53:45 (16.0 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
datanode_2  | 2019-10-30 05:53:46,067 [main] INFO       - STARTUP_MSG: 
datanode_3  | STARTUP_MSG:   args = []
s3g_1       | 
om_1        | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_1  | 
recon_1     | 
kms_1       | 
datanode_2  | /************************************************************
datanode_3  | STARTUP_MSG:   version = 3.2.0
kdc_1       | Entry for principal dn/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.f186250a45b8.keytab.
s3g_1       |      0K                                                       100% 17.5M=0s
om_1        | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
scm_1       | KVNO Timestamp         Principal
datanode_1  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
recon_1     |      0K                                                       100% 16.5M=0s
kms_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
kdc_1       | Generiting keytab
s3g_1       | 
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
om_1        | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
datanode_1  | KVNO Timestamp         Principal
recon_1     | 
kms_1       | KVNO Timestamp         Principal
datanode_2  | STARTUP_MSG:   host = e68c2c815db9/172.18.0.8
s3g_1       | 2019-10-30 05:53:46 (17.5 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | ---- ----------------- --------------------------------------------------------
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       |    2 10/30/19 05:53:45 s3g/scm@EXAMPLE.COM
datanode_1  | ---- ----------------- --------------------------------------------------------
recon_1     | 2019-10-30 05:54:05 (16.5 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [146/146]
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | STARTUP_MSG:   args = []
s3g_1       | 
kdc_1       | WARNING: no policy specified for dn/scm@EXAMPLE.COM; defaulting to no policy
om_1        |    2 10/30/19 05:53:46 s3g/om@EXAMPLE.COM
scm_1       |    2 10/30/19 05:53:45 s3g/scm@EXAMPLE.COM
datanode_3  | STARTUP_MSG:   java = 11.0.3
datanode_1  |    2 10/30/19 05:53:44 s3g/5bae0ed04c34@EXAMPLE.COM
recon_1     | 
kms_1       |    2 10/30/19 05:53:45 s3g/c1df53cef837@EXAMPLE.COM
datanode_2  | STARTUP_MSG:   version = 3.2.0
s3g_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kdc_1       | Principal "dn/scm@EXAMPLE.COM" created.
om_1        |    2 10/30/19 05:53:46 s3g/om@EXAMPLE.COM
scm_1       | 2019-10-30 05:53:47,114 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_3  | ************************************************************/
recon_1     | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kms_1       |    2 10/30/19 05:53:45 s3g/c1df53cef837@EXAMPLE.COM
datanode_1  |    2 10/30/19 05:53:44 s3g/5bae0ed04c34@EXAMPLE.COM
s3g_1       | KVNO Timestamp         Principal
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:53:47,579 [main] INFO       - STARTUP_MSG: 
datanode_3  | 2019-10-30 05:53:46,733 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
kms_1       | # Licensed to the Apache Software Foundation (ASF) under one or more
recon_1     | KVNO Timestamp         Principal
scm_1       | /************************************************************
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_1  | 2019-10-30 05:53:45,718 [main] INFO       - STARTUP_MSG: 
s3g_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Entry for principal dn/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.scm.keytab.
om_1        | /************************************************************
datanode_3  | 2019-10-30 05:53:47,067 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
kms_1       | # contributor license agreements.  See the NOTICE file distributed with
recon_1     | ---- ----------------- --------------------------------------------------------
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_1  | /************************************************************
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
s3g_1       |    2 10/30/19 05:53:45 s3g/s3g@EXAMPLE.COM
kdc_1       | Entry for principal dn/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.scm.keytab.
om_1        | STARTUP_MSG: Starting OzoneManager
kms_1       | # this work for additional information regarding copyright ownership.
datanode_3  | 2019-10-30 05:53:47,301 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     |    2 10/30/19 05:54:05 s3g/recon@EXAMPLE.COM
scm_1       | STARTUP_MSG:   host = scm/172.18.0.9
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   java = 11.0.3
s3g_1       |    2 10/30/19 05:53:45 s3g/s3g@EXAMPLE.COM
kdc_1       | Generiting keytab
om_1        | STARTUP_MSG:   host = om/172.18.0.5
kms_1       | # The ASF licenses this file to You under the Apache License, Version 2.0
datanode_3  | 2019-10-30 05:53:47,301 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
recon_1     |    2 10/30/19 05:54:05 s3g/recon@EXAMPLE.COM
scm_1       | STARTUP_MSG:   args = [--init]
datanode_1  | STARTUP_MSG:   host = 5bae0ed04c34/172.18.0.6
datanode_2  | ************************************************************/
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | WARNING: An illegal reflective access operation has occurred
om_1        | STARTUP_MSG:   args = [--init]
datanode_3  | 2019-10-30 05:53:47,531 [main] INFO       - HddsDatanodeService host:f186250a45b8 ip:172.18.0.10
recon_1     | WARNING: An illegal reflective access operation has occurred
scm_1       | STARTUP_MSG:   version = 3.2.0
datanode_2  | 2019-10-30 05:53:46,082 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | STARTUP_MSG:   args = []
kms_1       | # (the "License"); you may not use this file except in compliance with
kdc_1       | WARNING: no policy specified for om/5bae0ed04c34@EXAMPLE.COM; defaulting to no policy
s3g_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
om_1        | STARTUP_MSG:   version = 3.2.0
datanode_3  | 2019-10-30 05:53:47,924 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
datanode_2  | 2019-10-30 05:53:46,380 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | STARTUP_MSG:   version = 3.2.0
kdc_1       | Principal "om/5bae0ed04c34@EXAMPLE.COM" created.
kms_1       | # the License.  You may obtain a copy of the License at
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_2  | 2019-10-30 05:53:46,594 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | WARNING: An illegal reflective access operation has occurred
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | #
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  | 2019-10-30 05:53:46,594 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kdc_1       | Entry for principal om/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.5bae0ed04c34.keytab.
kms_1       | #     http://www.apache.org/licenses/LICENSE-2.0
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.3
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
s3g_1       | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2019-10-30 05:53:46,842 [main] INFO       - HddsDatanodeService host:e68c2c815db9 ip:172.18.0.8
datanode_3  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
kdc_1       | Entry for principal om/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.5bae0ed04c34.keytab.
recon_1     | WARNING: All illegal access operations will be denied in a future release
kms_1       | #
om_1        | STARTUP_MSG:   java = 11.0.3
scm_1       | ************************************************************/
datanode_1  | STARTUP_MSG:   java = 11.0.3
s3g_1       | 2019-10-30 05:53:47,633 INFO hdfs.DFSUtil: Starting web server as: HTTP/s3g@EXAMPLE.COM
datanode_2  | 2019-10-30 05:53:47,358 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_3  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kdc_1       | Generiting keytab
recon_1     | 2019-10-30 05:54:06,984 [main] INFO       - rest([/api/*]).packages(org.apache.hadoop.ozone.recon.api)
kms_1       | # Unless required by applicable law or agreed to in writing, software
om_1        | ************************************************************/
scm_1       | 2019-10-30 05:53:47,121 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | ************************************************************/
s3g_1       | 2019-10-30 05:53:47,634 INFO hdfs.DFSUtil: Starting Web-server for s3gateway at: http://0.0.0.0:9878
datanode_2  | WARNING: An illegal reflective access operation has occurred
datanode_3  | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | 2019-10-30 05:54:07,205 [main] INFO       - Initializing Recon server...
kms_1       | # distributed under the License is distributed on an "AS IS" BASIS,
om_1        | 2019-10-30 05:53:47,597 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2019-10-30 05:53:47,356 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-30 05:53:45,731 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
s3g_1       | 2019-10-30 05:53:47,672 INFO util.log: Logging initialized @1429ms
datanode_3  | 2019-10-30 05:53:48,236 INFO security.UserGroupInformation: Login successful for user dn/f186250a45b8@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
kdc_1       | WARNING: no policy specified for dn/s3g@EXAMPLE.COM; defaulting to no policy
recon_1     | 2019-10-30 05:54:07,369 [main] ERROR      - Error during initializing Recon server.
om_1        | 2019-10-30 05:53:48,823 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.5:9862
scm_1       | SCM initialization succeeded.Current cluster id for sd=/data/metadata/scm;cid=CID-58fde90c-9be9-4d66-b165-40c953096e71
datanode_1  | 2019-10-30 05:53:46,002 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
kms_1       | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
datanode_2  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
s3g_1       | 2019-10-30 05:53:47,815 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-10-30 05:53:48,236 [main] INFO       - Hdds Datanode login successful.
kdc_1       | Principal "dn/s3g@EXAMPLE.COM" created.
recon_1     | java.sql.SQLException: path to '//data/metadata/recon/ozone_recon_sqlite.db': '/data/metadata' does not exist
om_1        | 2019-10-30 05:53:48,823 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
scm_1       | 2019-10-30 05:53:47,436 INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_1  | 2019-10-30 05:53:46,160 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
kms_1       | # See the License for the specific language governing permissions and
datanode_2  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | 2019-10-30 05:53:47,843 INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
datanode_3  | 2019-10-30 05:53:48,244 [main] INFO       - Initializing secure Datanode.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | 	at org.sqlite.SQLiteConnection.open(SQLiteConnection.java:215)
om_1        | WARNING: An illegal reflective access operation has occurred
scm_1       | /************************************************************
datanode_1  | 2019-10-30 05:53:46,161 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
kms_1       | # limitations under the License.
datanode_2  | WARNING: All illegal access operations will be denied in a future release
s3g_1       | 2019-10-30 05:53:47,856 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2019-10-30 05:53:48,245 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
kdc_1       | Entry for principal dn/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.s3g.keytab.
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.9
datanode_1  | 2019-10-30 05:53:46,386 [main] INFO       - HddsDatanodeService host:5bae0ed04c34 ip:172.18.0.6
kms_1       | 
datanode_2  | 2019-10-30 05:53:47,582 INFO security.UserGroupInformation: Login successful for user dn/e68c2c815db9@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
recon_1     | 	at org.sqlite.SQLiteConnection.<init>(SQLiteConnection.java:61)
datanode_3  | 2019-10-30 05:53:48,245 INFO client.DNCertificateClient: Certificate client init case: 0
kdc_1       | Entry for principal dn/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.s3g.keytab.
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
s3g_1       | 2019-10-30 05:53:47,859 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
datanode_1  | 2019-10-30 05:53:46,809 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
scm_1       | ************************************************************/
kms_1       | [logging]
datanode_2  | 2019-10-30 05:53:47,582 [main] INFO       - Hdds Datanode login successful.
recon_1     | 	at org.sqlite.jdbc3.JDBC3Connection.<init>(JDBC3Connection.java:28)
datanode_3  | 2019-10-30 05:53:48,247 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
kdc_1       | Generiting keytab
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_1  | WARNING: An illegal reflective access operation has occurred
scm_1       | 2019-10-30 05:53:48,687 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
kms_1       |  default = FILE:/var/log/krb5libs.log
datanode_2  | 2019-10-30 05:53:47,582 [main] INFO       - Initializing secure Datanode.
recon_1     | 	at org.sqlite.jdbc4.JDBC4Connection.<init>(JDBC4Connection.java:21)
datanode_3  | 2019-10-30 05:53:48,791 [main] INFO       - Init response: GETCERT
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | WARNING: All illegal access operations will be denied in a future release
scm_1       | /************************************************************
datanode_1  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
kms_1       |  kdc = FILE:/var/log/krb5kdc.log
s3g_1       | 2019-10-30 05:53:47,860 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_2  | 2019-10-30 05:53:47,583 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1     | 	at org.sqlite.JDBC.createConnection(JDBC.java:116)
datanode_3  | 2019-10-30 05:53:48,802 [main] INFO       - Adding ip:172.18.0.10,host:f186250a45b8
kdc_1       | WARNING: no policy specified for om/e68c2c815db9@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:53:49,123 INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_1  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
kms_1       |  admin_server = FILE:/var/log/kadmind.log
s3g_1       | 2019-10-30 05:53:47,860 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2019-10-30 05:53:47,583 INFO client.DNCertificateClient: Certificate client init case: 0
recon_1     | 	at org.sqlite.SQLiteDataSource.getConnection(SQLiteDataSource.java:410)
datanode_3  | 2019-10-30 05:53:48,803 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
kdc_1       | Principal "om/e68c2c815db9@EXAMPLE.COM" created.
om_1        | 2019-10-30 05:53:49,124 [main] INFO       - Ozone Manager login successful.
scm_1       | STARTUP_MSG:   host = scm/172.18.0.9
datanode_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kms_1       | 
s3g_1       | 2019-10-30 05:53:47,882 [main] INFO       - Starting Ozone S3 gateway
datanode_2  | 2019-10-30 05:53:47,593 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1     | 	at org.sqlite.SQLiteDataSource.getConnection(SQLiteDataSource.java:398)
datanode_3  | 2019-10-30 05:53:48,808 [main] INFO       - Creating csr for DN-> subject:root@f186250a45b8
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:53:49,129 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | STARTUP_MSG:   args = []
datanode_1  | WARNING: All illegal access operations will be denied in a future release
kms_1       | [libdefaults]
s3g_1       | 2019-10-30 05:53:47,896 INFO http.HttpServer2: Jetty bound to port 9878
datanode_2  | 2019-10-30 05:53:48,175 [main] INFO       - Init response: GETCERT
recon_1     | 	at org.hadoop.ozone.recon.schema.StatsSchemaDefinition.initializeSchema(StatsSchemaDefinition.java:44)
datanode_3  | 2019-10-30 05:53:50,025 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Entry for principal om/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.e68c2c815db9.keytab.
om_1        | 2019-10-30 05:53:50,295 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1       | STARTUP_MSG:   version = 3.2.0
datanode_1  | 2019-10-30 05:53:47,102 INFO security.UserGroupInformation: Login successful for user dn/5bae0ed04c34@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
kms_1       |  dns_canonicalize_hostname = false
s3g_1       | 2019-10-30 05:53:47,897 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2  | 2019-10-30 05:53:48,189 [main] INFO       - Adding ip:172.18.0.8,host:e68c2c815db9
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:78)
datanode_3  | 2019-10-30 05:53:51,026 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Entry for principal om/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.e68c2c815db9.keytab.
om_1        | 2019-10-30 05:53:51,296 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-30 05:53:47,102 [main] INFO       - Hdds Datanode login successful.
kms_1       |  dns_lookup_realm = false
s3g_1       | 2019-10-30 05:53:47,935 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
datanode_2  | 2019-10-30 05:53:48,190 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:41)
datanode_3  | 2019-10-30 05:53:52,973 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
kdc_1       | Generiting keytab
om_1        | 2019-10-30 05:53:52,297 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-10-30 05:53:47,103 [main] INFO       - Initializing secure Datanode.
kms_1       |  ticket_lifetime = 24h
s3g_1       | 2019-10-30 05:53:47,947 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2  | 2019-10-30 05:53:48,200 [main] INFO       - Creating csr for DN-> subject:root@e68c2c815db9
recon_1     | 	at picocli.CommandLine.execute(CommandLine.java:1173)
datanode_3  | 2019-10-30 05:53:53,166 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:53:52,833 [main] INFO       - Initializing secure OzoneManager.
datanode_1  | 2019-10-30 05:53:47,104 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
kms_1       |  renew_lifetime = 7d
s3g_1       | 2019-10-30 05:53:48,000 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68878f6d{/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | STARTUP_MSG:   java = 11.0.3
datanode_2  | 2019-10-30 05:53:49,452 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
recon_1     | 	at picocli.CommandLine.access$800(CommandLine.java:141)
kdc_1       | WARNING: no policy specified for om/c1df53cef837@EXAMPLE.COM; defaulting to no policy
datanode_3  | 2019-10-30 05:53:53,168 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
om_1        | 2019-10-30 05:53:53,203 ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_1  | 2019-10-30 05:53:47,104 INFO client.DNCertificateClient: Certificate client init case: 0
kms_1       |  forwardable = true
s3g_1       | 2019-10-30 05:53:48,001 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@78fa769e{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | ************************************************************/
datanode_2  | 2019-10-30 05:53:50,453 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367)
kdc_1       | Principal "om/c1df53cef837@EXAMPLE.COM" created.
datanode_3  | 2019-10-30 05:53:53,178 [main] INFO       - Scheduling a check for /data/hdds/hdds
om_1        | 2019-10-30 05:53:53,204 INFO client.OMCertificateClient: Certificate client init case: 0
datanode_1  | 2019-10-30 05:53:47,106 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
kms_1       |  rdns = false
scm_1       | 2019-10-30 05:53:48,695 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
datanode_2  | 2019-10-30 05:53:51,454 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335)
datanode_3  | 2019-10-30 05:53:53,211 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
om_1        | 2019-10-30 05:53:53,204 INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_1  | 2019-10-30 05:53:47,685 [main] INFO       - Init response: GETCERT
kms_1       |  default_realm = EXAMPLE.COM
scm_1       | 2019-10-30 05:53:48,959 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 2019-10-30 05:53:49,953 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
datanode_2  | 2019-10-30 05:53:53,130 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
recon_1     | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243)
datanode_3  | 2019-10-30 05:53:53,660 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2019-10-30 05:53:47,704 [main] INFO       - Adding ip:172.18.0.6,host:5bae0ed04c34
om_1        | 2019-10-30 05:53:53,567 [main] INFO       - Init response: GETCERT
kms_1       | 
scm_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | Oct 30, 2019 5:53:50 AM org.glassfish.jersey.internal.Errors logErrors
datanode_2  | 2019-10-30 05:53:53,202 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
recon_1     | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526)
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:53,686 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2019-10-30 05:53:47,705 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
om_1        | 2019-10-30 05:53:53,592 [main] INFO       - Adding ip:172.18.0.5,host:om
kms_1       | [realms]
scm_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
datanode_2  | 2019-10-30 05:53:53,204 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
recon_1     | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465)
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-30 05:53:53,745 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2019-10-30 05:53:47,712 [main] INFO       - Creating csr for DN-> subject:root@5bae0ed04c34
om_1        | 2019-10-30 05:53:53,595 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
kms_1       |  EXAMPLE.COM = {
scm_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_2  | 2019-10-30 05:53:53,212 [main] INFO       - Scheduling a check for /data/hdds/hdds
s3g_1       | 
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65)
kdc_1       | Oct 30 05:53:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414817, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:53,746 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_1  | 2019-10-30 05:53:48,978 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-30 05:53:53,601 [main] INFO       - Creating csr for OM->dns:om,ip:172.18.0.5,scmId:e3f71745-98f7-461f-bfb4-4a9202f57bef,clusterId:CID-58fde90c-9be9-4d66-b165-40c953096e71,subject:root@om
scm_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kms_1       |   kdc = kdc
datanode_2  | 2019-10-30 05:53:53,241 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
s3g_1       | 2019-10-30 05:53:50,698 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@515b9d4a{/,file:///tmp/jetty-0.0.0.0-9878-s3gateway-_-any-5511577840894448829.dir/webapp/,AVAILABLE}{/s3gateway}
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56)
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-30 05:53:53,748 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-10-30 05:53:49,980 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | 2019-10-30 05:53:53,711 [main] INFO       - OzoneManager ports added:[name: "RPC"
scm_1       | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2019-10-30 05:53:53,715 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
s3g_1       | 2019-10-30 05:53:50,704 INFO server.AbstractConnector: Started ServerConnector@594131f2{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
kms_1       |   admin_server = kdc
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:52)
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:53,749 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_1  | 2019-10-30 05:53:50,982 INFO ipc.Client: Retrying connect to server: scm/172.18.0.9:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1        | value: 9862
scm_1       | 2019-10-30 05:53:49,210 INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
datanode_2  | 2019-10-30 05:53:53,740 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
s3g_1       | 2019-10-30 05:53:50,705 INFO server.Server: Started @4465ms
kms_1       |  }
recon_1     | 2019-10-30 05:54:07,371 [main] INFO       - Stopping Recon server
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-30 05:53:53,750 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2019-10-30 05:53:52,990 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
om_1        | ]
scm_1       | 2019-10-30 05:53:49,211 INFO server.StorageContainerManager: SCM login successful.
datanode_2  | 2019-10-30 05:53:53,800 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
s3g_1       | 2019-10-30 05:53:50,707 INFO server.BaseHttpServer: HTTP server of S3GATEWAY is listening at http://0.0.0.0:9878
kms_1       | 
recon_1     | java.lang.NullPointerException
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:53,881 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2019-10-30 05:53:53,174 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
om_1        | 2019-10-30 05:53:53,780 [main] INFO       - Successfully stored SCM signed certificate.
scm_1       | 2019-10-30 05:53:49,212 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2019-10-30 05:53:53,801 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
s3g_1       | 2019-10-30 06:00:23,315 [qtp359368949-110] INFO       - Location is /bucket-test123
kms_1       | [domain_realm]
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.stop(ReconServer.java:115)
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-30 05:53:53,947 INFO hdfs.DFSUtil: Starting web server as: HTTP/f186250a45b8@EXAMPLE.COM
datanode_1  | 2019-10-30 05:53:53,187 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-58fde90c-9be9-4d66-b165-40c953096e71
scm_1       | 2019-10-30 05:53:49,238 INFO util.log: Logging initialized @1583ms
datanode_2  | 2019-10-30 05:53:53,803 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kms_1       |  .example.com = EXAMPLE.COM
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:100)
s3g_1       | 2019-10-30 06:00:26,569 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:53,947 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2019-10-30 05:53:53,195 [main] INFO       - Scheduling a check for /data/hdds/hdds
om_1        | 2019-10-30 05:53:53,820 [shutdown-hook-0] INFO       - SHUTDOWN_MSG: 
scm_1       | 2019-10-30 05:53:49,342 INFO db.DBStoreBuilder: using custom profile for table: deletedBlocks
datanode_2  | 2019-10-30 05:53:53,804 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:41)
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
s3g_1       | 20191030T060026Z
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-30 05:53:53,967 INFO util.log: Logging initialized @8145ms
datanode_1  | 2019-10-30 05:53:53,217 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
om_1        | /************************************************************
scm_1       | 2019-10-30 05:53:49,342 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedBlocks
datanode_2  | 2019-10-30 05:53:53,804 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
recon_1     | 	at picocli.CommandLine.execute(CommandLine.java:1173)
kms_1       | WARNING: /opt/hadoop/logs does not exist. Creating.
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:54,050 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2019-10-30 05:53:53,693 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.18.0.5
scm_1       | 2019-10-30 05:53:49,342 INFO db.DBStoreBuilder: using custom profile for table: validCerts
datanode_2  | 2019-10-30 05:53:53,926 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
recon_1     | 	at picocli.CommandLine.access$800(CommandLine.java:141)
kms_1       | Oct 30, 2019 5:53:47 AM com.sun.jersey.api.core.PackagesResourceConfig init
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-10-30 05:53:54,052 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2019-10-30 05:53:53,718 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om_1        | ************************************************************/
scm_1       | 2019-10-30 05:53:49,343 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:validCerts
datanode_2  | 2019-10-30 05:53:53,992 INFO hdfs.DFSUtil: Starting web server as: HTTP/e68c2c815db9@EXAMPLE.COM
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367)
kms_1       | INFO: Scanning for root resource and provider classes in the packages:
s3g_1       | 2019-10-30 06:00:26,582 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:54,058 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2019-10-30 05:53:53,785 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
om_1        | 2019-10-30 05:53:54,820 [main] INFO       - STARTUP_MSG: 
scm_1       | 2019-10-30 05:53:49,343 INFO db.DBStoreBuilder: using custom profile for table: revokedCerts
datanode_2  | 2019-10-30 05:53:53,993 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335)
kms_1       |   org.apache.hadoop.crypto.key.kms.server
s3g_1       | 20191030T060026Z
datanode_3  | 2019-10-30 05:53:54,060 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_1  | 2019-10-30 05:53:53,786 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
om_1        | /************************************************************
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:53:49,343 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:revokedCerts
datanode_2  | 2019-10-30 05:53:54,015 INFO util.log: Logging initialized @8687ms
recon_1     | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243)
kms_1       | Oct 30, 2019 5:53:47 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_3  | 2019-10-30 05:53:54,060 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | 2019-10-30 05:53:53,788 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | STARTUP_MSG: Starting OzoneManager
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:53:49,352 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_2  | 2019-10-30 05:53:54,106 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1     | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526)
kms_1       | INFO: Root resource classes found:
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
datanode_1  | 2019-10-30 05:53:53,789 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1        | STARTUP_MSG:   host = om/172.18.0.5
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:53:49,352 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_2  | 2019-10-30 05:53:54,108 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
recon_1     | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465)
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMS
s3g_1       | 2019-10-30 06:00:26,583 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-10-30 05:53:54,060 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1        | STARTUP_MSG:   args = []
datanode_1  | 2019-10-30 05:53:53,789 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-30 05:53:49,353 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_2  | 2019-10-30 05:53:54,115 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65)
kms_1       | Oct 30, 2019 5:53:47 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
datanode_3  | 2019-10-30 05:53:54,080 INFO http.HttpServer2: Jetty bound to port 9882
s3g_1       | 20191030T060026Z
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | STARTUP_MSG:   version = 3.2.0
datanode_1  | 2019-10-30 05:53:53,923 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2019-10-30 05:53:50,663 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_2  | 2019-10-30 05:53:54,116 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56)
kms_1       | INFO: Provider classes found:
datanode_3  | 2019-10-30 05:53:54,081 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-30 05:53:53,999 INFO hdfs.DFSUtil: Starting web server as: HTTP/5bae0ed04c34@EXAMPLE.COM
scm_1       | 2019-10-30 05:53:50,686 INFO ipc.Server: Starting Socket Reader #1 for port 9961
datanode_2  | 2019-10-30 05:53:54,116 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:52)
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/metrics-ganglia-3.2.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/gmetric4j-1.0.7.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-3f446aa-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/metrics-jvm-3.2.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
datanode_3  | 2019-10-30 05:53:54,110 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-30 05:53:54,000 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1       | 2019-10-30 05:53:50,763 INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@6ad6fa53
datanode_2  | 2019-10-30 05:53:54,116 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3  | 2019-10-30 05:53:54,111 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/f186250a45b8@EXAMPLE.COM
s3g_1       | 2019-10-30 06:00:26,588 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-30 05:53:54,031 INFO util.log: Logging initialized @9098ms
scm_1       | 2019-10-30 05:53:50,764 INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_2  | 2019-10-30 05:53:54,136 INFO http.HttpServer2: Jetty bound to port 9882
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
om_1        | STARTUP_MSG:   java = 11.0.3
datanode_3  | 2019-10-30 05:53:54,114 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f9ab79d{/logs,file:///var/log/hadoop/,AVAILABLE}
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-30 05:53:54,113 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2019-10-30 05:53:50,831 INFO node.SCMNodeManager: Entering startup safe mode.
s3g_1       | 20191030T060026Z
datanode_2  | 2019-10-30 05:53:54,137 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
kms_1       | Oct 30, 2019 5:53:47 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
om_1        | ************************************************************/
datanode_3  | 2019-10-30 05:53:54,115 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@ea00de{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2019-10-30 05:53:54,115 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:53:50,942 INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_2  | 2019-10-30 05:53:54,165 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
kms_1       | INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
om_1        | 2019-10-30 05:53:54,830 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2019-10-30 05:53:54,174 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/f186250a45b8@EXAMPLE.COM
datanode_1  | 2019-10-30 05:53:54,122 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
scm_1       | 2019-10-30 05:53:50,958 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
datanode_2  | 2019-10-30 05:53:54,166 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/e68c2c815db9@EXAMPLE.COM
om_1        | 2019-10-30 05:53:55,662 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.5:9862
datanode_3  | 2019-10-30 05:53:54,179 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@592ca48c{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-7647655083074585989.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_1  | 2019-10-30 05:53:54,123 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
kdc_1       | Oct 30 05:53:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414818, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:53:51,391 INFO pipeline.SCMPipelineManager: No pipeline exists in current db
s3g_1       | 2019-10-30 06:00:26,588 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-30 05:53:54,169 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64ae105d{/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2019-10-30 05:53:55,663 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
datanode_3  | 2019-10-30 05:53:54,183 INFO server.AbstractConnector: Started ServerConnector@644a3add{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2019-10-30 05:53:54,123 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:53:51,393 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 20191030T060026Z
om_1        | 2019-10-30 05:53:55,668 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3  | 2019-10-30 05:53:54,183 INFO server.Server: Started @8361ms
datanode_1  | 2019-10-30 05:53:54,123 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:53:51,521 WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_2  | 2019-10-30 05:53:54,169 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@23ca36d{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | WARNING: An illegal reflective access operation has occurred
datanode_3  | 2019-10-30 05:53:54,187 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2019-10-30 05:53:54,144 INFO http.HttpServer2: Jetty bound to port 9882
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:53:51,866 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
datanode_2  | 2019-10-30 05:53:54,229 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/e68c2c815db9@EXAMPLE.COM
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
datanode_3  | 2019-10-30 05:53:54,187 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2019-10-30 05:53:54,145 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:53:51,867 INFO ipc.Server: Starting Socket Reader #1 for port 9861
s3g_1       | 2019-10-30 06:00:26,593 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-30 05:53:54,235 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5fed9976{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-9176341855640993293.dir/webapp/,AVAILABLE}{/hddsDatanode}
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_3  | 2019-10-30 05:53:54,189 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_1  | 2019-10-30 05:53:54,171 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:53:51,897 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | 20191030T060026Z
datanode_2  | 2019-10-30 05:53:54,242 INFO server.AbstractConnector: Started ServerConnector@4b765e92{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3  | 2019-10-30 05:53:54,204 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2019-10-30 05:53:54,173 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/5bae0ed04c34@EXAMPLE.COM
kdc_1       | Oct 30 05:53:37 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:53:51,898 INFO ipc.Server: Starting Socket Reader #1 for port 9863
datanode_3  | 2019-10-30 05:53:56,323 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
datanode_2  | 2019-10-30 05:53:54,242 INFO server.Server: Started @8914ms
om_1        | WARNING: All illegal access operations will be denied in a future release
datanode_1  | 2019-10-30 05:53:54,176 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@53aa2fc9{/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 20191030/us-west-1/s3/aws4_request
scm_1       | 2019-10-30 05:53:51,926 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3  | 2019-10-30 05:53:56,328 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-30 05:53:54,245 INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2019-10-30 05:53:55,913 INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
datanode_1  | 2019-10-30 05:53:54,177 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2b80e5a9{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-30 05:53:51,927 INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode_3  | 2019-10-30 05:53:56,328 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis f9b41af1-38ba-4dbb-b621-6fd57c378fab at port 9858
datanode_2  | 2019-10-30 05:53:54,245 INFO impl.MetricsSystemImpl: Registered sink prometheus
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:55,914 [main] INFO       - Ozone Manager login successful.
datanode_1  | 2019-10-30 05:53:54,256 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/5bae0ed04c34@EXAMPLE.COM
s3g_1       | 2019-10-30 06:00:26,593 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-30 05:53:51,966 INFO hdfs.DFSUtil: Starting web server as: HTTP/scm@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:56,347 INFO impl.RaftServerProxy: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start RPC server
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
datanode_2  | 2019-10-30 05:53:54,248 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
om_1        | 2019-10-30 05:53:55,914 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2019-10-30 05:53:54,266 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7302ff13{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-16511209097428468034.dir/webapp/,AVAILABLE}{/hddsDatanode}
s3g_1       | 20191030T060026Z
scm_1       | 2019-10-30 05:53:51,967 INFO hdfs.DFSUtil: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_3  | 2019-10-30 05:53:56,538 INFO server.GrpcService: f9b41af1-38ba-4dbb-b621-6fd57c378fab: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-30 05:53:54,314 INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2019-10-30 05:53:56,821 INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
datanode_1  | 2019-10-30 05:53:54,274 INFO server.AbstractConnector: Started ServerConnector@7fd99443{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
s3g_1       | 20191030/us-west-1/s3/aws4_request
scm_1       | 2019-10-30 05:53:52,074 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-30 05:53:56,411 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
om_1        | 2019-10-30 05:53:56,930 INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
datanode_1  | 2019-10-30 05:53:54,276 INFO server.Server: Started @9341ms
scm_1       | 2019-10-30 05:53:52,094 INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
datanode_3  | 2019-10-30 05:53:59,005 INFO impl.RaftServerProxy: f9b41af1-38ba-4dbb-b621-6fd57c378fab: addNew group-B5B4A47A99FC:[f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858] returns group-B5B4A47A99FC:java.util.concurrent.CompletableFuture@3fe48e4c[Not completed]
s3g_1       | 2019-10-30 06:00:26,598 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-30 05:53:56,416 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
om_1        | 2019-10-30 05:53:56,934 INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/12761625003271338.crt.
scm_1       | 2019-10-30 05:53:52,105 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2019-10-30 05:53:54,283 INFO impl.MetricsSinkAdapter: Sink prometheus started
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-30 05:53:59,019 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab: new RaftServerImpl for group-B5B4A47A99FC:[f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858] with ContainerStateMachine:uninitialized
s3g_1       | 20191030T060026Z
datanode_2  | 2019-10-30 05:53:56,417 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis f337c68d-5e1e-4f64-a71f-9d640f38d7aa at port 9858
om_1        | 2019-10-30 05:53:56,956 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2019-10-30 05:53:52,108 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
datanode_1  | 2019-10-30 05:53:54,283 INFO impl.MetricsSystemImpl: Registered sink prometheus
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
datanode_3  | 2019-10-30 05:53:59,021 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 05:53:56,986 INFO util.log: Logging initialized @2970ms
datanode_2  | 2019-10-30 05:53:56,441 INFO impl.RaftServerProxy: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start RPC server
datanode_1  | 2019-10-30 05:53:54,285 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
scm_1       | 2019-10-30 05:53:52,108 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_3  | 2019-10-30 05:53:59,021 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 05:53:57,075 INFO db.DBStoreBuilder: using custom profile for table: userTable
datanode_2  | 2019-10-30 05:53:56,608 INFO server.GrpcService: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
scm_1       | 2019-10-30 05:53:52,108 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-30 05:53:59,021 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
s3g_1       | 2019-10-30 06:00:26,599 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 05:53:57,075 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:userTable
datanode_1  | 2019-10-30 05:53:54,306 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2019-10-30 05:53:59,955 INFO impl.RaftServerProxy: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: addNew group-EA2EF99355B1:[f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858] returns group-EA2EF99355B1:java.util.concurrent.CompletableFuture@64102ba7[Not completed]
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:53:52,140 INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
datanode_3  | 2019-10-30 05:53:59,022 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
s3g_1       | 20191030T060026Z
om_1        | 2019-10-30 05:53:57,075 INFO db.DBStoreBuilder: using custom profile for table: volumeTable
datanode_1  | 2019-10-30 05:53:56,389 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
datanode_2  | 2019-10-30 05:53:59,977 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: new RaftServerImpl for group-EA2EF99355B1:[f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858] with ContainerStateMachine:uninitialized
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:53:52,207 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2019-10-30 05:53:59,022 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 05:53:57,075 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:volumeTable
datanode_1  | 2019-10-30 05:53:56,391 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
datanode_2  | 2019-10-30 05:53:59,978 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2019-10-30 05:53:56,392 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 0981213a-f8fa-4d9a-98e4-9d489458d959 at port 9858
scm_1       | 2019-10-30 05:53:52,245 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2019-10-30 05:53:59,029 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC: ConfigurationManager, init=-1: [f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null, confs=<EMPTY_MAP>
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 05:53:57,075 INFO db.DBStoreBuilder: using custom profile for table: bucketTable
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-30 05:53:59,979 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2019-10-30 05:53:56,408 INFO impl.RaftServerProxy: 0981213a-f8fa-4d9a-98e4-9d489458d959: start RPC server
scm_1       | 2019-10-30 05:53:52,245 INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
datanode_3  | 2019-10-30 05:53:59,029 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
s3g_1       | 2019-10-30 06:00:26,605 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 05:53:57,075 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:bucketTable
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-30 05:53:59,979 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1  | 2019-10-30 05:53:56,580 INFO server.GrpcService: 0981213a-f8fa-4d9a-98e4-9d489458d959: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
scm_1       | 2019-10-30 05:53:52,440 INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
datanode_3  | 2019-10-30 05:53:59,033 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1       | 20191030T060026Z
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:57,075 INFO db.DBStoreBuilder: using custom profile for table: keyTable
datanode_2  | 2019-10-30 05:53:59,979 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2019-10-30 05:53:59,500 INFO impl.RaftServerProxy: 0981213a-f8fa-4d9a-98e4-9d489458d959: addNew group-59F8A1BA03C4:[0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858] returns group-59F8A1BA03C4:java.util.concurrent.CompletableFuture@1bcd82af[Not completed]
scm_1       | 2019-10-30 05:53:52,441 INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2019-10-30 05:53:59,035 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/79938f87-2048-45ab-bc9f-b5b4a47a99fc does not exist. Creating ...
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-30 05:53:57,075 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:keyTable
datanode_2  | 2019-10-30 05:53:59,980 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-30 05:53:59,513 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959: new RaftServerImpl for group-59F8A1BA03C4:[0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2019-10-30 05:53:59,052 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/79938f87-2048-45ab-bc9f-b5b4a47a99fc/in_use.lock acquired by nodename 7@f186250a45b8
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-30 05:53:52,441 INFO ipc.Server: IPC Server listener on 9860: starting
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-30 05:53:57,076 INFO db.DBStoreBuilder: using custom profile for table: deletedTable
datanode_2  | 2019-10-30 05:53:59,985 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1: ConfigurationManager, init=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-10-30 05:53:59,067 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/79938f87-2048-45ab-bc9f-b5b4a47a99fc has been successfully formatted.
datanode_1  | 2019-10-30 05:53:59,514 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
s3g_1       | 2019-10-30 06:00:26,606 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-30 05:53:52,444 INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:57,076 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedTable
datanode_2  | 2019-10-30 05:53:59,986 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-30 05:53:59,070 [pool-9-thread-1] INFO       - group-B5B4A47A99FC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2019-10-30 05:53:59,515 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
s3g_1       | 20191030T060026Z
scm_1       | 2019-10-30 05:53:52,444 INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:57,076 INFO db.DBStoreBuilder: using custom profile for table: openKeyTable
datanode_2  | 2019-10-30 05:53:59,989 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2019-10-30 05:53:59,071 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 2019-10-30 05:53:59,515 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
scm_1       | 2019-10-30 05:53:52,445 INFO ipc.Server: IPC Server Responder: starting
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 05:53:57,076 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:openKeyTable
datanode_2  | 2019-10-30 05:53:59,991 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/033f6654-f9a4-43b6-92a5-ea2ef99355b1 does not exist. Creating ...
datanode_1  | 2019-10-30 05:53:59,515 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2019-10-30 05:53:59,073 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2019-10-30 05:53:52,445 INFO ipc.Server: IPC Server listener on 9863: starting
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 05:53:57,076 INFO db.DBStoreBuilder: using custom profile for table: s3Table
datanode_2  | 2019-10-30 05:54:00,015 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/033f6654-f9a4-43b6-92a5-ea2ef99355b1/in_use.lock acquired by nodename 7@e68c2c815db9
datanode_1  | 2019-10-30 05:53:59,516 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-30 05:53:59,077 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2019-10-30 05:53:52,448 INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-30 06:00:26,611 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 05:53:57,076 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3Table
datanode_2  | 2019-10-30 05:54:00,031 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/033f6654-f9a4-43b6-92a5-ea2ef99355b1 has been successfully formatted.
datanode_1  | 2019-10-30 05:53:59,523 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4: ConfigurationManager, init=-1: [0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-10-30 05:53:59,077 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-30 05:53:52,448 INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191030T060026Z
datanode_2  | 2019-10-30 05:54:00,034 [pool-9-thread-1] INFO       - group-EA2EF99355B1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2019-10-30 05:53:59,523 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-30 05:53:59,079 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        | 2019-10-30 05:53:57,076 INFO db.DBStoreBuilder: using custom profile for table: multipartInfoTable
scm_1       | 2019-10-30 05:53:52,449 INFO ipc.Server: IPC Server Responder: starting
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_2  | 2019-10-30 05:54:00,034 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_3  | 2019-10-30 05:53:59,081 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
om_1        | 2019-10-30 05:53:57,076 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:multipartInfoTable
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:53:52,449 INFO ipc.Server: IPC Server listener on 9861: starting
datanode_1  | 2019-10-30 05:53:59,528 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
datanode_2  | 2019-10-30 05:54:00,036 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2019-10-30 05:53:59,088 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:57,077 INFO db.DBStoreBuilder: using custom profile for table: dTokenTable
datanode_1  | 2019-10-30 05:53:59,530 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/913fa248-279a-4ff6-8f0b-59f8a1ba03c4 does not exist. Creating ...
scm_1       | 2019-10-30 05:53:52,451 INFO server.SCMClientProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
s3g_1       | 2019-10-30 06:00:26,612 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-30 05:54:00,040 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2019-10-30 05:53:59,126 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:57,077 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:dTokenTable
datanode_1  | 2019-10-30 05:53:59,555 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/913fa248-279a-4ff6-8f0b-59f8a1ba03c4/in_use.lock acquired by nodename 7@5bae0ed04c34
s3g_1       | 20191030T060026Z
datanode_2  | 2019-10-30 05:54:00,040 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-30 05:53:52,452 INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2019-10-30 05:53:59,131 INFO segmented.SegmentedRaftLogWorker: new f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/79938f87-2048-45ab-bc9f-b5b4a47a99fc
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-30 05:53:57,077 INFO db.DBStoreBuilder: using custom profile for table: s3SecretTable
datanode_1  | 2019-10-30 05:53:59,582 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/913fa248-279a-4ff6-8f0b-59f8a1ba03c4 has been successfully formatted.
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_2  | 2019-10-30 05:54:00,042 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-30 05:53:52,452 INFO ipc.Server: IPC Server listener on 9961: starting
datanode_3  | 2019-10-30 05:53:59,131 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-30 05:53:57,077 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3SecretTable
datanode_1  | 2019-10-30 05:53:59,585 [pool-9-thread-1] INFO       - group-59F8A1BA03C4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
datanode_2  | 2019-10-30 05:54:00,044 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
scm_1       | 2019-10-30 05:53:52,456 INFO http.HttpServer2: Jetty bound to port 9876
datanode_3  | 2019-10-30 05:53:59,131 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:57,077 INFO db.DBStoreBuilder: using custom profile for table: prefixTable
datanode_1  | 2019-10-30 05:53:59,586 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
s3g_1       | 2019-10-30 06:00:26,617 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-30 05:54:00,051 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2019-10-30 05:53:52,457 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3  | 2019-10-30 05:53:59,132 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:57,077 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:prefixTable
datanode_1  | 2019-10-30 05:53:59,588 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | 20191030T060026Z
scm_1       | 2019-10-30 05:53:52,510 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-10-30 05:53:59,133 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-30 05:53:57,086 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_1  | 2019-10-30 05:53:59,592 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_2  | 2019-10-30 05:54:00,096 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2019-10-30 05:53:59,133 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
scm_1       | 2019-10-30 05:53:52,512 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-30 05:53:57,086 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_1  | 2019-10-30 05:53:59,592 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
datanode_2  | 2019-10-30 05:54:00,100 INFO segmented.SegmentedRaftLogWorker: new f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/033f6654-f9a4-43b6-92a5-ea2ef99355b1
datanode_3  | 2019-10-30 05:53:59,133 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2019-10-30 05:53:52,519 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@355c94be{/logs,file:///var/log/hadoop/,AVAILABLE}
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:57,087 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_1  | 2019-10-30 05:53:59,594 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 2019-10-30 06:00:26,617 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_2  | 2019-10-30 05:54:00,101 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2019-10-30 05:53:59,134 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2019-10-30 05:53:52,520 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3166f664{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:58,100 INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
datanode_1  | 2019-10-30 05:53:59,596 WARN impl.MetricsSystemImpl: HddsDatanode metrics system already initialized!
s3g_1       | 20191030T060026Z
datanode_2  | 2019-10-30 05:54:00,101 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1       | 2019-10-30 05:53:52,628 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
datanode_3  | 2019-10-30 05:53:59,134 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-30 05:53:58,103 [main] INFO       - Loaded 0 tokens
datanode_1  | 2019-10-30 05:53:59,601 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_2  | 2019-10-30 05:54:00,102 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-30 05:53:52,634 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1bedc703{/,file:///tmp/jetty-0.0.0.0-9876-scm-_-any-4814389528768505002.dir/webapp/,AVAILABLE}{/scm}
datanode_3  | 2019-10-30 05:53:59,135 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-30 05:53:58,104 [main] INFO       - Loading token state into token manager.
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
datanode_1  | 2019-10-30 05:53:59,637 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2019-10-30 05:54:00,102 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 2019-10-30 05:53:52,640 INFO server.AbstractConnector: Started ServerConnector@2b84ade3{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
datanode_3  | 2019-10-30 05:53:59,145 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:58,156 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | 2019-10-30 06:00:26,623 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-10-30 05:53:59,641 INFO segmented.SegmentedRaftLogWorker: new 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/913fa248-279a-4ff6-8f0b-59f8a1ba03c4
datanode_2  | 2019-10-30 05:54:00,102 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
scm_1       | 2019-10-30 05:53:52,641 INFO server.Server: Started @4986ms
datanode_3  | 2019-10-30 05:53:59,150 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:53:58,166 INFO ipc.Server: Starting Socket Reader #1 for port 9862
s3g_1       | 20191030T060026Z
datanode_1  | 2019-10-30 05:53:59,641 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-10-30 05:54:00,103 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2019-10-30 05:53:52,642 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:53:59,154 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2019-10-30 05:53:58,266 [main] INFO       - OzoneManager RPC server is listening at om/172.18.0.5:9862
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_1  | 2019-10-30 05:53:59,642 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-10-30 05:54:00,103 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2019-10-30 05:53:52,644 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2019-10-30 05:53:59,155 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 2019-10-30 05:53:58,371 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
kdc_1       | Entry for principal om/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.c1df53cef837.keytab.
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
datanode_1  | 2019-10-30 05:53:59,643 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-30 05:54:00,104 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2019-10-30 05:53:52,644 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2019-10-30 05:53:59,155 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 2019-10-30 05:53:58,410 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
kdc_1       | Entry for principal om/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.c1df53cef837.keytab.
s3g_1       | 2019-10-30 06:00:26,624 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-10-30 05:53:59,643 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2019-10-30 05:54:00,104 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2019-10-30 05:53:52,646 INFO server.BaseHttpServer: HTTP server of SCM is listening at http://0.0.0.0:9876
datanode_3  | 2019-10-30 05:53:59,156 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2019-10-30 05:53:58,410 INFO impl.MetricsSystemImpl: OzoneManager metrics system started
kdc_1       | Generiting keytab
s3g_1       | 20191030T060026Z
datanode_2  | 2019-10-30 05:54:00,113 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 2019-10-30 05:53:52,654 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2019-10-30 05:53:59,187 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC: start as a follower, conf=-1: [f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
om_1        | 2019-10-30 05:53:58,441 [main] INFO       - Reading keypair and certificate from file system.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_1  | 2019-10-30 05:53:59,643 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2  | 2019-10-30 05:54:00,116 INFO segmented.SegmentedRaftLogWorker: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2019-10-30 05:53:52,655 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:53:59,188 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC: changes role from      null to FOLLOWER at term 0 for startAsFollower
kdc_1       | WARNING: no policy specified for dn/om@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:53:58,455 [main] INFO       - Starting OM block token secret manager
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
datanode_1  | 2019-10-30 05:53:59,644 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2019-10-30 05:54:00,121 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2019-10-30 05:53:52,657 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:53:59,189 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start FollowerState
om_1        | 2019-10-30 05:53:58,456 [main] INFO       - Updating the current master key for generating tokens
kdc_1       | Principal "dn/om@EXAMPLE.COM" created.
s3g_1       | 2019-10-30 06:00:26,630 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-10-30 05:53:59,644 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2019-10-30 05:54:00,122 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 2019-10-30 05:53:52,659 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:53:59,194 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B5B4A47A99FC,id=f9b41af1-38ba-4dbb-b621-6fd57c378fab
om_1        | 2019-10-30 05:53:58,457 [main] INFO       - Starting OM delegation token secret manager
s3g_1       | 20191030T060026Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-30 05:53:59,645 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2019-10-30 05:54:00,123 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 2019-10-30 05:53:52,663 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_3  | 2019-10-30 05:53:59,377 INFO impl.FollowerState: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC-FollowerState: change to CANDIDATE, lastRpcTime:188ms, electionTimeout:187ms
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 05:53:58,457 [main] INFO       - Updating the current master key for generating tokens
kdc_1       | Entry for principal dn/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.om.keytab.
datanode_1  | 2019-10-30 05:53:59,645 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2019-10-30 05:54:00,123 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1       | 2019-10-30 05:53:52,668 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
datanode_3  | 2019-10-30 05:53:59,378 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: shutdown FollowerState
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 05:53:58,458 [Thread[Thread-11,5,main]] INFO       - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
kdc_1       | Entry for principal dn/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.om.keytab.
datanode_1  | 2019-10-30 05:53:59,653 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2019-10-30 05:54:00,153 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1: start as a follower, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858], old=null
scm_1       | 2019-10-30 05:53:52,669 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
datanode_3  | 2019-10-30 05:53:59,379 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
s3g_1       | 2019-10-30 06:00:26,630 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 05:53:58,473 INFO ipc.Server: IPC Server Responder: starting
kdc_1       | Generiting keytab
datanode_1  | 2019-10-30 05:53:59,657 INFO segmented.SegmentedRaftLogWorker: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2019-10-30 05:54:00,154 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2019-10-30 05:53:52,670 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
datanode_3  | 2019-10-30 05:53:59,382 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start LeaderElection
s3g_1       | 20191030T060026Z
om_1        | 2019-10-30 05:53:58,474 INFO ipc.Server: IPC Server listener on 9862: starting
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-30 05:53:59,660 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2019-10-30 05:54:00,156 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start FollowerState
scm_1       | 2019-10-30 05:53:52,807 INFO server.SCMClientProtocolServer: Processing CSR for dn f186250a45b8, UUID: f9b41af1-38ba-4dbb-b621-6fd57c378fab
datanode_3  | 2019-10-30 05:53:59,423 INFO impl.LeaderElection: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC-LeaderElection1: begin an election at term 1 for -1: [f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 05:53:58,507 INFO hdfs.DFSUtil: Starting web server as: HTTP/om@EXAMPLE.COM
kdc_1       | WARNING: no policy specified for om/f186250a45b8@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-30 05:53:59,661 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2019-10-30 05:54:00,159 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EA2EF99355B1,id=f337c68d-5e1e-4f64-a71f-9d640f38d7aa
scm_1       | 2019-10-30 05:53:52,807 INFO server.SCMClientProtocolServer: Processing CSR for dn e68c2c815db9, UUID: f337c68d-5e1e-4f64-a71f-9d640f38d7aa
datanode_3  | 2019-10-30 05:53:59,425 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: shutdown LeaderElection
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 05:53:58,507 INFO hdfs.DFSUtil: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
kdc_1       | Principal "om/f186250a45b8@EXAMPLE.COM" created.
datanode_1  | 2019-10-30 05:53:59,661 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2019-10-30 05:54:00,246 INFO impl.RaftServerProxy: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: addNew group-462FB490FA97:[f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858] returns group-462FB490FA97:java.util.concurrent.CompletableFuture@3e535ae4[Not completed]
scm_1       | 2019-10-30 05:53:52,890 INFO server.SCMClientProtocolServer: Processing CSR for dn 5bae0ed04c34, UUID: 0981213a-f8fa-4d9a-98e4-9d489458d959
datanode_3  | 2019-10-30 05:53:59,425 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2019-10-30 05:53:58,629 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-10-30 06:00:26,637 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-10-30 05:53:59,661 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2019-10-30 05:54:00,248 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: new RaftServerImpl for group-462FB490FA97:[f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858] with ContainerStateMachine:uninitialized
scm_1       | 2019-10-30 05:53:53,745 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:53:58,631 INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_3  | 2019-10-30 05:53:59,426 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC: change Leader from null to f9b41af1-38ba-4dbb-b621-6fd57c378fab at term 1 for becomeLeader, leader elected after 354ms
kdc_1       | Entry for principal om/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.f186250a45b8.keytab.
s3g_1       | 20191030T060026Z
datanode_1  | 2019-10-30 05:53:59,688 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4: start as a follower, conf=-1: [0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858], old=null
datanode_2  | 2019-10-30 05:54:00,249 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 2019-10-30 05:53:53,749 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Entry for principal om/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.f186250a45b8.keytab.
datanode_3  | 2019-10-30 05:53:59,429 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2019-10-30 05:53:58,638 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
s3g_1       | 20191030/us-west-1/s3/aws4_request
datanode_1  | 2019-10-30 05:53:59,690 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2019-10-30 05:54:00,249 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2019-10-30 05:53:53,751 INFO server.SCMClientProtocolServer: Processing CSR for om om, UUID: 229babaf-53d3-4943-8d8b-412df600620a
kdc_1       | Generiting keytab
datanode_3  | 2019-10-30 05:53:59,429 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 05:53:58,641 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
datanode_1  | 2019-10-30 05:53:59,691 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: start FollowerState
datanode_2  | 2019-10-30 05:54:00,249 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 05:53:56,233 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:53:59,432 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
s3g_1       | 2019-10-30 06:00:26,637 [qtp359368949-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
datanode_1  | 2019-10-30 05:53:59,695 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59F8A1BA03C4,id=0981213a-f8fa-4d9a-98e4-9d489458d959
kdc_1       | WARNING: no policy specified for om/scm@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:53:58,641 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2019-10-30 05:54:00,249 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1       | 2019-10-30 05:53:56,236 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_3  | 2019-10-30 05:53:59,435 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
s3g_1       | 2019-10-30 06:00:26,639 [qtp359368949-27] ERROR      - Couldn't create RpcClient protocol exception: 
datanode_1  | 2019-10-30 05:53:59,807 INFO impl.FollowerState: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4-FollowerState: change to CANDIDATE, lastRpcTime:116ms, electionTimeout:115ms
kdc_1       | Principal "om/scm@EXAMPLE.COM" created.
om_1        | 2019-10-30 05:53:58,641 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_2  | 2019-10-30 05:54:00,249 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-10-30 05:53:59,435 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-30 05:53:56,332 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-30 05:53:59,808 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: shutdown FollowerState
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:53:58,664 INFO http.HttpServer2: Jetty bound to port 9874
datanode_2  | 2019-10-30 05:54:00,249 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: ConfigurationManager, init=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-10-30 05:53:59,436 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 20191030T060026Z
scm_1       | 2019-10-30 05:53:56,335 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-30 05:53:59,809 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
kdc_1       | Entry for principal om/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.scm.keytab.
om_1        | 2019-10-30 05:53:58,666 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2  | 2019-10-30 05:54:00,249 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-10-30 05:53:59,447 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start LeaderState
s3g_1       | 20191030/us-west-1/s3/aws4_request
scm_1       | 2019-10-30 05:53:56,345 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-30 05:53:59,812 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: start LeaderElection
kdc_1       | Entry for principal om/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.scm.keytab.
om_1        | 2019-10-30 05:53:58,696 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-10-30 05:54:00,250 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-30 05:53:56,348 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-10-30 05:53:59,858 INFO impl.LeaderElection: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4-LeaderElection1: begin an election at term 1 for -1: [0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858], old=null
kdc_1       | Generiting keytab
om_1        | 2019-10-30 05:53:58,697 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
datanode_2  | 2019-10-30 05:54:00,250 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97 does not exist. Creating ...
datanode_3  | 2019-10-30 05:53:59,462 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
scm_1       | 2019-10-30 05:53:56,365 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-10-30 05:53:59,860 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: shutdown LeaderElection
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:53:58,700 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@67f63d26{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2019-10-30 05:54:00,270 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97/in_use.lock acquired by nodename 7@e68c2c815db9
datanode_3  | 2019-10-30 05:53:59,469 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC: set configuration 0: [f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null at 0
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
scm_1       | 2019-10-30 05:53:56,379 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | WARNING: no policy specified for scm/5bae0ed04c34@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:53:58,700 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@679dd234{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2019-10-30 05:54:00,292 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97 has been successfully formatted.
datanode_1  | 2019-10-30 05:53:59,860 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2019-10-30 05:53:59,582 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-B5B4A47A99FC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/79938f87-2048-45ab-bc9f-b5b4a47a99fc/current/log_inprogress_0
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
scm_1       | 2019-10-30 05:53:58,231 INFO net.NetworkTopology: Added a new node: /default-rack/f9b41af1-38ba-4dbb-b621-6fd57c378fab
kdc_1       | Principal "scm/5bae0ed04c34@EXAMPLE.COM" created.
om_1        | 2019-10-30 05:53:58,804 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
datanode_2  | 2019-10-30 05:54:00,293 [pool-9-thread-1] INFO       - group-462FB490FA97: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2019-10-30 05:54:00,259 INFO impl.RaftServerProxy: f9b41af1-38ba-4dbb-b621-6fd57c378fab: addNew group-462FB490FA97:[f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858] returns group-462FB490FA97:java.util.concurrent.CompletableFuture@293e3fbb[Not completed]
datanode_1  | 2019-10-30 05:53:59,861 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4: change Leader from null to 0981213a-f8fa-4d9a-98e4-9d489458d959 at term 1 for becomeLeader, leader elected after 275ms
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
scm_1       | 2019-10-30 05:53:58,232 INFO node.SCMNodeManager: Registered Data node : f9b41af1-38ba-4dbb-b621-6fd57c378fab{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 12761624108837480}
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-30 05:54:00,293 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_3  | 2019-10-30 05:54:00,263 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab: new RaftServerImpl for group-462FB490FA97:[f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2019-10-30 05:53:59,865 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
scm_1       | 2019-10-30 05:53:58,235 INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
om_1        | 2019-10-30 05:53:58,809 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@45292ec1{/,file:///tmp/jetty-0.0.0.0-9874-ozoneManager-_-any-1168865221465558363.dir/webapp/,AVAILABLE}{/ozoneManager}
kdc_1       | Entry for principal scm/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.5bae0ed04c34.keytab.
datanode_2  | 2019-10-30 05:54:00,293 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2019-10-30 05:53:59,865 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
scm_1       | 2019-10-30 05:53:58,236 INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
om_1        | 2019-10-30 05:53:58,813 INFO server.AbstractConnector: Started ServerConnector@16d07cf3{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
kdc_1       | Entry for principal scm/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.5bae0ed04c34.keytab.
datanode_2  | 2019-10-30 05:54:00,294 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2019-10-30 05:53:59,867 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
scm_1       | 2019-10-30 05:53:58,237 INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
om_1        | 2019-10-30 05:53:58,813 INFO server.Server: Started @4798ms
datanode_2  | 2019-10-30 05:54:00,294 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kdc_1       | Generiting keytab
datanode_3  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1  | 2019-10-30 05:53:59,871 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 05:53:58,815 INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2019-10-30 05:53:58,327 INFO net.NetworkTopology: Added a new node: /default-rack/0981213a-f8fa-4d9a-98e4-9d489458d959
datanode_2  | 2019-10-30 05:54:00,294 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-30 05:53:59,871 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 05:53:58,816 INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2019-10-30 05:53:58,327 INFO node.SCMNodeManager: Registered Data node : 0981213a-f8fa-4d9a-98e4-9d489458d959{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 12761624142962785}
datanode_2  | 2019-10-30 05:54:00,294 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
kdc_1       | WARNING: no policy specified for om/s3g@EXAMPLE.COM; defaulting to no policy
datanode_1  | 2019-10-30 05:53:59,872 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-30 05:53:58,817 INFO server.BaseHttpServer: HTTP server of OZONEMANAGER is listening at http://0.0.0.0:9874
scm_1       | 2019-10-30 05:53:58,335 INFO net.NetworkTopology: Added a new node: /default-rack/f337c68d-5e1e-4f64-a71f-9d640f38d7aa
datanode_2  | 2019-10-30 05:54:00,294 INFO segmented.SegmentedRaftLogWorker: new f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97
datanode_3  | 2019-10-30 05:54:00,264 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: ConfigurationManager, init=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null, confs=<EMPTY_MAP>
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-30 05:53:59,884 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: start LeaderState
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-30 05:54:15,192 INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,294 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2019-10-30 05:53:59,898 INFO segmented.SegmentedRaftLogWorker: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-30 05:54:15,211 INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:53:58,336 INFO node.SCMNodeManager: Registered Data node : f337c68d-5e1e-4f64-a71f-9d640f38d7aa{ip: 172.18.0.8, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 12761624108814614}
datanode_3  | 2019-10-30 05:54:00,265 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2019-10-30 05:54:00,294 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-10-30 05:53:59,906 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4: set configuration 0: [0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858], old=null at 0
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-30 05:54:16,624 [IPC Server handler 0 on 9862] INFO       - created volume:vol-0-90297 for user:HTTP/scm@EXAMPLE.COM
scm_1       | 2019-10-30 05:53:59,287 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 79938f87-2048-45ab-bc9f-b5b4a47a99fc, Nodes: f9b41af1-38ba-4dbb-b621-6fd57c378fab{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_3  | 2019-10-30 05:54:00,265 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97 does not exist. Creating ...
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-30 05:54:00,294 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2019-10-30 05:54:00,015 INFO segmented.SegmentedRaftLogWorker: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-59F8A1BA03C4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/913fa248-279a-4ff6-8f0b-59f8a1ba03c4/current/log_inprogress_0
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-30 05:54:16,650 [IPC Server handler 2 on 9862] INFO       - created volume:vol-1-85618 for user:HTTP/scm@EXAMPLE.COM
scm_1       | 2019-10-30 05:53:59,749 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 913fa248-279a-4ff6-8f0b-59f8a1ba03c4, Nodes: 0981213a-f8fa-4d9a-98e4-9d489458d959{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_3  | 2019-10-30 05:54:00,291 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97/in_use.lock acquired by nodename 7@f186250a45b8
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-30 05:54:00,295 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2019-10-30 05:54:00,260 INFO impl.RaftServerProxy: 0981213a-f8fa-4d9a-98e4-9d489458d959: addNew group-462FB490FA97:[f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858] returns group-462FB490FA97:java.util.concurrent.CompletableFuture@24766898[Not completed]
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 05:54:16,665 [IPC Server handler 5 on 9862] INFO       - created volume:vol-2-25536 for user:HTTP/scm@EXAMPLE.COM
datanode_3  | 2019-10-30 05:54:00,315 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97 has been successfully formatted.
scm_1       | 2019-10-30 05:54:00,214 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 033f6654-f9a4-43b6-92a5-ea2ef99355b1, Nodes: f337c68d-5e1e-4f64-a71f-9d640f38d7aa{ip: 172.18.0.8, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-30 05:54:00,295 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_1  | 2019-10-30 05:54:00,264 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959: new RaftServerImpl for group-462FB490FA97:[f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858] with ContainerStateMachine:uninitialized
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-30 05:54:16,677 [IPC Server handler 6 on 9862] INFO       - created volume:vol-3-90749 for user:HTTP/scm@EXAMPLE.COM
datanode_3  | 2019-10-30 05:54:00,315 [pool-9-thread-1] INFO       - group-462FB490FA97: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | 2019-10-30 05:54:00,333 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 950b7df2-3205-4ec9-802d-462fb490fa97, Nodes: 0981213a-f8fa-4d9a-98e4-9d489458d959{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}f337c68d-5e1e-4f64-a71f-9d640f38d7aa{ip: 172.18.0.8, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}f9b41af1-38ba-4dbb-b621-6fd57c378fab{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-30 05:54:00,295 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-30 05:54:16,690 [IPC Server handler 8 on 9862] INFO       - created volume:vol-4-90973 for user:HTTP/scm@EXAMPLE.COM
datanode_3  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
scm_1       | 2019-10-30 05:54:15,664 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-30 05:54:00,295 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-30 05:54:28,949 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2019-10-30 05:54:15,671 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-30 05:54:00,295 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2019-10-30 05:54:00,264 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-30 05:54:28,964 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2019-10-30 05:54:17,156 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-30 05:54:00,295 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2019-10-30 05:54:00,265 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 05:54:29,649 [IPC Server handler 6 on 9862] INFO       - created volume:89237-rpcwoport for user:testuser/scm@EXAMPLE.COM
datanode_3  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-30 05:54:17,162 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-10-30 05:54:00,295 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2019-10-30 05:54:00,265 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 05:54:31,473 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-30 05:54:17,169 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-10-30 05:54:00,296 INFO segmented.SegmentedRaftLogWorker: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
datanode_1  | 2019-10-30 05:54:00,265 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97: ConfigurationManager, init=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null, confs=<EMPTY_MAP>
om_1        | 2019-10-30 05:54:31,485 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:54:17,174 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fdaacf54-a64e-4dcd-b006-626b96e04f82, Nodes: 0981213a-f8fa-4d9a-98e4-9d489458d959{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN]
om_1        | 2019-10-30 05:54:34,073 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2019-10-30 05:54:00,296 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
datanode_1  | 2019-10-30 05:54:00,265 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:54:18,264 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:54:34,083 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,316 INFO segmented.SegmentedRaftLogWorker: new f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97
datanode_2  | 2019-10-30 05:54:00,296 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
datanode_1  | 2019-10-30 05:54:00,265 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:54:18,268 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om_1        | 2019-10-30 05:54:36,528 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-10-30 05:54:00,296 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
datanode_1  | 2019-10-30 05:54:00,265 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97 does not exist. Creating ...
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:54:18,602 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:54:36,541 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-10-30 05:54:00,297 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
datanode_1  | 2019-10-30 05:54:00,291 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97/in_use.lock acquired by nodename 7@5bae0ed04c34
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:54:18,605 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:54:39,202 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-10-30 05:54:00,302 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: start as a follower, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
datanode_1  | 2019-10-30 05:54:00,315 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97 has been successfully formatted.
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
scm_1       | 2019-10-30 05:54:18,782 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:54:39,213 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2019-10-30 05:54:00,302 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2019-10-30 05:54:00,315 [pool-9-thread-1] INFO       - group-462FB490FA97: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
scm_1       | 2019-10-30 05:54:19,077 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:54:41,834 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2  | 2019-10-30 05:54:00,302 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start FollowerState
datanode_1  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
scm_1       | 2019-10-30 05:54:19,399 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:54:41,845 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2019-10-30 05:54:00,302 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-462FB490FA97,id=f337c68d-5e1e-4f64-a71f-9d640f38d7aa
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
datanode_1  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2019-10-30 05:54:19,462 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:54:44,428 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2019-10-30 05:54:00,324 INFO impl.FollowerState: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1-FollowerState: change to CANDIDATE, lastRpcTime:169ms, electionTimeout:168ms
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_1  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2019-10-30 05:54:19,514 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:54:44,441 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,318 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2019-10-30 05:54:00,326 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: shutdown FollowerState
kdc_1       | Oct 30 05:53:38 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_1  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-30 05:54:19,576 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:54:47,047 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,318 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2019-10-30 05:54:00,327 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_1  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2019-10-30 05:54:19,632 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:54:47,056 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,318 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
scm_1       | 2019-10-30 05:54:19,699 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2019-10-30 05:54:00,331 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start LeaderElection
om_1        | 2019-10-30 05:54:49,650 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,318 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
scm_1       | 2019-10-30 05:54:19,750 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,316 INFO segmented.SegmentedRaftLogWorker: new 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97
datanode_2  | 2019-10-30 05:54:00,351 INFO impl.LeaderElection: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1-LeaderElection1: begin an election at term 1 for -1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858], old=null
om_1        | 2019-10-30 05:54:49,663 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,319 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
scm_1       | 2019-10-30 05:54:19,801 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,316 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-10-30 05:54:00,352 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: shutdown LeaderElection
om_1        | 2019-10-30 05:54:54,543 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,319 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 2019-10-30 05:54:19,853 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_2  | 2019-10-30 05:54:00,353 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2019-10-30 05:54:54,554 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,319 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 2019-10-30 05:54:19,917 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-30 05:54:00,353 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1: change Leader from null to f337c68d-5e1e-4f64-a71f-9d640f38d7aa at term 1 for becomeLeader, leader elected after 318ms
om_1        | 2019-10-30 05:54:58,778 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,319 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1       | 2019-10-30 05:54:19,971 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-30 05:54:00,357 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2019-10-30 05:54:58,788 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,322 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: start as a follower, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
scm_1       | 2019-10-30 05:54:20,023 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-30 05:55:01,314 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,357 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2019-10-30 05:54:00,322 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: changes role from      null to FOLLOWER at term 0 for startAsFollower
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:54:20,078 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:55:01,324 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,361 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3  | 2019-10-30 05:54:00,323 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start FollowerState
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:20,130 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:55:03,791 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,365 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_3  | 2019-10-30 05:54:00,323 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-462FB490FA97,id=f9b41af1-38ba-4dbb-b621-6fd57c378fab
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:20,183 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:55:03,802 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,365 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2019-10-30 05:54:00,361 INFO impl.FollowerState: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-FollowerState: change to CANDIDATE, lastRpcTime:38ms, electionTimeout:38ms
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:20,234 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:55:06,290 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,366 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
datanode_3  | 2019-10-30 05:54:00,362 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: shutdown FollowerState
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:54:20,284 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_2  | 2019-10-30 05:54:00,378 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start LeaderState
datanode_1  | 2019-10-30 05:54:00,317 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-30 05:55:06,301 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,362 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:20,328 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_2  | 2019-10-30 05:54:00,394 INFO segmented.SegmentedRaftLogWorker: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2019-10-30 05:54:00,318 INFO segmented.SegmentedRaftLogWorker: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
datanode_3  | 2019-10-30 05:54:00,362 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start LeaderElection
om_1        | 2019-10-30 05:55:08,665 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_2  | 2019-10-30 05:54:00,402 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1: set configuration 0: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858], old=null at 0
scm_1       | 2019-10-30 05:54:20,374 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,318 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
datanode_3  | 2019-10-30 05:54:00,376 INFO impl.LeaderElection: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-LeaderElection2: begin an election at term 1 for -1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
om_1        | 2019-10-30 05:55:08,673 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:20,421 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,318 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2019-10-30 05:54:00,490 INFO impl.FollowerState: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-FollowerState: change to CANDIDATE, lastRpcTime:188ms, electionTimeout:188ms
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
datanode_3  | 2019-10-30 05:54:00,536 INFO impl.LeaderElection: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-LeaderElection2: Election DISCOVERED_A_NEW_TERM; received 2 response(s) [f9b41af1-38ba-4dbb-b621-6fd57c378fab<-f337c68d-5e1e-4f64-a71f-9d640f38d7aa#0:FAIL-t1, f9b41af1-38ba-4dbb-b621-6fd57c378fab<-0981213a-f8fa-4d9a-98e4-9d489458d959#0:FAIL-t2] and 0 exception(s); f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97:t1, leader=null, voted=f9b41af1-38ba-4dbb-b621-6fd57c378fab, raftlog=f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
om_1        | 2019-10-30 05:55:11,325 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:54:20,468 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,318 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
datanode_2  | 2019-10-30 05:54:00,501 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: shutdown FollowerState
datanode_3  | 2019-10-30 05:54:00,537 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
om_1        | 2019-10-30 05:55:11,336 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:20,512 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,318 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
datanode_2  | 2019-10-30 05:54:00,501 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2019-10-30 05:54:00,537 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: shutdown LeaderElection
om_1        | 2019-10-30 05:55:13,839 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:20,556 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,321 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97: start as a follower, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
datanode_2  | 2019-10-30 05:54:00,501 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start LeaderElection
datanode_3  | 2019-10-30 05:54:00,537 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start FollowerState
om_1        | 2019-10-30 05:55:13,848 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:20,607 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,322 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97: changes role from      null to FOLLOWER at term 0 for startAsFollower
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
datanode_3  | 2019-10-30 05:54:00,569 INFO impl.FollowerState: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-FollowerState: change to CANDIDATE, lastRpcTime:31ms, electionTimeout:30ms
datanode_2  | 2019-10-30 05:54:00,508 INFO impl.LeaderElection: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-LeaderElection2: begin an election at term 1 for -1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
om_1        | 2019-10-30 05:55:16,262 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:20,654 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-30 05:54:00,322 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: start FollowerState
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
datanode_3  | 2019-10-30 05:54:00,569 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: shutdown FollowerState
datanode_2  | 2019-10-30 05:54:00,527 INFO segmented.SegmentedRaftLogWorker: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-EA2EF99355B1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/033f6654-f9a4-43b6-92a5-ea2ef99355b1/current/log_inprogress_0
om_1        | 2019-10-30 05:55:16,270 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:54:20,705 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-30 05:54:00,322 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-462FB490FA97,id=0981213a-f8fa-4d9a-98e4-9d489458d959
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
datanode_3  | 2019-10-30 05:54:00,569 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode_2  | 2019-10-30 05:54:00,601 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: changes role from CANDIDATE to FOLLOWER at term 2 for recognizeCandidate:0981213a-f8fa-4d9a-98e4-9d489458d959
om_1        | 2019-10-30 05:55:16,871 [IPC Server handler 9 on 9862] INFO       - created volume:89237-rpcwoport2 for user:testuser/scm@EXAMPLE.COM
scm_1       | 2019-10-30 05:54:20,752 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-30 05:54:00,427 INFO impl.FollowerState: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-FollowerState: change to CANDIDATE, lastRpcTime:105ms, electionTimeout:105ms
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
datanode_3  | 2019-10-30 05:54:00,570 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start LeaderElection
datanode_2  | 2019-10-30 05:54:00,601 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: shutdown LeaderElection
om_1        | 2019-10-30 05:55:18,659 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
datanode_1  | 2019-10-30 05:54:00,428 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: shutdown FollowerState
scm_1       | 2019-10-30 05:54:20,799 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
datanode_3  | 2019-10-30 05:54:00,586 INFO impl.LeaderElection: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-LeaderElection3: begin an election at term 3 for -1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
datanode_2  | 2019-10-30 05:54:00,601 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start FollowerState
om_1        | 2019-10-30 05:55:18,671 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  | 2019-10-30 05:54:00,428 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
datanode_3  | 2019-10-30 05:54:00,680 INFO impl.LeaderElection: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-LeaderElection3: Election PASSED; received 2 response(s) [f9b41af1-38ba-4dbb-b621-6fd57c378fab<-f337c68d-5e1e-4f64-a71f-9d640f38d7aa#0:OK-t3, f9b41af1-38ba-4dbb-b621-6fd57c378fab<-0981213a-f8fa-4d9a-98e4-9d489458d959#0:FAIL-t3] and 0 exception(s); f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97:t3, leader=null, voted=f9b41af1-38ba-4dbb-b621-6fd57c378fab, raftlog=f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
scm_1       | 2019-10-30 05:54:20,840 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_2  | 2019-10-30 05:54:00,621 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:f9b41af1-38ba-4dbb-b621-6fd57c378fab
om_1        | 2019-10-30 05:55:21,289 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-30 05:54:00,428 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: start LeaderElection
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
datanode_3  | 2019-10-30 05:54:00,680 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: shutdown LeaderElection
datanode_2  | 2019-10-30 05:54:00,621 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: shutdown FollowerState
om_1        | 2019-10-30 05:55:21,300 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:54:20,890 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 2019-10-30 05:54:00,444 INFO impl.LeaderElection: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-LeaderElection2: begin an election at term 1 for -1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
datanode_3  | 2019-10-30 05:54:00,680 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
datanode_2  | 2019-10-30 05:54:00,623 INFO impl.FollowerState: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
om_1        | 2019-10-30 05:55:23,773 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:20,940 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,483 INFO impl.LeaderElection: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-LeaderElection2: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97:t1, leader=null, voted=0981213a-f8fa-4d9a-98e4-9d489458d959, raftlog=0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
datanode_3  | 2019-10-30 05:54:00,680 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: change Leader from null to f9b41af1-38ba-4dbb-b621-6fd57c378fab at term 3 for becomeLeader, leader elected after 364ms
datanode_2  | 2019-10-30 05:54:00,634 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start FollowerState
om_1        | 2019-10-30 05:55:23,784 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:54:20,994 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,506 INFO impl.LeaderElection: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-LeaderElection2: begin an election at term 2 for -1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
datanode_3  | 2019-10-30 05:54:00,680 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2019-10-30 05:54:00,637 INFO impl.LeaderElection: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-LeaderElection2: Election REJECTED; received 0 response(s) [] and 0 exception(s); f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97:t3, leader=null, voted=null, raftlog=f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
om_1        | 2019-10-30 05:55:26,370 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:21,048 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,606 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97: changes role from CANDIDATE to FOLLOWER at term 3 for recognizeCandidate:f9b41af1-38ba-4dbb-b621-6fd57c378fab
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
datanode_3  | 2019-10-30 05:54:00,680 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2019-10-30 05:54:00,707 INFO impl.FollowerState: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-FollowerState: change to CANDIDATE, lastRpcTime:73ms, electionTimeout:73ms
om_1        | 2019-10-30 05:55:26,380 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:54:21,101 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,607 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: shutdown LeaderElection
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-10-30 05:54:00,680 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_2  | 2019-10-30 05:54:00,708 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: shutdown FollowerState
om_1        | 2019-10-30 05:55:28,857 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:21,157 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_1  | 2019-10-30 05:54:00,607 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: start FollowerState
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
datanode_3  | 2019-10-30 05:54:00,681 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_2  | 2019-10-30 05:54:00,708 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
om_1        | 2019-10-30 05:55:28,869 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-10-30 05:54:00,639 INFO impl.LeaderElection: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-LeaderElection2: Election DISCOVERED_A_NEW_TERM; received 1 response(s) [0981213a-f8fa-4d9a-98e4-9d489458d959<-f9b41af1-38ba-4dbb-b621-6fd57c378fab#0:FAIL-t3] and 0 exception(s); 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97:t3, leader=null, voted=null, raftlog=0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:54:21,203 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_3  | 2019-10-30 05:54:00,681 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-30 05:55:31,456 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,708 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start LeaderElection
datanode_1  | 2019-10-30 05:54:00,733 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97: changes role from  FOLLOWER to FOLLOWER at term 4 for recognizeCandidate:f337c68d-5e1e-4f64-a71f-9d640f38d7aa
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:21,249 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_3  | 2019-10-30 05:54:00,682 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-10-30 05:55:31,467 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,715 INFO impl.LeaderElection: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-LeaderElection3: begin an election at term 4 for -1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
kdc_1       | Principal "om/s3g@EXAMPLE.COM" created.
datanode_1  | 2019-10-30 05:54:00,733 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: shutdown FollowerState
datanode_3  | 2019-10-30 05:54:00,687 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1       | 2019-10-30 05:54:21,300 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-30 05:55:33,917 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,756 INFO impl.LeaderElection: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-LeaderElection3: Election PASSED; received 1 response(s) [f337c68d-5e1e-4f64-a71f-9d640f38d7aa<-0981213a-f8fa-4d9a-98e4-9d489458d959#0:OK-t4] and 0 exception(s); f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97:t4, leader=null, voted=f337c68d-5e1e-4f64-a71f-9d640f38d7aa, raftlog=f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-10-30 05:54:00,734 INFO impl.RoleInfo: 0981213a-f8fa-4d9a-98e4-9d489458d959: start FollowerState
datanode_3  | 2019-10-30 05:54:00,688 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2019-10-30 05:54:21,345 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-30 05:55:33,928 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,757 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: shutdown LeaderElection
kdc_1       | Entry for principal om/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.s3g.keytab.
datanode_1  | 2019-10-30 05:54:00,734 INFO impl.FollowerState: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2019-10-30 05:54:00,688 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1       | 2019-10-30 05:54:21,388 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-30 05:55:36,422 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,757 INFO server.GrpcServerProtocolService: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: Completed APPEND_ENTRIES, lastRequest: f9b41af1-38ba-4dbb-b621-6fd57c378fab->f337c68d-5e1e-4f64-a71f-9d640f38d7aa#0-t3, previous=(t:0, i:0), leaderCommit=-1, initializing? false, entries: <empty>
kdc_1       | Entry for principal om/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.s3g.keytab.
datanode_1  | 2019-10-30 05:54:00,769 INFO server.GrpcServerProtocolService: 0981213a-f8fa-4d9a-98e4-9d489458d959: Completed APPEND_ENTRIES, lastRequest: f9b41af1-38ba-4dbb-b621-6fd57c378fab->0981213a-f8fa-4d9a-98e4-9d489458d959#0-t3, previous=(t:0, i:0), leaderCommit=-1, initializing? false, entries: <empty>
datanode_3  | 2019-10-30 05:54:00,691 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2019-10-30 05:54:21,459 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-10-30 05:55:36,433 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,758 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
kdc_1       | Generiting keytab
datanode_3  | 2019-10-30 05:54:00,691 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2019-10-30 05:54:00,827 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97: change Leader from null to f337c68d-5e1e-4f64-a71f-9d640f38d7aa at term 4 for appendEntries, leader elected after 511ms
scm_1       | 2019-10-30 05:54:21,502 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-10-30 05:55:38,907 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,758 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: change Leader from null to f337c68d-5e1e-4f64-a71f-9d640f38d7aa at term 4 for becomeLeader, leader elected after 464ms
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-30 05:54:00,691 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-30 05:54:00,842 INFO impl.RaftServerImpl: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97: set configuration 0: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null at 0
scm_1       | 2019-10-30 05:54:21,541 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-30 05:55:38,918 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,758 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
kdc_1       | WARNING: no policy specified for scm/e68c2c815db9@EXAMPLE.COM; defaulting to no policy
datanode_3  | 2019-10-30 05:54:00,695 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2019-10-30 05:54:00,843 INFO segmented.SegmentedRaftLogWorker: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2019-10-30 05:54:21,610 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-30 05:55:41,218 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,758 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
kdc_1       | Principal "scm/e68c2c815db9@EXAMPLE.COM" created.
datanode_3  | 2019-10-30 05:54:00,696 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-10-30 05:54:00,881 INFO segmented.SegmentedRaftLogWorker: 0981213a-f8fa-4d9a-98e4-9d489458d959@group-462FB490FA97-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97/current/log_inprogress_0
scm_1       | 2019-10-30 05:54:21,664 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-30 05:55:41,228 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-30 05:54:00,758 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3  | 2019-10-30 05:54:00,696 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2019-10-30 05:54:18,247 INFO client.DNCertificateClient: Getting certificate with certSerialId:12761625003271338.
scm_1       | 2019-10-30 05:54:21,722 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-30 05:55:41,806 [IPC Server handler 12 on 9862] ERROR      - Add acl [user:superuser1:rwxy[ACCESS]] to path /89237-rpcwoport2/bb1 failed, because acl already exist
kdc_1       | Entry for principal scm/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.e68c2c815db9.keytab.
datanode_2  | 2019-10-30 05:54:00,758 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_3  | 2019-10-30 05:54:00,696 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2019-10-30 05:55:59,960 WARN client.GrpcClientProtocolService: 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
scm_1       | 2019-10-30 05:54:21,774 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-30 05:55:43,686 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal scm/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.e68c2c815db9.keytab.
om_1        | 2019-10-30 05:55:43,697 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,696 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2019-10-30 05:56:43,107 WARN client.GrpcClientProtocolService: 1-OrderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
scm_1       | 2019-10-30 05:54:21,851 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_2  | 2019-10-30 05:54:00,758 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
kdc_1       | Generiting keytab
om_1        | 2019-10-30 05:55:46,260 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
datanode_3  | 2019-10-30 05:54:00,696 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-10-30 05:57:28,752 WARN client.GrpcClientProtocolService: 2-OrderedRequestStreamObserver2: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
scm_1       | 2019-10-30 05:54:21,907 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_2  | 2019-10-30 05:54:00,759 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:55:46,270 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
datanode_3  | 2019-10-30 05:54:00,700 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start LeaderState
scm_1       | 2019-10-30 05:54:21,950 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_2  | 2019-10-30 05:54:00,764 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2019-10-30 06:02:30,960 WARN client.GrpcClientProtocolService: 6-OrderedRequestStreamObserver6: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
kdc_1       | WARNING: no policy specified for scm/c1df53cef837@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:55:48,836 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-30 05:54:21,987 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_2  | 2019-10-30 05:54:00,764 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-10-30 05:54:00,701 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 2019-10-30 05:55:48,849 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
datanode_2  | 2019-10-30 05:54:00,765 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1       | 2019-10-30 05:54:22,037 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Principal "scm/c1df53cef837@EXAMPLE.COM" created.
datanode_3  | 2019-10-30 05:54:00,702 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: set configuration 0: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null at 0
om_1        | 2019-10-30 05:55:51,527 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
datanode_2  | 2019-10-30 05:54:00,767 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2019-10-30 05:54:22,068 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-10-30 05:54:00,745 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: change Leader from f9b41af1-38ba-4dbb-b621-6fd57c378fab to null at term 4 for updateCurrentTerm
om_1        | 2019-10-30 05:55:51,538 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
datanode_2  | 2019-10-30 05:54:00,768 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2019-10-30 05:54:22,099 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Entry for principal scm/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.c1df53cef837.keytab.
datanode_3  | 2019-10-30 05:54:00,749 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: changes role from    LEADER to FOLLOWER at term 4 for recognizeCandidate:f337c68d-5e1e-4f64-a71f-9d640f38d7aa
om_1        | 2019-10-30 05:55:54,126 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,768 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
scm_1       | 2019-10-30 05:54:22,155 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Entry for principal scm/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.c1df53cef837.keytab.
datanode_3  | 2019-10-30 05:54:00,749 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: shutdown LeaderState
om_1        | 2019-10-30 05:55:54,136 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,773 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Generiting keytab
scm_1       | 2019-10-30 05:54:22,203 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_3  | 2019-10-30 05:54:00,752 INFO impl.PendingRequests: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-PendingRequests: sendNotLeaderResponses
om_1        | 2019-10-30 05:55:57,067 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,774 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 05:54:22,251 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_3  | 2019-10-30 05:54:00,753 WARN server.GrpcLogAppender: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97->0981213a-f8fa-4d9a-98e4-9d489458d959-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
om_1        | 2019-10-30 05:55:57,077 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,774 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | WARNING: no policy specified for om/om@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-30 05:54:22,308 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:01,851 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-10-30 05:54:00,774 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
scm_1       | 2019-10-30 05:54:22,351 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Principal "om/om@EXAMPLE.COM" created.
datanode_3  | 2019-10-30 05:54:00,753 WARN server.GrpcLogAppender: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97->f337c68d-5e1e-4f64-a71f-9d640f38d7aa-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
om_1        | 2019-10-30 05:56:01,863 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-10-30 05:54:00,774 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
scm_1       | 2019-10-30 05:54:22,400 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:56:04,664 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,754 INFO impl.RoleInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab: start FollowerState
datanode_2  | 2019-10-30 05:54:00,774 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
scm_1       | 2019-10-30 05:54:22,435 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
om_1        | 2019-10-30 05:56:04,676 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,763 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97/current/log_inprogress_0
datanode_2  | 2019-10-30 05:54:00,779 INFO impl.RoleInfo: f337c68d-5e1e-4f64-a71f-9d640f38d7aa: start LeaderState
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
scm_1       | 2019-10-30 05:54:22,491 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:07,376 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,766 INFO server.GrpcLogAppender: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97->f337c68d-5e1e-4f64-a71f-9d640f38d7aa-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_2  | 2019-10-30 05:54:00,779 INFO segmented.SegmentedRaftLogWorker: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Generiting keytab
scm_1       | 2019-10-30 05:54:22,530 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:07,388 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,771 INFO server.GrpcLogAppender: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97->0981213a-f8fa-4d9a-98e4-9d489458d959-AppendLogResponseHandler: follower responses appendEntries COMPLETED
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-10-30 05:54:00,780 INFO impl.RaftServerImpl: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97: set configuration 0: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null at 0
scm_1       | 2019-10-30 05:54:22,569 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:10,086 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,774 INFO impl.FollowerInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97->f337c68d-5e1e-4f64-a71f-9d640f38d7aa: nextIndex: updateUnconditionally 0 -> 0
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
kdc_1       | WARNING: no policy specified for scm/f186250a45b8@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-30 05:54:22,605 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:10,097 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,774 INFO impl.FollowerInfo: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97->0981213a-f8fa-4d9a-98e4-9d489458d959: nextIndex: updateUnconditionally 0 -> 0
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
datanode_2  | 2019-10-30 05:54:00,825 INFO segmented.SegmentedRaftLogWorker: f337c68d-5e1e-4f64-a71f-9d640f38d7aa@group-462FB490FA97-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97/current/log_inprogress_0
kdc_1       | Principal "scm/f186250a45b8@EXAMPLE.COM" created.
scm_1       | 2019-10-30 05:54:22,652 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:12,776 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,831 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: change Leader from null to f337c68d-5e1e-4f64-a71f-9d640f38d7aa at term 4 for appendEntries, leader elected after 86ms
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
datanode_2  | 2019-10-30 05:54:51,776 INFO client.DNCertificateClient: Getting certificate with certSerialId:12761625003271338.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 05:54:22,691 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:12,786 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2019-10-30 05:54:00,845 INFO impl.RaftServerImpl: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97: set configuration 0: [f337c68d-5e1e-4f64-a71f-9d640f38d7aa:172.18.0.8:9858, 0981213a-f8fa-4d9a-98e4-9d489458d959:172.18.0.6:9858, f9b41af1-38ba-4dbb-b621-6fd57c378fab:172.18.0.10:9858], old=null at 0
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_2  | 2019-10-30 05:54:52,732 WARN client.GrpcClientProtocolService: 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
kdc_1       | Entry for principal scm/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.f186250a45b8.keytab.
scm_1       | 2019-10-30 05:54:22,725 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:15,321 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,848 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker: Truncating segments toTruncate: null
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
datanode_2  | 2019-10-30 05:58:54,448 WARN client.GrpcClientProtocolService: 1-OrderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
kdc_1       | Entry for principal scm/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.f186250a45b8.keytab.
scm_1       | 2019-10-30 05:54:22,777 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:15,333 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  |   toDelete: [(0, 0) isOpen? true, length=0, newEndIndex=-1], start index 0
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
scm_1       | 2019-10-30 05:54:22,810 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Generiting keytab
om_1        | 2019-10-30 05:56:17,840 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 2019-10-30 05:54:00,848 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
scm_1       | 2019-10-30 05:54:22,846 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_3  | 2019-10-30 05:54:00,849 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker: Deleted log file /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97/current/log_inprogress_0
om_1        | 2019-10-30 05:56:17,855 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-30 05:54:22,881 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_3  | 2019-10-30 05:54:00,849 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:56:20,550 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
scm_1       | 2019-10-30 05:54:22,917 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
datanode_3  | 2019-10-30 05:54:00,904 INFO segmented.SegmentedRaftLogWorker: f9b41af1-38ba-4dbb-b621-6fd57c378fab@group-462FB490FA97-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/950b7df2-3205-4ec9-802d-462fb490fa97/current/log_inprogress_0
kdc_1       | WARNING: no policy specified for scm/scm@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:56:20,561 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
datanode_3  | 2019-10-30 06:02:25,742 INFO client.DNCertificateClient: Getting certificate with certSerialId:12761625003271338.
scm_1       | 2019-10-30 05:54:22,973 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Principal "scm/scm@EXAMPLE.COM" created.
om_1        | 2019-10-30 05:56:21,205 [IPC Server handler 2 on 9862] INFO       - created volume:89237-rpcwport for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
scm_1       | 2019-10-30 05:54:23,017 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:23,127 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2019-10-30 05:54:23,062 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:23,137 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 2019-10-30 05:56:25,599 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:23,121 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414819, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-30 05:56:25,610 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:54:23,155 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-30 05:56:28,054 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:23,190 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-30 05:56:28,067 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:54:23,244 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-30 05:56:30,514 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:23,276 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:54:23,310 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2019-10-30 05:54:23,346 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-30 05:56:30,522 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
scm_1       | 2019-10-30 05:54:23,382 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-30 05:56:33,111 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
scm_1       | 2019-10-30 05:54:23,411 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-30 05:56:33,122 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
scm_1       | 2019-10-30 05:54:23,439 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:35,527 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
scm_1       | 2019-10-30 05:54:23,469 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:35,538 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
scm_1       | 2019-10-30 05:54:23,498 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:38,028 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:54:23,558 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:38,038 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:54:23,594 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:40,552 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:54:23,624 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:40,564 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
scm_1       | 2019-10-30 05:54:23,657 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:44,950 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-30 05:56:44,961 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:54:23,687 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:48,933 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:54:23,726 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:48,943 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:54:23,759 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:51,351 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2019-10-30 05:54:23,789 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:51,365 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Oct 30, 2019 6:00:26 AM org.glassfish.jersey.internal.Errors logErrors
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:54:23,818 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:53,895 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:54:23,847 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:53,905 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | MultiException stack 1 of 1
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:54:23,877 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:56,334 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | javax.enterprise.inject.CreationException
kdc_1       | Oct 30 05:53:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414820, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:54:23,907 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:56,348 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:23,935 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:56:58,766 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:23,964 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-10-30 05:56:58,776 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm_1       | 2019-10-30 05:54:23,992 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-30 05:57:01,207 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
scm_1       | 2019-10-30 05:54:24,021 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:57:01,217 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
kdc_1       | Oct 30 05:53:39 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:24,048 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-30 05:57:03,679 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:24,077 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:03,688 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:54:24,103 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:06,019 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:57:06,031 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:24,132 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:06,694 [IPC Server handler 9 on 9862] INFO       - created volume:89237-rpcwoscheme for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:24,202 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:08,516 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
scm_1       | 2019-10-30 05:54:24,231 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-30 05:57:08,526 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
scm_1       | 2019-10-30 05:54:24,258 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:57:10,936 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:24,286 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:24,312 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:10,945 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:24,341 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 05:57:13,423 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:54:24,373 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-30 05:57:13,436 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
scm_1       | 2019-10-30 05:54:24,404 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:16,018 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:24,435 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-30 05:57:16,027 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:24,462 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:18,410 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
scm_1       | 2019-10-30 05:54:24,491 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:18,420 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
scm_1       | 2019-10-30 05:54:24,521 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:57:21,017 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
scm_1       | 2019-10-30 05:54:24,552 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-30 05:57:21,029 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:24,582 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:28,989 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:57:23,605 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:28,992 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2019-10-30 05:57:23,615 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:54:30,223 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-30 05:57:26,224 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:30,227 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-30 05:57:26,232 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:54:30,341 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-30 05:57:30,602 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
scm_1       | 2019-10-30 05:54:30,344 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:57:30,613 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
scm_1       | 2019-10-30 05:54:49,305 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:57:34,601 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
scm_1       | 2019-10-30 05:54:49,309 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:57:34,611 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
scm_1       | 2019-10-30 05:54:50,423 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:57:37,292 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
scm_1       | 2019-10-30 05:54:50,426 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 05:57:37,302 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:54:50,426 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2019-10-30 05:57:39,878 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:54:51,794 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-30 05:57:39,888 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:54:51,797 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-30 05:57:42,396 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:54:52,109 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
scm_1       | 2019-10-30 05:54:52,112 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:57:42,405 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
scm_1       | 2019-10-30 05:55:00,228 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:57:44,952 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
scm_1       | 2019-10-30 05:55:00,231 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:57:44,965 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
scm_1       | 2019-10-30 05:55:19,298 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:57:47,497 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
scm_1       | 2019-10-30 05:55:19,300 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:57:47,507 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
scm_1       | 2019-10-30 05:55:22,119 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:57:50,119 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
scm_1       | 2019-10-30 05:55:22,122 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:57:50,132 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
scm_1       | 2019-10-30 05:55:30,231 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:57:56,332 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
scm_1       | 2019-10-30 05:55:30,234 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-30 05:57:56,344 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
scm_1       | 2019-10-30 05:55:49,302 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
om_1        | 2019-10-30 05:57:57,032 [IPC Server handler 3 on 9862] INFO       - created volume:fstest90 for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
scm_1       | 2019-10-30 05:55:49,304 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
om_1        | 2019-10-30 05:57:58,974 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
scm_1       | 2019-10-30 05:55:52,112 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
om_1        | 2019-10-30 05:57:58,991 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:55:52,116 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:57:59,654 [IPC Server handler 18 on 9862] INFO       - created volume:fstest290 for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
scm_1       | 2019-10-30 05:55:57,887 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for HTTP/5bae0ed04c34@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:58:01,633 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Principal "HTTP/5bae0ed04c34@EXAMPLE.COM" created.
scm_1       | 2019-10-30 05:55:57,891 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 05:58:01,647 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 05:55:57,892 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:58:04,246 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Entry for principal HTTP/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.5bae0ed04c34.keytab.
scm_1       | 2019-10-30 05:55:58,512 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
om_1        | 2019-10-30 05:58:04,257 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Entry for principal HTTP/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.5bae0ed04c34.keytab.
scm_1       | 2019-10-30 05:55:58,512 INFO block.BlockManagerImpl: Deleting blocks conID: 4 locID: 103049782259023997 bcsId: 0
om_1        | 2019-10-30 05:58:06,829 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
scm_1       | 2019-10-30 05:55:59,389 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
om_1        | 2019-10-30 05:58:06,840 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-30 05:55:59,392 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 05:58:09,766 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-30 05:56:00,237 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for scm/s3g@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:58:09,779 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-30 05:56:00,240 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Principal "scm/s3g@EXAMPLE.COM" created.
om_1        | 2019-10-30 05:58:12,116 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
scm_1       | 2019-10-30 05:56:22,113 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-30 05:58:12,128 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:56:22,116 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal scm/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.s3g.keytab.
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-30 05:58:12,855 [IPC Server handler 0 on 9862] INFO       - created volume:fstest390 for user:testuser/scm@EXAMPLE.COM
scm_1       | 2019-10-30 05:56:29,391 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal scm/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.s3g.keytab.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
scm_1       | 2019-10-30 05:56:29,393 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
scm_1       | 2019-10-30 05:56:30,234 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:58:14,761 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
scm_1       | 2019-10-30 05:56:30,238 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:58:14,771 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
scm_1       | 2019-10-30 05:56:41,221 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:58:17,356 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for HTTP/e68c2c815db9@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/e68c2c815db9@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
scm_1       | 2019-10-30 05:56:41,224 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 05:58:17,366 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
scm_1       | 2019-10-30 05:56:41,224 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Entry for principal HTTP/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.e68c2c815db9.keytab.
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-30 05:58:19,911 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:56:42,548 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.e68c2c815db9.keytab.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-30 05:58:19,926 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:56:42,552 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-30 05:58:22,473 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:56:52,111 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:58:22,484 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 05:56:52,115 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:58:24,898 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
scm_1       | 2019-10-30 05:57:00,227 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | WARNING: no policy specified for HTTP/c1df53cef837@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-10-30 05:58:24,909 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
scm_1       | 2019-10-30 05:57:00,230 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Principal "HTTP/c1df53cef837@EXAMPLE.COM" created.
om_1        | 2019-10-30 05:58:27,530 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
scm_1       | 2019-10-30 05:57:12,552 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-30 05:58:27,542 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:57:12,555 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal HTTP/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.c1df53cef837.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-30 05:58:29,989 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:57:22,115 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
kdc_1       | Entry for principal HTTP/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.c1df53cef837.keytab.
om_1        | 2019-10-30 05:58:30,000 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:57:22,117 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | Generiting keytab
om_1        | 2019-10-30 05:58:32,467 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:57:26,814 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 05:57:26,816 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 05:58:32,479 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | WARNING: no policy specified for scm/om@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-30 05:57:26,817 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:58:34,913 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Principal "scm/om@EXAMPLE.COM" created.
scm_1       | 2019-10-30 05:57:28,181 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:58:34,925 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 05:57:28,183 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:58:37,508 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:57:30,228 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:58:37,519 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:57:30,231 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:58:38,096 [IPC Server handler 7 on 9862] ERROR      - Add acl [user:superuser1:rwxy[ACCESS]] to path /fstest390/bk1 failed, because acl already exist
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 05:57:52,120 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:58:39,987 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
scm_1       | 2019-10-30 05:57:52,125 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:58:39,996 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
scm_1       | 2019-10-30 05:57:58,195 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:58:42,489 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
scm_1       | 2019-10-30 05:57:58,200 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-30 05:58:42,499 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
scm_1       | 2019-10-30 05:57:58,550 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:58:44,875 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2019-10-30 05:57:58,552 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 05:58:44,885 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
scm_1       | 2019-10-30 05:57:58,553 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
om_1        | 2019-10-30 05:58:47,174 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 2019-10-30 05:58:47,184 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:57:58,553 INFO block.BlockManagerImpl: Deleting blocks conID: 7 locID: 103049792508199040 bcsId: 0
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
scm_1       | 2019-10-30 05:57:58,554 INFO block.BlockManagerImpl: Deleting blocks conID: 6 locID: 103049789520281727 bcsId: 0
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-30 05:58:49,727 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:58:00,229 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-30 05:58:49,738 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:58:00,232 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-30 05:58:52,049 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
scm_1       | 2019-10-30 05:58:22,117 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-30 05:58:52,060 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:58:22,120 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-30 05:58:56,151 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:58:28,181 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 2019-10-30 05:58:56,162 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:58:28,183 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:58:58,722 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:58:30,223 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-30 05:58:58,732 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
scm_1       | 2019-10-30 05:58:30,226 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-30 05:59:01,225 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-30 05:59:01,235 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
scm_1       | 2019-10-30 05:58:52,116 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-10-30 05:59:03,711 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
scm_1       | 2019-10-30 05:58:52,118 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:59:03,723 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 05:58:52,701 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:59:06,261 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:58:52,702 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 05:59:06,271 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:58:52,703 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:59:08,610 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Oct 30 05:53:40 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:58:58,227 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:59:08,622 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:58:58,230 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:58:58,244 INFO container.ReplicationManager: Starting Replication Monitor Thread.
om_1        | 2019-10-30 05:59:11,037 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 05:59:11,048 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 05:58:58,256 INFO container.ReplicationManager: Replication Monitor Thread took 9 milliseconds for processing 8 containers.
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-30 05:59:13,605 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:59:00,232 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 05:59:00,235 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:59:23,920 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 05:59:13,616 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 05:59:23,922 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	... 92 more
om_1        | 2019-10-30 05:59:16,250 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 05:59:16,259 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191030T060026Z
om_1        | 2019-10-30 05:59:16,821 [IPC Server handler 4 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 05:59:18,610 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 05:59:28,193 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-30 05:59:28,200 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:59:18,622 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
scm_1       | 2019-10-30 05:59:30,231 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:59:19,283 [IPC Server handler 13 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:59:30,235 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-30 05:59:21,067 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 05:59:53,921 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:59:21,076 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-30 05:59:21,631 [IPC Server handler 1 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
scm_1       | 2019-10-30 05:59:53,924 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-30 05:59:21,632 [IPC Server handler 1 on 9862] ERROR      - Add acl user:testuser2/scm@EXAMPLE.COM:xy[ACCESS] to volume fstest390 failed!
scm_1       | 2019-10-30 05:59:58,183 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | PERMISSION_DENIED org.apache.hadoop.ozone.om.exceptions.OMException: User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
scm_1       | 2019-10-30 05:59:58,185 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1631)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
scm_1       | 2019-10-30 06:00:00,230 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
scm_1       | 2019-10-30 06:00:00,233 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:136)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2019-10-30 06:00:19,102 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.acl.OMVolumeAclRequest.validateAndUpdateCache(OMVolumeAclRequest.java:79)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2019-10-30 06:00:19,106 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
scm_1       | 2019-10-30 06:00:23,926 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:00:23,931 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
scm_1       | 2019-10-30 06:00:28,190 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102)
scm_1       | 2019-10-30 06:00:28,196 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm_1       | 2019-10-30 06:00:30,227 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 2019-10-30 06:00:30,229 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 2019-10-30 06:00:40,753 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 2019-10-30 06:00:40,756 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 2019-10-30 06:00:53,926 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 2019-10-30 06:00:53,930 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-10-30 06:00:58,192 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:00:58,195 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 06:01:00,230 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2019-10-30 06:01:00,234 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2019-10-30 06:01:02,409 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:59:23,563 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
scm_1       | 2019-10-30 06:01:02,411 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 05:59:23,573 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-30 05:59:26,092 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 06:01:02,412 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-30 05:59:26,102 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 06:01:09,218 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-30 05:59:26,756 [IPC Server handler 5 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access volume
scm_1       | 2019-10-30 06:01:10,313 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	... 101 more
om_1        | 2019-10-30 05:59:28,870 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 06:01:10,317 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
s3g_1       | 
om_1        | 2019-10-30 05:59:28,883 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 06:01:26,861 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 
om_1        | 2019-10-30 05:59:31,435 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 06:01:26,862 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-30 06:00:26,654 WARN servlet.ServletHandler: 
om_1        | 2019-10-30 05:59:31,447 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 06:01:26,862 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-30 05:59:33,858 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 06:01:28,189 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal scm/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.om.keytab.
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-30 05:59:33,870 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 06:01:28,194 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal scm/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.om.keytab.
s3g_1       | 
om_1        | 2019-10-30 05:59:36,220 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 06:01:30,231 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
scm_1       | 2019-10-30 06:01:30,233 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:59:36,230 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
scm_1       | 2019-10-30 06:01:40,312 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:59:36,822 [IPC Server handler 6 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket
kdc_1       | WARNING: no policy specified for HTTP/f186250a45b8@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-30 06:01:40,315 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 05:59:38,763 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-10-30 06:01:50,506 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:59:38,774 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 05:59:41,049 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
scm_1       | 2019-10-30 06:01:50,508 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 05:59:41,060 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Principal "HTTP/f186250a45b8@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
scm_1       | 2019-10-30 06:01:50,509 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 05:59:43,530 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
scm_1       | 2019-10-30 06:01:58,192 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 05:59:43,542 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Entry for principal HTTP/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.f186250a45b8.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-30 05:59:45,897 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.f186250a45b8.keytab.
scm_1       | 2019-10-30 06:01:58,196 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-30 05:59:45,911 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Generiting keytab
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
scm_1       | 2019-10-30 06:01:58,563 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
om_1        | 2019-10-30 06:00:19,074 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-30 06:01:58,563 INFO block.BlockManagerImpl: Deleting blocks conID: 5 locID: 103049806637432962 bcsId: 0
om_1        | 2019-10-30 06:00:19,085 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | WARNING: no policy specified for HTTP/scm@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
scm_1       | 2019-10-30 06:01:58,563 INFO block.BlockManagerImpl: Deleting blocks conID: 9 locID: 103049807083470979 bcsId: 0
om_1        | 2019-10-30 06:00:22,789 [Socket Reader #1 for port 9862] INFO       - 302809f5a5a3608bb00ab664650c2f843d5340ca36278c09340ae7a01336fdca
kdc_1       | Principal "HTTP/scm@EXAMPLE.COM" created.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
scm_1       | 2019-10-30 06:01:58,564 INFO block.BlockManagerImpl: Deleting blocks conID: 4 locID: 103049808239853700 bcsId: 0
om_1        | 2019-10-30 06:00:22,792 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 2019-10-30 06:00:22,807 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-10-30 06:02:00,241 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-30 06:00:24,024 [Socket Reader #1 for port 9862] INFO       - 302809f5a5a3608bb00ab664650c2f843d5340ca36278c09340ae7a01336fdca
scm_1       | 2019-10-30 06:02:00,245 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
om_1        | 2019-10-30 06:00:24,025 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
scm_1       | 2019-10-30 06:02:03,452 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 06:00:24,027 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Generiting keytab
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
scm_1       | 2019-10-30 06:02:07,744 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 06:00:26,564 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
scm_1       | 2019-10-30 06:02:10,319 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 20191030T060026Z
kdc_1       | WARNING: no policy specified for testuser/5bae0ed04c34@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
scm_1       | 2019-10-30 06:02:10,327 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Principal "testuser/5bae0ed04c34@EXAMPLE.COM" created.
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 20191030/us-west-1/s3/aws4_request
scm_1       | 2019-10-30 06:02:20,162 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-30 06:02:20,164 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Entry for principal testuser/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.5bae0ed04c34.keytab.
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2019-10-30 06:02:20,165 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Entry for principal testuser/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.5bae0ed04c34.keytab.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
scm_1       | 2019-10-30 06:02:24,620 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Generiting keytab
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
scm_1       | 2019-10-30 06:02:25,756 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
scm_1       | 2019-10-30 06:02:25,761 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | WARNING: no policy specified for HTTP/s3g@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
scm_1       | 2019-10-30 06:02:26,103 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Principal "HTTP/s3g@EXAMPLE.COM" created.
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
scm_1       | 2019-10-30 06:02:26,110 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
scm_1       | 2019-10-30 06:02:28,187 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
scm_1       | 2019-10-30 06:02:28,189 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
scm_1       | 2019-10-30 06:02:29,187 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Generiting keytab
scm_1       | 2019-10-30 06:02:40,317 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 06:02:40,320 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | WARNING: no policy specified for testuser/e68c2c815db9@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Principal "testuser/e68c2c815db9@EXAMPLE.COM" created.
scm_1       | 2019-10-30 06:02:56,103 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 06:02:56,106 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Entry for principal testuser/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.e68c2c815db9.keytab.
scm_1       | 2019-10-30 06:02:58,194 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Entry for principal testuser/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.e68c2c815db9.keytab.
scm_1       | 2019-10-30 06:02:58,198 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Generiting keytab
scm_1       | 2019-10-30 06:03:10,313 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 06:03:10,316 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | WARNING: no policy specified for testuser/c1df53cef837@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/c1df53cef837@EXAMPLE.COM" created.
scm_1       | 2019-10-30 06:03:16,117 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 1. javax.enterprise.inject.CreationException
scm_1       | 2019-10-30 06:03:16,118 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 
scm_1       | 2019-10-30 06:03:25,212 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:00:26,565 WARN ipc.Server: Auth failed for 172.18.0.2:33886:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414821, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
scm_1       | 2019-10-30 06:03:25,214 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
scm_1       | 2019-10-30 06:03:25,215 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
scm_1       | 2019-10-30 06:03:26,103 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
scm_1       | 2019-10-30 06:03:26,105 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-10-30 06:00:26,581 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
scm_1       | 2019-10-30 06:03:26,542 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 20191030T060026Z
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:03:26,544 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:03:26,609 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:03:26,612 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:03:30,014 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:03:58,257 INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 13 containers.
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:03:59,700 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:03:59,702 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:03:59,703 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:04:00,134 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-10-30 06:04:00,138 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
scm_1       | 2019-10-30 06:04:00,197 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
scm_1       | 2019-10-30 06:04:00,198 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
scm_1       | 2019-10-30 06:04:00,200 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:04:00,202 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:04:01,094 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
scm_1       | 2019-10-30 06:04:07,507 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
scm_1       | 2019-10-30 06:04:08,395 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
scm_1       | 2019-10-30 06:04:16,383 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:04:19,714 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:04:26,493 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
scm_1       | 2019-10-30 06:04:27,277 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
scm_1       | 2019-10-30 06:04:30,122 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
scm_1       | 2019-10-30 06:04:30,125 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 30 05:53:41 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	... 33 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
scm_1       | 2019-10-30 06:04:30,193 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-10-30 06:00:26,582 WARN ipc.Server: Auth failed for 172.18.0.2:33888:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-10-30 06:04:30,194 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
om_1        | 20191030T060026Z
scm_1       | 2019-10-30 06:04:30,196 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 20191030/us-west-1/s3/aws4_request
scm_1       | 2019-10-30 06:04:30,196 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
scm_1       | 2019-10-30 06:04:51,186 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm_1       | 2019-10-30 06:04:51,189 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2019-10-30 06:00:26,587 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm_1       | 2019-10-30 06:04:51,190 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
scm_1       | 2019-10-30 06:04:52,101 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:04:58,568 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:04:58,569 INFO block.BlockManagerImpl: Deleting blocks conID: 14 locID: 103049818256375949 bcsId: 0
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
scm_1       | 2019-10-30 06:04:58,569 INFO block.BlockManagerImpl: Deleting blocks conID: 13 locID: 103049821630627989 bcsId: 0
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
scm_1       | 2019-10-30 06:04:58,569 INFO block.BlockManagerImpl: Deleting blocks conID: 14 locID: 103049821690331286 bcsId: 0
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
scm_1       | 2019-10-30 06:05:00,122 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:05:00,125 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 06:05:00,192 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 06:05:00,195 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:05:00,200 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:05:00,203 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 06:05:00,772 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
scm_1       | 2019-10-30 06:05:00,786 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:05:00,786 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:05:08,710 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-10-30 06:05:10,185 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 06:05:17,808 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
scm_1       | 2019-10-30 06:05:19,660 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
scm_1       | 2019-10-30 06:05:20,950 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
scm_1       | 2019-10-30 06:05:30,122 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
scm_1       | 2019-10-30 06:05:30,125 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
scm_1       | 2019-10-30 06:05:30,194 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
scm_1       | 2019-10-30 06:05:30,198 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
scm_1       | 2019-10-30 06:05:30,200 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
scm_1       | 2019-10-30 06:05:30,203 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
scm_1       | 2019-10-30 06:05:36,758 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
scm_1       | 2019-10-30 06:05:36,761 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
scm_1       | 2019-10-30 06:05:36,762 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-10-30 06:00:26,587 WARN ipc.Server: Auth failed for 172.18.0.2:33890:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-10-30 06:05:38,178 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
scm_1       | 2019-10-30 06:05:39,644 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
scm_1       | 2019-10-30 06:05:58,579 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 06:00:26,592 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
scm_1       | 2019-10-30 06:05:58,581 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
om_1        | 20191030T060026Z
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
scm_1       | 2019-10-30 06:05:58,581 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
scm_1       | 2019-10-30 06:05:58,582 INFO block.BlockManagerImpl: Deleting blocks conID: 13 locID: 103049822259576985 bcsId: 0,conID: 13 locID: 103049822259511448 bcsId: 0,conID: 12 locID: 103049822258593943 bcsId: 0
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-10-30 06:06:00,128 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
scm_1       | 2019-10-30 06:06:00,131 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
scm_1       | 2019-10-30 06:06:00,195 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Entry for principal testuser/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.c1df53cef837.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
scm_1       | 2019-10-30 06:06:00,195 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Entry for principal testuser/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.c1df53cef837.keytab.
s3g_1       | 	... 60 more
scm_1       | 2019-10-30 06:06:00,197 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
kdc_1       | Generiting keytab
scm_1       | 2019-10-30 06:06:00,197 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 06:06:03,879 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | WARNING: no policy specified for HTTP/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
scm_1       | 2019-10-30 06:06:18,273 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
scm_1       | 2019-10-30 06:06:18,274 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Principal "HTTP/om@EXAMPLE.COM" created.
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
scm_1       | 2019-10-30 06:06:18,274 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
scm_1       | 2019-10-30 06:06:26,395 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
scm_1       | 2019-10-30 06:06:30,128 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
scm_1       | 2019-10-30 06:06:30,131 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Generiting keytab
scm_1       | 2019-10-30 06:06:30,195 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 06:06:30,199 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | WARNING: no policy specified for testuser/f186250a45b8@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-30 06:06:30,200 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Principal "testuser/f186250a45b8@EXAMPLE.COM" created.
scm_1       | 2019-10-30 06:06:30,204 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	... 92 more
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 06:06:40,434 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal testuser/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.f186250a45b8.keytab.
scm_1       | 2019-10-30 06:06:40,436 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191030T060026Z
kdc_1       | Entry for principal testuser/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.f186250a45b8.keytab.
scm_1       | 2019-10-30 06:06:40,436 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191030/us-west-1/s3/aws4_request
scm_1       | 2019-10-30 06:06:41,167 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Generiting keytab
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
scm_1       | 2019-10-30 06:06:41,877 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 2019-10-30 06:00:26,592 WARN ipc.Server: Auth failed for 172.18.0.2:33892:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
scm_1       | 2019-10-30 06:06:49,768 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 20191030T060026Z
kdc_1       | WARNING: no policy specified for testuser/scm@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-30 06:06:51,086 INFO server.SCMBlockProtocolServer: Allocating 1 blocks of size 268435456, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
om_1        | 20191030/us-west-1/s3/aws4_request
scm_1       | 2019-10-30 06:06:58,586 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 5 blocks
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
scm_1       | 2019-10-30 06:06:58,586 INFO block.BlockManagerImpl: Deleting blocks conID: 13 locID: 103049826394374306 bcsId: 0
om_1        | 2019-10-30 06:00:26,597 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Principal "testuser/scm@EXAMPLE.COM" created.
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
scm_1       | 2019-10-30 06:06:58,587 INFO block.BlockManagerImpl: Deleting blocks conID: 14 locID: 103049827337765027 bcsId: 0
om_1        | 20191030T060026Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
scm_1       | 2019-10-30 06:06:58,587 INFO block.BlockManagerImpl: Deleting blocks conID: 12 locID: 103049827870048420 bcsId: 0
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
scm_1       | 2019-10-30 06:06:58,587 INFO block.BlockManagerImpl: Deleting blocks conID: 13 locID: 103049828790173861 bcsId: 0
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
scm_1       | 2019-10-30 06:06:58,587 INFO block.BlockManagerImpl: Deleting blocks conID: 14 locID: 103049828838146214 bcsId: 0
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Generiting keytab
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
scm_1       | 2019-10-30 06:07:00,127 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2019-10-30 06:07:00,130 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | WARNING: no policy specified for testuser2/5bae0ed04c34@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Principal "testuser2/5bae0ed04c34@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
scm_1       | 2019-10-30 06:07:00,194 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
scm_1       | 2019-10-30 06:07:00,195 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal testuser2/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.5bae0ed04c34.keytab.
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
scm_1       | 2019-10-30 06:07:00,198 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal testuser2/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.5bae0ed04c34.keytab.
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
scm_1       | 2019-10-30 06:07:00,201 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Generiting keytab
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
scm_1       | 2019-10-30 06:07:30,127 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
scm_1       | 2019-10-30 06:07:30,130 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | WARNING: no policy specified for testuser/s3g@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
scm_1       | 2019-10-30 06:07:30,196 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "testuser/s3g@EXAMPLE.COM" created.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
scm_1       | 2019-10-30 06:07:30,197 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
scm_1       | 2019-10-30 06:07:30,198 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
scm_1       | 2019-10-30 06:07:30,199 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Generiting keytab
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-10-30 06:07:59,931 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | WARNING: no policy specified for testuser2/e68c2c815db9@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-10-30 06:07:59,941 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:08:00,057 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:53:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414822, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:08:00,060 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:08:00,132 INFO ipc.Server: Auth successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	... 101 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
scm_1       | 2019-10-30 06:08:00,135 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e68c2c815db9@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 2019-10-30 06:00:26,656 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
scm_1       | 2019-10-30 06:08:00,199 INFO ipc.Server: Auth successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
scm_1       | 2019-10-30 06:08:00,203 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/5bae0ed04c34@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-10-30 06:08:00,214 INFO ipc.Server: Auth successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 
om_1        | 2019-10-30 06:00:26,597 WARN ipc.Server: Auth failed for 172.18.0.2:33894:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-10-30 06:08:00,216 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/f186250a45b8@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-30 06:00:26,604 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 05:53:42 kdc kadmind[15](info): closing down fd 18
s3g_1       | 
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 06:00:26,604 WARN ipc.Server: Auth failed for 172.18.0.2:33896:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191030T060026Z
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-30 06:00:26,610 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	... 13 more
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:00:26,611 WARN ipc.Server: Auth failed for 172.18.0.2:33898:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Principal "testuser2/e68c2c815db9@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-10-30 06:00:26,616 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal testuser2/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.e68c2c815db9.keytab.
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 20191030T060026Z
kdc_1       | Entry for principal testuser2/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.e68c2c815db9.keytab.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | WARNING: no policy specified for testuser2/c1df53cef837@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Principal "testuser2/c1df53cef837@EXAMPLE.COM" created.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Entry for principal testuser2/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.c1df53cef837.keytab.
kdc_1       | Entry for principal testuser2/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.c1df53cef837.keytab.
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	... 33 more
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | WARNING: no policy specified for testuser/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Principal "testuser/om@EXAMPLE.COM" created.
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Entry for principal testuser/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.om.keytab.
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Entry for principal testuser/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.om.keytab.
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | WARNING: no policy specified for testuser2/f186250a45b8@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Principal "testuser2/f186250a45b8@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Entry for principal testuser2/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.f186250a45b8.keytab.
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Entry for principal testuser2/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.f186250a45b8.keytab.
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-30 06:00:26,616 WARN ipc.Server: Auth failed for 172.18.0.2:33904:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | WARNING: no policy specified for testuser2/scm@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 20191030T060026Z
kdc_1       | Principal "testuser2/scm@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
om_1        | 2019-10-30 06:00:26,622 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
om_1        | 20191030T060026Z
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Generiting keytab
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | WARNING: no policy specified for s3g/5bae0ed04c34@EXAMPLE.COM; defaulting to no policy
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
kdc_1       | Principal "s3g/5bae0ed04c34@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
kdc_1       | Entry for principal s3g/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.5bae0ed04c34.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
kdc_1       | Entry for principal s3g/5bae0ed04c34@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.5bae0ed04c34.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | WARNING: no policy specified for testuser2/s3g@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Principal "testuser2/s3g@EXAMPLE.COM" created.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:53:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414823, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	... 60 more
om_1        | 2019-10-30 06:00:26,622 WARN ipc.Server: Auth failed for 172.18.0.2:33906:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-30 06:00:26,629 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	... 92 more
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191030T060026Z
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 05:53:43 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-30 06:00:26,629 WARN ipc.Server: Auth failed for 172.18.0.2:33908:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 20191030T060026Z
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-30 06:00:26,635 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 20191030T060026Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	... 101 more
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 2019-10-30 06:00:27,414 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 2019-10-30 06:00:27,423 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 20191030T060027Z
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 2019-10-30 06:00:27,423 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191030T060027Z
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 06:00:26,636 WARN ipc.Server: Auth failed for 172.18.0.2:33910:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
om_1        | 20191030T060026Z
s3g_1       | 2019-10-30 06:00:27,431 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 20191030T060027Z
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | b5f3a22b9678700b6633133b84575c3c880da2954d48eb0799914bd72c92ec0c, signature=e345bb4c7abdbf29df26f669ea285079df28920f414a576088f2f0dcef6f849a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 06:00:27,413 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 2019-10-30 06:00:27,432 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 20191030T060027Z
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/5bae0ed04c34@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 2019-10-30 06:00:27,438 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191030T060027Z
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
s3g_1       | 2019-10-30 06:00:27,438 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Entry for principal testuser2/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.s3g.keytab.
s3g_1       | 2019-10-30 06:00:27,444 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Entry for principal testuser2/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.s3g.keytab.
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Generiting keytab
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | WARNING: no policy specified for s3g/e68c2c815db9@EXAMPLE.COM; defaulting to no policy
s3g_1       | 2019-10-30 06:00:27,444 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Principal "s3g/e68c2c815db9@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191030T060027Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Entry for principal s3g/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.e68c2c815db9.keytab.
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Entry for principal s3g/e68c2c815db9@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.e68c2c815db9.keytab.
s3g_1       | 2019-10-30 06:00:27,449 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:00:27,414 WARN ipc.Server: Auth failed for 172.18.0.2:33944:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Generiting keytab
s3g_1       | 20191030T060027Z
om_1        | 20191030T060027Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | WARNING: no policy specified for s3g/c1df53cef837@EXAMPLE.COM; defaulting to no policy
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Principal "s3g/c1df53cef837@EXAMPLE.COM" created.
s3g_1       | 2019-10-30 06:00:27,450 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:00:27,421 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191030T060027Z
om_1        | 20191030T060027Z
kdc_1       | Entry for principal s3g/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.c1df53cef837.keytab.
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Entry for principal s3g/c1df53cef837@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.c1df53cef837.keytab.
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Generiting keytab
s3g_1       | 2019-10-30 06:00:27,455 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | WARNING: no policy specified for testuser2/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Principal "testuser2/om@EXAMPLE.COM" created.
s3g_1       | 2019-10-30 06:00:27,456 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Entry for principal testuser2/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.om.keytab.
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Entry for principal testuser2/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.om.keytab.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 2019-10-30 06:00:27,461 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 20191030T060027Z
kdc_1       | WARNING: no policy specified for s3g/f186250a45b8@EXAMPLE.COM; defaulting to no policy
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Principal "s3g/f186250a45b8@EXAMPLE.COM" created.
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-10-30 06:00:27,461 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Entry for principal s3g/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.f186250a45b8.keytab.
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Entry for principal s3g/f186250a45b8@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.f186250a45b8.keytab.
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Generiting keytab
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 2019-10-30 06:00:27,467 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | WARNING: no policy specified for s3g/scm@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 20191030T060027Z
kdc_1       | Principal "s3g/scm@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Entry for principal s3g/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.scm.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 2019-10-30 06:00:27,467 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal s3g/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.scm.keytab.
om_1        | 2019-10-30 06:00:27,422 WARN ipc.Server: Auth failed for 172.18.0.2:33950:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
kdc_1       | Generiting keytab
om_1        | 20191030T060027Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 2019-10-30 06:00:27,472 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414824, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,429 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 20191030T060027Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:27,473 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 20191030T060027Z
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 2019-10-30 06:00:27,477 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 2019-10-30 06:00:27,477 [qtp359368949-29] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 2019-10-30 06:00:27,478 [qtp359368949-29] ERROR      - Couldn't create RpcClient protocol exception: 
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191030T060027Z
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | WARNING: no policy specified for s3g/s3g@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 05:53:44 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:00:27,430 WARN ipc.Server: Auth failed for 172.18.0.2:33952:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191030T060027Z
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 06:00:27,437 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 20191030T060027Z
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/e68c2c815db9@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/c1df53cef837@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/f186250a45b8@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 06:00:27,437 WARN ipc.Server: Auth failed for 172.18.0.2:33954:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 06:00:27,442 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191030T060027Z
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
kdc_1       | Principal "s3g/s3g@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | WARNING: no policy specified for s3g/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Principal "s3g/om@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Entry for principal s3g/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.om.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Entry for principal s3g/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.om.keytab.
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
kdc_1       | Oct 30 05:53:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414825, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:53:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 05:53:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414826, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:53:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 05:53:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414826, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-30 06:00:27,443 WARN ipc.Server: Auth failed for 172.18.0.2:33956:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
kdc_1       | Oct 30 05:53:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414826, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](info): closing down fd 18
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-10-30 06:00:27,448 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Oct 30 05:53:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 20191030T060027Z
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](info): closing down fd 18
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 05:53:46 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:53:46 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.6: ISSUE: authtime 1572414826, etypes {rep=18 tkt=18 ses=18}, dn/5bae0ed04c34@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 30 05:53:47 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.8: ISSUE: authtime 1572414827, etypes {rep=18 tkt=18 ses=18}, dn/e68c2c815db9@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 30 05:53:48 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.10: ISSUE: authtime 1572414828, etypes {rep=18 tkt=18 ses=18}, dn/f186250a45b8@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 05:53:49 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.5: ISSUE: authtime 1572414829, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 30 05:53:49 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.9: ISSUE: authtime 1572414829, etypes {rep=18 tkt=18 ses=18}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 05:53:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414829, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 30 05:53:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414831, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 30 05:53:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572414828, etypes {rep=18 tkt=18 ses=18}, dn/f186250a45b8@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Oct 30 05:53:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572414827, etypes {rep=18 tkt=18 ses=18}, dn/e68c2c815db9@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Oct 30 05:53:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1572414826, etypes {rep=18 tkt=18 ses=18}, dn/5bae0ed04c34@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 05:53:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572414829, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 05:53:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414834, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-30 06:00:27,449 WARN ipc.Server: Auth failed for 172.18.0.2:33958:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:54 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414834, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Oct 30 05:53:55 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.5: ISSUE: authtime 1572414835, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:53:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1572414835, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:53:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414836, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:53:56 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414836, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-30 06:00:27,454 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:53:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414839, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 20191030T060027Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Oct 30 05:53:59 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414839, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
kdc_1       | Generiting keytab
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | WARNING: no policy specified for dn/recon@EXAMPLE.COM; defaulting to no policy
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Principal "dn/recon@EXAMPLE.COM" created.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:54:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:54:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414844, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:54:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 05:54:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414844, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Oct 30 05:54:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 05:54:04 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 05:54:04 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Oct 30 05:54:04 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
kdc_1       | Oct 30 05:54:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Oct 30 05:54:04 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:54:04 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Entry for principal dn/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.recon.keytab.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-10-30 06:00:27,455 WARN ipc.Server: Auth failed for 172.18.0.2:33960:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal dn/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.recon.keytab.
om_1        | 20191030T060027Z
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
kdc_1       | Generiting keytab
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | WARNING: no policy specified for om/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Principal "om/recon@EXAMPLE.COM" created.
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Entry for principal om/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.recon.keytab.
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Entry for principal om/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.recon.keytab.
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Generiting keytab
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 2019-10-30 06:00:27,460 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 20191030T060027Z
kdc_1       | WARNING: no policy specified for scm/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | Oct 30, 2019 6:00:27 AM org.glassfish.jersey.internal.Errors logErrors
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Principal "scm/recon@EXAMPLE.COM" created.
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | MultiException stack 1 of 1
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | javax.enterprise.inject.CreationException
kdc_1       | Entry for principal scm/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.recon.keytab.
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
kdc_1       | Entry for principal scm/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.recon.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | WARNING: no policy specified for HTTP/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Principal "HTTP/recon@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | WARNING: no policy specified for testuser/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Principal "testuser/recon@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Entry for principal testuser/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.recon.keytab.
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Entry for principal testuser/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.recon.keytab.
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Generiting keytab
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | WARNING: no policy specified for testuser2/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 2019-10-30 06:00:27,460 WARN ipc.Server: Auth failed for 172.18.0.2:33962:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Principal "testuser2/recon@EXAMPLE.COM" created.
om_1        | 20191030T060027Z
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
kdc_1       | Entry for principal testuser2/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.recon.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Entry for principal testuser2/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.recon.keytab.
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-30 06:00:27,465 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Generiting keytab
om_1        | 20191030T060027Z
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | WARNING: no policy specified for s3g/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Principal "s3g/recon@EXAMPLE.COM" created.
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-30 06:00:27,466 WARN ipc.Server: Auth failed for 172.18.0.2:33964:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-30 06:00:27,471 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:54:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572414845, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:54:04 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 06:00:27,472 WARN ipc.Server: Auth failed for 172.18.0.2:33966:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
om_1        | 20191030T060027Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-10-30 06:00:27,476 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Entry for principal s3g/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.recon.keytab.
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Entry for principal s3g/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.recon.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-30 06:00:27,476 WARN ipc.Server: Auth failed for 172.18.0.2:33968:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
kdc_1       | Oct 30 05:54:05 kdc kadmind[15](info): closing down fd 18
kdc_1       | Oct 30 05:54:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414850, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:54:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414852, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Oct 30 05:54:12 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414852, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Oct 30 05:54:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414852, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,649 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 30 05:54:27 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 30 05:54:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 30 05:54:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 30 05:54:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 30 05:54:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	... 92 more
kdc_1       | Oct 30 05:54:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:54:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:54:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:54:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:54:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
kdc_1       | Oct 30 05:54:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
kdc_1       | Oct 30 05:54:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:55:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:55:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 05:55:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Oct 30 05:55:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 30 05:55:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 30 05:55:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414867, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:55:14 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:55:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Oct 30 05:55:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Oct 30 05:55:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
kdc_1       | Oct 30 05:55:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Oct 30 05:55:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 05:55:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-30 06:00:27,649 WARN ipc.Server: Auth failed for 172.18.0.2:33980:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:55:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:55:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414914, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:55:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:55:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-30 06:00:27,654 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:55:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:55:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:55:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:55:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	... 101 more
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:55:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:55:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:55:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414934, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 2019-10-30 06:00:27,483 WARN servlet.ServletHandler: 
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 05:55:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 05:55:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 05:56:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:56:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 05:56:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 05:56:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
kdc_1       | Oct 30 05:56:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
kdc_1       | Oct 30 05:56:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Oct 30 05:56:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414955, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:56:18 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:56:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 05:56:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 05:56:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 05:56:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 30 05:56:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Oct 30 05:56:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-30 06:00:27,654 WARN ipc.Server: Auth failed for 172.18.0.2:33982:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:56:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:56:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:56:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Oct 30 05:56:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,659 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Oct 30 05:56:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
kdc_1       | Oct 30 05:56:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Oct 30 05:56:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
kdc_1       | Oct 30 05:56:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Oct 30 05:56:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
kdc_1       | Oct 30 05:57:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
kdc_1       | Oct 30 05:57:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572414978, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 05:57:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 05:57:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 30 05:57:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 05:57:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 05:57:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:57:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:57:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 05:57:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 30 05:57:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 30 05:57:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 
kdc_1       | Oct 30 05:57:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
kdc_1       | Oct 30 05:57:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
kdc_1       | Oct 30 05:57:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
kdc_1       | Oct 30 05:57:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,660 WARN ipc.Server: Auth failed for 172.18.0.2:33984:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
kdc_1       | Oct 30 05:57:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030T060027Z
kdc_1       | Oct 30 05:57:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:57:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-30 06:00:27,664 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 05:57:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415024, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
kdc_1       | Oct 30 05:57:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 30 05:57:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
kdc_1       | Oct 30 05:57:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Oct 30 05:58:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:58:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 05:58:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 05:58:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 30 05:58:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 05:58:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 30 05:58:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 05:58:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 30 05:58:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 30 05:58:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Oct 30 05:58:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 30 05:58:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Oct 30 05:58:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Oct 30 05:58:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
kdc_1       | Oct 30 05:58:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
kdc_1       | Oct 30 05:58:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 05:58:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 05:58:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 05:58:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Oct 30 05:58:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 05:58:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Oct 30 05:58:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 05:58:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Oct 30 05:59:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	... 33 more
kdc_1       | Oct 30 05:59:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
kdc_1       | Oct 30 05:59:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,664 WARN ipc.Server: Auth failed for 172.18.0.2:33986:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
kdc_1       | Oct 30 05:59:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 05:59:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 05:59:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415074, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
kdc_1       | Oct 30 05:59:14 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415154, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,668 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
kdc_1       | Oct 30 05:59:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415154, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
kdc_1       | Oct 30 05:59:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415154, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
kdc_1       | Oct 30 05:59:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415154, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 05:59:21 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415161, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 05:59:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415161, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
kdc_1       | Oct 30 05:59:24 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415164, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
kdc_1       | Oct 30 05:59:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415164, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
kdc_1       | Oct 30 05:59:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415164, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
kdc_1       | Oct 30 05:59:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415164, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
kdc_1       | Oct 30 05:59:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415164, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 30 05:59:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415164, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
kdc_1       | Oct 30 05:59:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415177, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
kdc_1       | Oct 30 05:59:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415177, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Oct 30 05:59:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415177, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 30 05:59:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415181, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 05:59:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415181, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 05:59:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415181, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 05:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415186, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 06:00:17 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-30 06:00:27,668 WARN ipc.Server: Auth failed for 172.18.0.2:33988:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 06:00:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 06:00:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 06:00:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
kdc_1       | Oct 30 06:00:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
kdc_1       | Oct 30 06:00:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 06:00:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 06:00:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Oct 30 06:00:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Oct 30 06:00:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-30 06:00:27,672 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 06:01:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Oct 30 06:01:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Oct 30 06:01:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
kdc_1       | Oct 30 06:01:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
kdc_1       | Oct 30 06:01:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 06:01:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 06:01:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 06:01:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	... 60 more
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 06:01:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Oct 30 06:01:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 06:01:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 06:01:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 06:01:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 06:01:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Oct 30 06:01:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 06:01:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Oct 30 06:01:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Oct 30 06:01:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Oct 30 06:01:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 06:01:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 06:02:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 06:02:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	... 92 more
kdc_1       | Oct 30 06:02:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 06:02:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-30 06:00:27,672 WARN ipc.Server: Auth failed for 172.18.0.2:33990:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
om_1        | 20191030T060027Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 06:02:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 06:02:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
kdc_1       | Oct 30 06:02:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,676 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
kdc_1       | Oct 30 06:02:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 20191030/us-west-1/s3/aws4_request
kdc_1       | Oct 30 06:02:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
kdc_1       | Oct 30 06:02:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Oct 30 06:02:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 06:02:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 06:02:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 06:03:14 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415394, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 06:03:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415394, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 06:03:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415400, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Oct 30 06:03:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415400, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Oct 30 06:03:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415413, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 06:03:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415413, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 06:03:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415419, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 06:03:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415419, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 06:03:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415426, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 06:03:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415426, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Oct 30 06:03:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415432, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Oct 30 06:03:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415432, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Oct 30 06:04:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415442, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
kdc_1       | Oct 30 06:04:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415442, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
kdc_1       | Oct 30 06:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415450, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Oct 30 06:04:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415450, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,677 WARN ipc.Server: Auth failed for 172.18.0.2:33992:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	... 101 more
kdc_1       | Oct 30 06:04:21 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415461, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 2019-10-30 06:00:27,485 WARN server.HttpChannel: //s3g:9878/bucket-test123
kdc_1       | Oct 30 06:04:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415461, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Oct 30 06:04:28 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415468, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-30 06:00:27,681 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 06:04:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415468, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 
kdc_1       | Oct 30 06:04:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415474, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
kdc_1       | Oct 30 06:04:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415474, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
kdc_1       | Oct 30 06:04:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415480, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
kdc_1       | Oct 30 06:04:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415480, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
kdc_1       | Oct 30 06:04:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415485, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Oct 30 06:04:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415485, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Oct 30 06:04:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415495, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Oct 30 06:04:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415495, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Oct 30 06:05:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415504, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
kdc_1       | Oct 30 06:05:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415504, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
kdc_1       | Oct 30 06:05:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415512, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
kdc_1       | Oct 30 06:05:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415512, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
kdc_1       | Oct 30 06:05:23 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415523, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Oct 30 06:05:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415523, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 06:05:30 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415530, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
kdc_1       | Oct 30 06:05:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415530, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 30 06:05:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415541, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 
kdc_1       | Oct 30 06:05:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415541, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
kdc_1       | Oct 30 06:05:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415547, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Oct 30 06:05:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415547, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Oct 30 06:05:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415552, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 06:05:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415552, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
kdc_1       | Oct 30 06:05:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415558, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
kdc_1       | Oct 30 06:06:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415558, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
kdc_1       | Oct 30 06:06:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415566, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-30 06:00:27,682 WARN ipc.Server: Auth failed for 172.18.0.2:33994:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 06:06:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415566, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 20191030T060027Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
kdc_1       | Oct 30 06:06:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415573, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
kdc_1       | Oct 30 06:06:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415573, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-30 06:00:27,686 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Oct 30 06:06:21 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415581, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 20191030T060027Z
kdc_1       | Oct 30 06:06:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415581, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
kdc_1       | Oct 30 06:06:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415589, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
kdc_1       | Oct 30 06:06:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415589, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
kdc_1       | Oct 30 06:06:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415595, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
kdc_1       | Oct 30 06:06:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415595, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
kdc_1       | Oct 30 06:06:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415604, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Oct 30 06:06:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415604, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
kdc_1       | Oct 30 06:06:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415612, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	... 13 more
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Oct 30 06:06:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415612, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Oct 30 06:06:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415617, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 1. javax.enterprise.inject.CreationException
kdc_1       | Oct 30 06:06:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415617, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 
kdc_1       | Oct 30 06:07:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415624, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
kdc_1       | Oct 30 06:07:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415624, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Oct 30 06:07:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415630, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Oct 30 06:07:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415630, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Oct 30 06:07:15 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415635, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Oct 30 06:07:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415635, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Oct 30 06:07:21 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415641, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Oct 30 06:07:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415641, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Oct 30 06:07:27 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415647, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
kdc_1       | Oct 30 06:07:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415647, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Oct 30 06:07:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415653, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Oct 30 06:07:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415653, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Oct 30 06:07:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415659, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Oct 30 06:07:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415659, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 30 06:07:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415666, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,686 WARN ipc.Server: Auth failed for 172.18.0.2:33996:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191030T060027Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
kdc_1       | Oct 30 06:07:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415666, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
kdc_1       | Oct 30 06:07:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415671, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
kdc_1       | Oct 30 06:07:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.2: ISSUE: authtime 1572415671, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-10-30 06:00:27,691 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
kdc_1       | Oct 30 06:07:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415676, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191030T060027Z
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
kdc_1       | Oct 30 06:07:56 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.2: ISSUE: authtime 1572415676, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
kdc_1       | Oct 30 06:07:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1572415217, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	... 33 more
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-10-30 06:00:27,691 WARN ipc.Server: Auth failed for 172.18.0.2:33998:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 20191030T060027Z
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-30 06:00:27,695 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 20191030T060027Z
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-30 06:00:27,695 WARN ipc.Server: Auth failed for 172.18.0.2:34000:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060027Z
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-30 06:00:29,709 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 20191030T060029Z
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-10-30 06:00:29,709 WARN ipc.Server: Auth failed for 172.18.0.2:34090:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060029Z
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-30 06:00:29,715 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 20191030T060029Z
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	... 92 more
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-30 06:00:29,716 WARN ipc.Server: Auth failed for 172.18.0.2:34092:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060029Z
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:00:29,722 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 20191030T060029Z
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 2019-10-30 06:00:27,650 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:27,655 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 2019-10-30 06:00:27,655 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 2019-10-30 06:00:27,661 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 2019-10-30 06:00:27,661 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 20191030T060027Z
om_1        | 2019-10-30 06:00:29,722 WARN ipc.Server: Auth failed for 172.18.0.2:34094:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 20191030T060029Z
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 2019-10-30 06:00:27,665 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:27,665 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 20191030T060027Z
om_1        | 2019-10-30 06:00:29,727 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 20191030T060029Z
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 2019-10-30 06:00:27,669 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 20191030T060027Z
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 2019-10-30 06:00:27,669 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 2019-10-30 06:00:27,673 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 2019-10-30 06:00:27,673 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:00:29,727 WARN ipc.Server: Auth failed for 172.18.0.2:34096:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
om_1        | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:27,677 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 20191030T060027Z
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:00:29,733 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 20191030T060029Z
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 2019-10-30 06:00:27,678 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:27,682 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 2019-10-30 06:00:27,683 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 2019-10-30 06:00:27,686 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:27,687 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:00:29,733 WARN ipc.Server: Auth failed for 172.18.0.2:34098:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
om_1        | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 2019-10-30 06:00:27,691 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:00:29,738 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 20191030T060029Z
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 2019-10-30 06:00:27,692 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 20191030T060027Z
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 2019-10-30 06:00:27,696 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 2019-10-30 06:00:27,696 [qtp359368949-30] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 2019-10-30 06:00:27,696 [qtp359368949-30] ERROR      - Couldn't create RpcClient protocol exception: 
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-30 06:00:29,739 WARN ipc.Server: Auth failed for 172.18.0.2:34104:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 20191030T060029Z
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:00:29,744 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 20191030T060029Z
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-30 06:00:29,745 WARN ipc.Server: Auth failed for 172.18.0.2:34106:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191030T060029Z
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-30 06:00:29,750 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 20191030T060029Z
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-30 06:00:29,750 WARN ipc.Server: Auth failed for 172.18.0.2:34108:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 20191030T060029Z
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-30 06:00:29,755 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 20191030T060029Z
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:00:29,755 WARN ipc.Server: Auth failed for 172.18.0.2:34110:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 20191030T060029Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-30 06:00:29,760 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 20191030T060029Z
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-30 06:00:29,760 WARN ipc.Server: Auth failed for 172.18.0.2:34112:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 20191030T060029Z
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
s3g_1       | Oct 30, 2019 6:00:27 AM org.glassfish.jersey.internal.Errors logErrors
om_1        | 2019-10-30 06:00:29,765 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
om_1        | 20191030T060029Z
s3g_1       | MultiException stack 1 of 1
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-30 06:00:29,765 WARN ipc.Server: Auth failed for 172.18.0.2:34114:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 20191030T060029Z
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 06:00:37,117 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 20191030T060037Z
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-30 06:00:37,118 WARN ipc.Server: Auth failed for 172.18.0.2:34444:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 20191030T060037Z
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-30 06:00:37,122 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 20191030T060037Z
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	... 92 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:00:37,123 WARN ipc.Server: Auth failed for 172.18.0.2:34446:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060027Z
om_1        | 20191030T060037Z
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-30 06:00:37,126 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060037Z
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-30 06:00:37,127 WARN ipc.Server: Auth failed for 172.18.0.2:34448:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060037Z
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	... 101 more
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 
om_1        | 2019-10-30 06:00:37,130 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 
om_1        | 20191030T060037Z
s3g_1       | 2019-10-30 06:00:27,700 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-30 06:00:37,130 WARN ipc.Server: Auth failed for 172.18.0.2:34450:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060037Z
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-30 06:00:37,134 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 20191030T060037Z
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-30 06:00:37,134 WARN ipc.Server: Auth failed for 172.18.0.2:34452:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191030T060037Z
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-30 06:00:37,139 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 20191030T060037Z
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	... 33 more
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 06:00:37,139 WARN ipc.Server: Auth failed for 172.18.0.2:34454:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 20191030T060037Z
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 2019-10-30 06:00:37,143 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 20191030T060037Z
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-30 06:00:37,144 WARN ipc.Server: Auth failed for 172.18.0.2:34456:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191030T060037Z
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-10-30 06:00:37,148 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060037Z
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	... 92 more
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 20191030T060027Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-30 06:00:37,148 WARN ipc.Server: Auth failed for 172.18.0.2:34458:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060037Z
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-30 06:00:37,152 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 20191030T060037Z
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-30 06:00:27,702 WARN server.HttpChannel: //s3g:9878/bucket-test123
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-10-30 06:00:37,152 WARN ipc.Server: Auth failed for 172.18.0.2:34460:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060037Z
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-10-30 06:00:37,156 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191030T060037Z
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-30 06:00:37,156 WARN ipc.Server: Auth failed for 172.18.0.2:34462:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 20191030T060037Z
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-30 06:00:37,160 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 20191030T060037Z
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 20191030/us-west-1/s3/aws4_request
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	... 13 more
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-30 06:00:37,160 WARN ipc.Server: Auth failed for 172.18.0.2:34464:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 20191030T060037Z
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 20191030/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-30 06:00:40,733 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:00:40,744 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:00:41,478 [IPC Server handler 16 on 9862] INFO       - created volume:fstest for user:testuser/scm@EXAMPLE.COM
om_1        | 2019-10-30 06:00:43,240 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:00:43,253 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:00:43,920 [IPC Server handler 7 on 9862] INFO       - created volume:fstest2 for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-30 06:00:45,874 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-30 06:00:45,883 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:00:48,604 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:00:48,618 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-30 06:00:51,080 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-30 06:00:51,089 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-30 06:00:53,865 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:00:53,877 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-30 06:00:56,612 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-30 06:00:56,626 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-30 06:00:58,964 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-30 06:00:58,975 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-30 06:01:01,738 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-30 06:01:01,750 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 33 more
om_1        | 2019-10-30 06:01:05,826 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-10-30 06:01:05,844 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 2019-10-30 06:01:08,561 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-10-30 06:01:08,577 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-30 06:01:12,726 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 2019-10-30 06:01:12,737 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-30 06:01:15,435 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-30 06:01:15,447 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 06:01:18,113 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-30 06:01:18,129 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-30 06:01:20,614 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-30 06:01:20,625 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-30 06:01:23,451 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-30 06:01:23,464 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 06:01:26,191 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2019-10-30 06:01:26,203 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-30 06:01:30,292 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-30 06:01:30,303 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-30 06:01:32,950 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-10-30 06:01:32,963 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-30 06:01:35,677 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
om_1        | 2019-10-30 06:01:35,687 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:01:39,631 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:01:39,646 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-30 06:01:41,971 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:01:41,980 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030T060027Z
om_1        | 2019-10-30 06:01:44,906 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:01:44,918 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 561fa90073ca1bc7cfb70384dad658206a56d1e8616502e5a979b800122b3aed, signature=2228a1a9eb5d15fd4a93c04cccf164a71024b2dba8b78b6b243decbd7c8215c5, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 06:01:47,273 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-30 06:01:47,282 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:01:49,937 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:01:49,948 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:01:52,352 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-30 06:01:52,362 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:01:55,032 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-30 06:01:55,044 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:01:57,338 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:01:57,347 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:02:00,161 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:02:00,174 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:02:02,759 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 06:02:02,772 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-30 06:02:07,144 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-30 06:02:07,155 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:02:11,346 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:02:11,359 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-30 06:02:13,885 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-30 06:02:13,895 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-30 06:02:16,555 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:02:16,565 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:02:19,325 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-30 06:02:19,340 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-30 06:02:23,893 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-30 06:02:23,906 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-30 06:02:28,546 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:02:28,556 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:02:32,968 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:02:32,983 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:02:35,624 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:02:35,637 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:02:38,454 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:02:38,468 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:02:42,425 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:02:42,437 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 06:02:42,895 [IPC Server handler 16 on 9862] ERROR      - Check access operation failed for volume:pqrs
om_1        | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume pqrs is not found
om_1        | 	at org.apache.hadoop.ozone.om.VolumeManagerImpl.checkAccess(VolumeManagerImpl.java:685)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-30 06:00:29,710 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:29,716 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060029Z
om_1        | 	at org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer.checkAccess(OzoneNativeAuthorizer.java:101)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1628)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1591)
s3g_1       | 2019-10-30 06:00:29,717 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getVolumeInfo(OzoneManager.java:1751)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.infoVolume(OzoneManagerRequestHandler.java:520)
s3g_1       | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:177)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:219)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1       | 2019-10-30 06:00:29,723 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 20191030T060029Z
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102)
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:29,723 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 20191030T060029Z
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 2019-10-30 06:00:29,728 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 20191030T060029Z
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-10-30 06:03:16,095 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:03:16,106 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:03:19,434 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:03:19,435 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:03:19,439 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:03:21,968 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:03:21,979 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:03:25,145 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 06:03:25,146 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-10-30 06:00:29,728 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:25,148 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:29,985 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:29,986 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 06:03:29,989 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-30 06:00:29,734 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:30,997 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:30,999 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:31,002 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 06:03:31,686 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 2019-10-30 06:00:29,734 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:31,687 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:03:31,691 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:32,382 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:32,382 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 06:03:32,385 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-30 06:00:29,739 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:34,950 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:34,959 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:03:37,977 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:03:37,979 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:03:37,983 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:38,625 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:29,740 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:38,627 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 06:03:38,629 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-30 06:00:29,746 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:38,638 [IPC Server handler 16 on 9862] ERROR      - S3Bucket Creation Failed for userName: 2724f42bcd3225359401cb62da89c51d, s3BucketName bucket-55782, VolumeName s32724f42bcd3225359401cb62da89c51d
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:41,086 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:41,095 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:29,746 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 06:03:44,153 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 2019-10-30 06:00:29,751 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:44,154 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:44,156 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:44,830 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 06:03:44,830 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-10-30 06:00:29,751 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:44,834 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:45,451 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:45,451 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 06:03:45,453 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-10-30 06:00:29,756 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:48,061 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:29,756 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:48,070 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:51,242 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 06:03:51,243 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-10-30 06:00:29,761 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:51,245 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:51,868 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:51,869 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:29,761 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:51,871 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 2019-10-30 06:03:54,387 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-10-30 06:00:29,766 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:54,397 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:03:57,485 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:57,486 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:57,488 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:29,766 [qtp359368949-110] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 2019-10-30 06:03:58,151 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 2019-10-30 06:00:29,767 [qtp359368949-110] ERROR      - Couldn't create RpcClient protocol exception: 
om_1        | 2019-10-30 06:03:58,152 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:03:58,154 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:03:58,873 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:03:58,874 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:03:58,876 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:03:59,655 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:03:59,656 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:03:59,659 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 06:04:01,067 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:04:01,068 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-30 06:04:01,071 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-30 06:04:03,772 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-10-30 06:04:03,783 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-30 06:04:06,745 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-30 06:04:06,746 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:04:06,747 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:04:07,481 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:04:07,481 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-30 06:04:07,484 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:04:08,372 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 06:04:08,372 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-30 06:04:08,375 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-30 06:04:09,182 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-30 06:04:09,183 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-30 06:04:09,185 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:04:09,887 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-30 06:04:09,887 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:04:09,889 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-30 06:04:12,720 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-30 06:04:12,730 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-30 06:04:15,687 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-30 06:04:15,687 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:04:15,690 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 06:04:16,362 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-30 06:04:16,363 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-30 06:04:16,365 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-30 06:04:19,676 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-30 06:04:19,677 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-30 06:04:19,680 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-30 06:04:20,471 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-30 06:04:20,471 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:04:20,474 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-30 06:04:20,494 [IPC Server handler 14 on 9862] ERROR      - MultipartUpload: /s32724f42bcd3225359401cb62da89c51d/bucket-05265/multipartKey2Part number: 1size 6 is less than minimum part size 5242880
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:04:20,495 [IPC Server handler 14 on 9862] ERROR      - MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-05265
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-05265key: multipartKey2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-10-30 06:04:22,938 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:04:22,947 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-30 06:04:25,812 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-30 06:04:25,812 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-30 06:04:25,815 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-30 06:04:26,471 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-30 06:04:26,471 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-10-30 06:04:26,473 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:04:27,255 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-30 06:04:27,256 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-30 06:04:27,257 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-30 06:04:27,969 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-30 06:04:27,969 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-30 06:04:27,972 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-30 06:04:27,987 [IPC Server handler 3 on 9862] ERROR      - MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-05265
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-05265key: multipartKey3
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:195)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:04:30,419 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:04:30,428 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-30 06:04:33,470 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-30 06:04:33,471 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-30 06:04:33,474 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-30 06:04:34,105 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-30 06:04:34,105 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-30 06:04:34,107 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-30 06:04:36,481 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-30 06:04:36,491 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-30 06:04:39,534 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-30 06:04:39,535 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-30 06:04:39,538 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:04:39,552 [IPC Server handler 0 on 9862] ERROR      - Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-05265
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-05265key: multipartKey5
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:116)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-10-30 06:04:42,026 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 2019-10-30 06:04:42,039 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-30 06:04:44,949 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:04:44,950 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:04:44,952 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-30 06:04:44,967 [IPC Server handler 7 on 9862] ERROR      - ALLOCATE_KEY failed for Key: multipartKey in volume/bucket:s32724f42bcd3225359401cb62da89c51d/bucket-05265
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:471)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:423)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:182)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-10-30 06:04:47,517 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 2019-10-30 06:04:47,529 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Oct 30, 2019 6:00:29 AM org.glassfish.jersey.internal.Errors logErrors
om_1        | 2019-10-30 06:04:50,417 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
om_1        | 2019-10-30 06:04:50,417 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | MultiException stack 1 of 1
om_1        | 2019-10-30 06:04:50,419 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 2019-10-30 06:04:51,159 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 2019-10-30 06:04:51,159 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 2019-10-30 06:04:51,161 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-10-30 06:04:52,079 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-30 06:04:52,080 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-30 06:04:52,082 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 2019-10-30 06:04:52,910 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:04:52,911 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-10-30 06:04:52,914 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-30 06:04:53,620 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-30 06:04:53,620 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-30 06:04:53,623 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 2019-10-30 06:04:54,269 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:04:54,270 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-30 06:04:54,272 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-30 06:04:54,958 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-30 06:04:54,958 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:04:54,960 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:04:57,475 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-30 06:04:57,484 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 06:05:00,667 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-30 06:05:00,667 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-30 06:05:00,669 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:05:00,741 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-30 06:05:00,741 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:05:00,744 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-30 06:05:00,760 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-30 06:05:00,761 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-30 06:05:00,763 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-30 06:05:01,368 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-10-30 06:05:01,369 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-30 06:05:01,371 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:05:02,004 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-30 06:05:02,004 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:05:02,009 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-30 06:05:02,073 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-30 06:05:02,073 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-10-30 06:05:02,085 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-10-30 06:05:03,188 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-10-30 06:05:03,189 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-30 06:05:03,191 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-30 06:05:05,785 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:05:05,793 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-30 06:05:08,694 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-30 06:05:08,694 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:05:08,696 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:05:09,488 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-30 06:05:09,488 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-30 06:05:09,490 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-30 06:05:10,091 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-30 06:05:10,092 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-10-30 06:05:10,093 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-30 06:05:11,051 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-30 06:05:11,051 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-30 06:05:11,053 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-30 06:05:11,654 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-30 06:05:11,655 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-30 06:05:11,657 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-10-30 06:05:14,461 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-10-30 06:05:14,472 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-30 06:05:17,787 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-30 06:05:17,787 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-10-30 06:05:17,790 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:05:18,884 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:05:18,885 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-30 06:05:18,887 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-30 06:05:19,538 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-30 06:05:19,538 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-30 06:05:19,541 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 2019-10-30 06:05:20,706 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-30 06:05:20,706 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 2019-10-30 06:05:20,710 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-30 06:05:21,721 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:05:21,722 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-30 06:05:21,724 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 2019-10-30 06:05:22,376 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-30 06:05:22,377 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-30 06:05:22,378 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 2019-10-30 06:05:25,252 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-30 06:05:25,261 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 2019-10-30 06:05:28,442 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:05:28,443 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 2019-10-30 06:05:28,445 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 2019-10-30 06:05:29,134 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-30 06:05:29,135 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-30 06:05:29,137 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-30 06:05:29,817 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-10-30 06:05:29,818 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 2019-10-30 06:05:29,820 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-30 06:05:32,424 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-30 06:05:32,433 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-30 06:05:35,476 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-30 06:05:35,477 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-30 06:05:35,479 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:05:36,088 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 06:05:36,089 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:05:36,091 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-30 06:05:36,735 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:05:36,735 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:05:36,738 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 92 more
om_1        | 2019-10-30 06:05:37,495 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:05:37,495 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191030T060029Z
om_1        | 2019-10-30 06:05:37,498 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:05:38,145 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:05:38,146 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 06:05:38,149 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-30 06:05:38,927 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-30 06:05:38,928 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-30 06:05:38,929 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-30 06:05:39,614 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:05:39,614 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:05:39,616 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 06:05:40,489 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-30 06:05:40,490 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-30 06:05:40,492 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:05:43,065 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-30 06:05:43,076 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-30 06:05:46,019 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-30 06:05:46,020 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:05:46,022 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-30 06:05:46,657 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:05:46,657 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 06:05:46,661 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:05:49,221 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-30 06:05:49,230 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:05:52,182 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:05:52,183 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-30 06:05:52,186 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-30 06:05:54,567 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
om_1        | 2019-10-30 06:05:54,575 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 
om_1        | 2019-10-30 06:05:57,657 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 
om_1        | 2019-10-30 06:05:57,658 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-10-30 06:00:29,771 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-30 06:05:57,662 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:00,143 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 
om_1        | 2019-10-30 06:06:00,152 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 2019-10-30 06:06:03,192 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-10-30 06:06:03,192 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-10-30 06:06:03,194 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-10-30 06:06:03,863 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-10-30 06:06:03,864 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-10-30 06:06:03,866 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-10-30 06:06:04,581 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-30 06:06:04,581 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:06:04,584 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:05,301 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-10-30 06:06:05,301 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-10-30 06:06:05,303 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2019-10-30 06:06:05,961 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 2019-10-30 06:06:05,961 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 2019-10-30 06:06:05,967 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 2019-10-30 06:06:08,485 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 2019-10-30 06:06:08,494 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 2019-10-30 06:06:11,391 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-10-30 06:06:11,391 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-10-30 06:06:11,395 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:11,978 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:06:11,979 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 2019-10-30 06:06:11,984 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-10-30 06:06:12,548 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-30 06:06:12,549 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:06:12,551 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:15,040 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:06:15,049 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:18,251 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 2019-10-30 06:06:18,252 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-10-30 06:06:18,253 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 2019-10-30 06:06:18,998 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:06:18,999 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 2019-10-30 06:06:19,002 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-30 06:06:19,656 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-30 06:06:19,657 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-30 06:06:19,659 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-10-30 06:06:20,281 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-10-30 06:06:20,282 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-10-30 06:06:20,284 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:20,938 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:06:20,939 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-10-30 06:06:20,941 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-10-30 06:06:23,350 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-10-30 06:06:23,359 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-10-30 06:06:26,376 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-10-30 06:06:26,376 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-10-30 06:06:26,379 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:27,104 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-10-30 06:06:27,105 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:06:27,107 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:27,720 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:06:27,720 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:06:27,723 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:06:28,281 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:06:28,282 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-10-30 06:06:28,284 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-10-30 06:06:28,911 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-10-30 06:06:28,911 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-10-30 06:06:28,914 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-10-30 06:06:31,341 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-10-30 06:06:31,350 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-10-30 06:06:34,284 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-10-30 06:06:34,284 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-10-30 06:06:34,285 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-10-30 06:06:36,739 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:06:36,752 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:39,807 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-10-30 06:06:39,807 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:06:39,810 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:40,413 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:06:40,413 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-10-30 06:06:40,415 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om_1        | 2019-10-30 06:06:41,155 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-10-30 06:06:41,155 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2019-10-30 06:06:41,157 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-10-30 06:06:41,862 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-10-30 06:06:41,862 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:06:41,865 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-10-30 06:06:42,546 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:06:42,546 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 2019-10-30 06:06:42,548 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-10-30 06:06:43,179 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-10-30 06:06:43,179 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 06:06:43,182 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-30 06:06:43,820 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-30 06:06:43,820 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-30 06:06:43,822 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:46,226 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 2019-10-30 06:06:46,237 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 2019-10-30 06:06:49,159 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:06:49,159 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-10-30 06:06:49,162 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-10-30 06:06:49,752 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 2019-10-30 06:06:49,753 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-10-30 06:06:49,754 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:06:50,455 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-10-30 06:06:50,456 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-10-30 06:06:50,458 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 2019-10-30 06:06:51,069 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-10-30 06:06:51,069 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-10-30 06:06:51,072 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-10-30 06:06:51,657 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:06:51,657 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-10-30 06:06:51,659 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-10-30 06:06:54,075 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2019-10-30 06:06:54,085 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-10-30 06:06:57,085 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-10-30 06:06:57,085 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-10-30 06:06:57,087 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-10-30 06:06:59,639 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-10-30 06:06:59,649 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-10-30 06:07:02,658 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-10-30 06:07:02,659 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-10-30 06:07:02,661 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	... 60 more
om_1        | 2019-10-30 06:07:03,339 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-10-30 06:07:03,340 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 2019-10-30 06:07:03,342 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-10-30 06:07:03,973 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:07:03,974 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-10-30 06:07:03,975 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 2019-10-30 06:07:06,463 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-10-30 06:07:06,474 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-30 06:07:09,585 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-10-30 06:07:09,585 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-10-30 06:07:09,587 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
om_1        | 2019-10-30 06:07:12,006 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-10-30 06:07:12,015 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:07:14,882 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:07:14,882 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-10-30 06:07:14,884 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-10-30 06:07:17,419 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-10-30 06:07:17,429 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-10-30 06:07:20,463 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:07:20,464 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:07:20,471 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-10-30 06:07:22,943 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:07:22,952 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 2019-10-30 06:07:25,709 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 2019-10-30 06:07:25,709 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:07:25,711 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:07:26,360 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:07:26,360 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-10-30 06:07:26,362 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-10-30 06:07:28,832 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-10-30 06:07:28,841 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-10-30 06:07:31,900 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-10-30 06:07:31,900 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-10-30 06:07:31,903 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-10-30 06:07:32,621 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-10-30 06:07:32,622 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-10-30 06:07:32,624 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-10-30 06:07:35,100 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:07:35,112 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-10-30 06:07:38,014 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-10-30 06:07:38,014 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-10-30 06:07:38,017 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-10-30 06:07:38,729 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	... 101 more
om_1        | 2019-10-30 06:07:38,730 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-10-30 06:00:29,772 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 2019-10-30 06:07:38,732 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-10-30 06:07:41,290 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:07:41,303 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-10-30 06:07:44,366 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 2019-10-30 06:07:44,367 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 2019-10-30 06:07:44,370 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-10-30 06:07:45,028 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-10-30 06:07:45,028 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 2019-10-30 06:07:45,031 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 2019-10-30 06:07:45,663 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
om_1        | 2019-10-30 06:07:45,664 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-10-30 06:07:45,666 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-10-30 06:07:48,191 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-10-30 06:07:48,200 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 2019-10-30 06:07:51,111 [Socket Reader #1 for port 9862] INFO       - 7f9a8226bafa14f12d0f82d324d612dbf5b1689064cc116668b07bfc5b9ac87f
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
om_1        | 2019-10-30 06:07:51,112 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 2019-10-30 06:07:51,116 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 2019-10-30 06:07:53,572 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-10-30 06:07:53,583 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060029Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 339876a21bc14f0679b48990ec39d6c56df85c98c2ab376b0f17606e5dfc40b9, signature=c2a3daa525250c4deb56f88bf294fa28917998ea0625fe0ce898168e33791e74, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-30 06:00:37,118 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,123 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,123 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,127 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,128 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,131 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,131 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,135 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,135 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,140 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,140 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,144 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,145 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,149 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,149 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,153 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,153 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,157 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,157 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
s3g_1       | 2019-10-30 06:00:37,160 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-10-30 06:00:37,160 [qtp359368949-111] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
s3g_1       | 2019-10-30 06:00:37,161 [qtp359368949-111] ERROR      - Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Oct 30, 2019 6:00:37 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2019-10-30 06:00:37,164 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-30 06:00:37,165 WARN server.HttpChannel: //s3g:9878/bucket-test123
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191030T060037Z
s3g_1       | 20191030/us-west-1/s3/aws4_request
s3g_1       | 9ff295dfbb1a8d90a202cb3359d7cb5a1ce9a731534467fabeaaa324bd84aa24, signature=4ffa2d7e7d122ecfe17074d072d05adcaa6a2c02f20a2c159ea0c7dd225b54c7, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-10-30 06:03:19,456 [qtp359368949-127] INFO       - Location is /bucket-93979
s3g_1       | 2019-10-30 06:03:25,581 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2019-10-30 06:03:25,623 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2019-10-30 06:03:25,623 INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2019-10-30 06:03:25,625 WARN impl.MetricsSystemImpl: Sink prometheus already exists!
s3g_1       | 2019-10-30 06:03:37,996 [qtp359368949-127] INFO       - Location is /bucket-55782
s3g_1       | 2019-10-30 06:03:38,644 [qtp359368949-110] INFO       - Location is /bucket-55782
s3g_1       | 2019-10-30 06:03:44,169 [qtp359368949-127] INFO       - Location is /bucket-86755
s3g_1       | 2019-10-30 06:03:45,498 [qtp359368949-127] ERROR      - Exception occurred in headBucket
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:103)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:81)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:250)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-10-30 06:03:51,260 [qtp359368949-110] INFO       - Location is /bucket-98735
s3g_1       | 2019-10-30 06:03:57,503 [qtp359368949-30] INFO       - Location is /bucket-05265
s3g_1       | 2019-10-30 06:03:59,678 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:01,092 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:07,505 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:08,393 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:16,381 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:19,712 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:20,496 [qtp359368949-203] ERROR      - Error in Complete Multipart Upload Request for bucket: bucket-05265, key: multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-05265key: multipartKey2
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1104)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.completeMultipartUpload(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:883)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:445)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:498)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-10-30 06:04:26,490 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:27,275 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:27,988 [qtp359368949-203] ERROR      - Error in Complete Multipart Upload Request for bucket: bucket-05265, key: multipartKey3
s3g_1       | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-05265key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1104)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.completeMultipartUpload(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:883)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:445)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:498)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-10-30 06:04:51,176 [qtp359368949-172] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:04:52,098 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:05:00,769 [qtp359368949-110] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:05:00,785 [qtp359368949-27] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:05:00,785 [qtp359368949-203] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:05:10,182 [qtp359368949-27] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=149, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=135, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=181, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:563)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=161, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=165, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=193, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=153, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=134, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=197, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=157, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=177, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:563)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=49, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=133, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=201, target=172.18.0.10:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=57, target=172.18.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=53, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Oct 30, 2019 6:05:19 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=145, target=172.18.0.6:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2019-10-30 06:05:19,658 [qtp359368949-127] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:05:20,945 [qtp359368949-331] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-10-30 06:05:35,491 [qtp359368949-127] INFO       - Location is /bucket-55209
s3g_1       | 2019-10-30 06:05:36,103 [qtp359368949-331] INFO       - Location is /destbucket-60769
s3g_1       | 2019-10-30 06:06:03,207 [qtp359368949-213] INFO       - Location is /bucket-76401
s3g_1       | 2019-10-30 06:06:39,822 [qtp359368949-110] INFO       - Location is /bucket-84248
s3g_1       | 2019-10-30 06:06:49,175 [qtp359368949-213] INFO       - Location is /bucket-16620
s3g_1       | 2019-10-30 06:07:51,129 [qtp359368949-110] INFO       - Location is /bucket-15448
s3g_1       | 2019-10-30 06:07:56,080 [qtp359368949-172] ERROR      - Error: 
s3g_1       | java.lang.NullPointerException
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:78)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
