<?xml version="1.0" encoding="UTF-8"?>
<robot rpa="false" generated="20191115 21:02:44.884" generator="Robot 3.1.2 (Python 2.7.15 on linux2)">
<suite source="/opt/ozone/smoketest/ozonefs/hadoopo3fs.robot" id="s1" name="hadoop27-hadoopo3fs">
<test id="s1-t1" name="Test hadoop dfs">
<kw name="Generate Random String" library="String">
<doc>Generates a string with a desired ``length`` from the given ``chars``.</doc>
<arguments>
<arg>5</arg>
<arg>[NUMBERS]</arg>
</arguments>
<assign>
<var>${random}</var>
</assign>
<msg timestamp="20191115 21:02:44.936" level="INFO">${random} = 93163</msg>
<status status="PASS" endtime="20191115 21:02:44.936" starttime="20191115 21:02:44.935"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>hdfs dfs -put /opt/hadoop/NOTICE.txt o3fs://bucket1.vol1/${PREFIX}-${random}</arg>
</arguments>
<assign>
<var>${result}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191115 21:02:44.937" level="INFO">Running command 'hdfs dfs -put /opt/hadoop/NOTICE.txt o3fs://bucket1.vol1/ozone-93163 2&gt;&amp;1'.</msg>
<msg timestamp="20191115 21:03:24.873" level="INFO">${rc} = 0</msg>
<msg timestamp="20191115 21:03:24.873" level="INFO">${output} = 2019-11-15 21:02:46 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 21:02:47 INFO  MetricsConfig:118 - Load...</msg>
<status status="PASS" endtime="20191115 21:03:24.873" starttime="20191115 21:02:44.936"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191115 21:03:24.874" level="INFO">2019-11-15 21:02:46 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 21:02:47 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-15 21:02:47 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-11-15 21:02:47 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
2019-11-15 21:03:19 WARN  XceiverClientRatis:277 - 3 way commit failed on pipeline Pipeline[ Id: 06860454-899b-4750-b824-2911067d4a99, Nodes: 8159075f-bd3e-46e1-b7a9-e875254ded6a{ip: 172.18.0.4, host: hadoop27_datanode_2.hadoop27_default, networkLocation: /default-rack, certSerialId: null}259a7427-e615-4380-be03-a4ca7c0c62d9{ip: 172.18.0.9, host: hadoop27_datanode_3.hadoop27_default, networkLocation: /default-rack, certSerialId: null}af129bc1-ceaf-42ff-8831-8546a1c8e9bb{ip: 172.18.0.8, host: hadoop27_datanode_1.hadoop27_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
java.util.concurrent.TimeoutException
	at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:274)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:198)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:161)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:346)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:482)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.fs.ozone.OzoneFSOutputStream.close(OzoneFSOutputStream.java:56)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:62)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:120)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:466)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:391)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:328)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:263)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:248)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:317)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:289)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:243)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:271)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:255)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:220)
	at org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:267)
	at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:201)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:165)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:287)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:340)
2019-11-15 21:03:19 INFO  XceiverClientRatis:295 - Could not commit index 6 on pipeline Pipeline[ Id: 06860454-899b-4750-b824-2911067d4a99, Nodes: 8159075f-bd3e-46e1-b7a9-e875254ded6a{ip: 172.18.0.4, host: hadoop27_datanode_2.hadoop27_default, networkLocation: /default-rack, certSerialId: null}259a7427-e615-4380-be03-a4ca7c0c62d9{ip: 172.18.0.9, host: hadoop27_datanode_3.hadoop27_default, networkLocation: /default-rack, certSerialId: null}af129bc1-ceaf-42ff-8831-8546a1c8e9bb{ip: 172.18.0.8, host: hadoop27_datanode_1.hadoop27_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN] to all the nodes. Server 8159075f-bd3e-46e1-b7a9-e875254ded6a has failed. Committed by majority.
2019-11-15 21:03:19 WARN  BlockOutputStream:352 - Failed to commit BlockId conID: 2 locID: 103143949439926273 bcsId: 6 on Pipeline[ Id: 06860454-899b-4750-b824-2911067d4a99, Nodes: 8159075f-bd3e-46e1-b7a9-e875254ded6a{ip: 172.18.0.4, host: hadoop27_datanode_2.hadoop27_default, networkLocation: /default-rack, certSerialId: null}259a7427-e615-4380-be03-a4ca7c0c62d9{ip: 172.18.0.9, host: hadoop27_datanode_3.hadoop27_default, networkLocation: /default-rack, certSerialId: null}af129bc1-ceaf-42ff-8831-8546a1c8e9bb{ip: 172.18.0.8, host: hadoop27_datanode_1.hadoop27_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. Failed nodes: [8159075f-bd3e-46e1-b7a9-e875254ded6a{ip: null, host: null, networkLocation: /default-rack, certSerialId: null}]
2019-11-15 21:03:20 ERROR GrpcClientRpc:82 - client-B09B23CD6AA4: XXX Failed RaftClientRequest:client-B09B23CD6AA4-&gt;af129bc1-ceaf-42ff-8831-8546a1c8e9bb@group-2911067D4A99, cid=3, seq=0, Watch-ALL_COMMITTED(6), null
org.apache.ratis.protocol.AlreadyClosedException: client-B09B23CD6AA4 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:59)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:109)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsyncUnordered(GrpcClientRpc.java:78)
	at org.apache.ratis.client.impl.UnorderedAsync.sendRequestWithRetry(UnorderedAsync.java:75)
	at org.apache.ratis.client.impl.UnorderedAsync.lambda$null$2(UnorderedAsync.java:120)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)</msg>
<status status="PASS" endtime="20191115 21:03:24.874" starttime="20191115 21:03:24.874"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191115 21:03:24.875" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<status status="PASS" endtime="20191115 21:03:24.875" starttime="20191115 21:03:24.875"></status>
</kw>
<msg timestamp="20191115 21:03:24.876" level="INFO">${result} = 2019-11-15 21:02:46 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 21:02:47 INFO  MetricsConfig:118 - Load...</msg>
<status status="PASS" endtime="20191115 21:03:24.876" starttime="20191115 21:02:44.936"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>hdfs dfs -ls o3fs://bucket1.vol1/</arg>
</arguments>
<assign>
<var>${result}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191115 21:03:24.877" level="INFO">Running command 'hdfs dfs -ls o3fs://bucket1.vol1/ 2&gt;&amp;1'.</msg>
<msg timestamp="20191115 21:03:27.474" level="INFO">${rc} = 0</msg>
<msg timestamp="20191115 21:03:27.474" level="INFO">${output} = 2019-11-15 21:03:26 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18...</msg>
<status status="PASS" endtime="20191115 21:03:27.474" starttime="20191115 21:03:24.877"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191115 21:03:27.476" level="INFO">2019-11-15 21:03:26 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18189 2019-11-15 21:02 o3fs://bucket1.vol1/key1
-rw-rw-rw-   3 hadoop hadoop      14978 2019-11-15 21:03 o3fs://bucket1.vol1/ozone-93163
drwxrwxrwx   - hadoop hadoop          0 2019-11-15 21:03 o3fs://bucket1.vol1/user</msg>
<status status="PASS" endtime="20191115 21:03:27.476" starttime="20191115 21:03:27.475"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191115 21:03:27.477" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<status status="PASS" endtime="20191115 21:03:27.477" starttime="20191115 21:03:27.476"></status>
</kw>
<msg timestamp="20191115 21:03:27.478" level="INFO">${result} = 2019-11-15 21:03:26 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18...</msg>
<status status="PASS" endtime="20191115 21:03:27.478" starttime="20191115 21:03:24.876"></status>
</kw>
<kw name="Should Contain" library="BuiltIn">
<doc>Fails if ``container`` does not contain ``item`` one or more times.</doc>
<arguments>
<arg>${result}</arg>
<arg>${PREFIX}-${random}</arg>
</arguments>
<status status="PASS" endtime="20191115 21:03:27.479" starttime="20191115 21:03:27.478"></status>
</kw>
<status status="PASS" endtime="20191115 21:03:27.480" critical="yes" starttime="20191115 21:02:44.934"></status>
</test>
<doc>Test ozone fs with hadoopfs</doc>
<status status="PASS" endtime="20191115 21:03:27.481" starttime="20191115 21:02:44.885"></status>
</suite>
<statistics>
<total>
<stat fail="0" pass="1">Critical Tests</stat>
<stat fail="0" pass="1">All Tests</stat>
</total>
<tag>
</tag>
<suite>
<stat fail="0" id="s1" name="hadoop27-hadoopo3fs" pass="1">hadoop27-hadoopo3fs</stat>
</suite>
</statistics>
<errors>
</errors>
</robot>
