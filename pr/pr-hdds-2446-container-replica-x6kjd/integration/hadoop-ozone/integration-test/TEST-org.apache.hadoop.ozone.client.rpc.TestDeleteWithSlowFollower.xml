<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower" time="143.773" tests="1" errors="0" skipped="0" failures="1">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="ANSI_X3.4-1968"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/integration-test/target/test-classes:/workdir/hadoop-ozone/integration-test/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.5.0-ced7dbf-SNAPSHOT/ratis-server-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.5.0-ced7dbf-SNAPSHOT/ratis-proto-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.5.0-ced7dbf-SNAPSHOT/ratis-common-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.5.0-ced7dbf-SNAPSHOT/ratis-client-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.5.0-ced7dbf-SNAPSHOT/ratis-metrics-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.5.0-ced7dbf-SNAPSHOT/ratis-netty-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.5.0-ced7dbf-SNAPSHOT/ratis-grpc-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.2.0/hadoop-minikdc-3.2.0.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-core/1.19/jmh-core-1.19.jar:/home/user/.m2/repository/net/sf/jopt-simple/jopt-simple/4.6/jopt-simple-4.6.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.19/jmh-generator-annprocess-1.19.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/../lib/tools.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:"/>
    <property name="java.vm.vendor" value="Oracle Corporation"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/integration-test/target/surefire/surefirebooter4617825004036342200.jar /workdir/hadoop-ozone/integration-test/target/surefire 2019-11-08T11-17-08_079-jvmRun1 surefire2205245109298488076tmp surefire_312131907324880509648tmp"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/integration-test/target/test-classes:/workdir/hadoop-ozone/integration-test/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.9/jackson-annotations-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.5.0-ced7dbf-SNAPSHOT/ratis-server-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.5.0-ced7dbf-SNAPSHOT/ratis-proto-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.5.0-ced7dbf-SNAPSHOT/ratis-common-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.5.0-ced7dbf-SNAPSHOT/ratis-client-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.5.0-ced7dbf-SNAPSHOT/ratis-metrics-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.5.0-ced7dbf-SNAPSHOT/ratis-netty-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.5.0-ced7dbf-SNAPSHOT/ratis-grpc-0.5.0-ced7dbf-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.34.0/jaeger-client-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.34.0/jaeger-thrift-0.34.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.34.0/jaeger-core-0.34.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.34.0/jaeger-tracerresolver-0.34.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.2.0/hadoop-minikdc-3.2.0.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.9/jackson-module-jaxb-annotations-2.9.9.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-core/1.19/jmh-core-1.19.jar:/home/user/.m2/repository/net/sf/jopt-simple/jopt-simple/4.6/jopt-simple-4.6.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.19/jmh-generator-annprocess-1.19.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.25.v20180904/jetty-server-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.25.v20180904/jetty-http-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.25.v20180904/jetty-io-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.25.v20180904/jetty-webapp-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.25.v20180904/jetty-xml-9.3.25.v20180904.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.25.v20180904/jetty-util-9.3.25.v20180904.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9/jackson-databind-2.9.9.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.0/hadoop-kms-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/../lib/tools.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.25.v20180904/jetty-servlet-9.3.25.v20180904.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.25.v20180904/jetty-security-9.3.25.v20180904.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.25.v20180904/jetty-util-ajax-9.3.25.v20180904.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre"/>
    <property name="surefire.excludesFile" value="/tools/ozone-bad-unit-tests"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/integration-test"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/integration-test/target/surefire/surefirebooter4617825004036342200.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/resources.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/rt.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jce.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_222-b10"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="ANSI_X3.4-1968"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_222"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/lib:/workdir/hadoop-ozone/integration-test/target/native/target/usr/local/lib:/workdir/hadoop-ozone/integration-test/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="Oracle Corporation"/>
    <property name="java.vm.version" value="25.222-b10"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testDeleteKeyWithSlowFollower" classname="org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower" time="122.893">
    <failure type="java.lang.AssertionError">java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.testDeleteKeyWithSlowFollower(TestDeleteWithSlowFollower.java:265)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
</failure>
    <system-out><![CDATA[2019-11-08 11:40:48,751 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:48,881 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:48,884 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:48,910 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @814ms
2019-11-08 11:40:49,009 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-08 11:40:49,009 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-08 11:40:49,010 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-08 11:40:49,010 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-08 11:40:49,010 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-08 11:40:49,010 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-08 11:40:49,022 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-08 11:40:49,022 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-08 11:40:49,023 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-08 11:40:49,424 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@78691363
2019-11-08 11:40:49,427 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-08 11:40:49,495 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-08 11:40:49,497 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-08 11:40:49,499 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(117)) - Entering startup safe mode.
2019-11-08 11:40:49,559 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-08 11:40:49,572 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:49,683 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-08 11:40:49,685 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:49,861 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-08 11:40:50,212 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-08 11:40:50,325 [Socket Reader #1 for port 34327] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34327
2019-11-08 11:40:50,348 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-08 11:40:50,349 [Socket Reader #1 for port 44128] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44128
2019-11-08 11:40:50,357 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-08 11:40:50,358 [Socket Reader #1 for port 37434] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37434
2019-11-08 11:40:50,380 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-08 11:40:50,542 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-08 11:40:50,553 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-08 11:40:50,562 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-08 11:40:50,566 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-08 11:40:50,566 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-08 11:40:50,566 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-08 11:40:50,607 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37434
2019-11-08 11:40:50,670 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-08 11:40:50,681 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-08 11:40:50,681 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-08 11:40:50,895 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:37434
2019-11-08 11:40:50,896 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-08 11:40:50,896 [IPC Server listener on 37434] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37434: starting
2019-11-08 11:40:50,899 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(792)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:44128
2019-11-08 11:40:50,900 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:44128
2019-11-08 11:40:50,901 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-08 11:40:50,901 [IPC Server listener on 44128] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44128: starting
2019-11-08 11:40:50,903 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(796)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:34327
2019-11-08 11:40:50,904 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:34327
2019-11-08 11:40:50,905 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-08 11:40:50,905 [IPC Server listener on 34327] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34327: starting
2019-11-08 11:40:50,908 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38165
2019-11-08 11:40:50,911 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-08 11:40:50,955 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@340da44c{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-08 11:40:50,956 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37052337{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-08 11:40:50,993 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7689ddef{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-08 11:40:51,003 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62d363ab{HTTP/1.1,[http/1.1]}{0.0.0.0:38165}
2019-11-08 11:40:51,004 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2908ms
2019-11-08 11:40:51,007 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-11-08 11:40:51,007 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-11-08 11:40:51,009 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:38165
2019-11-08 11:40:51,015 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@cc6460c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-08 11:40:51,018 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:51,127 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-11-08 11:40:51,127 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-11-08 11:40:51,129 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:51,130 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:51,728 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-08 11:40:51,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-08 11:40:51,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-08 11:40:51,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-08 11:40:51,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-08 11:40:51,736 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-08 11:40:51,736 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-08 11:40:51,736 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-08 11:40:51,736 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-08 11:40:51,737 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-08 11:40:51,737 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-08 11:40:51,737 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-08 11:40:51,737 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-08 11:40:51,737 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-08 11:40:51,738 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-08 11:40:51,738 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-08 11:40:51,738 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-08 11:40:51,738 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-08 11:40:51,738 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-08 11:40:51,739 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-08 11:40:51,739 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-08 11:40:51,739 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-08 11:40:51,739 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-08 11:40:51,740 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-08 11:40:51,740 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-08 11:40:51,740 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-08 11:40:52,461 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-08 11:40:52,462 [Socket Reader #1 for port 45074] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45074
2019-11-08 11:40:52,486 [main] INFO  om.OzoneManager (OzoneManager.java:start(1076)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45074
2019-11-08 11:40:52,486 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-08 11:40:52,494 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-08 11:40:52,494 [IPC Server listener on 45074] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45074: starting
2019-11-08 11:40:52,501 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-11-08 11:40:52,502 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-08 11:40:52,503 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-08 11:40:52,505 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-08 11:40:52,506 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-08 11:40:52,506 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-08 11:40:52,506 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-08 11:40:52,508 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39642
2019-11-08 11:40:52,508 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-08 11:40:52,510 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5aae8eb5{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-08 11:40:52,510 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24a298a6{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-08 11:40:52,515 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5116ac09{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-08 11:40:52,516 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1bc425e7{HTTP/1.1,[http/1.1]}{0.0.0.0:39642}
2019-11-08 11:40:52,516 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4420ms
2019-11-08 11:40:52,516 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-08 11:40:52,517 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:39642
2019-11-08 11:40:52,717 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-08 11:40:52,755 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2446-container-replica-x6kjd-4280001881 ip:192.168.157.246
2019-11-08 11:40:52,780 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-08 11:40:52,781 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/containers/hdds to VolumeSet
2019-11-08 11:40:52,784 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/containers/hdds
2019-11-08 11:40:52,797 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/containers/hdds
2019-11-08 11:40:52,890 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-08 11:40:52,952 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-08 11:40:52,957 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-08 11:40:52,958 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-08 11:40:52,959 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:52,960 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-08 11:40:52,961 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-08 11:40:53,135 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis] (custom)
2019-11-08 11:40:53,184 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-08 11:40:53,185 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-08 11:40:53,186 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-08 11:40:53,188 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-08 11:40:53,188 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-08 11:40:53,189 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-08 11:40:53,189 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-08 11:40:53,190 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40670
2019-11-08 11:40:53,190 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-08 11:40:53,192 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2819c460{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-08 11:40:53,193 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@38bb9d7a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-08 11:40:53,231 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f37f1f9{/,file:///tmp/jetty-0.0.0.0-40670-hddsDatanode-_-any-2808374038098204736.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-08 11:40:53,231 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3374b5bc{HTTP/1.1,[http/1.1]}{0.0.0.0:40670}
2019-11-08 11:40:53,232 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5136ms
2019-11-08 11:40:53,232 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-08 11:40:53,234 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40670
2019-11-08 11:40:53,235 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-08 11:40:53,239 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2446-container-replica-x6kjd-4280001881 ip:192.168.157.246
2019-11-08 11:40:53,241 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@333da147] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-08 11:40:53,248 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-08 11:40:53,249 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/containers/hdds to VolumeSet
2019-11-08 11:40:53,249 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/containers/hdds
2019-11-08 11:40:53,250 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/containers/hdds
2019-11-08 11:40:53,263 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-08 11:40:53,263 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-08 11:40:53,263 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-08 11:40:53,264 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-08 11:40:53,264 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:53,264 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-08 11:40:53,264 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-08 11:40:53,265 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis] (custom)
2019-11-08 11:40:53,267 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-08 11:40:53,269 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-08 11:40:53,270 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-08 11:40:53,272 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-08 11:40:53,273 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-08 11:40:53,273 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-08 11:40:53,273 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-08 11:40:53,274 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41339
2019-11-08 11:40:53,274 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-08 11:40:53,279 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10a0fe30{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-08 11:40:53,279 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60f70249{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-08 11:40:53,311 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@26c47874{/,file:///tmp/jetty-0.0.0.0-41339-hddsDatanode-_-any-1028816071246889063.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-08 11:40:53,312 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@421056e5{HTTP/1.1,[http/1.1]}{0.0.0.0:41339}
2019-11-08 11:40:53,312 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5216ms
2019-11-08 11:40:53,313 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-08 11:40:53,314 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41339
2019-11-08 11:40:53,314 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-08 11:40:53,317 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@288e6f7b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-08 11:40:53,317 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2446-container-replica-x6kjd-4280001881 ip:192.168.157.246
2019-11-08 11:40:53,325 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-08 11:40:53,325 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers/hdds to VolumeSet
2019-11-08 11:40:53,325 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers/hdds
2019-11-08 11:40:53,326 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers/hdds
2019-11-08 11:40:53,340 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-08 11:40:53,340 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-08 11:40:53,341 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-08 11:40:53,341 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-08 11:40:53,341 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:53,341 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-08 11:40:53,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-08 11:40:53,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis] (custom)
2019-11-08 11:40:53,342 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/meta/datanode.id
2019-11-08 11:40:53,345 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/meta/datanode.id
2019-11-08 11:40:53,346 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-08 11:40:53,347 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-08 11:40:53,348 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-08 11:40:53,350 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-08 11:40:53,351 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-08 11:40:53,351 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-08 11:40:53,351 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-08 11:40:53,352 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43482
2019-11-08 11:40:53,352 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-08 11:40:53,354 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22a6e998{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-08 11:40:53,355 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e57e5d6{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-08 11:40:53,391 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@56a4f272{/,file:///tmp/jetty-0.0.0.0-43482-hddsDatanode-_-any-1555479876846906318.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-08 11:40:53,392 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3ee0b4f7{HTTP/1.1,[http/1.1]}{0.0.0.0:43482}
2019-11-08 11:40:53,393 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5297ms
2019-11-08 11:40:53,393 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-08 11:40:53,395 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43482
2019-11-08 11:40:53,396 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-08 11:40:53,397 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38efe5ad] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-08 11:40:53,399 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/meta/datanode.id
2019-11-08 11:40:54,397 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-08 11:40:55,314 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-11-08 11:40:55,317 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-11-08 11:40:55,317 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis aa7f8b24-2231-41b4-b786-06670f8a6b85 at port 0
2019-11-08 11:40:55,334 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-11-08 11:40:55,337 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start RPC server
2019-11-08 11:40:55,338 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-11-08 11:40:55,338 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 9cd44235-4493-4caa-8d24-81fb460b7910 at port 0
2019-11-08 11:40:55,347 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 9cd44235-4493-4caa-8d24-81fb460b7910: start RPC server
2019-11-08 11:40:55,398 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-08 11:40:55,420 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-11-08 11:40:55,421 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-11-08 11:40:55,421 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 at port 0
2019-11-08 11:40:55,433 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start RPC server
2019-11-08 11:40:55,480 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: GrpcService started, listening on 0.0.0.0/0.0.0.0:35561
2019-11-08 11:40:55,480 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 9cd44235-4493-4caa-8d24-81fb460b7910: GrpcService started, listening on 0.0.0.0/0.0.0.0:44345
2019-11-08 11:40:55,480 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: GrpcService started, listening on 0.0.0.0/0.0.0.0:43877
2019-11-08 11:40:55,481 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 9cd44235-4493-4caa-8d24-81fb460b7910 is started using port 44345
2019-11-08 11:40:55,481 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 is started using port 35561
2019-11-08 11:40:55,481 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis aa7f8b24-2231-41b4-b786-06670f8a6b85 is started using port 43877
2019-11-08 11:40:55,486 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc aa7f8b24-2231-41b4-b786-06670f8a6b85 is started using port 34380
2019-11-08 11:40:55,486 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 9cd44235-4493-4caa-8d24-81fb460b7910 is started using port 43882
2019-11-08 11:40:55,486 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 is started using port 37531
2019-11-08 11:40:56,400 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-08 11:40:57,269 [IPC Server handler 1 on 34327] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/aa7f8b24-2231-41b4-b786-06670f8a6b85
2019-11-08 11:40:57,270 [IPC Server handler 1 on 34327] INFO  node.SCMNodeManager (SCMNodeManager.java:register(313)) - Registered Data node : aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}
2019-11-08 11:40:57,272 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-11-08 11:40:57,272 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-11-08 11:40:57,272 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-11-08 11:40:57,321 [IPC Server handler 0 on 34327] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/9cd44235-4493-4caa-8d24-81fb460b7910
2019-11-08 11:40:57,321 [IPC Server handler 0 on 34327] INFO  node.SCMNodeManager (SCMNodeManager.java:register(313)) - Registered Data node : 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}
2019-11-08 11:40:57,400 [IPC Server handler 2 on 34327] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:40:57,400 [IPC Server handler 2 on 34327] INFO  node.SCMNodeManager (SCMNodeManager.java:register(313)) - Registered Data node : 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}
2019-11-08 11:40:57,401 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-11-08 11:40:57,691 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: addNew group-3FC0C01BED06:[aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877] returns group-3FC0C01BED06:java.util.concurrent.CompletableFuture@6d7d3abe[Not completed]
2019-11-08 11:40:57,704 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: new RaftServerImpl for group-3FC0C01BED06:[aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877] with ContainerStateMachine:uninitialized
2019-11-08 11:40:57,707 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:40:57,708 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:40:57,708 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:40:57,709 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:40:57,709 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:40:57,718 [pool-28-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06: ConfigurationManager, init=-1: [aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877], old=null, confs=<EMPTY_MAP>
2019-11-08 11:40:57,718 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis] (custom)
2019-11-08 11:40:57,725 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:40:57,727 [pool-28-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/75a35d9a-d325-4605-aedd-3fc0c01bed06 does not exist. Creating ...
2019-11-08 11:40:57,755 [pool-28-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/75a35d9a-d325-4605-aedd-3fc0c01bed06/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:40:57,781 [pool-28-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/75a35d9a-d325-4605-aedd-3fc0c01bed06 has been successfully formatted.
2019-11-08 11:40:57,784 [pool-28-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-3FC0C01BED06: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:40:57,785 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:40:57,787 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:40:57,793 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:40:57,794 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:57,796 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:57,802 [pool-28-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-11-08 11:40:57,806 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:57,812 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:40:57,819 [pool-28-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/75a35d9a-d325-4605-aedd-3fc0c01bed06
2019-11-08 11:40:57,820 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:40:57,821 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:40:57,823 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:57,823 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:40:57,824 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:40:57,824 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:40:57,826 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:40:57,826 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:40:57,827 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:40:57,840 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:40:57,845 [pool-28-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:40:57,849 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:40:57,850 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:40:57,851 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:40:57,851 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:40:57,875 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:57,875 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(291)) - Creating Volume: testcontainerstatemachinefailures, with jenkins1000 as owner.
2019-11-08 11:40:57,877 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:57,879 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06: start as a follower, conf=-1: [aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877], old=null
2019-11-08 11:40:57,879 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:40:57,880 [pool-28-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start FollowerState
2019-11-08 11:40:57,883 [pool-28-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3FC0C01BED06,id=aa7f8b24-2231-41b4-b786-06670f8a6b85
2019-11-08 11:40:57,884 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:57,933 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 75a35d9a-d325-4605-aedd-3fc0c01bed06, Nodes: aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-11-08 11:40:57,948 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: addNew group-CDA1A3F92AB2:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561] returns group-CDA1A3F92AB2:java.util.concurrent.CompletableFuture@ec6e667[Not completed]
2019-11-08 11:40:57,967 [pool-48-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: new RaftServerImpl for group-CDA1A3F92AB2:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561] with ContainerStateMachine:uninitialized
2019-11-08 11:40:57,969 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:40:57,969 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:40:57,969 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:40:57,969 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:40:57,969 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:40:57,969 [pool-48-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: ConfigurationManager, init=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null, confs=<EMPTY_MAP>
2019-11-08 11:40:57,969 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis] (custom)
2019-11-08 11:40:57,970 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:40:57,970 [pool-48-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2 does not exist. Creating ...
2019-11-08 11:40:57,985 [IPC Server handler 0 on 45074] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(193)) - created volume:testcontainerstatemachinefailures for user:jenkins1000
2019-11-08 11:40:57,993 [pool-48-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:40:58,016 [pool-48-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2 has been successfully formatted.
2019-11-08 11:40:58,017 [pool-48-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-CDA1A3F92AB2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:40:58,018 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:40:58,018 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:40:58,019 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:40:58,019 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:58,019 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,019 [pool-48-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,020 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:40:58,020 [pool-48-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2
2019-11-08 11:40:58,020 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:40:58,020 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:40:58,020 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,021 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:40:58,021 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:40:58,021 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:40:58,021 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:40:58,021 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:40:58,022 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:40:58,022 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:40:58,022 [pool-48-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:40:58,024 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:40:58,024 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:40:58,024 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:40:58,024 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:40:58,024 [pool-48-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,024 [pool-48-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,025 [pool-48-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: start as a follower, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null
2019-11-08 11:40:58,026 [pool-48-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:40:58,026 [pool-48-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start FollowerState
2019-11-08 11:40:58,027 [pool-48-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CDA1A3F92AB2,id=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:40:58,028 [pool-48-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,036 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 668af6bd-712a-4f35-9c41-cda1a3f92ab2, Nodes: 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-11-08 11:40:58,036 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(430)) - Creating Bucket: testcontainerstatemachinefailures/testcontainerstatemachinefailures, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-11-08 11:40:58,050 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9cd44235-4493-4caa-8d24-81fb460b7910: addNew group-289D09F41516:[9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] returns group-289D09F41516:java.util.concurrent.CompletableFuture@239c9dba[Not completed]
2019-11-08 11:40:58,062 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 9cd44235-4493-4caa-8d24-81fb460b7910: new RaftServerImpl for group-289D09F41516:[9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] with ContainerStateMachine:uninitialized
2019-11-08 11:40:58,063 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:40:58,063 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:40:58,063 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:40:58,063 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:40:58,063 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:40:58,063 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516: ConfigurationManager, init=-1: [9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null, confs=<EMPTY_MAP>
2019-11-08 11:40:58,064 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis] (custom)
2019-11-08 11:40:58,064 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:40:58,064 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/32e12165-0592-483d-9878-289d09f41516 does not exist. Creating ...
2019-11-08 11:40:58,086 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/32e12165-0592-483d-9878-289d09f41516/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:40:58,305 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/32e12165-0592-483d-9878-289d09f41516 has been successfully formatted.
2019-11-08 11:40:58,306 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-289D09F41516: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:40:58,306 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:40:58,307 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:40:58,307 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:40:58,307 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:58,307 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,308 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,308 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:40:58,308 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/32e12165-0592-483d-9878-289d09f41516
2019-11-08 11:40:58,308 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:40:58,308 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:40:58,309 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,309 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:40:58,309 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:40:58,309 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:40:58,310 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:40:58,310 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:40:58,310 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:40:58,312 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:40:58,313 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:40:58,313 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:40:58,314 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:40:58,314 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:40:58,314 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:40:58,314 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,315 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,317 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516: start as a follower, conf=-1: [9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:40:58,317 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:40:58,318 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9cd44235-4493-4caa-8d24-81fb460b7910: start FollowerState
2019-11-08 11:40:58,327 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-289D09F41516,id=9cd44235-4493-4caa-8d24-81fb460b7910
2019-11-08 11:40:58,328 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,339 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 32e12165-0592-483d-9878-289d09f41516, Nodes: 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-11-08 11:40:58,366 [IPC Server handler 1 on 44128] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:allocateBlock(179)) - Allocating 1 blocks of size 4194304, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
2019-11-08 11:40:58,369 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: addNew group-01E902698FE8:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] returns group-01E902698FE8:java.util.concurrent.CompletableFuture@c8ec7d0[Not completed]
2019-11-08 11:40:58,373 [pool-48-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: new RaftServerImpl for group-01E902698FE8:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] with ContainerStateMachine:uninitialized
2019-11-08 11:40:58,373 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:40:58,374 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:40:58,374 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:40:58,374 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:40:58,375 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:40:58,375 [pool-48-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: ConfigurationManager, init=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null, confs=<EMPTY_MAP>
2019-11-08 11:40:58,375 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: addNew group-01E902698FE8:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] returns group-01E902698FE8:java.util.concurrent.CompletableFuture@7a2cfe18[Not completed]
2019-11-08 11:40:58,376 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis] (custom)
2019-11-08 11:40:58,376 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:40:58,376 [pool-48-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8 does not exist. Creating ...
2019-11-08 11:40:58,378 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: new RaftServerImpl for group-01E902698FE8:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] with ContainerStateMachine:uninitialized
2019-11-08 11:40:58,379 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:40:58,379 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:40:58,379 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:40:58,380 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:40:58,380 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:40:58,380 [pool-28-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: ConfigurationManager, init=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null, confs=<EMPTY_MAP>
2019-11-08 11:40:58,380 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis] (custom)
2019-11-08 11:40:58,380 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9cd44235-4493-4caa-8d24-81fb460b7910: addNew group-01E902698FE8:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] returns group-01E902698FE8:java.util.concurrent.CompletableFuture@780f72e1[Not completed]
2019-11-08 11:40:58,381 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:40:58,381 [pool-28-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8 does not exist. Creating ...
2019-11-08 11:40:58,382 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 9cd44235-4493-4caa-8d24-81fb460b7910: new RaftServerImpl for group-01E902698FE8:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] with ContainerStateMachine:uninitialized
2019-11-08 11:40:58,382 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:40:58,383 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:40:58,383 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:40:58,383 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:40:58,383 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:40:58,383 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8: ConfigurationManager, init=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null, confs=<EMPTY_MAP>
2019-11-08 11:40:58,384 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis] (custom)
2019-11-08 11:40:58,384 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:40:58,384 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8 does not exist. Creating ...
2019-11-08 11:40:58,401 [pool-28-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:40:58,401 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:40:58,401 [pool-48-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:40:58,424 [pool-28-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8 has been successfully formatted.
2019-11-08 11:40:58,424 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8 has been successfully formatted.
2019-11-08 11:40:58,424 [pool-48-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8 has been successfully formatted.
2019-11-08 11:40:58,425 [pool-28-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-01E902698FE8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:40:58,425 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-01E902698FE8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:40:58,425 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:40:58,425 [pool-48-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-01E902698FE8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:40:58,425 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:40:58,425 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:40:58,426 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:40:58,425 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:40:58,426 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:58,426 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:40:58,426 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,426 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:40:58,426 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:40:58,426 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:40:58,427 [pool-28-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8
2019-11-08 11:40:58,427 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:40:58,427 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:40:58,427 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:58,427 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:40:58,427 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:40:58,428 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,427 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,428 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:40:58,428 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:40:58,428 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,428 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:40:58,428 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:40:58,429 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:40:58,429 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:40:58,429 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:40:58,429 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8
2019-11-08 11:40:58,429 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:40:58,429 [pool-48-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8
2019-11-08 11:40:58,429 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:40:58,430 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:40:58,430 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:40:58,430 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:40:58,430 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:40:58,430 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,430 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:40:58,430 [pool-28-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:40:58,431 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:40:58,431 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:40:58,431 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:40:58,431 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:40:58,431 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:40:58,431 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:40:58,431 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:40:58,432 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:40:58,432 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:40:58,432 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:40:58,432 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:40:58,432 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:40:58,432 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:40:58,433 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:40:58,433 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:40:58,433 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:40:58,433 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:40:58,433 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,433 [pool-48-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:40:58,434 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,434 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:40:58,434 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:40:58,434 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: start as a follower, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:40:58,434 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:40:58,434 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:40:58,435 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:40:58,435 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:40:58,435 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:40:58,435 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:40:58,435 [pool-28-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start FollowerState
2019-11-08 11:40:58,435 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:40:58,435 [pool-48-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:40:58,436 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:40:58,436 [pool-48-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,436 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,436 [pool-28-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-01E902698FE8,id=aa7f8b24-2231-41b4-b786-06670f8a6b85
2019-11-08 11:40:58,437 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,437 [pool-48-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,437 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8: start as a follower, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:40:58,437 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,438 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:40:58,438 [pool-48-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: start as a follower, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:40:58,438 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9cd44235-4493-4caa-8d24-81fb460b7910: start FollowerState
2019-11-08 11:40:58,438 [pool-48-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:40:58,438 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-01E902698FE8,id=9cd44235-4493-4caa-8d24-81fb460b7910
2019-11-08 11:40:58,438 [pool-48-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start FollowerState
2019-11-08 11:40:58,439 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,440 [pool-48-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-01E902698FE8,id=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:40:58,440 [pool-48-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:40:58,459 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 51bfbc5c-0ef9-40d3-83c7-01e902698fe8, Nodes: aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-11-08 11:40:58,580 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-11-08 11:41:00,278 [Thread-181] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-11-08 11:41:00,286 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 4 milliseconds for processing 1 containers.
2019-11-08 11:41:03,074 [Thread-189] INFO  impl.FollowerState (FollowerState.java:run(111)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-FollowerState: change to CANDIDATE, lastRpcTime:5193ms, electionTimeout:5193ms
2019-11-08 11:41:03,077 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: shutdown FollowerState
2019-11-08 11:41:03,077 [Thread-189] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-08 11:41:03,082 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start LeaderElection
2019-11-08 11:41:03,108 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1: begin an election at term 1 for -1: [aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877], old=null
2019-11-08 11:41:03,110 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: shutdown LeaderElection
2019-11-08 11:41:03,111 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-08 11:41:03,111 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06: change Leader from null to aa7f8b24-2231-41b4-b786-06670f8a6b85 at term 1 for becomeLeader, leader elected after 5326ms
2019-11-08 11:41:03,118 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-08 11:41:03,119 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-08 11:41:03,125 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-08 11:41:03,133 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-08 11:41:03,134 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-08 11:41:03,135 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-08 11:41:03,146 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start LeaderState
2019-11-08 11:41:03,168 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-08 11:41:03,181 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06: set configuration 0: [aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877], old=null at 0
2019-11-08 11:41:03,217 [Thread-192] INFO  impl.FollowerState (FollowerState.java:run(111)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-FollowerState: change to CANDIDATE, lastRpcTime:5191ms, electionTimeout:5190ms
2019-11-08 11:41:03,219 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown FollowerState
2019-11-08 11:41:03,219 [Thread-192] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-08 11:41:03,219 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start LeaderElection
2019-11-08 11:41:03,245 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2: begin an election at term 1 for -1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null
2019-11-08 11:41:03,248 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown LeaderElection
2019-11-08 11:41:03,248 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-08 11:41:03,248 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: change Leader from null to 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 at term 1 for becomeLeader, leader elected after 5230ms
2019-11-08 11:41:03,248 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-08 11:41:03,249 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-08 11:41:03,249 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-08 11:41:03,249 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-08 11:41:03,249 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-08 11:41:03,249 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-08 11:41:03,249 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start LeaderState
2019-11-08 11:41:03,250 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-08 11:41:03,250 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: set configuration 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null at 0
2019-11-08 11:41:03,356 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-3FC0C01BED06-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/75a35d9a-d325-4605-aedd-3fc0c01bed06/current/log_inprogress_0
2019-11-08 11:41:03,357 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2/current/log_inprogress_0
2019-11-08 11:41:03,476 [Thread-198] INFO  impl.FollowerState (FollowerState.java:run(111)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-FollowerState: change to CANDIDATE, lastRpcTime:5040ms, electionTimeout:5040ms
2019-11-08 11:41:03,476 [Thread-198] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: shutdown FollowerState
2019-11-08 11:41:03,476 [Thread-198] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-08 11:41:03,477 [Thread-198] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start LeaderElection
2019-11-08 11:41:03,500 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3: begin an election at term 1 for -1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:41:03,502 [Thread-195] INFO  impl.FollowerState (FollowerState.java:run(111)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-FollowerState: change to CANDIDATE, lastRpcTime:5184ms, electionTimeout:5175ms
2019-11-08 11:41:03,503 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9cd44235-4493-4caa-8d24-81fb460b7910: shutdown FollowerState
2019-11-08 11:41:03,503 [Thread-195] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-08 11:41:03,503 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9cd44235-4493-4caa-8d24-81fb460b7910: start LeaderElection
2019-11-08 11:41:03,521 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:aa7f8b24-2231-41b4-b786-06670f8a6b85
2019-11-08 11:41:03,521 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:aa7f8b24-2231-41b4-b786-06670f8a6b85
2019-11-08 11:41:03,521 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown FollowerState
2019-11-08 11:41:03,521 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9cd44235-4493-4caa-8d24-81fb460b7910: shutdown FollowerState
2019-11-08 11:41:03,521 [Thread-203] INFO  impl.FollowerState (FollowerState.java:run(120)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-08 11:41:03,521 [Thread-201] INFO  impl.FollowerState (FollowerState.java:run(120)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-08 11:41:03,521 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9cd44235-4493-4caa-8d24-81fb460b7910: start FollowerState
2019-11-08 11:41:03,521 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start FollowerState
2019-11-08 11:41:03,529 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4: begin an election at term 1 for -1: [9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:41:03,529 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 9cd44235-4493-4caa-8d24-81fb460b7910: shutdown LeaderElection
2019-11-08 11:41:03,530 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-08 11:41:03,530 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516: change Leader from null to 9cd44235-4493-4caa-8d24-81fb460b7910 at term 1 for becomeLeader, leader elected after 5223ms
2019-11-08 11:41:03,530 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-08 11:41:03,530 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-08 11:41:03,530 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-08 11:41:03,530 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-08 11:41:03,530 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-08 11:41:03,530 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-08 11:41:03,531 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9cd44235-4493-4caa-8d24-81fb460b7910: start LeaderState
2019-11-08 11:41:03,531 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-08 11:41:03,531 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516: set configuration 0: [9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null at 0
2019-11-08 11:41:03,564 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3: Election PASSED; received 1 response(s) [aa7f8b24-2231-41b4-b786-06670f8a6b85<-9cd44235-4493-4caa-8d24-81fb460b7910#0:OK-t1] and 0 exception(s); aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8:t1, leader=null, voted=aa7f8b24-2231-41b4-b786-06670f8a6b85, raftlog=aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:41:03,564 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: shutdown LeaderElection
2019-11-08 11:41:03,564 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-08 11:41:03,566 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: change Leader from null to aa7f8b24-2231-41b4-b786-06670f8a6b85 at term 1 for becomeLeader, leader elected after 5140ms
2019-11-08 11:41:03,566 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-08 11:41:03,566 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-08 11:41:03,566 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-08 11:41:03,566 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-08 11:41:03,566 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-08 11:41:03,567 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-08 11:41:03,569 [9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-289D09F41516-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/32e12165-0592-483d-9878-289d09f41516/current/log_inprogress_0
2019-11-08 11:41:03,570 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-11-08 11:41:03,570 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:41:03,571 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-11-08 11:41:03,574 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-11-08 11:41:03,574 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-08 11:41:03,574 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:41:03,575 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:41:03,576 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-11-08 11:41:03,576 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:41:03,576 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-11-08 11:41:03,576 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-11-08 11:41:03,576 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-08 11:41:03,577 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:41:03,578 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start LeaderState
2019-11-08 11:41:03,578 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-08 11:41:03,578 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: set configuration 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null at 0
2019-11-08 11:41:03,621 [aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/current/log_inprogress_0
2019-11-08 11:41:03,622 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: change Leader from null to aa7f8b24-2231-41b4-b786-06670f8a6b85 at term 1 for appendEntries, leader elected after 5196ms
2019-11-08 11:41:03,622 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8: change Leader from null to aa7f8b24-2231-41b4-b786-06670f8a6b85 at term 1 for appendEntries, leader elected after 5197ms
2019-11-08 11:41:03,643 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: set configuration 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null at 0
2019-11-08 11:41:03,643 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8: set configuration 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null at 0
2019-11-08 11:41:03,644 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-08 11:41:03,644 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-08 11:41:03,677 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/current/log_inprogress_0
2019-11-08 11:41:03,677 [9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/current/log_inprogress_0
2019-11-08 11:41:04,313 [Datanode ReportManager Thread - 2] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(50)) - Execution exception when running task in Datanode ReportManager Thread - 2
2019-11-08 11:41:04,314 [Datanode ReportManager Thread - 2] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(63)) - Caught exception in thread Datanode ReportManager Thread - 2: 
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@595d5767 rejected from org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor@579aa23c[Shutting down, pool size = 4, active threads = 1, queued tasks = 3, completed tasks = 90]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at org.apache.hadoop.ozone.container.common.report.ReportPublisher.run(ReportPublisher.java:76)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-08 11:41:04,473 [Datanode ReportManager Thread - 0] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(50)) - Execution exception when running task in Datanode ReportManager Thread - 0
2019-11-08 11:41:04,473 [Datanode ReportManager Thread - 0] WARN  concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(63)) - Caught exception in thread Datanode ReportManager Thread - 0: 
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4c08132e rejected from org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor@579aa23c[Shutting down, pool size = 4, active threads = 1, queued tasks = 2, completed tasks = 91]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at org.apache.hadoop.ozone.container.common.report.ReportPublisher.run(ReportPublisher.java:76)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-08 11:41:09,237 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-08 11:41:09,239 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-11-08 11:41:09,240 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: close
2019-11-08 11:41:09,241 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: shutdown
2019-11-08 11:41:09,242 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CDA1A3F92AB2,id=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:41:09,242 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown LeaderState
2019-11-08 11:41:09,243 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-PendingRequests: sendNotLeaderResponses
2019-11-08 11:41:09,244 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-StateMachineUpdater: set stopIndex = 0
2019-11-08 11:41:09,246 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: closes. applyIndex: 0
2019-11-08 11:41:09,247 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-08 11:41:09,249 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker close()
2019-11-08 11:41:09,251 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: shutdown
2019-11-08 11:41:09,252 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-01E902698FE8,id=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:41:09,252 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown FollowerState
2019-11-08 11:41:09,252 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater: set stopIndex = 4
2019-11-08 11:41:09,252 [Thread-244] INFO  impl.FollowerState (FollowerState.java:run(120)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-08 11:41:09,253 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-01E902698FE8: Taking a snapshot at:(t:1, i:3) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/sm/snapshot.1_3
2019-11-08 11:41:13,444 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(305)) - group-01E902698FE8: Finished taking a snapshot at:(t:1, i:3) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/sm/snapshot.1_3 time:4192
2019-11-08 11:41:13,446 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater: Took a snapshot at index 3
2019-11-08 11:41:13,449 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2019-11-08 11:41:13,454 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-01E902698FE8: Taking a snapshot at:(t:1, i:3) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/sm/snapshot.1_3
2019-11-08 11:41:13,486 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(305)) - group-01E902698FE8: Finished taking a snapshot at:(t:1, i:3) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/sm/snapshot.1_3 time:33
2019-11-08 11:41:13,487 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater: Took a snapshot at index 3
2019-11-08 11:41:13,487 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-StateMachineUpdater: snapshotIndex: updateIncreasingly 3 -> 3
2019-11-08 11:41:13,488 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: closes. applyIndex: 4
2019-11-08 11:41:13,488 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-08 11:41:13,490 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker close()
2019-11-08 11:41:13,492 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown server with port 35561 now
2019-11-08 11:41:13,500 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown server with port 35561 successfully
2019-11-08 11:41:13,501 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: installSnapshot onError, lastRequest: aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#8-t1, previous=(t:1, i:4), leaderCommit=4, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-11-08 11:41:13,503 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-11-08 11:41:13,505 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-08 11:41:13,524 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-08 11:41:13,527 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-08 11:41:13,531 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@56a4f272{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-08 11:41:13,536 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3ee0b4f7{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-08 11:41:13,536 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e57e5d6{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-08 11:41:13,537 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22a6e998{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-08 11:41:14,661 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#8-t1, previous=(t:1, i:4), leaderCommit=4, initializing? false, entries: <empty>
2019-11-08 11:41:16,547 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#9-t1, previous=(t:1, i:4), leaderCommit=4, initializing? false, entries: size=1, first=(t:1, i:5), STATEMACHINELOGENTRY, client-ED959550D0B4, cid=8
2019-11-08 11:41:16,548 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#10-t1, previous=(t:1, i:5), leaderCommit=4, initializing? false, entries: size=1, first=(t:1, i:6), STATEMACHINELOGENTRY, client-ED959550D0B4, cid=9
2019-11-08 11:41:16,561 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#11-t1, previous=(t:1, i:6), leaderCommit=5, initializing? false, entries: size=1, first=(t:1, i:7), METADATAENTRY(c5)
2019-11-08 11:41:16,562 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#12-t1, previous=(t:1, i:7), leaderCommit=6, initializing? false, entries: size=1, first=(t:1, i:8), METADATAENTRY(c6)
2019-11-08 11:41:19,063 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#13-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:21,564 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#14-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:22,591 [Thread-288] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c8, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c8]
2019-11-08 11:41:23,588 [Thread-291] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c8, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c8]
2019-11-08 11:41:24,064 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#15-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:26,566 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#16-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:29,067 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#17-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:31,571 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#18-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:31,625 [Thread-298] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c8, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c8]
2019-11-08 11:41:33,584 [Thread-301] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c8, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c8]
2019-11-08 11:41:34,076 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#19-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:36,580 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#20-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:39,082 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#21-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:40,660 [Thread-307] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c8, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c8]
2019-11-08 11:41:41,584 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#22-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:42,584 [Thread-311] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c8, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c8]
2019-11-08 11:41:43,577 [main] WARN  scm.XceiverClientRatis (XceiverClientRatis.java:watchForCommit(277)) - 3 way commit failed on pipeline Pipeline[ Id: 51bfbc5c-0ef9-40d3-83c7-01e902698fe8, Nodes: aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
java.util.concurrent.TimeoutException
	at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:274)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:198)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:161)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:346)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:482)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.testDeleteKeyWithSlowFollower(TestDeleteWithSlowFollower.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-11-08 11:41:43,601 [main] INFO  scm.XceiverClientRatis (XceiverClientRatis.java:lambda$watchForCommit$5(295)) - Could not commit index 6 on pipeline Pipeline[ Id: 51bfbc5c-0ef9-40d3-83c7-01e902698fe8, Nodes: aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN] to all the nodes. Server 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 has failed. Committed by majority.
2019-11-08 11:41:43,603 [main] WARN  storage.BlockOutputStream (BlockOutputStream.java:watchForCommit(352)) - Failed to commit BlockId conID: 1 locID: 103102104107220992 bcsId: 6 on Pipeline[ Id: 51bfbc5c-0ef9-40d3-83c7-01e902698fe8, Nodes: aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. Failed nodes: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: null, host: null, networkLocation: /default-rack, certSerialId: null}]
2019-11-08 11:41:43,707 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSING replica.
2019-11-08 11:41:43,717 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:flushAndSyncDB(386)) - Container 1 is synced with bcsId 6.
2019-11-08 11:41:43,718 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:flushAndSyncDB(386)) - Container 1 is synced with bcsId 6.
2019-11-08 11:41:43,740 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:close(335)) - Container 1 is closed with bcsId 6.
2019-11-08 11:41:43,743 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:43,744 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSING replica.
2019-11-08 11:41:43,750 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:flushAndSyncDB(386)) - Container 1 is synced with bcsId 6.
2019-11-08 11:41:43,751 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:flushAndSyncDB(386)) - Container 1 is synced with bcsId 6.
2019-11-08 11:41:43,775 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:close(335)) - Container 1 is closed with bcsId 6.
2019-11-08 11:41:43,777 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:43,942 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:44,078 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:44,086 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#23-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:44,241 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:44,378 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:44,533 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:44,533 [IPC Server handler 10 on 44128] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:deleteKeyBlocks(214)) - SCM is informed by OM to delete 1 blocks
2019-11-08 11:41:44,534 [IPC Server handler 10 on 44128] INFO  block.BlockManagerImpl (BlockManagerImpl.java:deleteBlocks(285)) - Deleting blocks conID: 1 locID: 103102104107220992 bcsId: 0
2019-11-08 11:41:44,534 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:44,642 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:44,678 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:44,878 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:45,042 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:45,178 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:45,342 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:45,479 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:45,534 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:45,537 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:45,643 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:45,779 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:45,843 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:46,144 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:46,179 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:46,343 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:46,380 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:46,536 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:46,538 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:46,543 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:46,586 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#24-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-11-08 11:41:46,670 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#25-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: size=1, first=(t:1, i:9), STATEMACHINELOGENTRY, client-28A4B224E8B8, cid=12
2019-11-08 11:41:46,683 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#26-t1, previous=(t:1, i:9), leaderCommit=9, initializing? false, entries: size=1, first=(t:1, i:10), METADATAENTRY(c9)
2019-11-08 11:41:46,781 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:46,944 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:47,082 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:47,143 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:47,383 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:47,444 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:47,538 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:47,540 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:47,646 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:47,683 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:48,048 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:48,084 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:48,383 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:48,447 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:48,544 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:48,544 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:48,584 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:48,847 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:48,987 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:49,148 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:49,184 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#27-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:41:49,287 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:49,448 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:49,547 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:49,547 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:49,688 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:49,749 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:49,888 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:50,152 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:50,289 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:50,451 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:50,549 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:50,549 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:50,651 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:50,690 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:50,723 [Thread-341] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c10]
2019-11-08 11:41:50,951 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:50,991 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:51,191 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:51,251 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:51,552 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:51,553 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:51,584 [Thread-347] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:41:51,590 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:51,650 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:51,689 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#28-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:41:51,850 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:51,890 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:52,151 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:52,290 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:52,551 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:52,555 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:52,555 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:52,590 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:52,850 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:52,891 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:53,050 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:53,253 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:53,291 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:53,490 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:53,551 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:53,557 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:53,557 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:53,750 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:53,790 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:53,950 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:54,151 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:54,190 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:54,190 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#29-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:41:54,390 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:54,550 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:54,558 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:54,558 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:54,590 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:54,750 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:54,990 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:55,050 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:55,290 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:55,350 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:55,560 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:55,560 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:55,590 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:55,751 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:55,890 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:56,052 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:56,290 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:56,351 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:56,490 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:56,562 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:56,562 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:56,691 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#30-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:41:56,753 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:56,790 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:56,953 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:56,990 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:57,190 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:57,254 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:57,392 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:57,455 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:57,565 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:57,565 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:57,755 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:57,790 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:57,990 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:58,156 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:58,390 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:58,455 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:58,567 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:58,567 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:58,590 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:58,755 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:58,891 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:58,956 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:59,158 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:59,193 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#31-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:41:59,193 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:59,458 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:59,494 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:59,569 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:59,569 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:41:59,759 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:41:59,794 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:00,059 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:00,194 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:00,360 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:00,495 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:00,561 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:00,571 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:00,571 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:00,763 [Thread-374] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c10]
2019-11-08 11:42:00,896 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:00,960 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:01,097 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:01,261 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:01,397 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:01,461 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:01,572 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:01,572 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:01,584 [Thread-380] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:42:01,694 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#32-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:01,762 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:01,798 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:02,099 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:02,162 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:02,398 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:02,462 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:02,575 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:02,575 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:02,662 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:02,798 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:02,963 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:03,198 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:03,263 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:03,498 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:03,563 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:03,577 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:03,577 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:03,764 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:03,798 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:04,099 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:04,166 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:04,196 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#33-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:04,399 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:04,467 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:04,580 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:04,580 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:04,599 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:04,666 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:04,999 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:05,068 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:05,199 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:05,369 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:05,501 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:05,583 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:05,583 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:05,702 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:05,768 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:05,968 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:06,102 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:06,267 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:06,404 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:06,467 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:06,585 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:06,585 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:06,697 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#34-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:06,704 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:06,868 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:07,004 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:07,068 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:07,369 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:07,406 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:07,568 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:07,586 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:07,586 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:07,606 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:07,807 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:07,869 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:08,069 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:08,207 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:08,369 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:08,507 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:08,589 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:08,589 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:08,707 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:08,769 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:09,008 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:09,069 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:09,199 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#35-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:09,272 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:09,408 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:09,569 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:09,591 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:09,591 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:09,708 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:09,869 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:10,008 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:10,269 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:10,308 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:10,569 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:10,592 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:10,593 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:10,708 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:10,805 [Thread-406] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c10]
2019-11-08 11:42:10,869 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:11,012 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:11,169 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:11,311 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:11,570 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:11,584 [Thread-410] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:42:11,594 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:11,594 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:11,611 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:11,701 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#36-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:11,814 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:11,970 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:12,111 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:12,170 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:12,411 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:12,572 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:12,596 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:12,596 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:12,612 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:12,872 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:13,011 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:13,172 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:13,311 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:13,472 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:13,511 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:13,598 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:13,599 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:13,773 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:13,813 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:14,075 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:14,202 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#37-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:14,213 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:14,375 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:14,414 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:14,575 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:14,601 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:14,601 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:14,815 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:14,875 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:15,117 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:15,175 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:15,375 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:15,417 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:15,603 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:15,603 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:15,675 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:15,717 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:15,917 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:15,977 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:16,277 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:16,317 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:16,517 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:16,605 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:16,605 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:16,676 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:16,705 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#38-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:16,717 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:16,878 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:16,917 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:17,178 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:17,218 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:17,419 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:17,579 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:17,607 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:17,607 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:17,817 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:17,880 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:18,117 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:18,180 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:18,417 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:18,580 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:18,609 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:18,609 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:18,780 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:18,818 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:19,019 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:19,080 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:19,207 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#39-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:19,283 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:19,320 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:19,583 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:19,613 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:19,613 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:19,621 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:19,819 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:19,883 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:20,183 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:20,221 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:20,521 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:20,583 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:20,615 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:20,615 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:20,783 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:20,823 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:21,124 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:21,184 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:21,424 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:21,484 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:21,584 [Thread-439] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:42:21,617 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:21,617 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:21,709 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#40-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:21,785 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:21,824 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:22,085 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:22,124 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:22,424 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:22,485 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:22,620 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:22,620 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:22,725 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:22,785 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:23,026 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:23,086 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:23,387 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:23,427 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:23,622 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:23,622 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:23,626 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:23,787 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:24,027 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:24,087 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:24,211 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#41-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:24,389 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:24,427 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:24,588 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:24,625 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:24,625 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:24,729 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:24,888 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:25,031 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:25,189 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:25,330 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:25,490 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:25,530 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:25,626 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:25,627 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:25,890 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:25,930 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:26,090 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:26,132 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:26,390 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:26,533 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:26,629 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:26,629 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:26,690 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:26,713 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#42-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:26,833 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:27,033 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:27,090 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:27,233 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:27,290 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:27,490 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:27,533 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:27,631 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:27,631 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:27,790 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:27,833 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:28,090 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:28,133 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:28,292 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:28,433 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:28,492 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:28,633 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:28,633 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:28,792 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:28,833 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:28,992 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:29,216 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#43-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:29,233 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:29,392 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:29,534 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:29,635 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:29,635 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:29,693 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:29,857 [Thread-463] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c10]
2019-11-08 11:42:29,934 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:29,992 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:30,192 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:30,335 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:30,592 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:30,634 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:30,637 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:30,643 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:30,834 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:30,894 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:31,192 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:31,235 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:31,435 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:31,584 [Thread-469] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:42:31,592 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:31,635 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:31,645 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:31,645 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:31,717 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#44-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:31,892 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:32,036 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:32,192 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:32,338 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:32,492 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:32,640 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:32,648 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:32,648 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:32,793 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:32,941 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:33,093 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:33,240 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:33,494 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:33,644 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:33,650 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:33,650 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:33,694 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:33,943 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:34,095 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:34,218 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#45-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:34,243 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:34,296 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:34,543 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:34,595 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:34,651 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:34,651 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:34,845 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:34,995 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:35,244 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:35,395 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:35,544 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:35,653 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:35,653 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:35,697 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:35,844 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:36,044 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:36,096 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:36,345 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:36,397 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:36,546 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:36,654 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:36,654 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:36,697 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:36,719 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#46-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:36,897 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:36,945 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:37,145 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:37,198 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:37,346 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:37,498 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:37,656 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:37,656 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:37,747 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:37,798 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:37,947 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:38,099 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:38,300 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:38,347 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:38,658 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:38,658 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:38,699 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:38,747 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:38,879 [Thread-491] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c10]
2019-11-08 11:42:38,899 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:38,948 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:39,200 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:39,220 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#47-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:39,247 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:39,400 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:39,648 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:39,659 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:39,659 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:39,701 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:39,903 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:39,949 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:40,304 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:40,348 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:40,584 [Thread-496] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:42:40,605 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:40,648 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:40,661 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:40,661 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:40,804 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:40,949 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:41,104 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:41,249 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:41,449 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:41,504 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:41,664 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:41,664 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:41,704 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:41,721 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#48-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:41,849 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:42,104 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:42,149 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:42,304 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:42,349 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:42,549 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:42,666 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:42,666 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:42,704 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:42,849 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:43,005 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:43,051 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:43,351 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:43,406 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:43,651 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:43,667 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:43,667 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:43,705 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:43,951 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:44,006 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:44,206 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:44,221 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#49-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:44,351 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:44,406 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:44,652 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:44,669 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:44,669 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:44,706 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:44,906 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:45,053 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:45,254 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:45,306 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:45,455 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:45,670 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:45,671 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:45,707 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:45,755 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:46,007 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:46,055 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:46,208 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:46,456 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:46,509 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:46,656 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:46,672 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:46,672 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:46,722 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#50-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:46,910 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:47,057 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:47,110 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:47,411 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:47,456 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:47,676 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:47,676 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:47,714 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:47,756 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:47,909 [Thread-518] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c10]
2019-11-08 11:42:48,057 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:48,114 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:48,356 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:48,413 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:48,656 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:48,678 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:48,678 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:48,813 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:48,856 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:49,156 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(146)) - Container #1 is in OPEN state, but the datanode 9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-11-08 11:42:49,174 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=668af6bd-712a-4f35-9c41-cda1a3f92ab2, PipelineID=51bfbc5c-0ef9-40d3-83c7-01e902698fe8]
2019-11-08 11:42:49,175 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 668af6bd-712a-4f35-9c41-cda1a3f92ab2, Nodes: 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-11-08 11:42:49,176 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 668af6bd-712a-4f35-9c41-cda1a3f92ab2, Nodes: 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-11-08 11:42:49,178 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 51bfbc5c-0ef9-40d3-83c7-01e902698fe8, Nodes: aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-11-08 11:42:49,178 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 51bfbc5c-0ef9-40d3-83c7-01e902698fe8, Nodes: aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
2019-11-08 11:42:49,179 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(61)) - Close container Event triggered for container : #1
2019-11-08 11:42:49,213 [EventQueue-ContainerReportForContainerReportHandler] INFO  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(179)) - Moving container #1 to CLOSED state, datanode aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null} reported CLOSED replica.
2019-11-08 11:42:49,223 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#51-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:49,584 [Thread-527] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:42:49,682 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:49,682 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:50,109 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 3 delete blocks command for 3 datanodes, task elapsed time: 5ms
2019-11-08 11:42:50,315 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode aa7f8b24-2231-41b4-b786-06670f8a6b85 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:50,357 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 9cd44235-4493-4caa-8d24-81fb460b7910 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:50,415 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:50,657 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 9cd44235-4493-4caa-8d24-81fb460b7910 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:50,683 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:50,684 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:50,810 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-08 11:42:50,844 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2446-container-replica-x6kjd-4280001881 ip:192.168.157.246
2019-11-08 11:42:50,848 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers : 4096 
2019-11-08 11:42:50,848 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-08 11:42:50,849 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers/hdds to VolumeSet
2019-11-08 11:42:50,849 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers/hdds
2019-11-08 11:42:50,849 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/containers/hdds
2019-11-08 11:42:50,889 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-08 11:42:50,890 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-08 11:42:50,890 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 35561 (custom)
2019-11-08 11:42:50,891 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-08 11:42:50,891 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:42:50,891 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-08 11:42:50,891 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-08 11:42:50,892 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis] (custom)
2019-11-08 11:42:50,892 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$null$0(191)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: found a subdirectory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8
2019-11-08 11:42:50,893 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: addNew group-01E902698FE8:[] returns group-01E902698FE8:java.util.concurrent.CompletableFuture@4ed4a7e4[Not completed]
2019-11-08 11:42:50,893 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$null$0(191)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: found a subdirectory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2
2019-11-08 11:42:50,893 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: addNew group-CDA1A3F92AB2:[] returns group-CDA1A3F92AB2:java.util.concurrent.CompletableFuture@1c7350b0[Not completed]
2019-11-08 11:42:50,896 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: new RaftServerImpl for group-01E902698FE8:[] with ContainerStateMachine:uninitialized
2019-11-08 11:42:50,896 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:43482
2019-11-08 11:42:50,903 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:42:50,903 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:42:50,904 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:42:50,904 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:42:50,904 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:42:50,904 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
2019-11-08 11:42:50,905 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis] (custom)
2019-11-08 11:42:50,905 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:42:50,907 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-08 11:42:50,909 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-08 11:42:50,913 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-08 11:42:50,914 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-08 11:42:50,914 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-08 11:42:50,915 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-08 11:42:50,917 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43482
2019-11-08 11:42:50,917 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-08 11:42:50,920 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37ad042b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-08 11:42:50,921 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30b975ad{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-08 11:42:50,936 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:42:50,939 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-01E902698FE8: Setting the last applied index to (t:1, i:3)
2019-11-08 11:42:50,943 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: set configuration 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null at 0
2019-11-08 11:42:50,944 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:42:50,944 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:42:50,944 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:42:50,944 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:42:50,944 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:50,945 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:42:50,945 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8
2019-11-08 11:42:50,945 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:42:50,945 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:42:50,945 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:50,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:42:50,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:42:50,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:42:50,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:42:50,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:42:50,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:42:50,947 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:42:50,952 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: set configuration 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null at 0
2019-11-08 11:42:50,953 [pool-60-thread-1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(140)) - Successfully read 5 entries from segment file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/51bfbc5c-0ef9-40d3-83c7-01e902698fe8/current/log_inprogress_0
2019-11-08 11:42:50,953 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
2019-11-08 11:42:50,959 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@47ac613b{/,file:///tmp/jetty-0.0.0.0-43482-hddsDatanode-_-any-2440767669799603985.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-08 11:42:50,960 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@60d6fdd4{HTTP/1.1,[http/1.1]}{0.0.0.0:43482}
2019-11-08 11:42:50,965 [pool-60-thread-1] INFO  raftlog.RaftLog (RaftLog.java:lambda$new$0(61)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLog: commitIndex: updateToMax old=3, new=3, updated? false
2019-11-08 11:42:50,965 [main] INFO  server.Server (Server.java:doStart(419)) - Started @122869ms
2019-11-08 11:42:50,965 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-08 11:42:50,965 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:42:50,965 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:42:50,966 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:42:50,966 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:42:50,966 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43482
2019-11-08 11:42:50,968 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d6a3644] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-08 11:42:50,968 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: new RaftServerImpl for group-CDA1A3F92AB2:[] with ContainerStateMachine:uninitialized
2019-11-08 11:42:50,968 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:42:50,968 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:42:50,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:42:50,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:42:50,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:42:50,969 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
2019-11-08 11:42:50,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis] (custom)
2019-11-08 11:42:50,969 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:42:51,012 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:42:51,012 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-CDA1A3F92AB2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:42:51,013 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:42:51,014 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:51,014 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:42:51,014 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:42:51,014 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:42:51,014 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:42:51,014 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:42:51,014 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:42:51,015 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:42:51,016 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: set configuration 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null at 0
2019-11-08 11:42:51,016 [pool-60-thread-1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(140)) - Successfully read 1 entries from segment file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2/current/log_inprogress_0
2019-11-08 11:42:51,016 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
2019-11-08 11:42:51,030 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:42:51,030 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:42:51,030 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:42:51,030 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:42:51,056 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:51,059 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 9cd44235-4493-4caa-8d24-81fb460b7910 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:51,110 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 2 delete blocks command for 2 datanodes, task elapsed time: 1ms
2019-11-08 11:42:51,111 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370109 timed out. Retrying.
2019-11-08 11:42:51,112 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370110 timed out. Retrying.
2019-11-08 11:42:51,684 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:51,685 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:51,724 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#52-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:52,109 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370111 timed out. Retrying.
2019-11-08 11:42:52,109 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370112 timed out. Retrying.
2019-11-08 11:42:52,111 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 2 delete blocks command for 2 datanodes, task elapsed time: 1ms
2019-11-08 11:42:52,112 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370109 timed out. Retrying.
2019-11-08 11:42:52,112 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370110 timed out. Retrying.
2019-11-08 11:42:52,157 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:52,157 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:52,687 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:52,687 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:52,971 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-11-08 11:42:52,972 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-11-08 11:42:52,972 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 at port 35561
2019-11-08 11:42:52,988 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: start as a follower, conf=0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null
2019-11-08 11:42:52,988 [Datanode State Machine Thread - 0] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: start as a follower, conf=0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:42:52,988 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: changes role from      null to FOLLOWER at term 1 for startAsFollower
2019-11-08 11:42:52,989 [Datanode State Machine Thread - 0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: changes role from      null to FOLLOWER at term 1 for startAsFollower
2019-11-08 11:42:52,989 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start FollowerState
2019-11-08 11:42:52,989 [Datanode State Machine Thread - 0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start FollowerState
2019-11-08 11:42:52,990 [Datanode State Machine Thread - 0] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-01E902698FE8,id=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:42:52,990 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CDA1A3F92AB2,id=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:42:52,991 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start RPC server
2019-11-08 11:42:52,995 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: GrpcService started, listening on 0.0.0.0/0.0.0.0:35561
2019-11-08 11:42:53,110 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370111 timed out. Retrying.
2019-11-08 11:42:53,110 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370112 timed out. Retrying.
2019-11-08 11:42:53,111 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370113 timed out. Retrying.
2019-11-08 11:42:53,111 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370114 timed out. Retrying.
2019-11-08 11:42:53,112 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370109 timed out. Retrying.
2019-11-08 11:42:53,113 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370110 timed out. Retrying.
2019-11-08 11:42:53,113 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 2 delete blocks command for 2 datanodes, task elapsed time: 1ms
2019-11-08 11:42:53,257 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:53,258 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:53,258 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:53,258 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:53,258 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:53,259 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(7)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:53,259 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:53,690 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:53,692 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:54,111 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370113 timed out. Retrying.
2019-11-08 11:42:54,111 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370111 timed out. Retrying.
2019-11-08 11:42:54,113 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370115 timed out. Retrying.
2019-11-08 11:42:54,113 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370109 timed out. Retrying.
2019-11-08 11:42:54,114 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 0ms
2019-11-08 11:42:54,225 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#53-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:54,691 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:54,694 [BlockDeletingService#1] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:54,970 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:55,112 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370111 timed out. Retrying.
2019-11-08 11:42:55,112 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370113 timed out. Retrying.
2019-11-08 11:42:55,114 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370117 timed out. Retrying.
2019-11-08 11:42:55,114 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370115 timed out. Retrying.
2019-11-08 11:42:55,115 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 0ms
2019-11-08 11:42:55,115 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370109 timed out. Retrying.
2019-11-08 11:42:55,693 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:55,697 [BlockDeletingService#1] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:56,113 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370113 timed out. Retrying.
2019-11-08 11:42:56,113 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370111 timed out. Retrying.
2019-11-08 11:42:56,115 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370117 timed out. Retrying.
2019-11-08 11:42:56,115 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370115 timed out. Retrying.
2019-11-08 11:42:56,115 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370118 timed out. Retrying.
2019-11-08 11:42:56,116 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 1ms
2019-11-08 11:42:56,118 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370109 timed out. Retrying.
2019-11-08 11:42:56,694 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:56,698 [BlockDeletingService#1] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:56,726 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#54-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:56,933 [Thread-576] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8 is not the leader, logIndex=0, commits[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c3]
2019-11-08 11:42:56,968 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:56,996 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: addNew group-B389A507CBBD:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561] returns group-B389A507CBBD:java.util.concurrent.CompletableFuture@7218b7f0[Not completed]
2019-11-08 11:42:56,998 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: new RaftServerImpl for group-B389A507CBBD:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561] with ContainerStateMachine:uninitialized
2019-11-08 11:42:56,998 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:42:56,998 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:42:56,998 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:42:56,998 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:42:56,998 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:42:56,999 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-B389A507CBBD: ConfigurationManager, init=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null, confs=<EMPTY_MAP>
2019-11-08 11:42:56,999 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis] (custom)
2019-11-08 11:42:56,999 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:42:56,999 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/8e9e7bd0-a7f8-4626-843d-b389a507cbbd does not exist. Creating ...
2019-11-08 11:42:57,021 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/8e9e7bd0-a7f8-4626-843d-b389a507cbbd/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:42:57,035 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/8e9e7bd0-a7f8-4626-843d-b389a507cbbd has been successfully formatted.
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-B389A507CBBD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-B389A507CBBD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/8e9e7bd0-a7f8-4626-843d-b389a507cbbd
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:42:57,036 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:42:57,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:57,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:42:57,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:42:57,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:42:57,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:42:57,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:42:57,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:42:57,037 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:42:57,038 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-B389A507CBBD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:42:57,038 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:42:57,038 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:42:57,038 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:42:57,038 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:42:57,038 [pool-60-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,038 [pool-60-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,039 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-B389A507CBBD: start as a follower, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null
2019-11-08 11:42:57,039 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-B389A507CBBD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:42:57,039 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start FollowerState
2019-11-08 11:42:57,039 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B389A507CBBD,id=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:42:57,039 [pool-60-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,045 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 8e9e7bd0-a7f8-4626-843d-b389a507cbbd, Nodes: 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-11-08 11:42:57,059 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: addNew group-59693DC2BCD6:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] returns group-59693DC2BCD6:java.util.concurrent.CompletableFuture@3e86938a[Not completed]
2019-11-08 11:42:57,059 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: addNew group-59693DC2BCD6:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] returns group-59693DC2BCD6:java.util.concurrent.CompletableFuture@77e59fc8[Not completed]
2019-11-08 11:42:57,059 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9cd44235-4493-4caa-8d24-81fb460b7910: addNew group-59693DC2BCD6:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] returns group-59693DC2BCD6:java.util.concurrent.CompletableFuture@5286d9b9[Not completed]
2019-11-08 11:42:57,060 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 9cd44235-4493-4caa-8d24-81fb460b7910: new RaftServerImpl for group-59693DC2BCD6:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] with ContainerStateMachine:uninitialized
2019-11-08 11:42:57,061 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:42:57,061 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:42:57,061 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:42:57,061 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:42:57,061 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:42:57,061 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-59693DC2BCD6: ConfigurationManager, init=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null, confs=<EMPTY_MAP>
2019-11-08 11:42:57,061 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis] (custom)
2019-11-08 11:42:57,061 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: new RaftServerImpl for group-59693DC2BCD6:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] with ContainerStateMachine:uninitialized
2019-11-08 11:42:57,062 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:42:57,062 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:42:57,062 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:42:57,062 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6 does not exist. Creating ...
2019-11-08 11:42:57,062 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:42:57,062 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:42:57,062 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: new RaftServerImpl for group-59693DC2BCD6:[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345] with ContainerStateMachine:uninitialized
2019-11-08 11:42:57,062 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:42:57,062 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-08 11:42:57,062 [pool-28-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-59693DC2BCD6: ConfigurationManager, init=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null, confs=<EMPTY_MAP>
2019-11-08 11:42:57,062 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-08 11:42:57,063 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis] (custom)
2019-11-08 11:42:57,063 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-11-08 11:42:57,063 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-08 11:42:57,063 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:42:57,063 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-08 11:42:57,063 [pool-28-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6 does not exist. Creating ...
2019-11-08 11:42:57,063 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-59693DC2BCD6: ConfigurationManager, init=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null, confs=<EMPTY_MAP>
2019-11-08 11:42:57,063 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis] (custom)
2019-11-08 11:42:57,064 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-08 11:42:57,064 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6 does not exist. Creating ...
2019-11-08 11:42:57,077 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:42:57,077 [pool-28-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:42:57,077 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6/in_use.lock acquired by nodename 3383@pr-hdds-2446-container-replica-x6kjd-4280001881
2019-11-08 11:42:57,102 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6 has been successfully formatted.
2019-11-08 11:42:57,102 [pool-28-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6 has been successfully formatted.
2019-11-08 11:42:57,102 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6 has been successfully formatted.
2019-11-08 11:42:57,102 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-59693DC2BCD6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:42:57,103 [pool-28-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-59693DC2BCD6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:42:57,103 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-59693DC2BCD6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-08 11:42:57,103 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:42:57,103 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:42:57,103 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-11-08 11:42:57,103 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:42:57,103 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:42:57,103 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:42:57,103 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-08 11:42:57,103 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:42:57,103 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:42:57,104 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:57,104 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-08 11:42:57,104 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:42:57,104 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:42:57,104 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 9cd44235-4493-4caa-8d24-81fb460b7910@group-59693DC2BCD6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-1/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6
2019-11-08 11:42:57,104 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-08 11:42:57,104 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:42:57,104 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:57,104 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:42:57,104 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:57,105 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:57,104 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:42:57,105 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:42:57,105 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-08 11:42:57,105 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:42:57,105 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-59693DC2BCD6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6
2019-11-08 11:42:57,105 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:42:57,105 [pool-28-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new aa7f8b24-2231-41b4-b786-06670f8a6b85@group-59693DC2BCD6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-0/data/ratis/7ddec1e3-fcc7-4039-807a-59693dc2bcd6
2019-11-08 11:42:57,105 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:42:57,105 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:42:57,105 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:42:57,105 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-08 11:42:57,106 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:42:57,105 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:42:57,106 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-08 11:42:57,106 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:42:57,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:57,106 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-08 11:42:57,106 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-59693DC2BCD6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:42:57,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:42:57,106 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-08 11:42:57,106 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:42:57,106 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:42:57,107 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:42:57,106 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-08 11:42:57,107 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:42:57,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:42:57,107 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:42:57,107 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-08 11:42:57,107 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:42:57,107 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,107 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-08 11:42:57,107 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-59693DC2BCD6: start as a follower, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:42:57,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:42:57,108 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-59693DC2BCD6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:42:57,107 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-08 11:42:57,108 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9cd44235-4493-4caa-8d24-81fb460b7910: start FollowerState
2019-11-08 11:42:57,108 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:42:57,108 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-08 11:42:57,108 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:42:57,108 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-08 11:42:57,108 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59693DC2BCD6,id=9cd44235-4493-4caa-8d24-81fb460b7910
2019-11-08 11:42:57,108 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-59693DC2BCD6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:42:57,108 [pool-38-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,109 [pool-28-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-59693DC2BCD6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-08 11:42:57,109 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:42:57,109 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:42:57,109 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:42:57,109 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-08 11:42:57,109 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:42:57,109 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-08 11:42:57,109 [pool-60-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,109 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-08 11:42:57,109 [pool-60-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,110 [pool-28-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-08 11:42:57,110 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-59693DC2BCD6: start as a follower, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:42:57,110 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,110 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-59693DC2BCD6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:42:57,111 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,111 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start FollowerState
2019-11-08 11:42:57,112 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-59693DC2BCD6: start as a follower, conf=-1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:42:57,112 [pool-28-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-59693DC2BCD6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-08 11:42:57,113 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59693DC2BCD6,id=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:42:57,113 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370111 timed out. Retrying.
2019-11-08 11:42:57,113 [pool-28-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start FollowerState
2019-11-08 11:42:57,113 [pool-60-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,114 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370113 timed out. Retrying.
2019-11-08 11:42:57,117 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 1ms
2019-11-08 11:42:57,120 [pool-28-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59693DC2BCD6,id=aa7f8b24-2231-41b4-b786-06670f8a6b85
2019-11-08 11:42:57,120 [pool-28-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-08 11:42:57,121 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370118 timed out. Retrying.
2019-11-08 11:42:57,122 [pool-8-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370109 timed out. Retrying.
2019-11-08 11:42:57,132 [pool-8-thread-4] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370115 timed out. Retrying.
2019-11-08 11:42:57,133 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370117 timed out. Retrying.
2019-11-08 11:42:57,133 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370119 timed out. Retrying.
2019-11-08 11:42:57,146 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7ddec1e3-fcc7-4039-807a-59693dc2bcd6, Nodes: aa7f8b24-2231-41b4-b786-06670f8a6b85{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}1e7fb4f5-6f16-4004-ac3f-6dfa33e29089{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}9cd44235-4493-4caa-8d24-81fb460b7910{ip: 192.168.157.246, host: pr-hdds-2446-container-replica-x6kjd-4280001881, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-11-08 11:42:57,168 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:57,368 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:57,669 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:57,695 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:57,700 [BlockDeletingService#1] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:57,955 [Thread-595] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c10]
2019-11-08 11:42:57,969 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-11-08 11:42:57,997 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,000 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,000 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,001 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,001 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,001 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,001 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,001 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,002 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(7)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,002 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,002 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,002 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,002 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(7)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,003 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,003 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,003 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,003 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,004 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,004 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(7)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,004 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,004 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,004 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,005 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,005 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,005 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(7)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,005 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,006 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,006 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,006 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,006 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,007 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(39)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,007 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,007 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,007 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(7)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,008 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,008 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:58,077 [Thread-558] INFO  impl.FollowerState (FollowerState.java:run(111)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-FollowerState: change to CANDIDATE, lastRpcTime:5087ms, electionTimeout:5087ms
2019-11-08 11:42:58,077 [Thread-558] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown FollowerState
2019-11-08 11:42:58,077 [Thread-558] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-11-08 11:42:58,077 [Thread-558] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start LeaderElection
2019-11-08 11:42:58,104 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5: begin an election at term 2 for 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null
2019-11-08 11:42:58,105 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown LeaderElection
2019-11-08 11:42:58,105 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-11-08 11:42:58,105 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: change Leader from null to 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 at term 2 for becomeLeader, leader elected after 7092ms
2019-11-08 11:42:58,106 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-08 11:42:58,107 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-08 11:42:58,107 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-08 11:42:58,107 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-08 11:42:58,107 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-08 11:42:58,107 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-08 11:42:58,107 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start LeaderState
2019-11-08 11:42:58,108 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(390)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2019-11-08 11:42:58,112 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2: set configuration 1: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561], old=null at 1
2019-11-08 11:42:58,114 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370111 timed out. Retrying.
2019-11-08 11:42:58,116 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(533)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2/current/log_inprogress_0 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2/current/log_0-0
2019-11-08 11:42:58,118 [SCMBlockDeletingService#0] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(187)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 1ms
2019-11-08 11:42:58,121 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370120 timed out. Retrying.
2019-11-08 11:42:58,156 [pool-8-thread-4] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370109 timed out. Retrying.
2019-11-08 11:42:58,156 [pool-8-thread-6] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370119 timed out. Retrying.
2019-11-08 11:42:58,156 [Thread-559] INFO  impl.FollowerState (FollowerState.java:run(111)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-FollowerState: change to CANDIDATE, lastRpcTime:5167ms, electionTimeout:5143ms
2019-11-08 11:42:58,156 [pool-8-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370113 timed out. Retrying.
2019-11-08 11:42:58,156 [Thread-559] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown FollowerState
2019-11-08 11:42:58,156 [pool-8-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370118 timed out. Retrying.
2019-11-08 11:42:58,156 [Thread-559] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-11-08 11:42:58,157 [pool-8-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370117 timed out. Retrying.
2019-11-08 11:42:58,157 [Thread-559] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start LeaderElection
2019-11-08 11:42:58,157 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370115 timed out. Retrying.
2019-11-08 11:42:58,178 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-CDA1A3F92AB2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-035c1a96-367d-4000-b85a-291890a3c0ab/datanode-2/data/ratis/668af6bd-712a-4f35-9c41-cda1a3f92ab2/current/log_inprogress_1
2019-11-08 11:42:58,201 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:58,201 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:58,201 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:58,202 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:58,202 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:58,202 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:58,202 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:58,214 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-LeaderElection6: begin an election at term 2 for 0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:42:58,270 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: change Leader from aa7f8b24-2231-41b4-b786-06670f8a6b85 to null at term 2 for updateCurrentTerm
2019-11-08 11:42:58,271 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8: changes role from    LEADER to FOLLOWER at term 2 for recognizeCandidate:1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:42:58,271 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: shutdown LeaderState
2019-11-08 11:42:58,281 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$552/654801563@79500904] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(149)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-11-08 11:42:58,282 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8: change Leader from aa7f8b24-2231-41b4-b786-06670f8a6b85 to null at term 2 for updateCurrentTerm
2019-11-08 11:42:58,282 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:1e7fb4f5-6f16-4004-ac3f-6dfa33e29089
2019-11-08 11:42:58,282 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9cd44235-4493-4caa-8d24-81fb460b7910: shutdown FollowerState
2019-11-08 11:42:58,283 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$552/654801563@2af8ed40] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(149)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->9cd44235-4493-4caa-8d24-81fb460b7910-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-11-08 11:42:58,284 [Thread-245] INFO  impl.FollowerState (FollowerState.java:run(120)) - 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-08 11:42:58,284 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9cd44235-4493-4caa-8d24-81fb460b7910: start FollowerState
2019-11-08 11:42:58,283 [grpc-default-executor-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8-PendingRequests: sendNotLeaderResponses
2019-11-08 11:42:58,287 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 9cd44235-4493-4caa-8d24-81fb460b7910: Completed APPEND_ENTRIES, lastRequest: aa7f8b24-2231-41b4-b786-06670f8a6b85->9cd44235-4493-4caa-8d24-81fb460b7910#55-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:58,293 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->9cd44235-4493-4caa-8d24-81fb460b7910-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-11-08 11:42:58,294 [Thread-605] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8 is not the leader, logIndex=0, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:42:58,296 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - aa7f8b24-2231-41b4-b786-06670f8a6b85: start FollowerState
2019-11-08 11:42:58,297 [Thread-606] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8 is not the leader, logIndex=0, commits[aa7f8b24-2231-41b4-b786-06670f8a6b85:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, 9cd44235-4493-4caa-8d24-81fb460b7910:c10]
2019-11-08 11:42:58,299 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->9cd44235-4493-4caa-8d24-81fb460b7910: nextIndex: updateUnconditionally 11 -> 10
2019-11-08 11:42:58,340 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-LeaderElection6: Election REJECTED; received 2 response(s) [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089<-aa7f8b24-2231-41b4-b786-06670f8a6b85#0:FAIL-t2, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089<-9cd44235-4493-4caa-8d24-81fb460b7910#0:FAIL-t2] and 0 exception(s); 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8:t2, leader=null, voted=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089, raftlog=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-SegmentedRaftLog:OPENED:c3,f4,i4, conf=0: [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:192.168.157.246:35561, aa7f8b24-2231-41b4-b786-06670f8a6b85:192.168.157.246:43877, 9cd44235-4493-4caa-8d24-81fb460b7910:192.168.157.246:44345], old=null
2019-11-08 11:42:58,356 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
2019-11-08 11:42:58,358 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: shutdown LeaderElection
2019-11-08 11:42:58,358 [1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089: start FollowerState
2019-11-08 11:42:58,698 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:58,701 [BlockDeletingService#1] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:59,097 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,097 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(47)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,097 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(39)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,098 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,098 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,098 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(4)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,098 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,098 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(11)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,099 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(7)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:42:59,118 [pool-8-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1573213370121 timed out. Retrying.
2019-11-08 11:42:59,204 [IPC Server handler 9 on 34327] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:incrementCount(141)) - Deleted TXID not found.
2019-11-08 11:42:59,205 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,205 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,205 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,205 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,206 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,206 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,206 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,206 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,206 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:42:59,206 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370109
2019-11-08 11:42:59,206 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370111
2019-11-08 11:42:59,206 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370120
2019-11-08 11:42:59,207 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370117
2019-11-08 11:42:59,207 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370118
2019-11-08 11:42:59,207 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370119
2019-11-08 11:42:59,207 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370113
2019-11-08 11:42:59,207 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370115
2019-11-08 11:42:59,227 [java.util.concurrent.ThreadPoolExecutor$Worker@2309ae49[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - aa7f8b24-2231-41b4-b786-06670f8a6b85@group-01E902698FE8->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089-GrpcLogAppender: appendEntries Timeout, request=aa7f8b24-2231-41b4-b786-06670f8a6b85->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089#55-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-11-08 11:42:59,406 [Thread-614] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 9cd44235-4493-4caa-8d24-81fb460b7910@group-01E902698FE8 is not the leader, logIndex=0, commits[9cd44235-4493-4caa-8d24-81fb460b7910:c10, 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c4, aa7f8b24-2231-41b4-b786-06670f8a6b85:c10]
2019-11-08 11:42:59,702 [BlockDeletingService#1] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:42:59,706 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:43:00,100 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(47)], numOfContainers=1, numOfBlocks=1
2019-11-08 11:43:00,207 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=1e7fb4f5-6f16-4004-ac3f-6dfa33e29089 for containerID=#1 failed. Corresponding entry not found.
2019-11-08 11:43:00,207 [EventQueue-DeleteBlockStatusForEventWatcher$$Lambda$29/35534346] WARN  events.EventWatcher (EventWatcher.java:lambda$start$0(110)) - Completion event without active lease. Id=1573213370121
2019-11-08 11:43:00,443 [Thread-620] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-ED959550D0B4->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-ED959550D0B4->1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 1e7fb4f5-6f16-4004-ac3f-6dfa33e29089@group-01E902698FE8 is not the leader, logIndex=0, commits[1e7fb4f5-6f16-4004-ac3f-6dfa33e29089:c3]
2019-11-08 11:43:00,704 [BlockDeletingService#1] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-11-08 11:43:00,732 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 51bfbc5c-0ef9-40d3-83c7-01e902698fe8 as the min replicated index is 4. Deletion is not allowed in this container yet.
]]></system-out>
    <system-err><![CDATA[ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
Nov 08, 2019 11:41:13 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@1b540d1e
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Nov 08, 2019 11:41:13 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed@16eb83bc
java.lang.NullPointerException
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onError(GrpcLogAppender.java:303)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

]]></system-err>
  </testcase>
</testsuite>