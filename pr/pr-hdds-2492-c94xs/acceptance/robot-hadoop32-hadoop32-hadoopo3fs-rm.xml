<?xml version="1.0" encoding="UTF-8"?>
<robot rpa="false" generated="20191115 04:38:44.634" generator="Robot 3.1.1 (Python 2.7.5 on linux2)">
<suite source="/opt/ozone/smoketest/ozonefs/hadoopo3fs.robot" id="s1" name="hadoop32-hadoopo3fs">
<test id="s1-t1" name="Test hadoop dfs">
<kw name="Generate Random String" library="String">
<doc>Generates a string with a desired ``length`` from the given ``chars``.</doc>
<arguments>
<arg>5</arg>
<arg>[NUMBERS]</arg>
</arguments>
<assign>
<var>${random}</var>
</assign>
<msg timestamp="20191115 04:38:44.698" level="INFO">${random} = 51749</msg>
<status status="PASS" endtime="20191115 04:38:44.698" starttime="20191115 04:38:44.698"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>hdfs dfs -put /opt/hadoop/NOTICE.txt o3fs://bucket1.vol1/${PREFIX}-${random}</arg>
</arguments>
<assign>
<var>${result}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191115 04:38:44.702" level="INFO">Running command 'hdfs dfs -put /opt/hadoop/NOTICE.txt o3fs://bucket1.vol1/ozone-51749 2&gt;&amp;1'.</msg>
<msg timestamp="20191115 04:39:24.503" level="INFO">${rc} = 0</msg>
<msg timestamp="20191115 04:39:24.503" level="INFO">${output} = 2019-11-15 04:38:47 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-15 04:38:47 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019...</msg>
<status status="PASS" endtime="20191115 04:39:24.503" starttime="20191115 04:38:44.700"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191115 04:39:24.504" level="INFO">2019-11-15 04:38:47 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-15 04:38:47 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-11-15 04:38:47 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
2019-11-15 04:39:18 WARN  XceiverClientRatis:277 - 3 way commit failed on pipeline Pipeline[ Id: cc9adef9-8478-49f8-a10c-717d99a3f9cd, Nodes: 88f71669-b763-4f70-8281-e4f93a985b54{ip: 172.18.0.8, host: hadoop32_datanode_3.hadoop32_default, networkLocation: /default-rack, certSerialId: null}392283af-ccd1-4730-a9e1-baed07c711db{ip: 172.18.0.6, host: hadoop32_datanode_1.hadoop32_default, networkLocation: /default-rack, certSerialId: null}93f310a3-c036-44b2-893a-46f723ece428{ip: 172.18.0.9, host: hadoop32_datanode_2.hadoop32_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
java.util.concurrent.TimeoutException
	at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:274)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:198)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:161)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:346)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:482)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.fs.ozone.OzoneFSOutputStream.close(OzoneFSOutputStream.java:56)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:70)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:367)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:304)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:286)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:270)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:295)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:177)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:327)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:390)
2019-11-15 04:39:18 INFO  XceiverClientRatis:295 - Could not commit index 6 on pipeline Pipeline[ Id: cc9adef9-8478-49f8-a10c-717d99a3f9cd, Nodes: 88f71669-b763-4f70-8281-e4f93a985b54{ip: 172.18.0.8, host: hadoop32_datanode_3.hadoop32_default, networkLocation: /default-rack, certSerialId: null}392283af-ccd1-4730-a9e1-baed07c711db{ip: 172.18.0.6, host: hadoop32_datanode_1.hadoop32_default, networkLocation: /default-rack, certSerialId: null}93f310a3-c036-44b2-893a-46f723ece428{ip: 172.18.0.9, host: hadoop32_datanode_2.hadoop32_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN] to all the nodes. Server 93f310a3-c036-44b2-893a-46f723ece428 has failed. Committed by majority.
2019-11-15 04:39:18 WARN  BlockOutputStream:352 - Failed to commit BlockId conID: 2 locID: 103140080168534017 bcsId: 6 on Pipeline[ Id: cc9adef9-8478-49f8-a10c-717d99a3f9cd, Nodes: 88f71669-b763-4f70-8281-e4f93a985b54{ip: 172.18.0.8, host: hadoop32_datanode_3.hadoop32_default, networkLocation: /default-rack, certSerialId: null}392283af-ccd1-4730-a9e1-baed07c711db{ip: 172.18.0.6, host: hadoop32_datanode_1.hadoop32_default, networkLocation: /default-rack, certSerialId: null}93f310a3-c036-44b2-893a-46f723ece428{ip: 172.18.0.9, host: hadoop32_datanode_2.hadoop32_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. Failed nodes: [93f310a3-c036-44b2-893a-46f723ece428{ip: null, host: null, networkLocation: /default-rack, certSerialId: null}]
2019-11-15 04:39:20 ERROR GrpcClientRpc:82 - client-9A08E0FD774B: XXX Failed RaftClientRequest:client-9A08E0FD774B-&gt;88f71669-b763-4f70-8281-e4f93a985b54@group-717D99A3F9CD, cid=3, seq=0, Watch-ALL_COMMITTED(6), null
org.apache.ratis.protocol.AlreadyClosedException: client-9A08E0FD774B is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:59)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:109)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsyncUnordered(GrpcClientRpc.java:78)
	at org.apache.ratis.client.impl.UnorderedAsync.sendRequestWithRetry(UnorderedAsync.java:75)
	at org.apache.ratis.client.impl.UnorderedAsync.lambda$null$2(UnorderedAsync.java:120)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-15 04:39:21 ERROR GrpcClientRpc:82 - client-9A08E0FD774B: XXX Failed RaftClientRequest:client-9A08E0FD774B-&gt;93f310a3-c036-44b2-893a-46f723ece428@group-717D99A3F9CD, cid=3, seq=0, Watch-ALL_COMMITTED(6), null
org.apache.ratis.protocol.AlreadyClosedException: client-9A08E0FD774B is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:59)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:109)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsyncUnordered(GrpcClientRpc.java:78)
	at org.apache.ratis.client.impl.UnorderedAsync.sendRequestWithRetry(UnorderedAsync.java:75)
	at org.apache.ratis.client.impl.UnorderedAsync.lambda$null$2(UnorderedAsync.java:120)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)</msg>
<status status="PASS" endtime="20191115 04:39:24.505" starttime="20191115 04:39:24.504"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191115 04:39:24.506" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<status status="PASS" endtime="20191115 04:39:24.506" starttime="20191115 04:39:24.505"></status>
</kw>
<msg timestamp="20191115 04:39:24.506" level="INFO">${result} = 2019-11-15 04:38:47 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-15 04:38:47 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019...</msg>
<status status="PASS" endtime="20191115 04:39:24.506" starttime="20191115 04:38:44.699"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>hdfs dfs -ls o3fs://bucket1.vol1/</arg>
</arguments>
<assign>
<var>${result}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191115 04:39:24.509" level="INFO">Running command 'hdfs dfs -ls o3fs://bucket1.vol1/ 2&gt;&amp;1'.</msg>
<msg timestamp="20191115 04:39:26.933" level="INFO">${rc} = 0</msg>
<msg timestamp="20191115 04:39:26.933" level="INFO">${output} = Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18189 2019-11-15 04:38 o3fs://bucket1.vol1/key1
-rw-rw-rw-   3 hadoop hadoop      22125 2019-11-15 04:39 o3fs://bucket1.vol1/ozone-51749
drwxrwxrwx   - ...</msg>
<status status="PASS" endtime="20191115 04:39:26.933" starttime="20191115 04:39:24.507"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191115 04:39:26.935" level="INFO">Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18189 2019-11-15 04:38 o3fs://bucket1.vol1/key1
-rw-rw-rw-   3 hadoop hadoop      22125 2019-11-15 04:39 o3fs://bucket1.vol1/ozone-51749
drwxrwxrwx   - hadoop hadoop          0 2019-11-15 04:39 o3fs://bucket1.vol1/user</msg>
<status status="PASS" endtime="20191115 04:39:26.935" starttime="20191115 04:39:26.934"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191115 04:39:26.937" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<status status="PASS" endtime="20191115 04:39:26.937" starttime="20191115 04:39:26.936"></status>
</kw>
<msg timestamp="20191115 04:39:26.937" level="INFO">${result} = Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18189 2019-11-15 04:38 o3fs://bucket1.vol1/key1
-rw-rw-rw-   3 hadoop hadoop      22125 2019-11-15 04:39 o3fs://bucket1.vol1/ozone-51749
drwxrwxrwx   - ...</msg>
<status status="PASS" endtime="20191115 04:39:26.938" starttime="20191115 04:39:24.506"></status>
</kw>
<kw name="Should Contain" library="BuiltIn">
<doc>Fails if ``container`` does not contain ``item`` one or more times.</doc>
<arguments>
<arg>${result}</arg>
<arg>${PREFIX}-${random}</arg>
</arguments>
<status status="PASS" endtime="20191115 04:39:26.939" starttime="20191115 04:39:26.938"></status>
</kw>
<status status="PASS" endtime="20191115 04:39:26.939" critical="yes" starttime="20191115 04:38:44.697"></status>
</test>
<doc>Test ozone fs with hadoopfs</doc>
<status status="PASS" endtime="20191115 04:39:26.940" starttime="20191115 04:38:44.634"></status>
</suite>
<statistics>
<total>
<stat fail="0" pass="1">Critical Tests</stat>
<stat fail="0" pass="1">All Tests</stat>
</total>
<tag>
</tag>
<suite>
<stat fail="0" id="s1" name="hadoop32-hadoopo3fs" pass="1">hadoop32-hadoopo3fs</stat>
</suite>
</statistics>
<errors>
</errors>
</robot>
