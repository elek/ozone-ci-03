Attaching to ozonesecure_s3g_1, ozonesecure_datanode_3, ozonesecure_scm_1, ozonesecure_recon_1, ozonesecure_om_1, ozonesecure_kms_1, ozonesecure_datanode_2, ozonesecure_datanode_1, ozonesecure_kdc_1
recon_1     | Sleeping for 5 seconds
recon_1     | Waiting for the service om:9874
recon_1     | Setting up kerberos!!
recon_1     | KDC ISSUER_SERVER => kdc:8081
recon_1     | Sleeping for 5 seconds
recon_1     | --2019-11-05 23:00:46--  http://kdc:8081/keytab/recon/dn
recon_1     | Got 200, KDC service ready!!
recon_1     | Download dn/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
recon_1     | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 144 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/dn.keytab'
recon_1     | 
recon_1     |      0K                                                       100% 12.8M=0s
recon_1     | 
recon_1     | 2019-11-05 23:00:47 (12.8 MB/s) - '/etc/security/keytabs/dn.keytab' saved [144/144]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/dn.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 11/05/19 23:00:46 dn/recon@EXAMPLE.COM
recon_1     |    2 11/05/19 23:00:46 dn/recon@EXAMPLE.COM
recon_1     | Download om/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
recon_1     | --2019-11-05 23:00:47--  http://kdc:8081/keytab/recon/om
recon_1     | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 144 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/om.keytab'
recon_1     | 
recon_1     |      0K                                                       100% 12.0M=0s
recon_1     | 
recon_1     | 2019-11-05 23:00:47 (12.0 MB/s) - '/etc/security/keytabs/om.keytab' saved [144/144]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/om.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 11/05/19 23:00:47 om/recon@EXAMPLE.COM
recon_1     |    2 11/05/19 23:00:47 om/recon@EXAMPLE.COM
recon_1     | Download scm/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
recon_1     | --2019-11-05 23:00:47--  http://kdc:8081/keytab/recon/scm
recon_1     | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 146 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/scm.keytab'
recon_1     | 
recon_1     |      0K                                                       100% 12.7M=0s
recon_1     | 
recon_1     | 2019-11-05 23:00:47 (12.7 MB/s) - '/etc/security/keytabs/scm.keytab' saved [146/146]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/scm.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 11/05/19 23:00:47 scm/recon@EXAMPLE.COM
recon_1     |    2 11/05/19 23:00:47 scm/recon@EXAMPLE.COM
recon_1     | Download HTTP/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
recon_1     | --2019-11-05 23:00:47--  http://kdc:8081/keytab/recon/HTTP
recon_1     | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Sleeping for 5 seconds
datanode_2  | Setting up kerberos!!
datanode_2  | KDC ISSUER_SERVER => kdc:8081
datanode_2  | Sleeping for 5 seconds
datanode_2  | Got 200, KDC service ready!!
datanode_2  | Download dn/90f7296b0733@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | --2019-11-05 22:59:45--  http://kdc:8081/keytab/90f7296b0733/dn
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 158 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 9.40M=0s
datanode_2  | 
datanode_2  | 2019-11-05 22:59:45 (9.40 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 11/05/19 22:59:45 dn/90f7296b0733@EXAMPLE.COM
datanode_3  | Sleeping for 5 seconds
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 148 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/HTTP.keytab'
recon_1     | 
om_1        | Sleeping for 5 seconds
recon_1     |      0K                                                       100% 15.2M=0s
kms_1       | Sleeping for 5 seconds
recon_1     | 
datanode_2  |    2 11/05/19 22:59:45 dn/90f7296b0733@EXAMPLE.COM
kms_1       | Setting up kerberos!!
kms_1       | KDC ISSUER_SERVER => kdc:8081
datanode_2  | Download om/90f7296b0733@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om_1        | Setting up kerberos!!
datanode_1  | Sleeping for 5 seconds
s3g_1       | Sleeping for 5 seconds
s3g_1       | Setting up kerberos!!
datanode_2  | --2019-11-05 22:59:45--  http://kdc:8081/keytab/90f7296b0733/om
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Sleeping for  seconds
kms_1       | /opt/starter.sh: line 66: SLEEP_SECONDS: command not found
kms_1       | Got 200, KDC service ready!!
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 158 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/om.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 14.7M=0s
datanode_2  | 
kms_1       | Download dn/c695af16ce49@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
kms_1       | --2019-11-05 22:59:48--  http://kdc:8081/keytab/c695af16ce49/dn
s3g_1       | KDC ISSUER_SERVER => kdc:8081
datanode_1  | Setting up kerberos!!
scm_1       | Sleeping for 5 seconds
scm_1       | Setting up kerberos!!
scm_1       | KDC ISSUER_SERVER => kdc:8081
kms_1       | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | HTTP request sent, awaiting response... 200 OK
kms_1       | Length: 158 [application/octet-stream]
datanode_3  | Setting up kerberos!!
datanode_3  | KDC ISSUER_SERVER => kdc:8081
datanode_1  | KDC ISSUER_SERVER => kdc:8081
datanode_1  | Sleeping for 5 seconds
datanode_1  | Got 200, KDC service ready!!
datanode_1  | Download dn/6143ae4c601c@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_3  | Sleeping for 5 seconds
datanode_2  | 2019-11-05 22:59:46 (14.7 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
kms_1       | Saving to: '/etc/security/keytabs/dn.keytab'
kms_1       | 
datanode_3  | Got 200, KDC service ready!!
datanode_1  | --2019-11-05 22:59:45--  http://kdc:8081/keytab/6143ae4c601c/dn
kms_1       |      0K                                                       100% 16.2M=0s
kms_1       | 
datanode_3  | Download dn/c95e120dae5a@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | 
datanode_3  | --2019-11-05 22:59:53--  http://kdc:8081/keytab/c95e120dae5a/dn
recon_1     | 2019-11-05 23:00:50 (15.2 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [148/148]
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
recon_1     | 
datanode_1  | HTTP request sent, awaiting response... 200 OK
kms_1       | 2019-11-05 22:59:52 (16.2 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
kms_1       | 
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | Length: 158 [application/octet-stream]
kms_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
kms_1       | KVNO Timestamp         Principal
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Saving to: '/etc/security/keytabs/dn.keytab'
kms_1       | ---- ----------------- --------------------------------------------------------
kms_1       |    2 11/05/19 22:59:51 dn/c695af16ce49@EXAMPLE.COM
datanode_3  | Length: 158 [application/octet-stream]
recon_1     | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_1  | 
datanode_1  |      0K                                                       100% 11.1M=0s
kms_1       |    2 11/05/19 22:59:51 dn/c695af16ce49@EXAMPLE.COM
recon_1     | KVNO Timestamp         Principal
datanode_3  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_2  | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_1  | 
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 11/05/19 22:59:46 om/90f7296b0733@EXAMPLE.COM
datanode_2  |    2 11/05/19 22:59:46 om/90f7296b0733@EXAMPLE.COM
datanode_2  | Download scm/90f7296b0733@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_2  | --2019-11-05 22:59:46--  http://kdc:8081/keytab/90f7296b0733/scm
kms_1       | Download om/c695af16ce49@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
kms_1       | --2019-11-05 22:59:52--  http://kdc:8081/keytab/c695af16ce49/om
kms_1       | Resolving kdc (kdc)... 172.18.0.2
recon_1     | ---- ----------------- --------------------------------------------------------
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | HTTP request sent, awaiting response... 200 OK
kms_1       | Length: 158 [application/octet-stream]
recon_1     |    2 11/05/19 23:00:50 HTTP/recon@EXAMPLE.COM
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | 2019-11-05 22:59:45 (11.1 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
recon_1     |    2 11/05/19 23:00:50 HTTP/recon@EXAMPLE.COM
datanode_3  | 
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 11/05/19 22:59:45 dn/6143ae4c601c@EXAMPLE.COM
recon_1     | Download testuser/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
kms_1       | Saving to: '/etc/security/keytabs/om.keytab'
datanode_2  | Length: 160 [application/octet-stream]
recon_1     | --2019-11-05 23:00:50--  http://kdc:8081/keytab/recon/testuser
kms_1       | 
datanode_2  | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_3  |      0K                                                       100% 17.0M=0s
datanode_3  | 
datanode_3  | 2019-11-05 22:59:56 (17.0 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
kms_1       |      0K                                                       100% 15.1M=0s
datanode_2  | 
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_3  | KVNO Timestamp         Principal
recon_1     | Resolving kdc (kdc)... 172.18.0.2
kms_1       | 
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 11/05/19 22:59:56 dn/c95e120dae5a@EXAMPLE.COM
datanode_3  |    2 11/05/19 22:59:56 dn/c95e120dae5a@EXAMPLE.COM
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | 2019-11-05 22:59:53 (15.1 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
datanode_2  |      0K                                                       100% 18.6M=0s
datanode_3  | Download om/c95e120dae5a@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_3  | --2019-11-05 22:59:56--  http://kdc:8081/keytab/c95e120dae5a/om
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
kms_1       | 
datanode_2  | 
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 158 [application/octet-stream]
recon_1     | HTTP request sent, awaiting response... 200 OK
kms_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_3  | Saving to: '/etc/security/keytabs/om.keytab'
datanode_3  | 
datanode_3  |      0K                                                       100% 15.2M=0s
recon_1     | Length: 156 [application/octet-stream]
datanode_3  | 
datanode_3  | 2019-11-05 22:59:58 (15.2 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
datanode_3  | 
datanode_2  | 2019-11-05 22:59:51 (18.6 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
kdc_1       | Issuer is listening on : 8081krb5kdc: starting...
kdc_1       | kadmind: starting...
datanode_3  | Keytab name: FILE:/etc/security/keytabs/om.keytab
kms_1       | KVNO Timestamp         Principal
datanode_2  | 
kdc_1       | Nov 05 22:58:41 b02a64d1ea45 kadmin.local[1](info): No dictionary file specified, continuing without one.
kdc_1       | Nov 05 22:58:49 a143a1a61774 kadmin.local[1](info): No dictionary file specified, continuing without one.
recon_1     | Saving to: '/etc/security/keytabs/testuser.keytab'
kms_1       | ---- ----------------- --------------------------------------------------------
kms_1       |    2 11/05/19 22:59:53 om/c695af16ce49@EXAMPLE.COM
s3g_1       | Sleeping for 5 seconds
s3g_1       | Got 200, KDC service ready!!
s3g_1       | Download dn/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
kdc_1       | Nov 05 22:59:35 kdc kadmind[15](info): No dictionary file specified, continuing without one.
kdc_1       | Nov 05 22:59:35 kdc kadmind[15](info): setting up network...
recon_1     | 
recon_1     |      0K                                                       100% 3.56M=0s
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
scm_1       | Sleeping for 5 seconds
s3g_1       | --2019-11-05 22:59:55--  http://kdc:8081/keytab/s3g/dn
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | kadmind: setsockopt(9,IPV6_V6ONLY,1) worked
kdc_1       | kadmind: setsockopt(11,IPV6_V6ONLY,1) worked
recon_1     | 
recon_1     | 2019-11-05 23:00:51 (3.56 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [156/156]
datanode_3  |    2 11/05/19 22:59:58 om/c95e120dae5a@EXAMPLE.COM
kms_1       |    2 11/05/19 22:59:53 om/c695af16ce49@EXAMPLE.COM
scm_1       | Got 200, KDC service ready!!
om_1        | KDC ISSUER_SERVER => kdc:8081
datanode_1  |    2 11/05/19 22:59:45 dn/6143ae4c601c@EXAMPLE.COM
datanode_1  | Download om/6143ae4c601c@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | 
kms_1       | Download scm/c695af16ce49@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
kms_1       | --2019-11-05 22:59:53--  http://kdc:8081/keytab/c695af16ce49/scm
scm_1       | Download dn/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
scm_1       | --2019-11-05 22:59:53--  http://kdc:8081/keytab/scm/dn
datanode_1  | --2019-11-05 22:59:45--  http://kdc:8081/keytab/6143ae4c601c/om
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
kms_1       | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
datanode_2  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_2  | KVNO Timestamp         Principal
s3g_1       |    2 11/05/19 22:59:57 dn/s3g@EXAMPLE.COM
kms_1       | HTTP request sent, awaiting response... 200 OK
kms_1       | Length: 160 [application/octet-stream]
datanode_1  | HTTP request sent, awaiting response... 200 OK
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 140 [application/octet-stream]
recon_1     | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 11/05/19 22:59:50 scm/90f7296b0733@EXAMPLE.COM
s3g_1       |    2 11/05/19 22:59:57 dn/s3g@EXAMPLE.COM
kms_1       | Saving to: '/etc/security/keytabs/scm.keytab'
kms_1       | 
kms_1       |      0K                                                       100% 16.0M=0s
scm_1       | Saving to: '/etc/security/keytabs/dn.keytab'
scm_1       | 
datanode_2  |    2 11/05/19 22:59:51 scm/90f7296b0733@EXAMPLE.COM
datanode_2  | Download HTTP/90f7296b0733@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
s3g_1       | Download om/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 140 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/dn.keytab'
scm_1       |      0K                                                       100% 13.7M=0s
scm_1       | 
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 11/05/19 23:00:51 testuser/recon@EXAMPLE.COM
kms_1       | 
kms_1       | 2019-11-05 22:59:53 (16.0 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
kms_1       | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
scm_1       | 2019-11-05 22:59:57 (13.7 MB/s) - '/etc/security/keytabs/dn.keytab' saved [140/140]
scm_1       | 
datanode_1  | Length: 158 [application/octet-stream]
datanode_2  | --2019-11-05 22:59:51--  http://kdc:8081/keytab/90f7296b0733/HTTP
kms_1       | KVNO Timestamp         Principal
kms_1       | ---- ----------------- --------------------------------------------------------
kms_1       |    2 11/05/19 22:59:53 scm/c695af16ce49@EXAMPLE.COM
scm_1       | Keytab name: FILE:/etc/security/keytabs/dn.keytab
scm_1       | KVNO Timestamp         Principal
s3g_1       | 
s3g_1       |      0K                                                       100% 14.5M=0s
datanode_1  | Saving to: '/etc/security/keytabs/om.keytab'
kms_1       |    2 11/05/19 22:59:53 scm/c695af16ce49@EXAMPLE.COM
kms_1       | Download HTTP/c695af16ce49@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
kms_1       | --2019-11-05 22:59:53--  http://kdc:8081/keytab/c695af16ce49/HTTP
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 11/05/19 22:59:56 dn/scm@EXAMPLE.COM
s3g_1       | 
s3g_1       | 2019-11-05 22:59:57 (14.5 MB/s) - '/etc/security/keytabs/dn.keytab' saved [140/140]
datanode_1  | 
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | HTTP request sent, awaiting response... 200 OK
scm_1       |    2 11/05/19 22:59:57 dn/scm@EXAMPLE.COM
scm_1       | Download om/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
s3g_1       | 
s3g_1       | --2019-11-05 22:59:57--  http://kdc:8081/keytab/s3g/om
datanode_1  |      0K                                                       100% 15.1M=0s
kms_1       | Length: 162 [application/octet-stream]
kms_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
kms_1       | 
scm_1       | --2019-11-05 22:59:57--  http://kdc:8081/keytab/scm/om
scm_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | 
kms_1       |      0K                                                       100% 16.6M=0s
kms_1       | 
kms_1       | 2019-11-05 22:59:56 (16.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
recon_1     |    2 11/05/19 23:00:51 testuser/recon@EXAMPLE.COM
datanode_1  | 2019-11-05 22:59:46 (15.1 MB/s) - '/etc/security/keytabs/om.keytab' saved [158/158]
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
kms_1       | KVNO Timestamp         Principal
om_1        | Sleeping for 5 seconds
s3g_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 140 [application/octet-stream]
recon_1     | Download testuser2/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_1  | KVNO Timestamp         Principal
kms_1       | ---- ----------------- --------------------------------------------------------
s3g_1       | Length: 140 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/om.keytab'
recon_1     | --2019-11-05 23:00:51--  http://kdc:8081/keytab/recon/testuser2
datanode_3  |    2 11/05/19 22:59:58 om/c95e120dae5a@EXAMPLE.COM
datanode_3  | Download scm/c95e120dae5a@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
om_1        | Got 200, KDC service ready!!
datanode_1  | ---- ----------------- --------------------------------------------------------
kms_1       |    2 11/05/19 22:59:56 HTTP/c695af16ce49@EXAMPLE.COM
s3g_1       | Saving to: '/etc/security/keytabs/om.keytab'
scm_1       | 
recon_1     | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | --2019-11-05 22:59:58--  http://kdc:8081/keytab/c95e120dae5a/scm
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
om_1        | Download dn/om@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_1  |    2 11/05/19 22:59:46 om/6143ae4c601c@EXAMPLE.COM
datanode_2  | HTTP request sent, awaiting response... 200 OK
kms_1       |    2 11/05/19 22:59:56 HTTP/c695af16ce49@EXAMPLE.COM
scm_1       |      0K                                                       100% 3.13M=0s
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
om_1        | --2019-11-05 22:59:48--  http://kdc:8081/keytab/om/dn
datanode_1  |    2 11/05/19 22:59:46 om/6143ae4c601c@EXAMPLE.COM
datanode_2  | Length: 162 [application/octet-stream]
kms_1       | Download testuser/c695af16ce49@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
scm_1       | 
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 160 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/scm.keytab'
om_1        | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Download scm/6143ae4c601c@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
datanode_2  | Saving to: '/etc/security/keytabs/HTTP.keytab'
kms_1       | --2019-11-05 22:59:56--  http://kdc:8081/keytab/c695af16ce49/testuser
scm_1       | 2019-11-05 22:59:58 (3.13 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
recon_1     | Length: 158 [application/octet-stream]
datanode_3  | 
datanode_3  |      0K                                                       100% 14.2M=0s
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | --2019-11-05 22:59:46--  http://kdc:8081/keytab/6143ae4c601c/scm
datanode_2  | 
kms_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | 
recon_1     | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_3  | 
datanode_3  | 2019-11-05 23:00:02 (14.2 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  |      0K                                                       100% 1.88M=0s
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
recon_1     | 
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
om_1        | Length: 138 [application/octet-stream]
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | 
kms_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | KVNO Timestamp         Principal
recon_1     |      0K                                                       100% 14.3M=0s
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
om_1        | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 160 [application/octet-stream]
s3g_1       | 
scm_1       | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 11/05/19 23:00:01 scm/c95e120dae5a@EXAMPLE.COM
kdc_1       | kadmind: setsockopt(13,IPV6_V6ONLY,1) worked
om_1        | 
datanode_1  | Saving to: '/etc/security/keytabs/scm.keytab'
datanode_1  | 
s3g_1       |      0K                                                       100% 14.2M=0s
scm_1       |    2 11/05/19 22:59:58 om/scm@EXAMPLE.COM
recon_1     | 
recon_1     | 2019-11-05 23:00:51 (14.3 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [158/158]
kdc_1       | Nov 05 22:59:35 kdc kadmind[15](info): set up 6 sockets
kdc_1       | Nov 05 22:59:35 kdc kadmind[15](info): Seeding random number generator
om_1        |      0K                                                       100% 10.4M=0s
datanode_1  |      0K                                                       100% 17.1M=0s
datanode_1  | 
s3g_1       | 
scm_1       |    2 11/05/19 22:59:58 om/scm@EXAMPLE.COM
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
kdc_1       | Nov 05 22:59:35 kdc kadmind[15](info): starting
kdc_1       | otp: Loaded
om_1        | 
datanode_1  | 2019-11-05 22:59:48 (17.1 MB/s) - '/etc/security/keytabs/scm.keytab' saved [160/160]
datanode_1  | 
s3g_1       | 2019-11-05 22:59:59 (14.2 MB/s) - '/etc/security/keytabs/om.keytab' saved [140/140]
scm_1       | Download scm/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
kdc_1       | Nov 05 22:59:31 kdc krb5kdc[9](info): setting up network...
kdc_1       | krb5kdc: setsockopt(9,IPV6_V6ONLY,1) worked
om_1        | 2019-11-05 22:59:51 (10.4 MB/s) - '/etc/security/keytabs/dn.keytab' saved [138/138]
datanode_1  | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_1  | KVNO Timestamp         Principal
s3g_1       | 
scm_1       | --2019-11-05 22:59:58--  http://kdc:8081/keytab/scm/scm
recon_1     |    2 11/05/19 23:00:51 testuser2/recon@EXAMPLE.COM
recon_1     |    2 11/05/19 23:00:51 testuser2/recon@EXAMPLE.COM
datanode_3  |    2 11/05/19 23:00:02 scm/c95e120dae5a@EXAMPLE.COM
om_1        | 
kdc_1       | krb5kdc: setsockopt(11,IPV6_V6ONLY,1) worked
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 11/05/19 22:59:48 scm/6143ae4c601c@EXAMPLE.COM
s3g_1       | Keytab name: FILE:/etc/security/keytabs/om.keytab
scm_1       | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Download s3g/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_2  | 2019-11-05 22:59:52 (1.88 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_3  | Download HTTP/c95e120dae5a@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om_1        | Keytab name: FILE:/etc/security/keytabs/dn.keytab
kdc_1       | Nov 05 22:59:31 kdc krb5kdc[9](info): set up 4 sockets
kdc_1       | Nov 05 22:59:31 kdc krb5kdc[9](info): commencing operation
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | --2019-11-05 23:00:51--  http://kdc:8081/keytab/recon/s3g
datanode_3  | --2019-11-05 23:00:02--  http://kdc:8081/keytab/c95e120dae5a/HTTP
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | 
om_1        | KVNO Timestamp         Principal
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  |    2 11/05/19 22:59:48 scm/6143ae4c601c@EXAMPLE.COM
datanode_2  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om_1        | ---- ----------------- --------------------------------------------------------
kdc_1       | Nov 05 22:59:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kms_1       | Length: 170 [application/octet-stream]
s3g_1       | KVNO Timestamp         Principal
scm_1       | Length: 142 [application/octet-stream]
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Download HTTP/6143ae4c601c@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_2  | KVNO Timestamp         Principal
om_1        |    2 11/05/19 22:59:51 dn/om@EXAMPLE.COM
kdc_1       | Nov 05 22:59:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994783, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kms_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1       | ---- ----------------- --------------------------------------------------------
scm_1       | Saving to: '/etc/security/keytabs/scm.keytab'
recon_1     | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 162 [application/octet-stream]
datanode_1  | --2019-11-05 22:59:48--  http://kdc:8081/keytab/6143ae4c601c/HTTP
om_1        |    2 11/05/19 22:59:51 dn/om@EXAMPLE.COM
datanode_2  | ---- ----------------- --------------------------------------------------------
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
kms_1       | 
s3g_1       |    2 11/05/19 22:59:59 om/s3g@EXAMPLE.COM
scm_1       | 
recon_1     | Length: 146 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
om_1        | Download om/om@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
datanode_2  |    2 11/05/19 22:59:52 HTTP/90f7296b0733@EXAMPLE.COM
kdc_1       | Principal "test/test@EXAMPLE.COM" created.
kms_1       |      0K                                                       100% 1.23M=0s
s3g_1       |    2 11/05/19 22:59:59 om/s3g@EXAMPLE.COM
scm_1       |      0K                                                       100% 1.75M=0s
recon_1     | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_3  | 
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | --2019-11-05 22:59:51--  http://kdc:8081/keytab/om/om
datanode_2  |    2 11/05/19 22:59:52 HTTP/90f7296b0733@EXAMPLE.COM
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kms_1       | 
s3g_1       | Download scm/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
recon_1     | 
scm_1       | 
datanode_3  |      0K                                                       100% 15.4M=0s
datanode_1  | HTTP request sent, awaiting response... 200 OK
om_1        | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Download testuser/90f7296b0733@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kms_1       | 2019-11-05 22:59:58 (1.23 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
s3g_1       | --2019-11-05 22:59:59--  http://kdc:8081/keytab/s3g/scm
recon_1     |      0K                                                       100% 13.6M=0s
scm_1       | 2019-11-05 23:00:02 (1.75 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
datanode_1  | Length: 162 [application/octet-stream]
datanode_3  | 
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | --2019-11-05 22:59:52--  http://kdc:8081/keytab/90f7296b0733/testuser
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kms_1       | 
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
recon_1     | 
scm_1       | 
datanode_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_3  | 2019-11-05 23:00:05 (15.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
om_1        | HTTP request sent, awaiting response... 200 OK
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Generiting keytab
kms_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | 2019-11-05 23:00:52 (13.6 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [146/146]
scm_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
datanode_1  | 
datanode_3  | 
om_1        | Length: 138 [application/octet-stream]
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | HTTP request sent, awaiting response... 200 OK
recon_1     | 
scm_1       | KVNO Timestamp         Principal
kms_1       | KVNO Timestamp         Principal
datanode_1  |      0K                                                       100% 17.6M=0s
datanode_3  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om_1        | Saving to: '/etc/security/keytabs/om.keytab'
datanode_2  | HTTP request sent, awaiting response... 200 OK
kdc_1       | WARNING: no policy specified for dn/6143ae4c601c@EXAMPLE.COM; defaulting to no policy
s3g_1       | Length: 142 [application/octet-stream]
recon_1     | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
scm_1       | ---- ----------------- --------------------------------------------------------
kms_1       | ---- ----------------- --------------------------------------------------------
datanode_1  | 
datanode_3  | KVNO Timestamp         Principal
om_1        | 
datanode_2  | Length: 170 [application/octet-stream]
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | Saving to: '/etc/security/keytabs/scm.keytab'
recon_1     | KVNO Timestamp         Principal
scm_1       |    2 11/05/19 23:00:02 scm/scm@EXAMPLE.COM
kms_1       |    2 11/05/19 22:59:58 testuser/c695af16ce49@EXAMPLE.COM
datanode_1  | 2019-11-05 22:59:52 (17.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_3  | ---- ----------------- --------------------------------------------------------
om_1        |      0K                                                       100% 3.93M=0s
datanode_2  | Saving to: '/etc/security/keytabs/testuser.keytab'
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994785, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 
recon_1     | ---- ----------------- --------------------------------------------------------
kms_1       |    2 11/05/19 22:59:58 testuser/c695af16ce49@EXAMPLE.COM
scm_1       |    2 11/05/19 23:00:02 scm/scm@EXAMPLE.COM
datanode_1  | 
datanode_3  |    2 11/05/19 23:00:05 HTTP/c95e120dae5a@EXAMPLE.COM
om_1        | 
datanode_2  | 
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       |      0K                                                       100% 20.2M=0s
recon_1     |    2 11/05/19 23:00:51 s3g/recon@EXAMPLE.COM
kms_1       | Download testuser2/c695af16ce49@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       | Download HTTP/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om_1        | 2019-11-05 22:59:52 (3.93 MB/s) - '/etc/security/keytabs/om.keytab' saved [138/138]
datanode_3  |    2 11/05/19 23:00:05 HTTP/c95e120dae5a@EXAMPLE.COM
datanode_2  |      0K                                                       100% 13.2M=0s
s3g_1       | 
recon_1     |    2 11/05/19 23:00:52 s3g/recon@EXAMPLE.COM
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
scm_1       | --2019-11-05 23:00:02--  http://kdc:8081/keytab/scm/HTTP
scm_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 144 [application/octet-stream]
datanode_2  | 
s3g_1       | 2019-11-05 23:00:03 (20.2 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2019-11-05 23:00:54,039 [main] INFO       - rest([/api/*]).packages(org.apache.hadoop.ozone.recon.api)
scm_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
scm_1       | 
om_1        | 
datanode_2  | 2019-11-05 22:59:53 (13.2 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
s3g_1       | 
recon_1     | 2019-11-05 23:00:54,659 [main] INFO       - Initializing Recon server...
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994785, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:43 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:44 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | Download testuser/c95e120dae5a@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
scm_1       |      0K                                                       100% 3.04M=0s
om_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
datanode_2  | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | --2019-11-05 22:59:58--  http://kdc:8081/keytab/c695af16ce49/testuser2
datanode_1  | KVNO Timestamp         Principal
datanode_3  | --2019-11-05 23:00:05--  http://kdc:8081/keytab/c95e120dae5a/testuser
recon_1     | 2019-11-05 23:00:55,515 [main] ERROR      - Error during initializing Recon server.
scm_1       | 
om_1        | KVNO Timestamp         Principal
datanode_2  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
s3g_1       | KVNO Timestamp         Principal
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](info): closing down fd 18
kms_1       | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
recon_1     | java.sql.SQLException: path to '//data/metadata/recon/ozone_recon_sqlite.db': '/data/metadata' does not exist
scm_1       | 2019-11-05 23:00:06 (3.04 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
om_1        | ---- ----------------- --------------------------------------------------------
datanode_2  | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
datanode_1  |    2 11/05/19 22:59:52 HTTP/6143ae4c601c@EXAMPLE.COM
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | 	at org.sqlite.SQLiteConnection.open(SQLiteConnection.java:215)
scm_1       | 
om_1        |    2 11/05/19 22:59:52 om/om@EXAMPLE.COM
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 11/05/19 22:59:53 testuser/90f7296b0733@EXAMPLE.COM
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  |    2 11/05/19 22:59:52 HTTP/6143ae4c601c@EXAMPLE.COM
kms_1       | HTTP request sent, awaiting response... 200 OK
datanode_3  | HTTP request sent, awaiting response... 200 OK
recon_1     | 	at org.sqlite.SQLiteConnection.<init>(SQLiteConnection.java:61)
scm_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om_1        |    2 11/05/19 22:59:52 om/om@EXAMPLE.COM
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | Length: 172 [application/octet-stream]
recon_1     | 	at org.sqlite.jdbc3.JDBC3Connection.<init>(JDBC3Connection.java:28)
datanode_1  | Download testuser/6143ae4c601c@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
datanode_1  | --2019-11-05 22:59:52--  http://kdc:8081/keytab/6143ae4c601c/testuser
datanode_2  |    2 11/05/19 22:59:53 testuser/90f7296b0733@EXAMPLE.COM
scm_1       | KVNO Timestamp         Principal
om_1        | Download scm/om@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](info): closing down fd 18
kms_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
recon_1     | 	at org.sqlite.jdbc4.JDBC4Connection.<init>(JDBC4Connection.java:21)
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | Length: 170 [application/octet-stream]
datanode_2  | Download testuser2/90f7296b0733@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       | ---- ----------------- --------------------------------------------------------
om_1        | --2019-11-05 22:59:52--  http://kdc:8081/keytab/om/scm
s3g_1       |    2 11/05/19 23:00:03 scm/s3g@EXAMPLE.COM
kms_1       | 
recon_1     | 	at org.sqlite.JDBC.createConnection(JDBC.java:116)
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_2  | --2019-11-05 22:59:53--  http://kdc:8081/keytab/90f7296b0733/testuser2
scm_1       |    2 11/05/19 23:00:05 HTTP/scm@EXAMPLE.COM
om_1        | Resolving kdc (kdc)... 172.18.0.2
s3g_1       |    2 11/05/19 23:00:03 scm/s3g@EXAMPLE.COM
kms_1       |      0K                                                       100% 12.5M=0s
recon_1     | 	at org.sqlite.SQLiteDataSource.getConnection(SQLiteDataSource.java:410)
recon_1     | 	at org.sqlite.SQLiteDataSource.getConnection(SQLiteDataSource.java:398)
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_3  | 
datanode_3  |      0K                                                       100% 17.0M=0s
scm_1       |    2 11/05/19 23:00:05 HTTP/scm@EXAMPLE.COM
scm_1       | Download testuser/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
scm_1       | --2019-11-05 23:00:06--  http://kdc:8081/keytab/scm/testuser
kms_1       | 
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Principal "dn/6143ae4c601c@EXAMPLE.COM" created.
kms_1       | 2019-11-05 22:59:59 (12.5 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
kms_1       | 
kms_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
kms_1       | KVNO Timestamp         Principal
datanode_1  | Length: 170 [application/octet-stream]
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 172 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 28.4M=0s
datanode_1  | Saving to: '/etc/security/keytabs/testuser.keytab'
scm_1       | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | 
recon_1     | 	at org.hadoop.ozone.recon.schema.StatsSchemaDefinition.initializeSchema(StatsSchemaDefinition.java:44)
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:78)
s3g_1       | Download HTTP/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
kms_1       | ---- ----------------- --------------------------------------------------------
kms_1       |    2 11/05/19 22:59:59 testuser2/c695af16ce49@EXAMPLE.COM
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  |      0K                                                       100% 14.5M=0s
datanode_3  | 
s3g_1       | --2019-11-05 23:00:03--  http://kdc:8081/keytab/s3g/HTTP
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
kms_1       |    2 11/05/19 22:59:59 testuser2/c695af16ce49@EXAMPLE.COM
kdc_1       | Entry for principal dn/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.6143ae4c601c.keytab.
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:41)
recon_1     | 	at picocli.CommandLine.execute(CommandLine.java:1173)
recon_1     | 	at picocli.CommandLine.access$800(CommandLine.java:141)
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367)
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335)
recon_1     | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243)
recon_1     | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526)
recon_1     | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465)
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 140 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/scm.keytab'
om_1        | 
om_1        |      0K                                                       100% 2.96M=0s
om_1        | 
om_1        | 2019-11-05 22:59:53 (2.96 MB/s) - '/etc/security/keytabs/scm.keytab' saved [140/140]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/scm.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
kdc_1       | Entry for principal dn/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.6143ae4c601c.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/90f7296b0733@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/90f7296b0733@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.90f7296b0733.keytab.
kdc_1       | Entry for principal dn/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.90f7296b0733.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for om/6143ae4c601c@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "om/6143ae4c601c@EXAMPLE.COM" created.
datanode_3  | 2019-11-05 23:00:06 (17.0 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 11/05/19 23:00:06 testuser/c95e120dae5a@EXAMPLE.COM
datanode_3  |    2 11/05/19 23:00:06 testuser/c95e120dae5a@EXAMPLE.COM
datanode_3  | Download testuser2/c95e120dae5a@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_3  | --2019-11-05 23:00:06--  http://kdc:8081/keytab/c95e120dae5a/testuser2
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | Download s3g/c695af16ce49@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
kms_1       | --2019-11-05 22:59:59--  http://kdc:8081/keytab/c695af16ce49/s3g
kms_1       | Resolving kdc (kdc)... 172.18.0.2
kms_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kms_1       | HTTP request sent, awaiting response... 200 OK
kms_1       | Length: 160 [application/octet-stream]
kms_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
kms_1       | 
kms_1       |      0K                                                       100% 15.5M=0s
kms_1       | 
kms_1       | 2019-11-05 23:00:05 (15.5 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
kms_1       | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal om/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.6143ae4c601c.keytab.
kdc_1       | Entry for principal om/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.6143ae4c601c.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for om/90f7296b0733@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "om/90f7296b0733@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994785, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65)
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56)
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:52)
recon_1     | 2019-11-05 23:00:55,534 [main] INFO       - Stopping Recon server
recon_1     | java.lang.NullPointerException
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.stop(ReconServer.java:115)
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:100)
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:41)
recon_1     | 	at picocli.CommandLine.execute(CommandLine.java:1173)
recon_1     | 	at picocli.CommandLine.access$800(CommandLine.java:141)
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1367)
recon_1     | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:1335)
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 172 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_3  | 
datanode_3  |      0K                                                       100% 17.0M=0s
datanode_3  | 
datanode_3  | 2019-11-05 23:00:06 (17.0 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 11/05/19 23:00:06 testuser2/c95e120dae5a@EXAMPLE.COM
datanode_3  |    2 11/05/19 23:00:06 testuser2/c95e120dae5a@EXAMPLE.COM
datanode_3  | Download s3g/c95e120dae5a@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_3  | --2019-11-05 23:00:06--  http://kdc:8081/keytab/c95e120dae5a/s3g
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994785, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994785, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:45 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994785, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994786, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994786, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994786, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kms_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
kms_1       | KVNO Timestamp         Principal
kms_1       | ---- ----------------- --------------------------------------------------------
kms_1       |    2 11/05/19 23:00:04 s3g/c695af16ce49@EXAMPLE.COM
kms_1       |    2 11/05/19 23:00:04 s3g/c695af16ce49@EXAMPLE.COM
kms_1       | # Licensed to the Apache Software Foundation (ASF) under one or more
kms_1       | # contributor license agreements.  See the NOTICE file distributed with
kms_1       | # this work for additional information regarding copyright ownership.
kms_1       | # The ASF licenses this file to You under the Apache License, Version 2.0
kms_1       | # (the "License"); you may not use this file except in compliance with
kms_1       | # the License.  You may obtain a copy of the License at
kms_1       | #
kms_1       | #     http://www.apache.org/licenses/LICENSE-2.0
kms_1       | #
kms_1       | # Unless required by applicable law or agreed to in writing, software
kms_1       | # distributed under the License is distributed on an "AS IS" BASIS,
recon_1     | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:1243)
recon_1     | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:1526)
recon_1     | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:1465)
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:65)
recon_1     | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:56)
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:52)
om_1        |    2 11/05/19 22:59:53 scm/om@EXAMPLE.COM
om_1        |    2 11/05/19 22:59:53 scm/om@EXAMPLE.COM
om_1        | Download HTTP/om@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om_1        | --2019-11-05 22:59:53--  http://kdc:8081/keytab/om/HTTP
om_1        | Resolving kdc (kdc)... 172.18.0.2
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 142 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        | 
om_1        |      0K                                                       100% 13.4M=0s
om_1        | 
om_1        | 2019-11-05 22:59:55 (13.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [142/142]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om_1        | KVNO Timestamp         Principal
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
kms_1       | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 11/05/19 22:59:54 HTTP/om@EXAMPLE.COM
om_1        |    2 11/05/19 22:59:54 HTTP/om@EXAMPLE.COM
kms_1       | # See the License for the specific language governing permissions and
kms_1       | # limitations under the License.
datanode_3  | Length: 160 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_3  | 
kms_1       | 
datanode_3  |      0K                                                       100% 15.8M=0s
datanode_3  | 
datanode_3  | 2019-11-05 23:00:07 (15.8 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 11/05/19 23:00:07 s3g/c95e120dae5a@EXAMPLE.COM
datanode_3  |    2 11/05/19 23:00:07 s3g/c95e120dae5a@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:09,523 [main] INFO       - STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = c95e120dae5a/172.18.0.7
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 3.2.0
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3  | STARTUP_MSG:   java = 11.0.3
datanode_3  | ************************************************************/
datanode_3  | 2019-11-05 23:00:09,539 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2019-11-05 23:00:09,975 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
kms_1       | [logging]
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:45 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Entry for principal om/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.90f7296b0733.keytab.
kdc_1       | Entry for principal om/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.90f7296b0733.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/6143ae4c601c@EXAMPLE.COM; defaulting to no policy
kdc_1       | Nov 05 22:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994786, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:46 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:47 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:47 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | Download testuser/om@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
om_1        | --2019-11-05 22:59:55--  http://kdc:8081/keytab/om/testuser
om_1        | Resolving kdc (kdc)... 172.18.0.2
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 150 [application/octet-stream]
kms_1       |  default = FILE:/var/log/krb5libs.log
om_1        | Saving to: '/etc/security/keytabs/testuser.keytab'
om_1        | 
om_1        |      0K                                                       100% 3.24M=0s
om_1        | 
om_1        | 2019-11-05 22:59:57 (3.24 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [150/150]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 11/05/19 22:59:57 testuser/om@EXAMPLE.COM
om_1        |    2 11/05/19 22:59:57 testuser/om@EXAMPLE.COM
om_1        | Download testuser2/om@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
om_1        | --2019-11-05 22:59:57--  http://kdc:8081/keytab/om/testuser2
om_1        | Resolving kdc (kdc)... 172.18.0.2
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 152 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/testuser2.keytab'
om_1        | 
om_1        |      0K                                                       100% 14.1M=0s
om_1        | 
om_1        | 2019-11-05 22:59:59 (14.1 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [152/152]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 11/05/19 22:59:59 testuser2/om@EXAMPLE.COM
om_1        |    2 11/05/19 22:59:59 testuser2/om@EXAMPLE.COM
om_1        | Download s3g/om@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
om_1        | --2019-11-05 22:59:59--  http://kdc:8081/keytab/om/s3g
om_1        | Resolving kdc (kdc)... 172.18.0.2
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 140 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/s3g.keytab'
om_1        | 
om_1        |      0K                                                       100% 13.9M=0s
om_1        | 
datanode_3  | 2019-11-05 23:00:10,187 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2019-11-05 23:00:10,187 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2019-11-05 23:00:10,685 [main] INFO       - HddsDatanodeService host:c95e120dae5a ip:172.18.0.7
datanode_3  | 2019-11-05 23:00:11,495 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_3  | WARNING: An illegal reflective access operation has occurred
datanode_3  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
datanode_3  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_3  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3  | WARNING: All illegal access operations will be denied in a future release
datanode_3  | 2019-11-05 23:00:12,011 INFO security.UserGroupInformation: Login successful for user dn/c95e120dae5a@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_3  | 2019-11-05 23:00:12,012 [main] INFO       - Hdds Datanode login successful.
datanode_3  | 2019-11-05 23:00:12,118 [main] INFO       - Initializing secure Datanode.
datanode_3  | 2019-11-05 23:00:12,119 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_3  | 2019-11-05 23:00:12,119 INFO client.DNCertificateClient: Certificate client init case: 0
datanode_3  | 2019-11-05 23:00:12,122 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_3  | 2019-11-05 23:00:12,853 [main] INFO       - Init response: GETCERT
datanode_3  | 2019-11-05 23:00:12,867 [main] INFO       - Adding ip:172.18.0.7,host:c95e120dae5a
datanode_3  | 2019-11-05 23:00:12,869 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
datanode_3  | 2019-11-05 23:00:12,876 [main] INFO       - Creating csr for DN-> subject:root@c95e120dae5a
datanode_3  | 2019-11-05 23:00:14,197 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:15,198 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:16,199 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:17,200 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:18,201 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:19,203 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:20,204 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:21,206 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:22,207 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2019-11-05 23:00:26,746 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
datanode_3  | 2019-11-05 23:00:27,240 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
datanode_3  | 2019-11-05 23:00:27,245 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2019-11-05 23:00:27,260 [main] INFO       - Scheduling a check for /data/hdds/hdds
datanode_3  | 2019-11-05 23:00:27,292 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2019-11-05 23:00:28,616 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2019-11-05 23:00:28,714 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2019-11-05 23:00:28,916 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2019-11-05 23:00:28,918 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_3  | 2019-11-05 23:00:28,922 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kdc_1       | Principal "scm/6143ae4c601c@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 22:59:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994788, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:47 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:47 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:48 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Entry for principal scm/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.6143ae4c601c.keytab.
kdc_1       | Entry for principal scm/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.6143ae4c601c.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/90f7296b0733@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "scm/90f7296b0733@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 22:59:48 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:48 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:48 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:49 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:49 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:49 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:Nov 05 22:59:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994788, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-11-05 23:00:03 (13.9 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [140/140]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 11/05/19 23:00:03 s3g/om@EXAMPLE.COM
om_1        |    2 11/05/19 23:00:03 s3g/om@EXAMPLE.COM
om_1        | Ozone Manager classpath extended by 
om_1        | 2019-11-05 23:00:04,288 [main] INFO       - STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.18.0.6
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 3.2.0
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.3
om_1        | ************************************************************/
om_1        | 2019-11-05 23:00:04,355 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2019-11-05 23:00:06,638 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.6:9862
om_1        | 2019-11-05 23:00:06,642 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | WARNING: An illegal reflective access operation has occurred
kms_1       |  kdc = FILE:/var/log/krb5kdc.log
kms_1       |  admin_server = FILE:/var/log/kadmind.log
kms_1       | 
kms_1       | [libdefaults]
kms_1       |  dns_canonicalize_hostname = false
kms_1       |  dns_lookup_realm = false
kms_1       |  ticket_lifetime = 24h
kms_1       |  renew_lifetime = 7d
kms_1       |  forwardable = true
kms_1       |  rdns = false
kms_1       |  default_realm = EXAMPLE.COM
kms_1       | 
kms_1       | [realms]
kms_1       |  EXAMPLE.COM = {
kms_1       |   kdc = kdc
kms_1       |   admin_server = kdc
kms_1       |  }
kms_1       | 
kms_1       | [domain_realm]
kms_1       |  .example.com = EXAMPLE.COM
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
kms_1       | WARNING: /opt/hadoop/logs does not exist. Creating.
kms_1       | Nov 05, 2019 11:00:10 PM com.sun.jersey.api.core.PackagesResourceConfig init
kms_1       | INFO: Scanning for root resource and provider classes in the packages:
kms_1       |   org.apache.hadoop.crypto.key.kms.server
kms_1       | Nov 05, 2019 11:00:10 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
kms_1       | INFO: Root resource classes found:
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMS
kms_1       | Nov 05, 2019 11:00:10 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
kms_1       | INFO: Provider classes found:
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
kms_1       | Nov 05, 2019 11:00:10 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
kms_1       | INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
kdc_1       | Nov 05 22:59:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | 59:49 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994789, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:49 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:50 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:50 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Entry for principal scm/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.90f7296b0733.keytab.
kdc_1       | Entry for principal scm/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.90f7296b0733.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.om.keytab.
kdc_1       | Entry for principal dn/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/c695af16ce49@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/c695af16ce49@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 22:59:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 144 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 14.4M=0s
s3g_1       | 
s3g_1       | 2019-11-05 23:00:06 (14.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 11/05/19 23:00:06 HTTP/s3g@EXAMPLE.COM
s3g_1       |    2 11/05/19 23:00:06 HTTP/s3g@EXAMPLE.COM
s3g_1       | Download testuser/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
s3g_1       | --2019-11-05 23:00:06--  http://kdc:8081/keytab/s3g/testuser
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 152 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
datanode_3  | 2019-11-05 23:00:28,923 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_3  | 2019-11-05 23:00:28,923 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_3  | 2019-11-05 23:00:29,496 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-11-05 23:00:29,814 INFO hdfs.DFSUtil: Starting web server as: HTTP/c95e120dae5a@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:29,816 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2019-11-05 23:00:29,938 INFO util.log: Logging initialized @22458ms
datanode_3  | 2019-11-05 23:00:30,261 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-11-05 23:00:30,265 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2019-11-05 23:00:30,276 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2019-11-05 23:00:30,278 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3  | 2019-11-05 23:00:30,278 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 2019-11-05 23:00:30,278 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2019-11-05 23:00:30,341 INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2019-11-05 23:00:30,345 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3  | 2019-11-05 23:00:30,429 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-11-05 23:00:30,432 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/c95e120dae5a@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:30,436 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4e0cc334{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2019-11-05 23:00:30,437 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@69364b2d{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2019-11-05 23:00:30,595 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/c95e120dae5a@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:30,611 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2415e4c7{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-3775778419691664012.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_3  | 2019-11-05 23:00:30,640 INFO server.AbstractConnector: Started ServerConnector@13cb860b{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2019-11-05 23:00:30,640 INFO server.Server: Started @23160ms
datanode_3  | 2019-11-05 23:00:30,663 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2019-11-05 23:00:30,663 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2019-11-05 23:00:30,668 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_3  | 2019-11-05 23:00:30,744 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 
datanode_2  | 2019-11-05 22:59:54 (28.4 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 11/05/19 22:59:53 testuser2/90f7296b0733@EXAMPLE.COM
datanode_2  |    2 11/05/19 22:59:54 testuser2/90f7296b0733@EXAMPLE.COM
datanode_2  | Download s3g/90f7296b0733@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_2  | --2019-11-05 22:59:54--  http://kdc:8081/keytab/90f7296b0733/s3g
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 160 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 14.8M=0s
datanode_2  | 
datanode_2  | 2019-11-05 22:59:57 (14.8 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 11/05/19 22:59:57 s3g/90f7296b0733@EXAMPLE.COM
datanode_2  |    2 11/05/19 22:59:57 s3g/90f7296b0733@EXAMPLE.COM
datanode_2  | 2019-11-05 22:59:59,718 [main] INFO       - STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
om_1        | 2019-11-05 23:00:07,222 INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om_1        | 2019-11-05 23:00:07,224 [main] INFO       - Ozone Manager login successful.
om_1        | 2019-11-05 23:00:07,234 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2019-11-05 23:00:08,914 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:09,916 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:10,923 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:11,925 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:12,927 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:13,930 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:14,932 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:15,934 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:16,935 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:17,936 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:17,939 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1        | 2019-11-05 23:00:24,108 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2019-11-05 23:00:26,202 [main] INFO       - Initializing secure OzoneManager.
om_1        | 2019-11-05 23:00:27,211 ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om_1        | 2019-11-05 23:00:27,211 INFO client.OMCertificateClient: Certificate client init case: 0
om_1        | 2019-11-05 23:00:27,212 INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om_1        | 2019-11-05 23:00:27,987 [main] INFO       - Init response: GETCERT
om_1        | 2019-11-05 23:00:28,013 [main] INFO       - Adding ip:172.18.0.6,host:om
om_1        | 2019-11-05 23:00:28,014 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
om_1        | 2019-11-05 23:00:28,019 [main] INFO       - Creating csr for OM->dns:om,ip:172.18.0.6,scmId:ecaf0460-54fd-4119-ab0f-9fc5273ba420,clusterId:CID-0e013de4-f2f1-444d-bd50-58e2c64dc923,subject:root@om
om_1        | 2019-11-05 23:00:28,243 [main] INFO       - OzoneManager ports added:[name: "RPC"
om_1        | value: 9862
om_1        | ]
datanode_1  | 
datanode_1  | 2019-11-05 22:59:53 (14.5 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [170/170]
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 11/05/19 23:00:06 testuser/s3g@EXAMPLE.COM
s3g_1       |    2 11/05/19 23:00:06 testuser/s3g@EXAMPLE.COM
s3g_1       |      0K                                                       100% 13.8M=0s
s3g_1       | 
s3g_1       | 2019-11-05 23:00:06 (13.8 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
s3g_1       | 
s3g_1       | Download testuser2/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
s3g_1       | --2019-11-05 23:00:06--  http://kdc:8081/keytab/s3g/testuser2
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 154 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 3.40M=0s
s3g_1       | 
s3g_1       | 2019-11-05 23:00:07 (3.40 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 11/05/19 23:00:06 testuser2/s3g@EXAMPLE.COM
kdc_1       | Nov 05 22:59:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994791, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994791, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994791, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994791, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:51 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Entry for principal dn/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.c695af16ce49.keytab.
kdc_1       | Entry for principal dn/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.c695af16ce49.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-11-05 23:00:33,114 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
datanode_3  | 2019-11-05 23:00:33,116 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
datanode_3  | 2019-11-05 23:00:33,116 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 3076f321-0139-4771-991e-8bdf0bbb6f06 at port 9858
datanode_3  | 2019-11-05 23:00:33,139 INFO impl.RaftServerProxy: 3076f321-0139-4771-991e-8bdf0bbb6f06: start RPC server
datanode_3  | 2019-11-05 23:00:33,344 INFO server.GrpcService: 3076f321-0139-4771-991e-8bdf0bbb6f06: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2019-11-05 23:00:39,803 INFO impl.RaftServerProxy: 3076f321-0139-4771-991e-8bdf0bbb6f06: addNew group-AD7ACDC16093:[3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858] returns group-AD7ACDC16093:java.util.concurrent.CompletableFuture@39b47f[Not completed]
datanode_3  | 2019-11-05 23:00:39,818 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06: new RaftServerImpl for group-AD7ACDC16093:[3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2019-11-05 23:00:39,820 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2019-11-05 23:00:39,821 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2019-11-05 23:00:39,821 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3  | 2019-11-05 23:00:39,822 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2019-11-05 23:00:39,822 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2019-11-05 23:00:39,835 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093: ConfigurationManager, init=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-11-05 23:00:39,841 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-11-05 23:00:39,847 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2019-11-05 23:00:39,848 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fa0275ca-0581-4327-b49d-ad7acdc16093 does not exist. Creating ...
datanode_3  | 2019-11-05 23:00:39,886 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fa0275ca-0581-4327-b49d-ad7acdc16093/in_use.lock acquired by nodename 7@c95e120dae5a
datanode_3  | 2019-11-05 23:00:39,944 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fa0275ca-0581-4327-b49d-ad7acdc16093 has been successfully formatted.
datanode_3  | 2019-11-05 23:00:39,950 [pool-9-thread-1] INFO       - group-AD7ACDC16093: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2019-11-05 23:00:39,950 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_3  | 2019-11-05 23:00:39,954 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2019-11-05 23:00:39,975 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2019-11-05 23:00:39,977 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2019-11-05 23:00:39,993 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-11-05 23:00:40,044 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2019-11-05 23:00:40,053 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-11-05 23:00:40,059 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  |    2 11/05/19 22:59:53 testuser/6143ae4c601c@EXAMPLE.COM
datanode_1  |    2 11/05/19 22:59:53 testuser/6143ae4c601c@EXAMPLE.COM
datanode_1  | Download testuser2/6143ae4c601c@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
datanode_1  | --2019-11-05 22:59:53--  http://kdc:8081/keytab/6143ae4c601c/testuser2
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 172 [application/octet-stream]
datanode_1  | Saving to: '/etc/security/keytabs/testuser2.keytab'
datanode_1  | 
datanode_1  |      0K                                                       100% 12.7M=0s
datanode_1  | 
datanode_1  | 2019-11-05 22:59:53 (12.7 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [172/172]
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 11/05/19 22:59:53 testuser2/6143ae4c601c@EXAMPLE.COM
datanode_1  |    2 11/05/19 22:59:53 testuser2/6143ae4c601c@EXAMPLE.COM
datanode_1  | Download s3g/6143ae4c601c@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
datanode_1  | --2019-11-05 22:59:53--  http://kdc:8081/keytab/6143ae4c601c/s3g
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 160 [application/octet-stream]
datanode_1  | Saving to: '/etc/security/keytabs/s3g.keytab'
datanode_1  | 
datanode_1  |      0K                                                       100% 2.25M=0s
datanode_1  | 
datanode_1  | 2019-11-05 22:59:56 (2.25 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [160/160]
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 11/05/19 22:59:56 s3g/6143ae4c601c@EXAMPLE.COM
datanode_1  |    2 11/05/19 22:59:56 s3g/6143ae4c601c@EXAMPLE.COM
datanode_1  | 2019-11-05 22:59:59,578 [main] INFO       - STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 6143ae4c601c/172.18.0.3
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 3.2.0
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | STARTUP_MSG:   java = 11.0.3
datanode_1  | ************************************************************/
datanode_1  | 2019-11-05 22:59:59,596 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2019-11-05 23:00:00,071 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2019-11-05 23:00:00,257 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | STARTUP_MSG:   host = 90f7296b0733/172.18.0.4
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 3.2.0
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2  | STARTUP_MSG:   java = 11.0.3
datanode_2  | ************************************************************/
datanode_2  | 2019-11-05 22:59:59,750 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2019-11-05 23:00:00,232 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2019-11-05 23:00:00,417 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2019-11-05 23:00:00,418 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2019-11-05 23:00:00,779 [main] INFO       - HddsDatanodeService host:90f7296b0733 ip:172.18.0.4
datanode_2  | 2019-11-05 23:00:02,730 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_2  | WARNING: An illegal reflective access operation has occurred
datanode_2  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
datanode_2  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_2  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2019-11-05 23:00:03,271 INFO security.UserGroupInformation: Login successful for user dn/90f7296b0733@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_2  | 2019-11-05 23:00:03,271 [main] INFO       - Hdds Datanode login successful.
datanode_2  | 2019-11-05 23:00:03,271 [main] INFO       - Initializing secure Datanode.
datanode_2  | 2019-11-05 23:00:03,272 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_2  | 2019-11-05 23:00:03,272 INFO client.DNCertificateClient: Certificate client init case: 0
datanode_2  | 2019-11-05 23:00:03,273 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_2  | 2019-11-05 23:00:03,626 [main] INFO       - Init response: GETCERT
datanode_2  | 2019-11-05 23:00:03,633 [main] INFO       - Adding ip:172.18.0.4,host:90f7296b0733
om_1        | 2019-11-05 23:00:28,618 [main] INFO       - Successfully stored SCM signed certificate.
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-0e013de4-f2f1-444d-bd50-58e2c64dc923
om_1        | 2019-11-05 23:00:28,745 [shutdown-hook-0] INFO       - SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.18.0.6
om_1        | ************************************************************/
om_1        | Ozone Manager classpath extended by 
om_1        | 2019-11-05 23:00:31,587 [main] INFO       - STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.18.0.6
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 3.2.0
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.3
om_1        | ************************************************************/
om_1        | 2019-11-05 23:00:31,694 [main] INFO       - registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2019-11-05 23:00:33,589 [main] INFO       - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.6:9862
om_1        | 2019-11-05 23:00:33,593 [main] INFO       - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2019-11-05 23:00:33,600 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | WARNING: An illegal reflective access operation has occurred
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       |    2 11/05/19 23:00:06 testuser2/s3g@EXAMPLE.COM
s3g_1       | Download s3g/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
scm_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | --2019-11-05 23:00:07--  http://kdc:8081/keytab/s3g/s3g
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 142 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
kdc_1       | WARNING: no policy specified for HTTP/6143ae4c601c@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/6143ae4c601c@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.6143ae4c601c.keytab.
kdc_1       | Entry for principal HTTP/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.6143ae4c601c.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/90f7296b0733@EXAMPLE.COM; defaulting to no policy
datanode_3  | 2019-11-05 23:00:40,138 INFO segmented.SegmentedRaftLogWorker: new 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fa0275ca-0581-4327-b49d-ad7acdc16093
datanode_3  | 2019-11-05 23:00:40,139 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2019-11-05 23:00:40,139 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2019-11-05 23:00:40,154 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-11-05 23:00:40,180 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
s3g_1       | 
kdc_1       | Principal "HTTP/90f7296b0733@EXAMPLE.COM" created.
datanode_2  | 2019-11-05 23:00:03,634 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
om_1        | WARNING: All illegal access operations will be denied in a future release
datanode_1  | 2019-11-05 23:00:00,258 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2019-11-05 23:00:40,183 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
s3g_1       |      0K                                                       100% 14.1M=0s
scm_1       | Length: 152 [application/octet-stream]
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-11-05 23:00:03,637 [main] INFO       - Creating csr for DN-> subject:root@90f7296b0733
om_1        | 2019-11-05 23:00:34,274 INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
datanode_1  | 2019-11-05 23:00:00,730 [main] INFO       - HddsDatanodeService host:6143ae4c601c ip:172.18.0.3
datanode_3  | 2019-11-05 23:00:40,193 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2019-11-05 23:00:40,308 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2019-11-05 23:00:40,313 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2019-11-05 23:00:40,317 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2019-11-05 23:00:40,341 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-11-05 23:00:40,347 INFO segmented.SegmentedRaftLogWorker: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2019-11-05 23:00:34,275 [main] INFO       - Ozone Manager login successful.
datanode_1  | 2019-11-05 23:00:02,459 [main] INFO       - Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_2  | 2019-11-05 23:00:04,836 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Entry for principal HTTP/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.90f7296b0733.keytab.
scm_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1       | 
datanode_3  | 2019-11-05 23:00:40,355 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2019-11-05 23:00:34,276 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | WARNING: An illegal reflective access operation has occurred
datanode_2  | 2019-11-05 23:00:05,838 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Entry for principal HTTP/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.90f7296b0733.keytab.
scm_1       | 
s3g_1       | 2019-11-05 23:00:07 (14.1 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
datanode_3  | 2019-11-05 23:00:40,357 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 2019-11-05 23:00:36,163 INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
datanode_1  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
datanode_2  | 2019-11-05 23:00:06,886 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Generiting keytab
scm_1       |      0K                                                       100% 15.1M=0s
s3g_1       | 
datanode_3  | 2019-11-05 23:00:40,358 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2019-11-05 23:00:40,359 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_2  | 2019-11-05 23:00:07,889 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
datanode_3  | 2019-11-05 23:00:40,444 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1        | 2019-11-05 23:00:36,300 INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
om_1        | 2019-11-05 23:00:36,308 INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/12193783896913573.crt.
datanode_2  | 2019-11-05 23:00:08,925 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2019-11-05 23:00:06 (15.1 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
kdc_1       | WARNING: no policy specified for om/om@EXAMPLE.COM; defaulting to no policy
s3g_1       | KVNO Timestamp         Principal
om_1        | 2019-11-05 23:00:36,337 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
scm_1       | 
datanode_2  | 2019-11-05 23:00:09,928 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Principal "om/om@EXAMPLE.COM" created.
s3g_1       | ---- ----------------- --------------------------------------------------------
om_1        | 2019-11-05 23:00:36,371 INFO util.log: Logging initialized @6616ms
datanode_3  | 2019-11-05 23:00:40,473 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | WARNING: All illegal access operations will be denied in a future release
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
datanode_2  | 2019-11-05 23:00:10,933 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       |    2 11/05/19 23:00:07 s3g/s3g@EXAMPLE.COM
om_1        | 2019-11-05 23:00:36,469 INFO db.DBStoreBuilder: using custom profile for table: userTable
datanode_1  | 2019-11-05 23:00:02,629 INFO security.UserGroupInformation: Login successful for user dn/6143ae4c601c@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_3  | 2019-11-05 23:00:40,481 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093: start as a follower, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858], old=null
scm_1       | KVNO Timestamp         Principal
datanode_2  | 2019-11-05 23:00:12,161 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
s3g_1       |    2 11/05/19 23:00:07 s3g/s3g@EXAMPLE.COM
om_1        | 2019-11-05 23:00:36,469 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:userTable
datanode_1  | 2019-11-05 23:00:02,629 [main] INFO       - Hdds Datanode login successful.
datanode_3  | 2019-11-05 23:00:40,483 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | ---- ----------------- --------------------------------------------------------
datanode_2  | 2019-11-05 23:00:13,163 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | WARNING: An illegal reflective access operation has occurred
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
om_1        | 2019-11-05 23:00:36,469 INFO db.DBStoreBuilder: using custom profile for table: volumeTable
datanode_1  | 2019-11-05 23:00:02,633 [main] INFO       - Initializing secure Datanode.
datanode_3  | 2019-11-05 23:00:40,487 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: start FollowerState
scm_1       |    2 11/05/19 23:00:06 testuser/scm@EXAMPLE.COM
s3g_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
kdc_1       | Generiting keytab
om_1        | 2019-11-05 23:00:36,469 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:volumeTable
om_1        | 2019-11-05 23:00:36,470 INFO db.DBStoreBuilder: using custom profile for table: bucketTable
datanode_3  | 2019-11-05 23:00:40,542 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AD7ACDC16093,id=3076f321-0139-4771-991e-8bdf0bbb6f06
datanode_2  | 2019-11-05 23:00:14,168 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       |    2 11/05/19 23:00:06 testuser/scm@EXAMPLE.COM
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_1  | 2019-11-05 23:00:02,634 ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_3  | 2019-11-05 23:00:40,547 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
scm_1       | Download testuser2/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
om_1        | 2019-11-05 23:00:36,470 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:bucketTable
datanode_2  | 2019-11-05 23:00:15,169 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-11-05 23:00:02,634 INFO client.DNCertificateClient: Certificate client init case: 0
datanode_3  | 2019-11-05 23:00:40,870 INFO impl.RaftServerProxy: 3076f321-0139-4771-991e-8bdf0bbb6f06: addNew group-4562290EF030:[3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858] returns group-4562290EF030:java.util.concurrent.CompletableFuture@3ce3fc4f[Not completed]
scm_1       | --2019-11-05 23:00:06--  http://kdc:8081/keytab/scm/testuser2
om_1        | 2019-11-05 23:00:36,470 INFO db.DBStoreBuilder: using custom profile for table: keyTable
datanode_2  | 2019-11-05 23:00:16,170 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994792, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | WARNING: All illegal access operations will be denied in a future release
datanode_1  | 2019-11-05 23:00:02,636 INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_3  | 2019-11-05 23:00:40,892 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06: new RaftServerImpl for group-4562290EF030:[3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858] with ContainerStateMachine:uninitialized
scm_1       | Resolving kdc (kdc)... 172.18.0.2
om_1        | 2019-11-05 23:00:36,470 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:keyTable
datanode_2  | 2019-11-05 23:00:17,171 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-11-05 23:00:18,173 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-11-05 23:00:19,174 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-11-05 23:00:20,176 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-11-05 23:00:21,177 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-11-05 23:00:22,178 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2019-11-05 23:00:26,651 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
datanode_2  | 2019-11-05 23:00:26,774 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
datanode_2  | 2019-11-05 23:00:26,799 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2019-11-05 23:00:26,813 [main] INFO       - Scheduling a check for /data/hdds/hdds
datanode_2  | 2019-11-05 23:00:26,837 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2019-11-05 23:00:27,876 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2019-11-05 23:00:27,992 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2019-11-05 23:00:28,134 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2019-11-05 23:00:28,136 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_2  | 2019-11-05 23:00:28,140 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2019-11-05 23:00:28,141 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_2  | 2019-11-05 23:00:28,142 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
s3g_1       | 2019-11-05 23:00:10,518 INFO hdfs.DFSUtil: Starting web server as: HTTP/s3g@EXAMPLE.COM
s3g_1       | 2019-11-05 23:00:10,519 INFO hdfs.DFSUtil: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2019-11-05 23:00:10,586 INFO util.log: Logging initialized @2623ms
datanode_3  | 2019-11-05 23:00:40,893 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-11-05 23:00:36,470 INFO db.DBStoreBuilder: using custom profile for table: deletedTable
s3g_1       | 2019-11-05 23:00:11,074 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2019-11-05 23:00:11,173 INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2019-11-05 23:00:11,183 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2019-11-05 23:00:11,187 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
datanode_3  | 2019-11-05 23:00:40,893 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2019-11-05 23:00:36,470 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedTable
datanode_1  | 2019-11-05 23:00:03,342 [main] INFO       - Init response: GETCERT
datanode_1  | 2019-11-05 23:00:03,356 [main] INFO       - Adding ip:172.18.0.3,host:6143ae4c601c
datanode_3  | 2019-11-05 23:00:40,897 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3  | 2019-11-05 23:00:40,900 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
s3g_1       | 2019-11-05 23:00:11,188 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1       | 2019-11-05 23:00:11,188 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om_1        | 2019-11-05 23:00:36,470 INFO db.DBStoreBuilder: using custom profile for table: openKeyTable
datanode_1  | 2019-11-05 23:00:03,357 [main] INFO       - ip:127.0.0.1,host:localhost not returned.
datanode_1  | 2019-11-05 23:00:03,366 [main] INFO       - Creating csr for DN-> subject:root@6143ae4c601c
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994792, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 2019-11-05 23:00:11,217 [main] INFO       - Starting Ozone S3 gateway
datanode_3  | 2019-11-05 23:00:40,901 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-11-05 23:00:04,565 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:05,566 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | HTTP request sent, awaiting response... 200 OK
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994792, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-11-05 23:00:36,470 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:openKeyTable
s3g_1       | 2019-11-05 23:00:11,276 INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2019-11-05 23:00:11,278 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
s3g_1       | 2019-11-05 23:00:11,321 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | Length: 154 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 2.05M=0s
scm_1       | 
scm_1       | 2019-11-05 23:00:06 (2.05 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
scm_1       | 
s3g_1       | 2019-11-05 23:00:11,367 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1       | 2019-11-05 23:00:11,515 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61710c6{/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2019-11-05 23:00:11,521 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5f9edf14{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1       | 2019-11-05 23:00:14,706 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1       | Nov 05, 2019 11:00:15 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2019-11-05 23:00:15,407 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6af5b246{/,file:///tmp/jetty-0.0.0.0-9878-s3gateway-_-any-2526497467915723564.dir/webapp/,AVAILABLE}{/s3gateway}
s3g_1       | 2019-11-05 23:00:15,413 INFO server.AbstractConnector: Started ServerConnector@1a1ccaaf{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1       | 2019-11-05 23:00:15,413 INFO server.Server: Started @7453ms
s3g_1       | 2019-11-05 23:00:15,415 INFO server.BaseHttpServer: HTTP server of S3GATEWAY is listening at http://0.0.0.0:9878
s3g_1       | 2019-11-05 23:15:03,289 [qtp262445056-118] INFO       - Location is /bucket-test123
s3g_1       | 2019-11-05 23:15:08,012 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
datanode_1  | 2019-11-05 23:00:06,569 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:07,571 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:08,574 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:09,576 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:10,578 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:11,580 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:12,582 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:13,590 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:14,595 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:15,596 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:16,597 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:17,599 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:18,600 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:19,602 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:20,604 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:21,606 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:22,607 INFO ipc.Client: Retrying connect to server: scm/172.18.0.8:9961. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2019-11-05 23:00:26,931 [main] INFO       - Successfully stored SCM signed certificate, case:GETCERT.
datanode_1  | 2019-11-05 23:00:27,141 [main] INFO       - Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
datanode_1  | 2019-11-05 23:00:27,163 [main] INFO       - Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2019-11-05 23:00:27,174 [main] INFO       - Scheduling a check for /data/hdds/hdds
datanode_1  | 2019-11-05 23:00:27,203 [main] INFO       - Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2019-11-05 23:00:40,902 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030: ConfigurationManager, init=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2019-11-05 23:00:40,917 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2019-11-05 23:00:40,919 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2019-11-05 23:00:40,923 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030 does not exist. Creating ...
datanode_2  | 2019-11-05 23:00:28,400 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2019-11-05 23:00:28,633 INFO hdfs.DFSUtil: Starting web server as: HTTP/90f7296b0733@EXAMPLE.COM
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
datanode_1  | 2019-11-05 23:00:28,114 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2019-11-05 23:00:28,634 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2019-11-05 23:00:28,670 INFO util.log: Logging initialized @31177ms
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994792, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | KVNO Timestamp         Principal
datanode_1  | 2019-11-05 23:00:28,240 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
s3g_1       | 2019-11-05 23:15:09,009 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | ---- ----------------- --------------------------------------------------------
s3g_1       | 20191105T231507Z
datanode_1  | 2019-11-05 23:00:28,447 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2019-11-05 23:00:28,926 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       |    2 11/05/19 23:00:06 testuser2/scm@EXAMPLE.COM
scm_1       |    2 11/05/19 23:00:06 testuser2/scm@EXAMPLE.COM
scm_1       | Download s3g/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
om_1        | 2019-11-05 23:00:36,471 INFO db.DBStoreBuilder: using custom profile for table: s3Table
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994792, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:40,953 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030/in_use.lock acquired by nodename 7@c95e120dae5a
scm_1       | --2019-11-05 23:00:06--  http://kdc:8081/keytab/scm/s3g
scm_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | 2019-11-05 23:00:36,471 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3Table
om_1        | 2019-11-05 23:00:36,471 INFO db.DBStoreBuilder: using custom profile for table: multipartInfoTable
datanode_3  | 2019-11-05 23:00:41,016 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030 has been successfully formatted.
scm_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:00:36,471 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:multipartInfoTable
datanode_1  | 2019-11-05 23:00:28,450 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 2019-11-05 23:00:41,017 [pool-9-thread-1] INFO       - group-4562290EF030: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | Length: 142 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 14.8M=0s
om_1        | 2019-11-05 23:00:36,471 INFO db.DBStoreBuilder: using custom profile for table: dTokenTable
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994792, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:41,021 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
scm_1       | 
om_1        | 2019-11-05 23:00:36,471 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:dTokenTable
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-11-05 23:00:28,457 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-11-05 23:00:28,458 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
s3g_1       | 2019-11-05 23:15:09,009 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
om_1        | 2019-11-05 23:00:36,471 INFO db.DBStoreBuilder: using custom profile for table: s3SecretTable
scm_1       | 2019-11-05 23:00:07 (14.8 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
datanode_3  | 2019-11-05 23:00:41,022 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2019-11-05 23:00:28,934 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2019-11-05 23:00:28,967 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
scm_1       | 
s3g_1       | 20191105/us-west-1/s3/aws4_request
datanode_3  | 2019-11-05 23:00:41,031 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2019-11-05 23:00:28,976 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_2  | 2019-11-05 23:00:28,976 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1        | 2019-11-05 23:00:36,471 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3SecretTable
om_1        | 2019-11-05 23:00:36,472 INFO db.DBStoreBuilder: using custom profile for table: prefixTable
om_1        | 2019-11-05 23:00:36,472 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:prefixTable
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:09,380 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:09,382 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
om_1        | 2019-11-05 23:00:36,482 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_3  | 2019-11-05 23:00:41,031 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:09,415 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:09,417 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:09,433 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:09,434 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
kdc_1       | WARNING: no policy specified for om/c695af16ce49@EXAMPLE.COM; defaulting to no policy
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-11-05 23:00:36,483 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
om_1        | 2019-11-05 23:00:36,484 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
om_1        | 2019-11-05 23:00:40,038 INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
scm_1       | KVNO Timestamp         Principal
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:09,843 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-11-05 23:00:28,459 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2019-11-05 23:00:28,923 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2019-11-05 23:00:28,977 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om_1        | 2019-11-05 23:00:40,045 [main] INFO       - Loaded 0 tokens
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
datanode_1  | 2019-11-05 23:00:29,378 INFO hdfs.DFSUtil: Starting web server as: HTTP/6143ae4c601c@EXAMPLE.COM
datanode_1  | 2019-11-05 23:00:29,379 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2019-11-05 23:00:29,419 INFO util.log: Logging initialized @32608ms
datanode_1  | 2019-11-05 23:00:29,805 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2019-11-05 23:00:29,821 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2019-11-05 23:00:29,088 INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2019-11-05 23:00:29,094 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2  | 2019-11-05 23:00:29,280 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-11-05 23:00:29,284 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/90f7296b0733@EXAMPLE.COM
datanode_2  | 2019-11-05 23:00:29,319 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@53aa2fc9{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2019-11-05 23:00:29,325 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2b80e5a9{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2019-11-05 23:00:29,655 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/90f7296b0733@EXAMPLE.COM
datanode_2  | 2019-11-05 23:00:29,665 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7302ff13{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-11123186592856473697.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_2  | 2019-11-05 23:00:29,673 INFO server.AbstractConnector: Started ServerConnector@7fd99443{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2019-11-05 23:00:29,679 INFO server.Server: Started @32187ms
datanode_2  | 2019-11-05 23:00:29,704 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2019-11-05 23:00:29,706 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2019-11-05 23:00:29,710 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_2  | 2019-11-05 23:00:29,825 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2019-11-05 23:00:32,249 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
datanode_2  | 2019-11-05 23:00:32,376 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
datanode_2  | 2019-11-05 23:00:32,515 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57 at port 9858
datanode_3  | 2019-11-05 23:00:41,032 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-11-05 23:00:41,032 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2019-11-05 23:00:41,032 INFO segmented.SegmentedRaftLogWorker: new 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030
datanode_3  | 2019-11-05 23:00:41,033 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2019-11-05 23:00:41,034 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
datanode_2  | 2019-11-05 23:00:32,614 INFO impl.RaftServerProxy: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start RPC server
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](info): closing down fd 18
om_1        | 2019-11-05 23:00:40,049 [main] INFO       - Loading token state into token manager.
s3g_1       | 2019-11-05 23:15:09,845 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
datanode_2  | 2019-11-05 23:00:33,091 INFO server.GrpcService: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2019-11-05 23:00:36,395 INFO impl.RaftServerProxy: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: addNew group-152CA07F9185:[25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858] returns group-152CA07F9185:java.util.concurrent.CompletableFuture@4e316e39[Not completed]
datanode_2  | 2019-11-05 23:00:36,410 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: new RaftServerImpl for group-152CA07F9185:[25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858] with ContainerStateMachine:uninitialized
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 2019-11-05 23:00:40,166 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2019-11-05 23:00:40,195 INFO ipc.Server: Starting Socket Reader #1 for port 9862
s3g_1       | 20191105/us-west-1/s3/aws4_request
datanode_2  | 2019-11-05 23:00:36,412 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2019-11-05 23:00:36,412 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2019-11-05 23:00:36,412 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
datanode_2  | 2019-11-05 23:00:36,413 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2019-11-05 23:00:36,414 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2019-11-05 23:00:36,422 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185: ConfigurationManager, init=-1: [25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2019-11-05 23:00:41,034 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2019-11-05 23:00:41,034 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2019-11-05 23:00:36,423 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2019-11-05 23:00:36,429 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2019-11-05 23:00:36,431 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e3c2a642-4c83-46a6-b955-152ca07f9185 does not exist. Creating ...
datanode_3  | 2019-11-05 23:00:41,034 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3  | 2019-11-05 23:00:41,035 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 11/05/19 23:00:07 s3g/scm@EXAMPLE.COM
datanode_1  | 2019-11-05 23:00:29,831 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
om_1        | 2019-11-05 23:00:40,483 [main] INFO       - OzoneManager RPC server is listening at om/172.18.0.6:9862
scm_1       |    2 11/05/19 23:00:07 s3g/scm@EXAMPLE.COM
scm_1       | 2019-11-05 23:00:09,614 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_1  | 2019-11-05 23:00:29,834 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
om_1        | 2019-11-05 23:00:40,686 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_1  | 2019-11-05 23:00:29,834 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2019-11-05 23:00:41,035 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2019-11-05 23:00:41,035 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2019-11-05 23:00:41,035 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2019-11-05 23:00:36,448 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e3c2a642-4c83-46a6-b955-152ca07f9185/in_use.lock acquired by nodename 8@90f7296b0733
om_1        | 2019-11-05 23:00:40,827 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2019-11-05 23:15:10,301 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-11-05 23:00:29,834 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 2019-11-05 23:00:41,036 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2019-11-05 23:00:41,036 INFO segmented.SegmentedRaftLogWorker: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2019-11-05 23:00:41,037 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2019-11-05 23:00:41,037 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
s3g_1       | 20191105T231507Z
datanode_1  | 2019-11-05 23:00:29,897 INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2019-11-05 23:00:41,037 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2019-11-05 23:00:41,038 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2019-11-05 23:00:41,039 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 2019-11-05 23:00:41,039 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1        | 2019-11-05 23:00:40,834 INFO impl.MetricsSystemImpl: OzoneManager metrics system started
s3g_1       | 20191105/us-west-1/s3/aws4_request
datanode_1  | 2019-11-05 23:00:29,904 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3  | 2019-11-05 23:00:41,040 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030: start as a follower, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](info): closing down fd 18
scm_1       | STARTUP_MSG:   host = scm/172.18.0.8
datanode_2  | 2019-11-05 23:00:36,490 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e3c2a642-4c83-46a6-b955-152ca07f9185 has been successfully formatted.
om_1        | 2019-11-05 23:00:40,905 [main] INFO       - Reading keypair and certificate from file system.
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
datanode_1  | 2019-11-05 23:00:30,039 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2019-11-05 23:00:41,041 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030: changes role from      null to FOLLOWER at term 0 for startAsFollower
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | STARTUP_MSG:   args = [--init]
datanode_2  | 2019-11-05 23:00:36,516 [pool-9-thread-1] INFO       - group-152CA07F9185: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om_1        | 2019-11-05 23:00:40,934 [main] INFO       - Starting OM block token secret manager
s3g_1       | 2019-11-05 23:15:10,303 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-11-05 23:00:30,042 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/6143ae4c601c@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:41,043 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: start FollowerState
kdc_1       | Nov 05 22:59:52 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | STARTUP_MSG:   version = 3.2.0
datanode_2  | 2019-11-05 23:00:36,596 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1        | 2019-11-05 23:00:40,935 [main] INFO       - Updating the current master key for generating tokens
s3g_1       | 20191105T231507Z
datanode_1  | 2019-11-05 23:00:30,072 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7bbcf6f0{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2019-11-05 23:00:41,044 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4562290EF030,id=3076f321-0139-4771-991e-8bdf0bbb6f06
kdc_1       | Principal "om/c695af16ce49@EXAMPLE.COM" created.
datanode_2  | 2019-11-05 23:00:36,599 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2019-11-05 23:00:40,938 [main] INFO       - Starting OM delegation token secret manager
s3g_1       | 20191105/us-west-1/s3/aws4_request
datanode_1  | 2019-11-05 23:00:30,074 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@794f11cd{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2019-11-05 23:00:41,046 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_2  | 2019-11-05 23:00:36,603 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2019-11-05 23:00:40,939 [main] INFO       - Updating the current master key for generating tokens
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
datanode_1  | 2019-11-05 23:00:30,264 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/6143ae4c601c@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:45,634 INFO impl.FollowerState: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093-FollowerState: change to CANDIDATE, lastRpcTime:5147ms, electionTimeout:5060ms
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
kdc_1       | Entry for principal om/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.c695af16ce49.keytab.
datanode_2  | 2019-11-05 23:00:36,604 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 2019-11-05 23:15:10,399 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-11-05 23:00:30,276 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6b37df8e{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-14029062566252749612.dir/webapp/,AVAILABLE}{/hddsDatanode}
om_1        | 2019-11-05 23:00:40,951 [Thread[Thread-11,5,main]] INFO       - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
scm_1       | STARTUP_MSG:   java = 11.0.3
kdc_1       | Entry for principal om/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.c695af16ce49.keytab.
datanode_2  | 2019-11-05 23:00:36,605 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 20191105T231507Z
datanode_1  | 2019-11-05 23:00:30,301 INFO server.AbstractConnector: Started ServerConnector@518d346c{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2019-11-05 23:00:30,302 INFO server.Server: Started @33490ms
scm_1       | ************************************************************/
scm_1       | 2019-11-05 23:00:09,625 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2019-11-05 23:00:45,636 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: shutdown FollowerState
datanode_2  | 2019-11-05 23:00:36,611 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1       | 20191105/us-west-1/s3/aws4_request
datanode_1  | 2019-11-05 23:00:30,306 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2019-11-05 23:00:30,306 INFO impl.MetricsSystemImpl: Registered sink prometheus
kdc_1       | Generiting keytab
datanode_3  | 2019-11-05 23:00:45,638 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | 2019-11-05 23:00:09,985 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:00:41,037 INFO ipc.Server: IPC Server Responder: starting
datanode_2  | 2019-11-05 23:00:36,614 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-11-05 23:00:30,309 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
datanode_3  | 2019-11-05 23:00:45,643 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: start LeaderElection
scm_1       | SCM initialization succeeded.Current cluster id for sd=/data/metadata/scm;cid=CID-0e013de4-f2f1-444d-bd50-58e2c64dc923
s3g_1       | 2019-11-05 23:15:10,400 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
kdc_1       | WARNING: no policy specified for testuser/6143ae4c601c@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-11-05 23:00:41,038 INFO ipc.Server: IPC Server listener on 9862: starting
scm_1       | 2019-11-05 23:00:10,081 INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.8
scm_1       | ************************************************************/
scm_1       | 2019-11-05 23:00:13,085 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om_1        | 2019-11-05 23:00:41,124 INFO hdfs.DFSUtil: Starting web server as: HTTP/om@EXAMPLE.COM
om_1        | 2019-11-05 23:00:41,127 INFO hdfs.DFSUtil: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
s3g_1       | 20191105/us-west-1/s3/aws4_request
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = scm/172.18.0.8
om_1        | 2019-11-05 23:00:41,309 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
kdc_1       | Principal "testuser/6143ae4c601c@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.3
scm_1       | ************************************************************/
scm_1       | 2019-11-05 23:00:13,101 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2019-11-05 23:00:13,651 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | WARNING: An illegal reflective access operation has occurred
scm_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar) to method sun.security.krb5.Config.getInstance()
scm_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
scm_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
scm_1       | WARNING: All illegal access operations will be denied in a future release
scm_1       | 2019-11-05 23:00:14,000 INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm_1       | 2019-11-05 23:00:14,000 INFO server.StorageContainerManager: SCM login successful.
scm_1       | 2019-11-05 23:00:14,001 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2019-11-05 23:00:14,025 INFO util.log: Logging initialized @3597ms
scm_1       | 2019-11-05 23:00:14,124 INFO db.DBStoreBuilder: using custom profile for table: deletedBlocks
kdc_1       | Entry for principal testuser/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.6143ae4c601c.keytab.
kdc_1       | Entry for principal testuser/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.6143ae4c601c.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/90f7296b0733@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/90f7296b0733@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.90f7296b0733.keytab.
kdc_1       | Entry for principal testuser/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.90f7296b0733.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "scm/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal scm/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.om.keytab.
kdc_1       | Entry for principal scm/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-11-05 23:15:10,419 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_1  | 2019-11-05 23:00:30,355 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2019-11-05 23:00:33,032 [Datanode State Machine Thread - 0] INFO       - Attempting to start container services.
s3g_1       | 20191105T231507Z
kdc_1       | WARNING: no policy specified for scm/c695af16ce49@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-11-05 23:00:41,315 INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_2  | 2019-11-05 23:00:36,618 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2019-11-05 23:00:36,622 INFO segmented.SegmentedRaftLogWorker: new 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e3c2a642-4c83-46a6-b955-152ca07f9185
datanode_2  | 2019-11-05 23:00:36,623 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2019-11-05 23:00:36,623 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-11-05 23:00:36,625 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-11-05 23:00:36,625 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2019-11-05 23:00:45,838 INFO impl.LeaderElection: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093-LeaderElection1: begin an election at term 1 for -1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858], old=null
datanode_3  | 2019-11-05 23:00:45,841 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: shutdown LeaderElection
datanode_3  | 2019-11-05 23:00:45,842 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2019-11-05 23:00:45,843 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093: change Leader from null to 3076f321-0139-4771-991e-8bdf0bbb6f06 at term 1 for becomeLeader, leader elected after 5892ms
datanode_3  | 2019-11-05 23:00:45,849 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
kdc_1       | Principal "scm/c695af16ce49@EXAMPLE.COM" created.
datanode_2  | 2019-11-05 23:00:36,626 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2  | 2019-11-05 23:00:36,626 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2019-11-05 23:00:45,850 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2019-11-05 23:00:45,855 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3  | 2019-11-05 23:00:45,866 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_3  | 2019-11-05 23:00:45,866 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2019-11-05 23:00:45,868 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2019-11-05 23:00:46,001 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: start LeaderState
datanode_3  | 2019-11-05 23:00:46,031 INFO segmented.SegmentedRaftLogWorker: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2019-11-05 23:00:46,078 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093: set configuration 0: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858], old=null at 0
datanode_3  | 2019-11-05 23:00:46,158 INFO impl.FollowerState: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-FollowerState: change to CANDIDATE, lastRpcTime:5116ms, electionTimeout:5112ms
datanode_1  | 2019-11-05 23:00:33,035 [Datanode State Machine Thread - 0] INFO       - Background container scanner has been disabled.
datanode_1  | 2019-11-05 23:00:33,035 [Datanode State Machine Thread - 0] INFO       - Starting XceiverServerRatis 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2 at port 9858
datanode_1  | 2019-11-05 23:00:33,074 INFO impl.RaftServerProxy: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start RPC server
datanode_1  | 2019-11-05 23:00:33,262 INFO server.GrpcService: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2019-11-05 23:00:37,100 INFO impl.RaftServerProxy: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: addNew group-C6F7231AADC0:[4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858] returns group-C6F7231AADC0:java.util.concurrent.CompletableFuture@7578316[Not completed]
datanode_1  | 2019-11-05 23:00:37,115 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: new RaftServerImpl for group-C6F7231AADC0:[4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2019-11-05 23:00:37,116 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2019-11-05 23:00:37,117 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2019-11-05 23:00:37,118 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1  | 2019-11-05 23:00:37,119 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2019-11-05 23:00:37,119 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-11-05 23:00:37,126 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0: ConfigurationManager, init=-1: [4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2019-11-05 23:00:37,126 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2019-11-05 23:00:37,131 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2019-11-05 23:00:37,132 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9f2cbbad-2e54-48b8-af4a-c6f7231aadc0 does not exist. Creating ...
datanode_1  | 2019-11-05 23:00:38,208 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9f2cbbad-2e54-48b8-af4a-c6f7231aadc0/in_use.lock acquired by nodename 7@6143ae4c601c
datanode_1  | 2019-11-05 23:00:38,788 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9f2cbbad-2e54-48b8-af4a-c6f7231aadc0 has been successfully formatted.
datanode_1  | 2019-11-05 23:00:38,793 [pool-9-thread-1] INFO       - group-C6F7231AADC0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2019-11-05 23:00:38,793 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 2019-11-05 23:00:38,798 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2019-11-05 23:00:38,804 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2019-11-05 23:00:38,805 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2019-11-05 23:00:36,627 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2019-11-05 23:00:36,627 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2019-11-05 23:00:36,627 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2019-11-05 23:00:36,633 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2019-11-05 23:00:36,711 INFO segmented.SegmentedRaftLogWorker: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2019-11-05 23:00:36,715 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2019-11-05 23:00:36,716 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2019-11-05 23:00:36,717 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2019-11-05 23:00:36,717 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2019-11-05 23:00:36,739 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2  | 2019-11-05 23:00:36,741 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2  | 2019-11-05 23:00:36,744 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185: start as a follower, conf=-1: [25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_2  | 2019-11-05 23:00:36,746 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2019-11-05 23:00:36,747 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start FollowerState
datanode_2  | 2019-11-05 23:00:36,750 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-152CA07F9185,id=25f2f6ba-ed69-4f1f-8b52-ab8f96757a57
datanode_2  | 2019-11-05 23:00:36,752 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2  | 2019-11-05 23:00:40,825 INFO impl.RaftServerProxy: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: addNew group-4562290EF030:[3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858] returns group-4562290EF030:java.util.concurrent.CompletableFuture@4eb60290[Not completed]
datanode_2  | 2019-11-05 23:00:40,851 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: new RaftServerImpl for group-4562290EF030:[3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2019-11-05 23:00:40,852 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2019-11-05 23:00:40,853 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2019-11-05 23:00:40,853 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_2  | 2019-11-05 23:00:40,854 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2019-11-05 23:00:40,854 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:10,422 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:10,613 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:10,614 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:11,101 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-11-05 23:00:41,327 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
scm_1       | 2019-11-05 23:00:14,124 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedBlocks
datanode_2  | 2019-11-05 23:00:40,854 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: ConfigurationManager, init=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
s3g_1       | 20191105/us-west-1/s3/aws4_request
datanode_3  | 2019-11-05 23:00:46,158 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: shutdown FollowerState
datanode_1  | 2019-11-05 23:00:38,807 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1       | Entry for principal scm/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.c695af16ce49.keytab.
scm_1       | 2019-11-05 23:00:14,125 INFO db.DBStoreBuilder: using custom profile for table: validCerts
datanode_2  | 2019-11-05 23:00:40,855 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2019-11-05 23:00:41,332 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-11-05 23:00:46,159 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2019-11-05 23:00:38,817 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
kdc_1       | Entry for principal scm/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.c695af16ce49.keytab.
scm_1       | 2019-11-05 23:00:14,125 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:validCerts
datanode_2  | 2019-11-05 23:00:40,855 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2019-11-05 23:00:40,856 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030 does not exist. Creating ...
datanode_3  | 2019-11-05 23:00:46,159 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: start LeaderElection
datanode_1  | 2019-11-05 23:00:38,823 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
kdc_1       | Generiting keytab
scm_1       | 2019-11-05 23:00:14,125 INFO db.DBStoreBuilder: using custom profile for table: revokedCerts
om_1        | 2019-11-05 23:00:41,332 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1        | 2019-11-05 23:00:41,332 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1       | 2019-11-05 23:15:11,102 [qtp262445056-28] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
datanode_3  | 2019-11-05 23:00:46,174 INFO impl.LeaderElection: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-LeaderElection2: begin an election at term 1 for -1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_1  | 2019-11-05 23:00:38,830 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-11-05 23:00:41,376 INFO http.HttpServer2: Jetty bound to port 9874
datanode_2  | 2019-11-05 23:00:40,880 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030/in_use.lock acquired by nodename 8@90f7296b0733
s3g_1       | 2019-11-05 23:15:11,114 [qtp262445056-28] ERROR      - Couldn't create RpcClient protocol exception: 
datanode_3  | 2019-11-05 23:00:46,198 INFO segmented.SegmentedRaftLogWorker: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-AD7ACDC16093-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fa0275ca-0581-4327-b49d-ad7acdc16093/current/log_inprogress_0
scm_1       | 2019-11-05 23:00:14,125 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:revokedCerts
datanode_1  | 2019-11-05 23:00:38,838 INFO segmented.SegmentedRaftLogWorker: new 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9f2cbbad-2e54-48b8-af4a-c6f7231aadc0
om_1        | 2019-11-05 23:00:41,383 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
kdc_1       | WARNING: no policy specified for testuser2/6143ae4c601c@EXAMPLE.COM; defaulting to no policy
datanode_2  | 2019-11-05 23:00:40,904 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030 has been successfully formatted.
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
datanode_3  | 2019-11-05 23:00:47,339 INFO impl.LeaderElection: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-LeaderElection2: Election REJECTED; received 2 response(s) [3076f321-0139-4771-991e-8bdf0bbb6f06<-4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2#0:FAIL-t1, 3076f321-0139-4771-991e-8bdf0bbb6f06<-25f2f6ba-ed69-4f1f-8b52-ab8f96757a57#0:FAIL-t1] and 0 exception(s); 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030:t1, leader=null, voted=3076f321-0139-4771-991e-8bdf0bbb6f06, raftlog=3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
scm_1       | 2019-11-05 23:00:14,135 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_1  | 2019-11-05 23:00:38,838 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
om_1        | 2019-11-05 23:00:41,598 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2019-11-05 23:00:40,905 [pool-9-thread-1] INFO       - group-4562290EF030: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
s3g_1       | 20191105T231507Z
datanode_3  | 2019-11-05 23:00:47,343 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
scm_1       | 2019-11-05 23:00:14,135 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
kdc_1       | Principal "testuser2/6143ae4c601c@EXAMPLE.COM" created.
datanode_1  | 2019-11-05 23:00:38,839 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
om_1        | 2019-11-05 23:00:41,602 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2019-11-05 23:00:41,619 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16134476{/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 20191105/us-west-1/s3/aws4_request
datanode_3  | 2019-11-05 23:00:47,344 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: shutdown LeaderElection
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser2/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.6143ae4c601c.keytab.
datanode_2  | 2019-11-05 23:00:40,909 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1        | 2019-11-05 23:00:41,620 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@789c3057{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
datanode_3  | 2019-11-05 23:00:47,344 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: start FollowerState
datanode_1  | 2019-11-05 23:00:38,840 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2019-11-05 23:00:38,840 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1       | Entry for principal testuser2/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.6143ae4c601c.keytab.
scm_1       | 2019-11-05 23:00:14,137 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
om_1        | 2019-11-05 23:00:42,107 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2019-11-05 23:00:42,114 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@19b02dfd{/,file:///tmp/jetty-0.0.0.0-9874-ozoneManager-_-any-9179404790469211108.dir/webapp/,AVAILABLE}{/ozoneManager}
om_1        | 2019-11-05 23:00:42,155 INFO server.AbstractConnector: Started ServerConnector@3cbfc95{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2019-11-05 23:00:42,156 INFO server.Server: Started @12401ms
datanode_1  | 2019-11-05 23:00:38,841 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-11-05 23:00:21,621 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3  | 2019-11-05 23:00:52,520 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2
datanode_3  | 2019-11-05 23:00:52,522 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: shutdown FollowerState
datanode_3  | 2019-11-05 23:00:52,523 INFO impl.RoleInfo: 3076f321-0139-4771-991e-8bdf0bbb6f06: start FollowerState
om_1        | 2019-11-05 23:00:42,180 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2019-11-05 23:00:38,842 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2019-11-05 23:00:38,844 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
kdc_1       | WARNING: no policy specified for testuser2/90f7296b0733@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser2/90f7296b0733@EXAMPLE.COM" created.
datanode_3  | 2019-11-05 23:00:52,523 INFO impl.FollowerState: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2019-11-05 23:00:52,728 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030: change Leader from null to 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2 at term 2 for appendEntries, leader elected after 11709ms
datanode_3  | 2019-11-05 23:00:52,821 INFO impl.RaftServerImpl: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030: set configuration 0: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null at 0
om_1        | 2019-11-05 23:00:42,181 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2019-11-05 23:00:38,844 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2019-11-05 23:00:38,845 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 22:59:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994792, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-11-05 23:00:52,821 INFO segmented.SegmentedRaftLogWorker: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2019-11-05 23:00:53,091 INFO segmented.SegmentedRaftLogWorker: 3076f321-0139-4771-991e-8bdf0bbb6f06@group-4562290EF030-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030/current/log_inprogress_0
datanode_3  | 2019-11-05 23:01:02,519 INFO client.DNCertificateClient: Getting certificate with certSerialId:12193783896913573.
om_1        | 2019-11-05 23:00:42,186 INFO server.BaseHttpServer: HTTP server of OZONEMANAGER is listening at http://0.0.0.0:9874
datanode_1  | 2019-11-05 23:00:38,855 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2019-11-05 23:00:38,860 INFO segmented.SegmentedRaftLogWorker: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_3  | 2019-11-05 23:01:05,558 WARN server.GrpcServerProtocolService: 3076f321-0139-4771-991e-8bdf0bbb6f06: installSnapshot onError, lastRequest: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2->3076f321-0139-4771-991e-8bdf0bbb6f06#7-t2, previous=(t:2, i:2), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_3  | Nov 05, 2019 11:01:05 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
datanode_3  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@5fbeed4d
om_1        | 2019-11-05 23:00:56,055 INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:38,867 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2019-11-05 23:00:38,868 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-11-05 23:00:56,073 INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-11-05 23:00:38,869 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2019-11-05 23:00:38,870 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-11-05 23:00:40,909 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2019-11-05 23:00:40,923 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2019-11-05 23:00:40,925 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2019-11-05 23:00:57,960 [IPC Server handler 17 on 9862] INFO       - created volume:vol-0-33825 for user:HTTP/scm@EXAMPLE.COM
datanode_1  | 2019-11-05 23:00:38,893 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-11-05 23:00:40,926 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-11-05 23:00:40,926 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2019-11-05 23:00:40,926 INFO segmented.SegmentedRaftLogWorker: new 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030
datanode_2  | 2019-11-05 23:00:40,927 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
om_1        | 2019-11-05 23:00:58,145 [IPC Server handler 4 on 9862] INFO       - created volume:vol-1-65010 for user:HTTP/scm@EXAMPLE.COM
datanode_1  | 2019-11-05 23:00:38,896 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2019-11-05 23:00:40,927 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-11-05 23:00:40,927 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2019-11-05 23:00:40,928 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1        | 2019-11-05 23:00:58,184 [IPC Server handler 5 on 9862] INFO       - created volume:vol-2-34986 for user:HTTP/scm@EXAMPLE.COM
datanode_1  | 2019-11-05 23:00:38,899 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0: start as a follower, conf=-1: [4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858], old=null
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
om_1        | 2019-11-05 23:00:58,260 [IPC Server handler 2 on 9862] INFO       - created volume:vol-3-32988 for user:HTTP/scm@EXAMPLE.COM
datanode_1  | 2019-11-05 23:00:38,900 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0: changes role from      null to FOLLOWER at term 0 for startAsFollower
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
om_1        | 2019-11-05 23:00:58,294 [IPC Server handler 3 on 9862] INFO       - created volume:vol-4-97246 for user:HTTP/scm@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-11-05 23:02:16,303 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:38,902 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start FollowerState
scm_1       | 2019-11-05 23:00:21,660 INFO ipc.Server: Starting Socket Reader #1 for port 9961
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
scm_1       | 2019-11-05 23:00:21,793 INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@4bdcaf36
scm_1       | 2019-11-05 23:00:21,795 INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_1  | 2019-11-05 23:00:38,910 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C6F7231AADC0,id=4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2
datanode_2  | 2019-11-05 23:00:40,928 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2  | 2019-11-05 23:00:40,928 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2019-11-05 23:00:40,929 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2019-11-05 23:00:40,929 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2019-11-05 23:00:40,930 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2019-11-05 23:00:40,930 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-11-05 23:00:21,899 INFO node.SCMNodeManager: Entering startup safe mode.
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
om_1        | 2019-11-05 23:02:16,313 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 2019-11-05 23:00:40,945 INFO segmented.SegmentedRaftLogWorker: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2019-11-05 23:00:22,025 INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_1  | 2019-11-05 23:00:38,912 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2019-11-05 23:00:22,039 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2019-11-05 23:00:22,474 INFO pipeline.SCMPipelineManager: No pipeline exists in current db
datanode_1  | 2019-11-05 23:00:40,796 INFO impl.RaftServerProxy: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: addNew group-4562290EF030:[3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858] returns group-4562290EF030:java.util.concurrent.CompletableFuture@4c08247b[Not completed]
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2019-11-05 23:00:40,945 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2019-11-05 23:02:19,073 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:40,805 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: new RaftServerImpl for group-4562290EF030:[3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858] with ContainerStateMachine:uninitialized
scm_1       | 2019-11-05 23:00:22,476 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2019-11-05 23:00:22,674 WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
scm_1       | 2019-11-05 23:00:23,571 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2019-11-05 23:00:23,603 INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2019-11-05 23:00:23,744 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
scm_1       | 2019-11-05 23:00:23,747 INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2019-11-05 23:00:24,143 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2019-11-05 23:00:24,145 INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2019-11-05 23:00:24,282 INFO hdfs.DFSUtil: Starting web server as: HTTP/scm@EXAMPLE.COM
scm_1       | 2019-11-05 23:00:24,283 INFO hdfs.DFSUtil: Starting Web-server for scm at: http://0.0.0.0:9876
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
scm_1       | 2019-11-05 23:00:24,445 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2019-11-05 23:00:24,473 INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2019-11-05 23:00:24,487 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
scm_1       | 2019-11-05 23:00:24,490 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm_1       | 2019-11-05 23:00:24,490 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1       | 2019-11-05 23:00:24,490 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | 2019-11-05 23:00:40,805 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-11-05 23:00:24,624 INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2019-11-05 23:00:24,716 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2019-11-05 23:00:24,832 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2019-11-05 23:00:40,805 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2019-11-05 23:10:26,240 INFO util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1040ms
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-11-05 23:00:24,832 INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2019-11-05 23:00:25,194 INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2019-11-05 23:00:25,195 INFO ipc.Server: IPC Server Responder: starting
datanode_1  | 2019-11-05 23:00:40,806 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3  | No GCs detected
datanode_3  | 2019-11-05 23:23:50,890 [Datanode State Machine Thread - 0] ERROR      - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
scm_1       | 2019-11-05 23:00:25,206 INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2019-11-05 23:00:25,211 INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2019-11-05 23:00:25,215 INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
datanode_1  | 2019-11-05 23:00:40,806 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | java.net.SocketTimeoutException: Call From c95e120dae5a/172.18.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:35292 remote=scm/172.18.0.8:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm_1       | 2019-11-05 23:00:25,217 INFO ipc.Server: IPC Server Responder: starting
datanode_2  | 2019-11-05 23:00:40,947 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 2019-11-05 23:02:19,086 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-11-05 23:00:40,806 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm_1       | 2019-11-05 23:00:25,217 INFO ipc.Server: IPC Server listener on 9863: starting
datanode_2  | 2019-11-05 23:00:40,949 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 2019-11-05 23:02:19,813 [IPC Server handler 0 on 9862] INFO       - created volume:49846-rpcwoport for user:testuser/scm@EXAMPLE.COM
datanode_1  | 2019-11-05 23:00:40,807 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: ConfigurationManager, init=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
kdc_1       | Nov 05 22:59:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994793, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2019-11-05 23:00:25,230 INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
datanode_2  | 2019-11-05 23:00:40,949 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2019-11-05 23:02:21,787 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:40,807 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2019-11-05 23:00:25,230 INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
om_1        | 2019-11-05 23:02:21,797 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:02:24,349 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_2  | 2019-11-05 23:00:40,949 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
scm_1       | 2019-11-05 23:00:25,235 INFO ipc.Server: IPC Server Responder: starting
om_1        | 2019-11-05 23:02:24,359 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-11-05 23:00:40,808 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2019-11-05 23:00:40,950 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
scm_1       | 2019-11-05 23:00:25,237 INFO ipc.Server: IPC Server listener on 9861: starting
om_1        | 2019-11-05 23:02:29,791 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:40,811 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030 does not exist. Creating ...
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_2  | 2019-11-05 23:00:40,951 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: start as a follower, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
scm_1       | 2019-11-05 23:00:25,240 INFO server.SCMClientProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
om_1        | 2019-11-05 23:02:29,801 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-11-05 23:00:40,838 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030/in_use.lock acquired by nodename 7@6143ae4c601c
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_2  | 2019-11-05 23:00:40,951 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: changes role from      null to FOLLOWER at term 0 for startAsFollower
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-11-05 23:02:32,535 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:25,241 INFO ipc.Server: IPC Server Responder: starting
datanode_1  | 2019-11-05 23:00:40,865 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030 has been successfully formatted.
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_2  | 2019-11-05 23:00:40,951 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start FollowerState
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-11-05 23:02:32,545 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-11-05 23:00:25,243 INFO http.HttpServer2: Jetty bound to port 9876
datanode_1  | 2019-11-05 23:00:40,866 [pool-9-thread-1] INFO       - group-4562290EF030: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2019-11-05 23:00:40,952 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4562290EF030,id=25f2f6ba-ed69-4f1f-8b52-ab8f96757a57
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_3  | 	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:143)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:35292 remote=scm/172.18.0.8:9861]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:290)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)
datanode_3  | 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
om_1        | 2019-11-05 23:02:35,053 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:02:35,064 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:02:37,546 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:02:37,557 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:02:40,242 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:02:40,275 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:02:44,430 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:02:44,442 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:02:49,501 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:02:49,514 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:02:54,125 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:02:54,135 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:02:56,933 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:02:56,943 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:03:00,224 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:00,234 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:03:02,834 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:02,846 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:03:05,409 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:05,419 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:03:07,923 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:07,939 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-11-05 23:00:40,952 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1        | 2019-11-05 23:03:10,445 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_2  | 2019-11-05 23:00:41,918 INFO impl.FollowerState: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185-FollowerState: change to CANDIDATE, lastRpcTime:5171ms, electionTimeout:5171ms
datanode_2  | 2019-11-05 23:00:41,922 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: shutdown FollowerState
datanode_2  | 2019-11-05 23:00:41,923 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2019-11-05 23:00:41,927 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start LeaderElection
datanode_2  | 2019-11-05 23:00:42,168 INFO impl.LeaderElection: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185-LeaderElection1: begin an election at term 1 for -1: [25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_2  | 2019-11-05 23:00:42,170 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: shutdown LeaderElection
datanode_2  | 2019-11-05 23:00:42,171 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2019-11-05 23:00:42,172 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185: change Leader from null to 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57 at term 1 for becomeLeader, leader elected after 5576ms
datanode_2  | 2019-11-05 23:00:42,179 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2019-11-05 23:00:42,179 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2019-11-05 23:00:42,183 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_2  | 2019-11-05 23:00:42,219 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_2  | 2019-11-05 23:00:42,220 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2019-11-05 23:00:42,221 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2019-11-05 23:00:42,240 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start LeaderState
datanode_2  | 2019-11-05 23:00:42,273 INFO segmented.SegmentedRaftLogWorker: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2019-11-05 23:00:42,294 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185: set configuration 0: [25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null at 0
datanode_2  | 2019-11-05 23:00:42,446 INFO segmented.SegmentedRaftLogWorker: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-152CA07F9185-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e3c2a642-4c83-46a6-b955-152ca07f9185/current/log_inprogress_0
datanode_2  | 2019-11-05 23:00:46,120 INFO impl.FollowerState: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-FollowerState: change to CANDIDATE, lastRpcTime:5168ms, electionTimeout:5162ms
datanode_2  | 2019-11-05 23:00:46,153 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: shutdown FollowerState
datanode_2  | 2019-11-05 23:00:46,153 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2019-11-05 23:00:46,153 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start LeaderElection
datanode_2  | 2019-11-05 23:00:46,173 INFO impl.LeaderElection: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-LeaderElection2: begin an election at term 1 for -1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_2  | 2019-11-05 23:00:47,356 INFO impl.LeaderElection: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-LeaderElection2: Election REJECTED; received 2 response(s) [25f2f6ba-ed69-4f1f-8b52-ab8f96757a57<-3076f321-0139-4771-991e-8bdf0bbb6f06#0:FAIL-t1, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57<-4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2#0:FAIL-t1] and 0 exception(s); 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030:t1, leader=null, voted=25f2f6ba-ed69-4f1f-8b52-ab8f96757a57, raftlog=25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_2  | 2019-11-05 23:00:47,378 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_2  | 2019-11-05 23:00:47,384 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: shutdown LeaderElection
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-11-05 23:03:10,454 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-11-05 23:00:40,869 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 2019-11-05 23:00:40,870 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2019-11-05 23:00:40,882 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2019-11-05 23:00:40,882 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-11-05 23:00:40,882 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2019-11-05 23:00:40,883 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2019-11-05 23:00:40,883 INFO segmented.SegmentedRaftLogWorker: new 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030
om_1        | 2019-11-05 23:03:13,031 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
scm_1       | 2019-11-05 23:00:25,244 INFO ipc.Server: IPC Server listener on 9961: starting
scm_1       | 2019-11-05 23:00:25,246 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
scm_1       | 2019-11-05 23:00:25,559 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2019-11-05 23:00:25,562 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1       | 2019-11-05 23:00:25,574 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4086d8fb{/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2019-11-05 23:03:13,041 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-11-05 23:03:13,679 [IPC Server handler 10 on 9862] INFO       - created volume:49846-rpcwoport2 for user:testuser/scm@EXAMPLE.COM
om_1        | 2019-11-05 23:03:15,594 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:25,576 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@633fd91{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-11-05 23:03:15,602 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:03:18,482 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:18,495 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-11-05 23:00:25,757 INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_2  | 2019-11-05 23:00:47,384 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start FollowerState
om_1        | 2019-11-05 23:03:21,192 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:21,202 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:03:23,703 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:25,764 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3a7b2e2{/,file:///tmp/jetty-0.0.0.0-9876-scm-_-any-13957584702248387289.dir/webapp/,AVAILABLE}{/scm}
datanode_1  | 2019-11-05 23:00:40,883 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
datanode_2  | 2019-11-05 23:00:52,486 INFO impl.FollowerState: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-FollowerState: change to CANDIDATE, lastRpcTime:5101ms, electionTimeout:5100ms
om_1        | 2019-11-05 23:03:23,715 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
scm_1       | 2019-11-05 23:00:25,847 INFO server.AbstractConnector: Started ServerConnector@6fd21c07{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
datanode_1  | 2019-11-05 23:00:40,883 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2019-11-05 23:00:52,488 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: shutdown FollowerState
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-11-05 23:00:25,850 INFO server.Server: Started @15423ms
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 2019-11-05 23:03:27,525 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:27,547 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_2  | 2019-11-05 23:00:52,488 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
scm_1       | 2019-11-05 23:00:25,857 INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
datanode_2  | 2019-11-05 23:00:52,488 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start LeaderElection
datanode_2  | 2019-11-05 23:00:52,513 INFO impl.LeaderElection: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-LeaderElection3: begin an election at term 2 for -1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
scm_1       | 2019-11-05 23:00:25,857 INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-11-05 23:03:32,813 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:32,827 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
datanode_2  | 2019-11-05 23:00:52,641 INFO impl.LeaderElection: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-LeaderElection3: Election REJECTED; received 2 response(s) [25f2f6ba-ed69-4f1f-8b52-ab8f96757a57<-3076f321-0139-4771-991e-8bdf0bbb6f06#0:FAIL-t2, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57<-4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2#0:FAIL-t2] and 0 exception(s); 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030:t2, leader=null, voted=25f2f6ba-ed69-4f1f-8b52-ab8f96757a57, raftlog=25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
om_1        | 2019-11-05 23:03:49,751 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:49,774 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-11-05 23:00:40,883 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2019-11-05 23:00:40,884 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2019-11-05 23:00:40,884 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
scm_1       | 2019-11-05 23:00:25,862 INFO server.BaseHttpServer: HTTP server of SCM is listening at http://0.0.0.0:9876
scm_1       | 2019-11-05 23:00:25,884 INFO util.JvmPauseMonitor: Starting JVM pause monitor
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2019-11-05 23:03:55,181 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
datanode_2  | 2019-11-05 23:00:52,642 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
datanode_1  | 2019-11-05 23:00:40,885 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2019-11-05 23:00:40,885 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2019-11-05 23:00:25,924 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:25,927 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
datanode_2  | 2019-11-05 23:00:52,642 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: shutdown LeaderElection
datanode_1  | 2019-11-05 23:00:40,885 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2019-11-05 23:00:40,885 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2019-11-05 23:00:25,932 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:25,938 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:25,949 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2019-11-05 23:00:25,952 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
datanode_2  | 2019-11-05 23:00:52,642 INFO impl.RoleInfo: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: start FollowerState
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
datanode_2  | 2019-11-05 23:00:52,726 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: change Leader from null to 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2 at term 2 for appendEntries, leader elected after 11819ms
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
datanode_2  | 2019-11-05 23:00:52,793 INFO impl.RaftServerImpl: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030: set configuration 0: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null at 0
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
scm_1       | 2019-11-05 23:00:25,953 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:00:25,956 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2019-11-05 23:00:26,174 INFO server.SCMClientProtocolServer: Processing CSR for dn 6143ae4c601c, UUID: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2
scm_1       | 2019-11-05 23:00:26,174 INFO server.SCMClientProtocolServer: Processing CSR for dn 90f7296b0733, UUID: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57
scm_1       | 2019-11-05 23:00:26,313 INFO server.SCMClientProtocolServer: Processing CSR for dn c95e120dae5a, UUID: 3076f321-0139-4771-991e-8bdf0bbb6f06
scm_1       | 2019-11-05 23:00:28,399 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:28,453 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2019-11-05 23:00:28,457 INFO server.SCMClientProtocolServer: Processing CSR for om om, UUID: 3795a254-7a0b-4559-9a90-c3689fd2b14c
scm_1       | 2019-11-05 23:00:31,897 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:31,900 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:00:32,464 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:32,472 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:00:32,816 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:33,008 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:00:33,908 INFO net.NetworkTopology: Added a new node: /default-rack/25f2f6ba-ed69-4f1f-8b52-ab8f96757a57
scm_1       | 2019-11-05 23:00:33,910 INFO node.SCMNodeManager: Registered Data node : 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57{ip: 172.18.0.4, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 12193781650833419}
scm_1       | 2019-11-05 23:00:33,927 INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
scm_1       | 2019-11-05 23:00:33,946 INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2019-11-05 23:00:33,947 INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2019-11-05 23:00:34,440 INFO net.NetworkTopology: Added a new node: /default-rack/4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2
scm_1       | 2019-11-05 23:00:34,442 INFO node.SCMNodeManager: Registered Data node : 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2{ip: 172.18.0.3, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 12193781650833422}
scm_1       | 2019-11-05 23:00:34,988 INFO net.NetworkTopology: Added a new node: /default-rack/3076f321-0139-4771-991e-8bdf0bbb6f06
scm_1       | 2019-11-05 23:00:34,988 INFO node.SCMNodeManager: Registered Data node : 3076f321-0139-4771-991e-8bdf0bbb6f06{ip: 172.18.0.7, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 12193781860132237}
scm_1       | 2019-11-05 23:00:35,499 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:40,885 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2019-11-05 23:00:40,901 INFO segmented.SegmentedRaftLogWorker: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2019-11-05 23:00:40,911 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2019-11-05 23:00:40,911 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2019-11-05 23:00:40,911 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2019-11-05 23:00:40,912 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2019-11-05 23:00:40,912 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-11-05 23:00:40,912 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-11-05 23:00:40,913 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: start as a follower, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_1  | 2019-11-05 23:00:40,913 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2019-11-05 23:00:40,915 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start FollowerState
datanode_1  | 2019-11-05 23:00:40,916 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4562290EF030,id=4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2
datanode_1  | 2019-11-05 23:00:40,916 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-11-05 23:00:43,919 INFO impl.FollowerState: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0-FollowerState: change to CANDIDATE, lastRpcTime:5017ms, electionTimeout:5016ms
datanode_1  | 2019-11-05 23:00:43,920 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: shutdown FollowerState
datanode_1  | 2019-11-05 23:00:43,921 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2019-11-05 23:00:43,923 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start LeaderElection
datanode_1  | 2019-11-05 23:00:44,463 INFO impl.LeaderElection: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0-LeaderElection1: begin an election at term 1 for -1: [4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858], old=null
datanode_1  | 2019-11-05 23:00:44,464 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: shutdown LeaderElection
datanode_1  | 2019-11-05 23:00:44,465 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2019-11-05 23:00:44,465 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0: change Leader from null to 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2 at term 1 for becomeLeader, leader elected after 5672ms
datanode_1  | 2019-11-05 23:00:44,470 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2019-11-05 23:00:44,471 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2019-11-05 23:03:55,194 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:03:59,929 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:03:59,946 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:04:05,711 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:04:05,744 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:04:07,696 [IPC Server handler 10 on 9862] ERROR      - Add acl [user:superuser1:rwxy[ACCESS]] to path /49846-rpcwoport2/bb1 failed, because acl already exist
om_1        | 2019-11-05 23:04:12,452 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:04:12,474 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:04:22,595 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:04:22,622 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:04:28,581 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:04:28,603 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:04:35,476 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:04:35,502 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:04:41,401 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:04:41,427 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:04:47,242 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:04:47,269 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:04:58,555 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:04:58,565 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:05:04,056 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:05:04,111 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:53 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
datanode_2  | 2019-11-05 23:00:52,794 INFO segmented.SegmentedRaftLogWorker: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2019-11-05 23:00:52,974 INFO segmented.SegmentedRaftLogWorker: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57@group-4562290EF030-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030/current/log_inprogress_0
datanode_2  | 2019-11-05 23:01:02,517 INFO client.DNCertificateClient: Getting certificate with certSerialId:12193783896913573.
datanode_2  | 2019-11-05 23:01:05,619 WARN server.GrpcServerProtocolService: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: installSnapshot onError, lastRequest: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2->25f2f6ba-ed69-4f1f-8b52-ab8f96757a57#7-t2, previous=(t:2, i:2), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_2  | Nov 05, 2019 11:01:05 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
datanode_2  | SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@65506657
datanode_2  | org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 
scm_1       | 2019-11-05 23:00:35,595 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:00:36,868 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e3c2a642-4c83-46a6-b955-152ca07f9185, Nodes: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57{ip: 172.18.0.4, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
scm_1       | 2019-11-05 23:00:39,301 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 9f2cbbad-2e54-48b8-af4a-c6f7231aadc0, Nodes: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2{ip: 172.18.0.3, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
scm_1       | 2019-11-05 23:00:40,684 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fa0275ca-0581-4327-b49d-ad7acdc16093, Nodes: 3076f321-0139-4771-991e-8bdf0bbb6f06{ip: 172.18.0.7, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
scm_1       | 2019-11-05 23:00:41,092 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e738925e-84c8-46e2-a256-4562290ef030, Nodes: 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57{ip: 172.18.0.4, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2{ip: 172.18.0.3, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}3076f321-0139-4771-991e-8bdf0bbb6f06{ip: 172.18.0.7, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
scm_1       | 2019-11-05 23:00:56,681 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:00:56,694 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:01:00,183 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:00,187 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:01:02,236 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:02,248 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2019-11-05 23:01:02,542 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:02,544 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:02,545 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2019-11-05 23:01:02,547 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2019-11-05 23:01:05,443 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:05,544 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:01:05,577 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:05,584 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:05,584 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:01:05,589 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:01:42,400 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:42,430 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:01:42,438 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:05:10,106 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:05:10,145 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:05:15,542 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:42,444 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:01:42,450 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
datanode_1  | 2019-11-05 23:00:44,474 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_1  | 2019-11-05 23:00:44,479 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
kdc_1       | Entry for principal testuser2/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.90f7296b0733.keytab.
scm_1       | 2019-11-05 23:01:42,456 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:02:12,421 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:44,479 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
kdc_1       | Entry for principal testuser2/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.90f7296b0733.keytab.
kdc_1       | Generiting keytab
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/om@EXAMPLE.COM" created.
scm_1       | 2019-11-05 23:02:12,511 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:44,480 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2019-11-05 23:00:44,488 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start LeaderState
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
datanode_1  | 2019-11-05 23:00:44,509 INFO segmented.SegmentedRaftLogWorker: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2019-11-05 23:00:44,521 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0: set configuration 0: [4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858], old=null at 0
datanode_1  | 2019-11-05 23:00:45,354 INFO segmented.SegmentedRaftLogWorker: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-C6F7231AADC0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9f2cbbad-2e54-48b8-af4a-c6f7231aadc0/current/log_inprogress_0
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
kdc_1       | Nov 05 22:59:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 2019-11-05 23:00:45,971 INFO impl.FollowerState: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-FollowerState: change to CANDIDATE, lastRpcTime:5057ms, electionTimeout:5049ms
om_1        | 2019-11-05 23:05:15,570 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-11-05 23:02:12,521 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode_1  | 2019-11-05 23:00:46,153 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: shutdown FollowerState
datanode_1  | 2019-11-05 23:00:46,153 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
kdc_1       | Nov 05 22:59:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994794, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994794, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
kdc_1       | Nov 05 22:59:54 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:54 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:54 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:54 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:54 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:54 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:54 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:54 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:55 kdc kadmind[15](info): closing down fd 18
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/c695af16ce49@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/c695af16ce49@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.c695af16ce49.keytab.
kdc_1       | Entry for principal HTTP/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.c695af16ce49.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/c95e120dae5a@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/c95e120dae5a@EXAMPLE.COM" created.
om_1        | 2019-11-05 23:05:21,728 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:05:21,740 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2019-11-05 23:02:12,528 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
datanode_1  | 2019-11-05 23:00:46,153 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start LeaderElection
datanode_1  | 2019-11-05 23:00:46,172 INFO impl.LeaderElection: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-LeaderElection2: begin an election at term 1 for -1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
scm_1       | 2019-11-05 23:02:12,573 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-11-05 23:05:27,025 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-11-05 23:02:12,586 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-11-05 23:05:27,034 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:05:33,923 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal dn/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.c95e120dae5a.keytab.
scm_1       | 2019-11-05 23:02:16,354 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-11-05 23:05:33,947 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:05:38,147 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal dn/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.c95e120dae5a.keytab.
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
scm_1       | 2019-11-05 23:02:16,356 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2019-11-05 23:05:38,188 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
scm_1       | 2019-11-05 23:02:42,419 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:05:43,441 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
datanode_1  | 2019-11-05 23:00:47,393 INFO impl.LeaderElection: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-LeaderElection2: Election REJECTED; received 2 response(s) [4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2<-3076f321-0139-4771-991e-8bdf0bbb6f06#0:FAIL-t1, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2<-25f2f6ba-ed69-4f1f-8b52-ab8f96757a57#0:FAIL-t1] and 0 exception(s); 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030:t1, leader=null, voted=4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2, raftlog=4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
kdc_1       | Generiting keytab
scm_1       | 2019-11-05 23:02:42,456 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-11-05 23:05:43,459 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2019-11-05 23:00:47,397 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-11-05 23:02:42,459 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-11-05 23:05:45,080 [IPC Server handler 3 on 9862] INFO       - created volume:49846-rpcwport for user:testuser/scm@EXAMPLE.COM
datanode_1  | 2019-11-05 23:00:47,397 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: shutdown LeaderElection
datanode_1  | 2019-11-05 23:00:47,397 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start FollowerState
kdc_1       | WARNING: no policy specified for s3g/6143ae4c601c@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
datanode_1  | 2019-11-05 23:00:52,450 INFO impl.FollowerState: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-FollowerState: change to CANDIDATE, lastRpcTime:5052ms, electionTimeout:5051ms
scm_1       | 2019-11-05 23:02:42,464 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Principal "s3g/6143ae4c601c@EXAMPLE.COM" created.
om_1        | 2019-11-05 23:05:48,504 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
datanode_1  | 2019-11-05 23:00:52,452 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: shutdown FollowerState
scm_1       | 2019-11-05 23:02:42,471 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2019-11-05 23:05:48,522 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:05:53,216 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:52,453 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
kdc_1       | Nov 05 22:59:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
om_1        | 2019-11-05 23:05:53,243 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:05:58,905 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:00:52,454 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start LeaderElection
scm_1       | 2019-11-05 23:02:42,488 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 22:59:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994795, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2019-11-05 23:05:58,916 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:06:04,388 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:04,405 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:06:10,946 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:10,957 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994796, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos daNov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
scm_1       | 2019-11-05 23:02:45,308 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:02:45,310 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:03:12,368 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:03:12,368 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:03:12,370 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
scm_1       | 2019-11-05 23:03:12,371 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:03:12,378 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:03:12,383 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:03:41,229 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:03:41,236 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode_1  | 2019-11-05 23:00:52,484 INFO impl.LeaderElection: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-LeaderElection3: begin an election at term 2 for -1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_1  | 2019-11-05 23:00:52,597 INFO impl.LeaderElection: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-LeaderElection3: Election PASSED; received 2 response(s) [4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2<-3076f321-0139-4771-991e-8bdf0bbb6f06#0:OK-t2, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2<-25f2f6ba-ed69-4f1f-8b52-ab8f96757a57#0:FAIL-t2] and 0 exception(s); 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030:t2, leader=null, voted=4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2, raftlog=4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null
datanode_1  | 2019-11-05 23:00:52,602 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: shutdown LeaderElection
datanode_1  | 2019-11-05 23:00:52,603 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
datanode_1  | 2019-11-05 23:00:52,604 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: change Leader from null to 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2 at term 2 for becomeLeader, leader elected after 11736ms
datanode_1  | 2019-11-05 23:00:52,604 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2019-11-05 23:00:52,609 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2019-11-05 23:00:52,609 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_1  | 2019-11-05 23:00:52,610 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
datanode_1  | 2019-11-05 23:00:52,610 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2019-11-05 23:00:52,610 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2019-11-05 23:00:52,615 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2019-11-05 23:00:52,628 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-11-05 23:00:52,630 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_1  | 2019-11-05 23:00:52,636 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2019-11-05 23:00:52,638 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2019-11-05 23:00:52,638 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-11-05 23:00:52,639 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1  | 2019-11-05 23:00:52,640 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
datanode_1  | 2019-11-05 23:00:52,641 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2019-11-05 23:00:52,641 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2019-11-05 23:00:52,642 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2019-11-05 23:00:52,642 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2019-11-05 23:00:52,643 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2019-11-05 23:00:52,645 INFO impl.RoleInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2: start LeaderState
datanode_1  | 2019-11-05 23:00:52,646 INFO segmented.SegmentedRaftLogWorker: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2019-11-05 23:00:52,647 INFO impl.RaftServerImpl: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030: set configuration 0: [3076f321-0139-4771-991e-8bdf0bbb6f06:172.18.0.7:9858, 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2:172.18.0.3:9858, 25f2f6ba-ed69-4f1f-8b52-ab8f96757a57:172.18.0.4:9858], old=null at 0
datanode_1  | 2019-11-05 23:00:52,681 INFO segmented.SegmentedRaftLogWorker: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e738925e-84c8-46e2-a256-4562290ef030/current/log_inprogress_0
datanode_1  | 2019-11-05 23:01:02,197 INFO client.DNCertificateClient: Getting certificate with certSerialId:12193783896913573.
datanode_1  | 2019-11-05 23:01:05,432 WARN server.GrpcLogAppender: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030->25f2f6ba-ed69-4f1f-8b52-ab8f96757a57-GrpcLogAppender: appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:2, i:1)
datanode_1  | 2019-11-05 23:01:05,445 WARN server.GrpcLogAppender: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030->3076f321-0139-4771-991e-8bdf0bbb6f06-GrpcLogAppender: appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:2, i:1)
datanode_1  | 2019-11-05 23:01:05,445 WARN server.GrpcLogAppender: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030->3076f321-0139-4771-991e-8bdf0bbb6f06-GrpcLogAppender: appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:2, i:2)
datanode_1  | 2019-11-05 23:01:05,449 WARN server.GrpcLogAppender: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030->25f2f6ba-ed69-4f1f-8b52-ab8f96757a57-GrpcLogAppender: appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:2, i:2)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-11-05 23:06:17,387 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:17,431 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:06:23,822 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:23,842 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:06:28,892 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:28,929 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:06:37,428 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:37,445 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:06:46,585 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:46,657 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:06:52,547 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:52,569 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:06:58,717 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:06:58,732 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:04,708 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:04,731 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:09,999 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:10,034 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:16,426 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:16,484 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:22,862 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:22,879 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:28,328 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:28,351 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:33,923 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXtabase
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994796, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994796, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994796, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@AMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/adEXAMPLE.COM
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994796, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | min@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-11-05 23:03:41,247 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2019-11-05 23:03:41,248 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103087798046621821 bcsId: 0
scm_1       | 2019-11-05 23:03:43,971 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:03:44,006 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:03:44,494 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:03:44,512 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:03:44,516 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:03:44,518 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:03:49,795 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:03:49,804 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:04:14,015 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:04:14,043 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:04:14,740 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:04:14,797 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:04:14,820 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:04:14,821 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:04:43,951 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:04:43,955 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:04:44,620 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:04:44,636 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:04:44,673 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:04:44,683 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-11-05 23:07:33,950 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:35,145 [IPC Server handler 13 on 9862] INFO       - created volume:49846-rpcwoscheme for user:testuser/scm@EXAMPLE.COM
om_1        | 2019-11-05 23:07:38,915 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:38,953 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:44,609 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:44,632 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:49,986 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:50,024 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:07:55,434 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:07:55,449 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:01,547 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:08:01,567 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:07,606 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:08:07,634 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:13,397 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:08:13,416 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:19,232 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:08:19,278 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:28,184 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:08:28,211 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:37,604 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
datanode_1  | 2019-11-05 23:01:05,551 WARN server.GrpcLogAppender: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030->3076f321-0139-4771-991e-8bdf0bbb6f06-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
datanode_1  | 2019-11-05 23:01:05,567 INFO impl.FollowerInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030->3076f321-0139-4771-991e-8bdf0bbb6f06: nextIndex: updateUnconditionally 3 -> 1
datanode_1  | 2019-11-05 23:01:05,604 WARN server.GrpcLogAppender: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030->25f2f6ba-ed69-4f1f-8b52-ab8f96757a57-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: Failed to read message.
datanode_1  | 2019-11-05 23:01:05,617 INFO impl.FollowerInfo: 4db3fd6c-1d6b-4022-bafa-ee461ee9f3f2@group-4562290EF030->25f2f6ba-ed69-4f1f-8b52-ab8f96757a57: nextIndex: updateUnconditionally 3 -> 1
datanode_1  | 2019-11-05 23:02:47,430 WARN client.GrpcClientProtocolService: 4-UnorderedRequestStreamObserver4: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:02:47,430 WARN client.GrpcClientProtocolService: 3-OrderedRequestStreamObserver3: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:04:52,764 WARN client.GrpcClientProtocolService: 5-OrderedRequestStreamObserver5: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:04:52,775 WARN client.GrpcClientProtocolService: 6-UnorderedRequestStreamObserver6: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:06:33,928 WARN client.GrpcClientProtocolService: 7-OrderedRequestStreamObserver7: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:06:33,931 WARN client.GrpcClientProtocolService: 8-UnorderedRequestStreamObserver8: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:08:24,119 WARN client.GrpcClientProtocolService: 9-OrderedRequestStreamObserver9: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:08:24,125 WARN client.GrpcClientProtocolService: 10-UnorderedRequestStreamObserver10: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:12:00,502 WARN client.GrpcClientProtocolService: 11-OrderedRequestStreamObserver11: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:12:00,502 WARN client.GrpcClientProtocolService: 12-UnorderedRequestStreamObserver12: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:19:55,756 WARN client.GrpcClientProtocolService: 27-OrderedRequestStreamObserver27: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2019-11-05 23:19:55,757 WARN client.GrpcClientProtocolService: 28-UnorderedRequestStreamObserver28: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Nov 05, 2019 11:15:11 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 2019-11-05 23:08:37,629 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:43,190 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:08:43,209 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:48,950 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:08:48,972 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:08:56,785 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:08:56,803 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:09:02,149 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:02,175 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:09:07,248 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:07,263 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:09:11,978 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:11,997 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:09:24,979 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:24,992 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:09:26,250 [IPC Server handler 5 on 9862] INFO       - created volume:fstest59 for user:testuser/scm@EXAMPLE.COM
om_1        | 2019-11-05 23:09:32,675 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:32,689 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:09:33,963 [IPC Server handler 3 on 9862] INFO       - created volume:fstest259 for user:testuser/scm@EXAMPLE.COM
om_1        | 2019-11-05 23:09:37,677 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:37,715 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/6143ae4c601c@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Entry for principal s3g/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.6143ae4c601c.keytab.
kdc_1       | Entry for principal s3g/6143ae4c601c@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.6143ae4c601c.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.scm.keytab.
kdc_1       | Entry for principal dn/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/90f7296b0733@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/90f7296b0733@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.90f7296b0733.keytab.
kdc_1       | Entry for principal s3g/90f7296b0733@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.90f7296b0733.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.om.keytab.
kdc_1       | Entry for principal testuser/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994796, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994796, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994797, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994797, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994797, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994797, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994797, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994797, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-11-05 23:04:49,138 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:04:49,152 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:04:59,328 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:04:59,340 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:05:13,974 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:05:13,984 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:05:14,729 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:05:14,730 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:05:14,733 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:05:14,734 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:05:34,007 INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2019-11-05 23:05:34,015 INFO container.ReplicationManager: Replication Monitor Thread took 5 milliseconds for processing 3 containers.
scm_1       | 2019-11-05 23:05:43,947 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:05:43,961 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:05:44,688 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:05:44,733 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:05:44,735 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:05:44,745 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:06:13,956 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:06:13,963 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:06:14,737 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:06:14,743 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:06:14,744 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:06:14,747 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:06:30,334 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:06:30,346 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:06:43,938 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:06:43,949 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:06:44,994 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:06:45,003 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:06:45,008 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:06:45,017 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-11-05 23:09:42,494 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:42,525 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:09:48,743 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:48,757 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:09:55,314 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:09:55,336 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:10:01,420 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:01,433 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:10:02,622 [IPC Server handler 16 on 9862] INFO       - created volume:fstest359 for user:testuser/scm@EXAMPLE.COM
om_1        | 2019-11-05 23:10:13,821 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:13,846 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:10:19,194 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:19,204 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:10:24,838 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:24,849 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:10:35,013 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:35,026 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:10:42,026 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:42,037 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:10:46,513 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:46,523 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:10:52,408 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:52,432 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:56 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/90f7296b0733@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](info): closing down fd 18
kdc_1       | Entry for principal dn/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.s3g.keytab.
kdc_1       | Entry for principal dn/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/c695af16ce49@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/c695af16ce49@EXAMPLE.COM" created.
scm_1       | 2019-11-05 23:07:14,647 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:07:14,669 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:07:14,875 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:07:14,876 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:07:14,880 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:07:14,883 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:07:44,416 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:07:44,431 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:07:44,675 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:07:44,678 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:07:44,679 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2019-11-05 23:07:44,679 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103087812794581119 bcsId: 0
scm_1       | 2019-11-05 23:07:45,124 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:07:45,132 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:07:45,140 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:07:45,168 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:08:14,585 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:08:14,601 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:08:15,170 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:08:15,187 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:08:15,239 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:08:15,254 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:08:20,878 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:08:20,881 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:08:44,433 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:08:44,443 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-11-05 23:08:45,163 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
scm_1       | 2019-11-05 23:08:45,167 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:08:45,178 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
kdc_1       | Entry for principal testuser/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.c695af16ce49.keytab.
kdc_1       | Entry for principal testuser/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.c695af16ce49.keytab.
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
kdc_1       | Generiting keytab
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:57 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994797, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994798, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for om/c95e120dae5a@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "om/c95e120dae5a@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal om/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.c95e120dae5a.keytab.
kdc_1       | Entry for principal om/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.c95e120dae5a.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for om/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "om/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal om/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.scm.keytab.
kdc_1       | Entry for principal om/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser2/om@EXAMPLE.COM; defaulting to no policy
om_1        | 2019-11-05 23:10:59,039 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:10:59,052 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:11:05,138 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:11:05,154 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:11:11,063 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:11:11,078 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:11:12,429 [IPC Server handler 0 on 9862] ERROR      - Add acl [user:superuser1:rwxy[ACCESS]] to path /fstest359/bk1 failed, because acl already exist
om_1        | 2019-11-05 23:11:22,512 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:11:22,524 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:11:27,843 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:11:27,865 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:11:33,041 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:11:33,057 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:11:37,678 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:11:37,713 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:11:43,055 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:11:43,071 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:11:49,826 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:11:49,849 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:04,637 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:04,686 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:09,659 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:09,708 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:14,863 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:14,874 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:19,925 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:19,957 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:25,283 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:25,304 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:31,016 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:31,027 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:36,862 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:36,873 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:43,276 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:43,292 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:49,471 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:49,493 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:50,702 [IPC Server handler 13 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume
om_1        | 2019-11-05 23:12:55,846 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:12:55,861 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:12:56,754 [IPC Server handler 16 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume
om_1        | 2019-11-05 23:13:01,049 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:01,079 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:04,158 [IPC Server handler 13 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
om_1        | 2019-11-05 23:13:04,159 [IPC Server handler 13 on 9862] ERROR      - Add acl user:testuser2/scm@EXAMPLE.COM:xy[ACCESS] to volume fstest359 failed!
om_1        | PERMISSION_DENIED org.apache.hadoop.ozone.om.exceptions.OMException: User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1628)
om_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:135)
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.acl.OMVolumeAclRequest.validateAndUpdateCache(OMVolumeAclRequest.java:79)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
scm_1       | 2019-11-05 23:08:45,191 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:09:14,621 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:09:14,662 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:09:15,366 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:09:15,385 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:09:15,765 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:09:15,796 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:09:25,027 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:09:25,030 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:09:44,472 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:09:44,483 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:09:45,201 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:09:45,268 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:09:45,270 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:09:45,284 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:09:45,398 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:09:45,406 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:09:45,407 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2019-11-05 23:09:45,408 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103087820038733952 bcsId: 0
scm_1       | 2019-11-05 23:10:13,867 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:10:13,872 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:10:14,459 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:10:14,464 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:10:15,157 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:10:15,167 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:10:15,231 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:10:15,246 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:10:34,016 INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 3 containers.
scm_1       | 2019-11-05 23:10:35,053 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:10:35,061 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:10:44,455 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:10:44,457 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:10:45,469 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:10:45,483 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:10:45,618 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:10:45,636 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:11:15,394 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:11:15,402 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:11:17,118 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:11:17,120 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:11:17,363 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:11:17,381 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:11:22,547 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:11:22,552 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:11:45,393 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:11:45,417 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:11:45,420 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:11:45,426 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:11:47,391 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:11:47,413 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:11:51,343 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:11:51,352 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:12:04,738 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:12:04,743 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:12:15,409 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:12:15,475 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:12:15,506 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:12:15,512 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:12:17,551 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:12:17,560 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:12:45,505 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:12:45,514 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:12:45,515 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:12:45,528 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:12:47,549 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:12:47,565 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:13:15,570 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:13:15,577 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:13:15,590 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:13:15,595 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:13:17,545 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:13:17,552 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:13:45,488 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:13:45,496 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:13:45,497 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:13:45,502 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:13:47,568 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Principal "testuser2/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser2/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.om.keytab.
kdc_1       | Entry for principal testuser2/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for om/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "om/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal om/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.s3g.keytab.
kdc_1       | Entry for principal om/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser2/c695af16ce49@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser2/c695af16ce49@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:58 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-11-05 23:13:10,274 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:10,300 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:16,442 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:16,466 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:17,745 [IPC Server handler 15 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access volume
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-11-05 23:13:22,104 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:22,116 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:29,282 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:29,304 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:34,799 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:34,821 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:40,031 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:40,057 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:41,302 [IPC Server handler 14 on 9862] WARN       - User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket
om_1        | 2019-11-05 23:13:45,226 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:45,245 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:50,538 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:50,554 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:13:55,967 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:13:55,997 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:14:02,723 INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:14:02,761 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:14:56,855 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:14:56,869 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:15:02,290 [Socket Reader #1 for port 9862] INFO       - 06fd94eaabad85b070f1353707d11d6289c33d6395a119099404547db24c8510
om_1        | 2019-11-05 23:15:02,304 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:15:02,322 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:15:04,225 [Socket Reader #1 for port 9862] INFO       - 06fd94eaabad85b070f1353707d11d6289c33d6395a119099404547db24c8510
om_1        | 2019-11-05 23:15:04,227 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:15:04,259 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:15:08,000 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994798, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994798, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994798, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994798, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994798, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994799, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994799, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994799, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994799, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994799, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Entry for principal testuser2/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.c695af16ce49.keytab.
kdc_1       | Entry for principal testuser2/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.c695af16ce49.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/c95e120dae5a@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "scm/c95e120dae5a@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 22:59:59 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:00 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:00 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 22:59:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994799, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994800, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | 1
kdc_1       | Nov 05 23:00:00 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:00 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Entry for principal scm/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.c95e120dae5a.keytab.
kdc_1       | Entry for principal scm/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.c95e120dae5a.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "scm/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 23:00:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994802, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:08,007 WARN ipc.Server: Auth failed for 172.18.0.10:44232:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:09,007 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
scm_1       | 2019-11-05 23:13:47,576 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:09,008 WARN ipc.Server: Auth failed for 172.18.0.10:44236:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:09,372 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
scm_1       | 2019-11-05 23:14:17,359 INFO util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1678ms
scm_1       | No GCs detected
scm_1       | 2019-11-05 23:14:17,366 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:14:17,369 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:14:17,409 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:14:17,419 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:14:17,835 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:14:17,844 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:14:46,582 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:14:46,585 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:14:46,896 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:14:46,899 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:14:47,859 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:14:47,873 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:14:56,893 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:14:56,909 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:15:16,593 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:15:16,597 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:15:16,922 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:15:16,952 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:15:17,844 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:15:17,851 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:15:34,018 INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 3 containers.
scm_1       | 2019-11-05 23:15:35,911 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:15:35,928 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:15:46,758 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:15:46,773 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:15:46,927 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:15:46,937 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:15:47,907 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:15:47,911 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:16:16,627 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:16:16,632 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:16:17,438 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:16:17,441 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:16:17,908 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:16:17,911 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:16:19,394 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:16:19,401 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:16:29,098 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:16:29,106 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:16:39,104 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:16:39,109 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:16:46,628 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Nov 05 23:00:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:02 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.3: ISSUE: authtime 1572994802, etypes {rep=18 tkt=18 ses=18}, dn/6143ae4c601c@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994802, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:01 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:01 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.om.keytab.
kdc_1       | Entry for principal s3g/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "scm/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal scm/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.s3g.keytab.
kdc_1       | Entry for principal scm/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 23:00:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994802, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:09,373 WARN ipc.Server: Auth failed for 172.18.0.10:44242:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:09,408 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
scm_1       | 2019-11-05 23:16:46,643 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:16:47,466 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:16:47,481 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:16:47,914 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:16:47,925 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:17:15,240 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:15,243 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:17:16,700 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:16,739 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:17:17,478 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:17,494 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:17:17,978 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:18,008 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:17:22,105 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:22,112 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:17:31,965 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:31,976 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:17:46,747 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:46,763 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:17:47,463 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:47,468 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:17:48,011 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:17:48,025 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:18:16,009 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:09,409 WARN ipc.Server: Auth failed for 172.18.0.10:44252:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994803, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994803, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.4: ISSUE: authtime 1572994803, etypes {rep=18 tkt=18 ses=18}, dn/90f7296b0733@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994803, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994803, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:02 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](info): closing down fd 18
kdc_1       | WARNING: no policy specified for s3g/c695af16ce49@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/c695af16ce49@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.c695af16ce49.keytab.
scm_1       | 2019-11-05 23:18:16,019 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:18:16,696 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:18:16,719 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:18:17,496 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:18:17,536 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:18:17,970 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:18:17,979 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:18:45,488 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:18:45,495 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:18:45,497 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
scm_1       | 2019-11-05 23:18:45,497 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103087851398889602 bcsId: 0
scm_1       | 2019-11-05 23:18:45,498 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103087852690604163 bcsId: 0
scm_1       | 2019-11-05 23:18:45,502 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103087855508717700 bcsId: 0
scm_1       | 2019-11-05 23:18:46,627 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:18:46,648 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:18:47,454 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:18:47,460 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:18:47,976 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:18:47,980 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:19:10,652 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:10,654 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 2019-11-05 23:15:09,429 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:09,431 WARN ipc.Server: Auth failed for 172.18.0.10:44254:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:09,837 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
scm_1       | 2019-11-05 23:19:16,635 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:16,673 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:19:17,838 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:17,852 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:19:18,098 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:18,128 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:19:29,869 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:29,872 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:19:40,313 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:40,315 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:19:42,393 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:42,404 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:19:46,690 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:46,702 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:19:47,832 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:47,838 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:19:48,073 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:48,083 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:19:59,712 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:19:59,716 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:20:16,754 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:20:16,758 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:20:17,841 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:20:17,855 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:20:18,077 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:20:18,095 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:20:34,019 INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 3 containers.
kdc_1       | Entry for principal s3g/c695af16ce49@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.c695af16ce49.keytab.
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994803, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:03 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:04 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:04 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:04 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/c695af16ce49@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/c95e120dae5a@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/c95e120dae5a@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 23:00:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994805, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994805, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:04 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Entry for principal HTTP/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.c95e120dae5a.keytab.
kdc_1       | Entry for principal HTTP/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.c95e120dae5a.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/scm@EXAMPLE.COM; defaulting to no policy
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:09,839 WARN ipc.Server: Auth failed for 172.18.0.10:44258:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Principal "HTTP/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/c95e120dae5a@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/c95e120dae5a@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.c95e120dae5a.keytab.
kdc_1       | Entry for principal testuser/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.c95e120dae5a.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/scm@EXAMPLE.COM; defaulting to no policy
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2019-11-05 23:15:11,155 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
scm_1       | 2019-11-05 23:20:48,762 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:20:48,770 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:20:48,775 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:20:48,785 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:20:48,794 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:20:48,800 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:21:17,892 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:21:17,897 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:21:18,739 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:21:18,742 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:21:18,760 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:21:18,762 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:21:18,792 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:21:18,794 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:21:28,964 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:21:28,966 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:21:48,788 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:21:48,791 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:21:48,821 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:21:48,822 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:21:48,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2019-11-05 23:15:10,116 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
scm_1       | 2019-11-05 23:21:48,834 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:22:17,210 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:17,224 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:22:18,740 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:18,743 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:22:18,762 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:18,793 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:22:18,803 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:18,810 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:22:30,060 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:30,065 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:22:45,689 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:45,691 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:22:45,692 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2019-11-05 23:22:45,692 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103087874849177741 bcsId: 0
scm_1       | 2019-11-05 23:22:48,776 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:48,791 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:22:48,809 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:48,821 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:22:48,825 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:22:48,851 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:23:01,240 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:23:01,252 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:23:18,743 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:23:18,776 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:23:18,805 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:23:18,810 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:23:18,815 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:10,298 WARN ipc.Server: Auth failed for 172.18.0.10:44260:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:10,398 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
kdc_1       | Principal "testuser/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser2/c95e120dae5a@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser2/c95e120dae5a@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser2/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.c95e120dae5a.keytab.
kdc_1       | Entry for principal testuser2/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.c95e120dae5a.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser2/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:05 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:10,398 WARN ipc.Server: Auth failed for 172.18.0.10:44264:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:10,414 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:10,416 WARN ipc.Server: Auth failed for 172.18.0.10:44280:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:10,605 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Principal "testuser2/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 23:00:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994805, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994805, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:10,611 WARN ipc.Server: Auth failed for 172.18.0.10:44282:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:10,631 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser2/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser2/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser2/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.s3g.keytab.
kdc_1       | Entry for principal testuser2/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/c95e120dae5a@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/c95e120dae5a@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.c95e120dae5a.keytab.
kdc_1       | Entry for principal s3g/c95e120dae5a@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.c95e120dae5a.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.scm.keytab.
kdc_1       | Entry for principal s3g/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	... 60 more
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
scm_1       | 2019-11-05 23:23:18,829 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
scm_1       | 2019-11-05 23:23:49,822 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
scm_1       | 2019-11-05 23:23:49,823 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
scm_1       | 2019-11-05 23:23:49,826 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
scm_1       | 2019-11-05 23:23:49,827 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm_1       | 2019-11-05 23:23:49,882 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm_1       | 2019-11-05 23:23:49,884 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
scm_1       | 2019-11-05 23:23:51,156 WARN ipc.Server: IPC Server handler 7 on 9861, call Call#52 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.7:35292: output error
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
scm_1       | 2019-11-05 23:23:51,160 INFO ipc.Server: IPC Server handler 7 on 9861 caught an exception
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
scm_1       | java.nio.channels.AsynchronousCloseException
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
s3g_1       | 	... 92 more
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:06 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191105T231507Z
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:11,098 WARN ipc.Server: Auth failed for 172.18.0.10:44284:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-11-05 23:15:11,159 WARN server.HttpChannel: //s3g:9878/bucket-test123
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:11,704 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:11,714 WARN ipc.Server: Auth failed for 172.18.0.10:44292:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:11,747 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/c95e120dae5a@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](info): closing down fd 18
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2019-11-05 23:23:52,574 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:23:52,579 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:24:07,556 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:07,567 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:24:19,772 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:19,787 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:24:19,843 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:19,852 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:19,856 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:24:19,858 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:24:27,063 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:27,069 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:24:44,536 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:44,537 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:24:45,787 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
scm_1       | 2019-11-05 23:24:45,788 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103087882080616599 bcsId: 0,conID: 3 locID: 103087882083500184 bcsId: 0,conID: 1 locID: 103087882085138585 bcsId: 0
scm_1       | 2019-11-05 23:24:45,789 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103087881098428565 bcsId: 0
scm_1       | 2019-11-05 23:24:45,789 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103087881179037846 bcsId: 0
scm_1       | 2019-11-05 23:24:49,788 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:49,801 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:24:49,853 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:49,872 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:24:49,874 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:24:49,899 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:25:16,812 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:25:16,829 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:07 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994806, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.6: ISSUE: authtime 1572994807, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994807, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994807, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994807, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994807, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:11,748 WARN ipc.Server: Auth failed for 172.18.0.10:44294:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:11,803 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994807, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994807, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994808, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:11 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994811, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:11 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.7: ISSUE: authtime 1572994811, etypes {rep=18 tkt=18 ses=18}, dn/c95e120dae5a@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:13 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.8: ISSUE: authtime 1572994813, etypes {rep=18 tkt=18 ses=18}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994813, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:21 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994821, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
scm_1       | 2019-11-05 23:25:20,010 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:25:20,019 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:25:20,020 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:25:20,051 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:25:20,052 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:25:20,062 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 23:00:23 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994823, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
scm_1       | 2019-11-05 23:25:34,020 INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 3 containers.
scm_1       | 2019-11-05 23:25:50,025 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:25:50,026 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:25:50,030 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:25:50,033 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:25:50,061 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:25:50,076 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:26:09,082 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:09,086 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:26:20,031 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:20,038 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:20,051 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:26:20,058 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:20,063 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:26:20,064 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:11,805 WARN ipc.Server: Auth failed for 172.18.0.10:44296:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:11,827 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
scm_1       | 2019-11-05 23:26:33,736 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:33,739 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2019-11-05 23:26:45,931 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:45,934 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
scm_1       | 2019-11-05 23:26:45,935 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2019-11-05 23:26:45,935 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103087890044551330 bcsId: 0
scm_1       | 2019-11-05 23:26:45,936 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103087891660144803 bcsId: 0
scm_1       | 2019-11-05 23:26:50,017 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:50,021 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:26:50,029 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:50,031 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:26:50,033 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:26:50,037 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:27:15,496 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:27:15,501 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Nov 05 23:00:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1572994807, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Nov 05 23:00:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.7: ISSUE: authtime 1572994811, etypes {rep=18 tkt=18 ses=18}, dn/c95e120dae5a@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Nov 05 23:00:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.4: ISSUE: authtime 1572994803, etypes {rep=18 tkt=18 ses=18}, dn/90f7296b0733@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Nov 05 23:00:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.3: ISSUE: authtime 1572994802, etypes {rep=18 tkt=18 ses=18}, dn/6143ae4c601c@EXAMPLE.COM for scm/scm@EXAMPLE.COM
scm_1       | 2019-11-05 23:27:20,208 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
scm_1       | 2019-11-05 23:27:20,210 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:27:20,213 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Nov 05 23:00:26 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994826, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:26 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994826, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
scm_1       | 2019-11-05 23:27:20,220 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 23:00:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994829, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
scm_1       | 2019-11-05 23:27:20,227 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 23:00:29 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994829, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
kdc_1       | Nov 05 23:00:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994832, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
scm_1       | 2019-11-05 23:27:20,228 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 23:00:32 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994832, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
kdc_1       | Nov 05 23:00:33 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.6: ISSUE: authtime 1572994833, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
scm_1       | 2019-11-05 23:27:31,142 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Nov 05 23:00:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1572994833, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
scm_1       | 2019-11-05 23:27:31,152 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
kdc_1       | Nov 05 23:00:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994835, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Nov 05 23:00:35 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994835, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
scm_1       | 2019-11-05 23:27:45,968 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Generiting keytab
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 2019-11-05 23:15:11,828 WARN ipc.Server: Auth failed for 172.18.0.10:44300:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-11-05 23:27:45,970 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
kdc_1       | WARNING: no policy specified for dn/recon@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-11-05 23:27:45,970 INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 20191105T231511Z
kdc_1       | Principal "dn/recon@EXAMPLE.COM" created.
scm_1       | 2019-11-05 23:27:45,970 INFO block.BlockManagerImpl: Deleting blocks conID: 3 locID: 103087892609433764 bcsId: 0
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 20191105/us-west-1/s3/aws4_request
scm_1       | 2019-11-05 23:27:45,971 INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 103087894397059237 bcsId: 0
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:11,868 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Entry for principal dn/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.recon.keytab.
kdc_1       | Entry for principal dn/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.recon.keytab.
scm_1       | 2019-11-05 23:27:45,971 INFO block.BlockManagerImpl: Deleting blocks conID: 2 locID: 103087894471901350 bcsId: 0
scm_1       | 2019-11-05 23:27:50,203 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-11-05 23:27:50,222 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:27:50,349 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Nov 05 23:00:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994846, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
scm_1       | 2019-11-05 23:27:50,352 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
scm_1       | 2019-11-05 23:27:50,358 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:27:50,365 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:27:51,963 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:27:51,972 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2019-11-05 23:28:20,774 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:28:20,774 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:28:20,776 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:28:20,783 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:28:20,793 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:28:20,800 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
scm_1       | 2019-11-05 23:28:30,794 INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:11,883 WARN ipc.Server: Auth failed for 172.18.0.10:44302:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
scm_1       | 2019-11-05 23:28:30,831 INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:11,901 WARN ipc.Server: Auth failed for 172.18.0.10:44304:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-11-05 23:28:50,750 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
scm_1       | 2019-11-05 23:28:50,750 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:15:11,900 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
scm_1       | 2019-11-05 23:28:50,759 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
scm_1       | 2019-11-05 23:28:50,760 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Nov 05 23:00:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994846, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994847, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
scm_1       | 2019-11-05 23:28:50,763 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
scm_1       | 2019-11-05 23:28:50,766 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
scm_1       | 2019-11-05 23:29:20,760 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
scm_1       | 2019-11-05 23:29:20,762 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
scm_1       | 2019-11-05 23:29:20,771 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
kdc_1       | WARNING: no policy specified for om/recon@EXAMPLE.COM; defaulting to no policy
scm_1       | 2019-11-05 23:29:20,774 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm_1       | 2019-11-05 23:29:20,782 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2019-11-05 23:29:20,793 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
scm_1       | 2019-11-05 23:29:50,761 INFO ipc.Server: Auth successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191105T231507Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
kdc_1       | Principal "om/recon@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
scm_1       | 2019-11-05 23:29:50,762 INFO ipc.Server: Auth successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
scm_1       | 2019-11-05 23:29:50,776 INFO ipc.Server: Auth successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:29:50,778 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6143ae4c601c@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:29:50,782 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/c95e120dae5a@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:29:50,799 INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/90f7296b0733@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2019-11-05 23:29:54,506 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2019-11-05 23:29:54,521 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
kdc_1       | Entry for principal om/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.recon.keytab.
scm_1       | 2019-11-05 23:29:54,927 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Entry for principal om/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.recon.keytab.
kdc_1       | Generiting keytab
scm_1       | 2019-11-05 23:29:54,933 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Principal "scm/recon@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Entry for principal scm/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.recon.keytab.
kdc_1       | Entry for principal scm/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.recon.keytab.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Nov 05 23:00:46 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:46 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:46 kdc kadmind[15](Notice): Request: kadm5_create_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:46 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:46 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:46 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:46 kdc kadmind[15](Notice): Request: kadm5_get_principal, dn/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_create_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_get_principal, om/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_create_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:11,921 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
s3g_1       | cc647127df79bf6893b0ff4fa22005c5f8bab96152c5df6c9a2385a386706a2a, signature=738dea4267a0c266a4bccc08d940ffac401fa9292cfb2a2832342f4a20678c18, awsAccessKeyId=dlfknslnfslf
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](Notice): Request: kadm5_get_principal, scm/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
kdc_1       | Nov 05 23:00:47 kdc kadmind[15](info): closing down fd 18
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994847, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994847, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994847, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994847, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-11-05 23:15:11,718 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:11,760 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:11,761 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
kdc_1       | Nov 05 23:00:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994847, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | WARNING: no policy specified for HTTP/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
kdc_1       | Principal "HTTP/recon@EXAMPLE.COM" created.
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:11,809 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:11,812 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
kdc_1       | Nov 05 23:00:48 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:49 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:49 kdc kadmind[15](Notice): Request: kadm5_create_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191105/us-west-1/s3/aws4_request
kdc_1       | Nov 05 23:00:49 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1       | Nov 05 23:00:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994849, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Generiting keytab
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:11,831 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191105T231511Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:15:11,923 WARN ipc.Server: Auth failed for 172.18.0.10:44306:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
s3g_1       | 2019-11-05 23:15:11,833 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:15:11,939 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 2019-11-05 23:15:11,885 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Nov 05 23:00:50 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 2019-11-05 23:15:11,886 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Nov 05 23:00:50 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:50 kdc kadmind[15](Notice): Request: kadm5_get_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:50 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:50 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:50 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994850, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | WARNING: no policy specified for testuser/recon@EXAMPLE.COM; defaulting to no policy
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Principal "testuser/recon@EXAMPLE.COM" created.
s3g_1       | 20191105T231511Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 2019-11-05 23:15:11,903 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Entry for principal testuser/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.recon.keytab.
kdc_1       | Entry for principal testuser/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.recon.keytab.
kdc_1       | Generiting keytab
s3g_1       | 20191105T231511Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | WARNING: no policy specified for testuser2/recon@EXAMPLE.COM; defaulting to no policy
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Principal "testuser2/recon@EXAMPLE.COM" created.
s3g_1       | 2019-11-05 23:15:11,906 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 20191105T231511Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Entry for principal testuser2/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.recon.keytab.
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
kdc_1       | Entry for principal testuser2/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.recon.keytab.
om_1        | 2019-11-05 23:15:11,940 WARN ipc.Server: Auth failed for 172.18.0.10:44308:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-11-05 23:15:11,925 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/recon@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/recon@EXAMPLE.COM" created.
s3g_1       | 20191105T231511Z
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.recon.keytab.
kdc_1       | Entry for principal s3g/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.recon.keytab.
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994851, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994851, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994851, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994851, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:12,021 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994851, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994851, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
s3g_1       | 20191105/us-west-1/s3/aws4_request
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Nov 05 23:00:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1572994851, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:11,926 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | 00:51 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_create_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_get_principal, testuser2/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191105T231511Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_create_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191105/us-west-1/s3/aws4_request
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](info): closing down fd 18
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:11,958 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
s3g_1       | 20191105T231511Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:12,029 WARN ipc.Server: Auth failed for 172.18.0.10:44310:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-11-05 23:15:11,959 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 20191105T231511Z
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_randkey_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:12,034 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
kdc_1       | Nov 05 23:00:51 kdc kadmind[15](Notice): Request: kadm5_get_principal, s3g/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:12,036 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:15:12,297 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
kdc_1       | Nov 05 23:00:52 kdc kadmind[15](info): closing down fd 18
kdc_1       | Nov 05 23:00:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994851, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:02:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191105T231511Z
s3g_1       | 2019-11-05 23:15:12,302 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:12,303 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 2019-11-05 23:15:12,612 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Nov 05 23:02:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Nov 05 23:02:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:02:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:02:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:02:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:02:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:12,298 WARN ipc.Server: Auth failed for 172.18.0.10:44312:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-11-05 23:15:12,617 [qtp262445056-30] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
s3g_1       | 2019-11-05 23:15:12,619 [qtp262445056-30] ERROR      - Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 20191105T231511Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:12,604 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231511Z
kdc_1       | Nov 05 23:02:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
kdc_1       | Nov 05 23:02:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
kdc_1       | Nov 05 23:02:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
kdc_1       | Nov 05 23:02:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
kdc_1       | Nov 05 23:02:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
kdc_1       | Nov 05 23:02:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
kdc_1       | Nov 05 23:02:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
kdc_1       | Nov 05 23:02:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
kdc_1       | Nov 05 23:03:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
kdc_1       | Nov 05 23:03:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
kdc_1       | Nov 05 23:03:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
kdc_1       | Nov 05 23:03:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994933, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
kdc_1       | Nov 05 23:03:11 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
kdc_1       | Nov 05 23:03:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
kdc_1       | Nov 05 23:03:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-11-05 23:15:12,605 WARN ipc.Server: Auth failed for 172.18.0.10:44324:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
kdc_1       | Nov 05 23:03:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:03:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:03:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:03:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:03:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 20191105T231511Z
kdc_1       | Nov 05 23:03:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572994991, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:03:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:03:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:03:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 20191105/us-west-1/s3/aws4_request
kdc_1       | Nov 05 23:04:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:04:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf)
kdc_1       | Nov 05 23:04:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
kdc_1       | Nov 05 23:04:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:04:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:04:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995031, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:04:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:04:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:04:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-11-05 23:15:16,508 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Nov 05 23:05:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:05:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:05:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
kdc_1       | Nov 05 23:05:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
kdc_1       | Nov 05 23:05:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
kdc_1       | Nov 05 23:05:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995082, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:05:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Nov 05 23:05:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:05:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
kdc_1       | Nov 05 23:05:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:05:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:05:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:06:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Nov 05 23:06:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:06:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
kdc_1       | Nov 05 23:06:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
kdc_1       | Nov 05 23:06:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:06:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Nov 05 23:06:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Nov 05 23:06:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
kdc_1       | Nov 05 23:06:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
kdc_1       | Nov 05 23:07:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:07:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:07:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:07:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995134, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Nov 05 23:07:24 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-11-05 23:15:16,510 WARN ipc.Server: Auth failed for 172.18.0.10:44440:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-11-05 23:15:16,553 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
kdc_1       | Nov 05 23:07:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Nov 05 23:07:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:07:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:07:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:07:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Nov 05 23:07:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:08:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:08:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:08:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:16,560 WARN ipc.Server: Auth failed for 172.18.0.10:44444:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:16,599 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:16,600 WARN ipc.Server: Auth failed for 172.18.0.10:44446:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:16,624 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
kdc_1       | Nov 05 23:08:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:08:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:08:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:08:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:08:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:08:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995244, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:22 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:09:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:09:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:10:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:11:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:11:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:11:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:11:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:11:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:11:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:11:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:11:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995362, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:44 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995564, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:12:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995564, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:12:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995564, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995564, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995585, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:13:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995585, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995592, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:13:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995592, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995592, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995592, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995592, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995592, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995621, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:13:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995621, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:13:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995621, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
s3g_1       | 	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Nov 05, 2019 11:15:13 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
kdc_1       | Nov 05 23:13:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995632, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
kdc_1       | Nov 05 23:13:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995632, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:16,624 WARN ipc.Server: Auth failed for 172.18.0.10:44448:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:16,651 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Nov 05 23:14:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995632, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:14:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995644, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:14:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:14:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:15:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:15:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:15:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:15:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:15:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:16:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:17:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:17:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:17:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:17:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:17:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:17:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:17:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:17:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:18:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:18:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:18:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:18:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:18:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
kdc_1       | Nov 05 23:18:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Nov 05 23:18:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:18:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
kdc_1       | Nov 05 23:18:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Nov 05 23:19:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:19:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:16,652 WARN ipc.Server: Auth failed for 172.18.0.10:44450:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:16,677 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
kdc_1       | Nov 05 23:19:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:19:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:19:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:19:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:19:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:20:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:20:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:20:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:21:14 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996074, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:21:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996074, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:21:24 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996084, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:21:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996084, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:21:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996095, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:21:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996095, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:21:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996102, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:21:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996102, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:21:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996113, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:21:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996113, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:22:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996125, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:22:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996125, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:22:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996140, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:22:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996140, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:22:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996155, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:22:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996155, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:22:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996171, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:22:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996171, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:23:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996188, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:23:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996188, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:23:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996200, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:23:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996200, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:23:30 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996210, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:23:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996210, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:23:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996220, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:23:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996220, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:23:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996238, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:24:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996238, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:24:16 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996256, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:24:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996256, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 2019-11-05 23:15:16,691 WARN ipc.Server: Auth failed for 172.18.0.10:44452:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:16,703 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
kdc_1       | Nov 05 23:24:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996274, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
kdc_1       | Nov 05 23:24:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996274, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
kdc_1       | Nov 05 23:24:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996294, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
kdc_1       | Nov 05 23:24:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996294, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:25:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996306, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:25:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996306, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Nov 05 23:25:25 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996325, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:25:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996325, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:25:38 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996338, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
kdc_1       | Nov 05 23:25:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996338, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:25:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996349, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:25:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996349, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Nov 05 23:25:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996358, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:26:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996358, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:26:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996373, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2019-11-05 23:15:16,704 WARN ipc.Server: Auth failed for 172.18.0.10:44454:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
kdc_1       | Nov 05 23:26:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996373, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:26:26 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996386, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:26:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996386, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:26:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996400, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
s3g_1       | 	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:16,737 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
kdc_1       | Nov 05 23:26:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996400, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
kdc_1       | Nov 05 23:26:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996414, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
kdc_1       | Nov 05 23:26:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996414, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2019-11-05 23:15:16,738 WARN ipc.Server: Auth failed for 172.18.0.10:44456:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	... 93 more
kdc_1       | Nov 05 23:27:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996424, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
kdc_1       | Nov 05 23:27:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996424, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-11-05 23:15:16,749 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 20191105T231515Z
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
kdc_1       | Nov 05 23:27:22 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996442, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
kdc_1       | Nov 05 23:27:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996442, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
kdc_1       | Nov 05 23:27:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996455, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
kdc_1       | Nov 05 23:27:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996455, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:27:53 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996473, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:27:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996473, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:28:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996484, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	... 102 more
kdc_1       | Nov 05 23:28:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996484, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 
s3g_1       | 
kdc_1       | Nov 05 23:28:15 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996495, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:28:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996495, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
kdc_1       | Nov 05 23:28:31 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996511, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 2019-11-05 23:15:13,066 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
kdc_1       | Nov 05 23:28:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996511, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
kdc_1       | Nov 05 23:28:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996521, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:28:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996521, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:28:50 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996530, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:28:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996530, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
kdc_1       | Nov 05 23:29:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996543, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
kdc_1       | Nov 05 23:29:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996543, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:29:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996553, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
kdc_1       | Nov 05 23:29:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996553, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
kdc_1       | Nov 05 23:29:26 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996566, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:29:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996566, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Nov 05 23:29:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996579, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:29:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1572996579, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
kdc_1       | Nov 05 23:29:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996586, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Nov 05 23:29:46 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.10: ISSUE: authtime 1572996586, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1       | Nov 05 23:29:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1572995692, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-11-05 23:15:16,750 WARN ipc.Server: Auth failed for 172.18.0.10:44460:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 20191105T231515Z
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:16,779 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:16,780 WARN ipc.Server: Auth failed for 172.18.0.10:44462:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 2019-11-05 23:15:16,794 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:16,795 WARN ipc.Server: Auth failed for 172.18.0.10:44464:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231515Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,286 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,287 WARN ipc.Server: Auth failed for 172.18.0.10:44482:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,297 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,298 WARN ipc.Server: Auth failed for 172.18.0.10:44484:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,311 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,311 WARN ipc.Server: Auth failed for 172.18.0.10:44486:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,323 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,325 WARN ipc.Server: Auth failed for 172.18.0.10:44488:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,346 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 34 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,348 WARN ipc.Server: Auth failed for 172.18.0.10:44490:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 2019-11-05 23:15:19,365 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,366 WARN ipc.Server: Auth failed for 172.18.0.10:44492:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,382 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 61 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 93 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,384 WARN ipc.Server: Auth failed for 172.18.0.10:44494:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,394 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	... 102 more
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 2019-11-05 23:15:13,093 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-11-05 23:15:19,394 WARN ipc.Server: Auth failed for 172.18.0.10:44496:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,400 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,401 WARN ipc.Server: Auth failed for 172.18.0.10:44498:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-11-05 23:15:19,410 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
s3g_1       | 	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-11-05 23:15:19,414 WARN ipc.Server: Auth failed for 172.18.0.10:44500:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 14 more
om_1        | 20191105T231519Z
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:19,425 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231519Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:19,426 WARN ipc.Server: Auth failed for 172.18.0.10:44502:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 20191105T231519Z
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-11-05 23:15:22,594 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 34 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:22,595 WARN ipc.Server: Auth failed for 172.18.0.10:44530:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:22,610 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 61 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-11-05 23:15:22,613 WARN ipc.Server: Auth failed for 172.18.0.10:44532:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:22,629 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
s3g_1       | 	... 93 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 20191105T231511Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 96ea0ccbb8a82c9b88858546baaeea5ccc27b4c54e3755760076ac328d8a94de, signature=846c82c8c66c156e659c53738a2bf5fa1911b86949f06ea010b9f1575a555cbc, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 102 more
s3g_1       | 2019-11-05 23:15:16,519 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 2019-11-05 23:15:16,565 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:16,566 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:22,630 WARN ipc.Server: Auth failed for 172.18.0.10:44534:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:16,602 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:16,603 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:22,649 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:16,626 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:16,628 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 2019-11-05 23:15:16,667 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:16,668 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:16,693 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 2019-11-05 23:15:16,695 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 20191105T231515Z
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 2019-11-05 23:15:16,719 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 20191105T231515Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 2019-11-05 23:15:16,722 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 20191105T231515Z
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
om_1        | 2019-11-05 23:15:22,650 WARN ipc.Server: Auth failed for 172.18.0.10:44536:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 2019-11-05 23:15:16,740 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
om_1        | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 2019-11-05 23:15:16,741 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
om_1        | 2019-11-05 23:15:22,675 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 20191105T231522Z
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:16,751 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 20191105T231515Z
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:16,752 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 2019-11-05 23:15:16,781 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 20191105T231515Z
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 2019-11-05 23:15:16,783 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 20191105T231515Z
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:16,796 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 2019-11-05 23:15:16,796 [qtp262445056-123] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
s3g_1       | 2019-11-05 23:15:16,797 [qtp262445056-123] ERROR      - Couldn't create RpcClient protocol exception: 
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 20191105T231515Z
om_1        | 2019-11-05 23:15:22,676 WARN ipc.Server: Auth failed for 172.18.0.10:44538:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-11-05 23:15:22,693 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 20191105T231522Z
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:22,694 WARN ipc.Server: Auth failed for 172.18.0.10:44540:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-11-05 23:15:22,707 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-11-05 23:15:22,707 WARN ipc.Server: Auth failed for 172.18.0.10:44542:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 20191105T231522Z
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-11-05 23:15:22,718 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-11-05 23:15:22,719 WARN ipc.Server: Auth failed for 172.18.0.10:44544:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-11-05 23:15:22,728 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 20191105T231522Z
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | Nov 05, 2019 11:15:16 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:22,728 WARN ipc.Server: Auth failed for 172.18.0.10:44546:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:22,735 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20191105T231522Z
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
om_1        | 2019-11-05 23:15:22,735 WARN ipc.Server: Auth failed for 172.18.0.10:44548:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-11-05 23:15:22,742 [Socket Reader #1 for port 9862] ERROR      - Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 20191105T231522Z
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3Token(OzoneDelegationTokenSecretManager.java:401)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:349)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:1955)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:1932)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1825)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2532)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2360)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2109)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1249)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1105)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1076)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2019-11-05 23:15:22,742 WARN ipc.Server: Auth failed for 172.18.0.10:44550:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 20191105T231522Z
om_1        | 20191105/us-west-1/s3/aws4_request
om_1        | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf)
om_1        | 2019-11-05 23:15:35,835 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:15:35,882 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:15:37,244 [IPC Server handler 1 on 9862] INFO       - created volume:fstest for user:testuser/scm@EXAMPLE.COM
om_1        | 2019-11-05 23:15:41,422 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-11-05 23:15:41,477 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-11-05 23:15:42,833 [IPC Server handler 7 on 9862] INFO       - created volume:fstest2 for user:testuser/scm@EXAMPLE.COM
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:15:45,746 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191105T231515Z
om_1        | 2019-11-05 23:15:45,772 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:15:51,255 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:15:51,319 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:15:56,011 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2019-11-05 23:15:16,803 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 2019-11-05 23:15:56,038 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:02,142 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:02,162 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:08,030 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:08,057 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:13,592 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:13,680 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:18,343 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:18,356 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:28,910 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:28,929 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:35,461 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:35,484 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:45,392 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:45,431 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:51,980 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:52,018 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:16:57,237 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:16:57,253 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:17:02,143 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:17:02,195 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:17:15,200 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:17:15,222 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:17:20,778 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 2019-11-05 23:17:20,806 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:17:31,914 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 2019-11-05 23:17:31,950 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2019-11-05 23:17:38,192 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | 2019-11-05 23:17:38,243 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 2019-11-05 23:17:43,691 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 2019-11-05 23:17:43,705 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 2019-11-05 23:17:51,847 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 2019-11-05 23:17:51,860 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
om_1        | 2019-11-05 23:17:56,923 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
om_1        | 2019-11-05 23:17:56,959 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 2019-11-05 23:18:01,924 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
om_1        | 2019-11-05 23:18:01,936 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 2019-11-05 23:18:07,251 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:18:07,287 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:18:12,971 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:18:12,986 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:18:19,675 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:18:19,690 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:18:29,581 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:18:29,633 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:18:34,784 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:18:34,806 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:18:40,488 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:18:40,533 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:18:45,380 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:18:45,394 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:18:53,935 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:18:53,950 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:19:10,616 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:19:10,631 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:19:16,079 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:19:16,113 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:19:22,557 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:19:22,578 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:19:28,043 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:19:28,060 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:19:38,631 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:19:38,642 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:19:48,402 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:19:48,418 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:19:59,679 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:19:59,696 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-11-05 23:20:04,886 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-11-05 23:20:04,904 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:20:11,525 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:20:11,536 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:20:18,945 INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:20:18,970 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:17,842 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:21:17,876 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:21,521 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-11-05 23:21:21,522 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:21,529 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:25,905 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:21:25,914 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-11-05 23:21:28,895 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-11-05 23:21:28,896 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:28,898 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:31,912 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:21:31,913 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:31,916 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:32,967 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:21:32,969 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:32,980 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:33,715 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:21:33,715 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:33,718 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:34,397 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-11-05 23:21:34,397 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-11-05 23:21:34,400 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-11-05 23:21:36,965 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-11-05 23:21:36,976 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-11-05 23:21:40,654 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:21:40,660 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-11-05 23:21:40,673 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:41,333 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
om_1        | 2019-11-05 23:21:41,333 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:41,335 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-11-05 23:21:41,347 [IPC Server handler 2 on 9862] ERROR      - S3Bucket Creation Failed for userName: 2724f42bcd3225359401cb62da89c51d, s3BucketName bucket-24796, VolumeName s32724f42bcd3225359401cb62da89c51d
om_1        | 2019-11-05 23:21:46,205 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:21:46,223 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:50,699 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:21:50,700 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:50,711 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:51,686 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:21:51,687 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:51,695 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:21:52,546 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:21:52,546 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:21:52,549 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-11-05 23:21:58,493 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:21:58,508 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-11-05 23:22:03,091 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-11-05 23:22:03,095 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:03,110 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 2019-11-05 23:22:04,028 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:04,029 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-11-05 23:22:04,031 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:09,124 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-11-05 23:22:09,159 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:14,149 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:14,150 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:14,172 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-11-05 23:22:15,044 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-11-05 23:22:15,048 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-11-05 23:22:15,054 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
om_1        | 2019-11-05 23:22:15,950 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2019-11-05 23:22:15,953 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
om_1        | 2019-11-05 23:22:15,965 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:17,058 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 2019-11-05 23:22:17,059 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:17,073 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
om_1        | 2019-11-05 23:22:18,878 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:18,880 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-11-05 23:22:18,903 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:23,974 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
om_1        | 2019-11-05 23:22:23,987 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:28,958 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-11-05 23:22:28,959 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:28,961 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:29,992 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:29,994 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:30,006 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-11-05 23:22:31,511 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:31,512 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:31,528 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
om_1        | 2019-11-05 23:22:32,540 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:32,541 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:32,562 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:33,475 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:33,475 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:33,488 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om_1        | 2019-11-05 23:22:37,913 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-11-05 23:22:37,921 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
om_1        | 2019-11-05 23:22:45,858 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
om_1        | 2019-11-05 23:22:45,859 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-11-05 23:22:45,866 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
om_1        | 2019-11-05 23:22:47,014 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-11-05 23:22:47,015 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-11-05 23:22:47,031 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:48,454 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:48,455 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:48,466 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:49,998 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:22:50,000 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:22:50,008 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:22:50,040 [IPC Server handler 0 on 9862] ERROR      - MultipartUpload: /s32724f42bcd3225359401cb62da89c51d/bucket-01639/multipartKey2Part number: 1size 6 is less than minimum part size 5242880
om_1        | 2019-11-05 23:22:50,042 [IPC Server handler 0 on 9862] ERROR      - MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-01639
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-01639key: multipartKey2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-11-05 23:22:55,266 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:22:55,282 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:23:00,128 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:23:00,132 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:00,143 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:23:01,104 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:23:01,105 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:01,132 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:23:02,412 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:23:02,412 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:02,414 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:23:07,472 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:23:07,473 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:07,477 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:23:07,502 [IPC Server handler 17 on 9862] ERROR      - MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-01639
om_1        | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-01639key: multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:195)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	... 60 more
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231515Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2019-11-05 23:23:12,065 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:23:12,097 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:23:18,669 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-11-05 23:23:18,671 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:18,699 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-11-05 23:23:19,698 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-11-05 23:23:19,699 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	... 101 more
om_1        | 2019-11-05 23:23:19,714 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:23:25,028 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-11-05 23:15:16,807 WARN server.HttpChannel: //s3g:9878/bucket-test123
om_1        | 2019-11-05 23:23:25,047 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 2019-11-05 23:23:29,560 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 2019-11-05 23:23:29,561 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 
om_1        | 2019-11-05 23:23:29,573 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
om_1        | 2019-11-05 23:23:29,613 [IPC Server handler 0 on 9862] ERROR      - Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket s32724f42bcd3225359401cb62da89c51d/bucket-01639
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-01639key: multipartKey5
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:116)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-11-05 23:23:34,131 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-11-05 23:23:34,151 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:23:38,947 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
om_1        | 2019-11-05 23:23:38,949 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | 2019-11-05 23:23:38,956 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-11-05 23:23:38,988 [IPC Server handler 2 on 9862] ERROR      - ALLOCATE_KEY failed for Key: multipartKey in volume/bucket:s32724f42bcd3225359401cb62da89c51d/bucket-01639
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:471)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:423)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:182)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:217)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:72)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:100)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
s3g_1       | 	... 13 more
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 1. javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
om_1        | 2019-11-05 23:23:43,711 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-11-05 23:23:43,723 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-11-05 23:23:51,154 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-11-05 23:23:51,156 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
om_1        | 2019-11-05 23:23:51,173 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-11-05 23:23:52,461 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-11-05 23:23:52,461 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:52,469 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-11-05 23:23:53,750 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
om_1        | 2019-11-05 23:23:53,752 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-11-05 23:23:53,758 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
om_1        | 2019-11-05 23:23:54,952 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
om_1        | 2019-11-05 23:23:54,953 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:54,957 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-11-05 23:23:55,903 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:23:55,903 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:55,905 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
om_1        | 2019-11-05 23:23:56,632 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-11-05 23:23:56,632 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:23:56,635 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-11-05 23:23:57,476 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 2019-11-05 23:23:57,478 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 2019-11-05 23:23:57,481 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-11-05 23:24:02,261 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-11-05 23:24:02,284 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-11-05 23:24:07,118 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	... 33 more
om_1        | 2019-11-05 23:24:07,119 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | Caused by: javax.enterprise.inject.CreationException
om_1        | 2019-11-05 23:24:07,134 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om_1        | 2019-11-05 23:24:07,379 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2019-11-05 23:24:07,385 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-11-05 23:24:07,387 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
om_1        | 2019-11-05 23:24:07,389 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-11-05 23:24:07,401 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-11-05 23:24:07,421 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:10,295 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:24:10,471 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:24:10,483 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-11-05 23:24:11,691 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:24:11,692 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
om_1        | 2019-11-05 23:24:11,703 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:11,842 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
om_1        | 2019-11-05 23:24:11,844 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:24:11,857 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	... 60 more
om_1        | 2019-11-05 23:24:11,858 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:24:11,862 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
om_1        | 2019-11-05 23:24:11,866 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:11,926 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
om_1        | 2019-11-05 23:24:11,932 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:24:11,940 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-11-05 23:24:14,986 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
om_1        | 2019-11-05 23:24:14,988 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-11-05 23:24:14,998 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-11-05 23:24:20,078 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:24:20,104 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:26,991 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:24:26,992 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2019-11-05 23:24:26,997 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
om_1        | 2019-11-05 23:24:29,547 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	... 92 more
om_1        | 2019-11-05 23:24:29,547 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:24:29,551 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:30,520 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:24:30,521 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:24:30,525 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:31,886 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105T231515Z
om_1        | 2019-11-05 23:24:31,886 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:24:31,888 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 05e1b6224fd93840c2c54faecd055ecd22f57db6cf8f2c825350dbb48aa28ae1, signature=0dd02c7723062e46b4450c17cde01b2d3a8096927a7338b9763f64b9829c1d4a, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:24:32,744 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
om_1        | 2019-11-05 23:24:32,745 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
om_1        | 2019-11-05 23:24:32,754 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:38,965 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
om_1        | 2019-11-05 23:24:38,989 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
om_1        | 2019-11-05 23:24:44,088 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:24:44,090 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-11-05 23:24:44,102 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:46,103 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
om_1        | 2019-11-05 23:24:46,105 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-11-05 23:24:46,110 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
om_1        | 2019-11-05 23:24:46,998 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-11-05 23:24:46,999 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:24:47,022 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:50,018 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:24:50,019 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-11-05 23:24:50,026 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-11-05 23:24:51,926 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:24:51,927 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:24:51,934 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:52,840 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:24:52,844 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:24:52,852 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:24:57,797 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:24:57,811 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:25:02,636 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:25:02,637 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:25:02,639 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:25:04,115 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:25:04,117 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:25:04,133 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:25:05,309 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:25:05,310 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:25:05,319 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
om_1        | 2019-11-05 23:25:10,515 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:25:10,538 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-11-05 23:25:14,770 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-11-05 23:25:14,770 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:25:14,773 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-11-05 23:25:15,727 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	... 101 more
om_1        | 2019-11-05 23:25:15,728 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-11-05 23:15:19,289 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:25:15,733 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:25:16,731 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:25:16,732 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:25:16,746 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:19,299 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:19,299 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:25:18,129 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:25:18,132 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:25:18,145 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:25:18,820 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:25:18,821 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:25:18,823 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:19,312 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:25:20,197 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:25:20,199 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-11-05 23:15:19,312 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:25:20,208 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:25:21,340 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:25:21,443 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:25:21,455 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
om_1        | 2019-11-05 23:25:23,247 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 2019-11-05 23:15:19,330 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:25:23,249 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:25:23,253 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:25:31,565 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:25:31,616 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-11-05 23:15:19,334 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:25:36,442 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:25:36,446 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:25:36,462 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:19,352 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:25:37,151 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:25:37,151 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:25:37,160 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:19,352 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:25:42,844 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:25:42,858 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
om_1        | 2019-11-05 23:25:48,204 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 2019-11-05 23:15:19,369 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:25:48,205 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:25:48,252 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:25:53,007 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:25:53,055 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:25:57,770 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:25:57,771 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:25:57,773 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:03,158 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:26:03,178 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:07,948 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:26:07,954 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:26:07,977 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:08,992 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 2019-11-05 23:15:19,370 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:26:08,996 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:09,006 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:10,638 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
om_1        | 2019-11-05 23:26:10,639 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 2019-11-05 23:15:19,386 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:19,388 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:26:10,642 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:11,514 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:11,515 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:19,396 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:11,519 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:26:12,500 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:26:12,503 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:26:12,512 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:18,639 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2019-11-05 23:15:19,396 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:26:18,651 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:23,299 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:23,300 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
om_1        | 2019-11-05 23:26:23,305 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-11-05 23:15:19,402 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:26:24,256 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:24,257 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:19,402 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:26:24,267 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:25,185 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:25,187 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:19,416 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:25,193 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:28,871 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:26:28,885 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:33,635 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:26:33,635 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:26:33,640 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:19,416 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:35,339 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:35,342 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:19,429 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:35,349 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:37,005 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
om_1        | 2019-11-05 23:26:37,005 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:26:37,031 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:37,862 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 2019-11-05 23:15:19,430 [qtp262445056-27] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
om_1        | 2019-11-05 23:26:37,862 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:26:37,871 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:38,788 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:26:38,788 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:26:38,793 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2019-11-05 23:15:19,451 [qtp262445056-27] ERROR      - Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 2019-11-05 23:26:43,840 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 20191105T231519Z
om_1        | 2019-11-05 23:26:43,860 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 20191105/us-west-1/s3/aws4_request
om_1        | 2019-11-05 23:26:48,193 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:26:48,194 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:26:48,199 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:49,284 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:26:49,285 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:26:49,297 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:26:50,212 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
om_1        | 2019-11-05 23:26:50,214 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-11-05 23:26:50,232 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-11-05 23:26:51,115 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
om_1        | 2019-11-05 23:26:51,115 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
om_1        | 2019-11-05 23:26:51,121 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
om_1        | 2019-11-05 23:26:52,139 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
om_1        | 2019-11-05 23:26:52,139 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
om_1        | 2019-11-05 23:26:52,141 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2019-11-05 23:26:58,683 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:26:58,706 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:03,624 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:03,625 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:03,636 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2019-11-05 23:27:08,809 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-11-05 23:27:08,824 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
om_1        | 2019-11-05 23:27:14,540 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
om_1        | 2019-11-05 23:27:14,540 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
om_1        | 2019-11-05 23:27:14,546 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
om_1        | 2019-11-05 23:27:15,401 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
om_1        | 2019-11-05 23:27:15,402 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:15,409 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:16,576 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2019-11-05 23:27:16,579 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:16,603 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:17,655 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:17,656 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:17,663 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:18,786 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:18,786 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:18,789 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:19,563 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:19,563 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:19,565 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:21,073 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:21,074 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:21,085 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:25,527 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:27:25,563 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:30,099 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:30,100 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
om_1        | 2019-11-05 23:27:30,111 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
om_1        | 2019-11-05 23:27:31,109 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
om_1        | 2019-11-05 23:27:31,109 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:31,114 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:32,401 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:32,401 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:32,435 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:33,418 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:33,418 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:33,427 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-11-05 23:27:34,462 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
om_1        | 2019-11-05 23:27:34,463 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
om_1        | 2019-11-05 23:27:34,465 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:39,700 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
om_1        | 2019-11-05 23:27:39,711 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:51,944 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:27:51,945 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:27:51,950 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:27:56,266 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:27:56,282 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:28:00,896 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:28:00,897 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:28:00,911 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
om_1        | 2019-11-05 23:28:01,965 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:28:01,970 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:28:01,978 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
om_1        | 2019-11-05 23:28:02,975 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2019-11-05 23:28:02,977 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
om_1        | 2019-11-05 23:28:02,988 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
om_1        | 2019-11-05 23:28:09,188 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:28:09,210 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:28:14,260 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:28:14,262 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
om_1        | 2019-11-05 23:28:14,276 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
om_1        | 2019-11-05 23:28:19,650 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 2019-11-05 23:28:19,662 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
om_1        | 2019-11-05 23:28:30,746 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
om_1        | 2019-11-05 23:28:30,746 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
om_1        | 2019-11-05 23:28:30,757 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2019-11-05 23:28:36,086 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 2019-11-05 23:28:36,104 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2019-11-05 23:28:40,078 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 2019-11-05 23:28:40,080 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 2019-11-05 23:28:40,092 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2019-11-05 23:28:44,257 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2019-11-05 23:28:44,279 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 2019-11-05 23:28:48,566 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 2019-11-05 23:28:48,566 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 2019-11-05 23:28:48,578 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
om_1        | 2019-11-05 23:28:49,660 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:28:49,660 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
om_1        | 2019-11-05 23:28:49,665 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
om_1        | 2019-11-05 23:28:53,912 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:28:53,928 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
om_1        | 2019-11-05 23:29:01,073 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:29:01,074 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:29:01,084 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:29:02,516 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:29:02,517 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:29:02,529 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:29:06,739 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:29:06,759 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:29:11,263 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:29:11,267 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:29:11,278 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:29:12,464 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:29:12,464 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:29:12,468 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:29:17,676 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:29:17,698 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Nov 05, 2019 11:15:19 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
om_1        | 2019-11-05 23:29:22,833 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
om_1        | 2019-11-05 23:29:22,834 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
om_1        | 2019-11-05 23:29:22,845 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 2019-11-05 23:29:24,641 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 2019-11-05 23:29:24,642 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:29:24,657 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:29:25,682 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
om_1        | 2019-11-05 23:29:25,683 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2019-11-05 23:29:25,695 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2019-11-05 23:29:30,778 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2019-11-05 23:29:30,801 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 2019-11-05 23:29:37,776 [Socket Reader #1 for port 9862] INFO       - 42e949483bc3d41be59ac2b60762cca4820b35e3fb31d571aadb6f658e721d8b
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | 2019-11-05 23:29:37,777 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
om_1        | 2019-11-05 23:29:37,787 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2019-11-05 23:29:42,858 INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2019-11-05 23:29:42,870 INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2019-11-05 23:15:19,459 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-11-05 23:15:19,463 WARN server.HttpChannel: //s3g:9878/bucket-test123
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231519Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 106c940d797dbfba0f9a3c56bcd662d1d9ac495f4bb8eaee3ae73d2f738ecd42, signature=493cc341463b57f94fba763ec1f9c7f6108c2f452e24e50b03e3df75688f144e, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-11-05 23:15:22,598 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,615 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,616 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,635 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,636 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,654 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,656 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,677 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,677 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,695 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,695 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 5 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,709 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,711 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 6 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,721 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,722 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 7 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,730 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,730 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 8 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,736 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,736 INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf, while invoking $Proxy83.submitRequest over nodeId=null,nodeAddress=om:9862 after 9 failover attempts. Trying to failover immediately.
s3g_1       | 2019-11-05 23:15:22,743 [qtp262445056-28] ERROR      - Failed to connect to OM. Attempted 10 retries and 10 failovers
s3g_1       | 2019-11-05 23:15:22,743 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 2019-11-05 23:15:22,744 [qtp262445056-28] ERROR      - Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Nov 05, 2019 11:15:22 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2019-11-05 23:15:22,752 WARN servlet.ServletHandler: 
s3g_1       | javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-11-05 23:15:22,754 WARN server.HttpChannel: //s3g:9878/bucket-test123
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:139)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	... 13 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 33 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 60 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:263)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 92 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20191105T231522Z
s3g_1       | 20191105/us-west-1/s3/aws4_request
s3g_1       | 5c8f6d65bf24b6793dbd80c68ec40aaa6dab3580f731de58c7635e8b52fd99b7, signature=7026c6cdeaa8963821755c66bf501854b9d057ef30719799be54b47704a37f2c, awsAccessKeyId=dlfknslnfslf
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy83.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.getServiceInfo(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
s3g_1       | 	... 101 more
s3g_1       | 2019-11-05 23:21:23,276 [qtp262445056-29] INFO       - Location is /bucket-11072
s3g_1       | 2019-11-05 23:21:29,432 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2019-11-05 23:21:29,487 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2019-11-05 23:21:29,487 INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2019-11-05 23:21:29,489 WARN impl.MetricsSystemImpl: Sink prometheus already exists!
s3g_1       | 2019-11-05 23:21:40,727 [qtp262445056-28] INFO       - Location is /bucket-24796
s3g_1       | 2019-11-05 23:21:41,422 [qtp262445056-29] INFO       - Location is /bucket-24796
s3g_1       | 2019-11-05 23:21:50,838 [qtp262445056-28] INFO       - Location is /bucket-18373
s3g_1       | 2019-11-05 23:21:52,666 [qtp262445056-28] ERROR      - Exception occurred in headBucket
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:103)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:81)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:250)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-11-05 23:22:03,160 [qtp262445056-119] INFO       - Location is /bucket-09541
s3g_1       | 2019-11-05 23:22:14,203 [qtp262445056-187] INFO       - Location is /bucket-01639
s3g_1       | 2019-11-05 23:22:17,180 [qtp262445056-183] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:22:18,968 [qtp262445056-119] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:22:30,043 [qtp262445056-119] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:22:31,577 [qtp262445056-28] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:22:47,075 [qtp262445056-236] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:22:48,528 [qtp262445056-187] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:22:50,118 [qtp262445056-187] ERROR      - Error in Complete Multipart Upload Request for bucket: bucket-01639, key: multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-01639key: multipartKey2
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1104)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.completeMultipartUpload(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:883)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:445)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:498)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-11-05 23:23:01,196 [qtp262445056-28] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:23:02,530 [qtp262445056-183] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:23:07,525 [qtp262445056-236] ERROR      - Error in Complete Multipart Upload Request for bucket: bucket-01639, key: multipartKey3
s3g_1       | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s32724f42bcd3225359401cb62da89c51dbucket: bucket-01639key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1104)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
s3g_1       | 	at com.sun.proxy.$Proxy84.completeMultipartUpload(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:883)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:445)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:498)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2019-11-05 23:23:52,556 [qtp262445056-183] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:23:53,806 [qtp262445056-236] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:24:07,544 [qtp262445056-119] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:24:07,603 [qtp262445056-187] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:24:07,607 [qtp262445056-183] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | Nov 05, 2019 11:24:27 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=57, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:24:27 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=53, target=172.18.0.3:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:24:27 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=49, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2019-11-05 23:24:30,693 [qtp262445056-252] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:24:47,884 [qtp262445056-187] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:24:50,772 [qtp262445056-119] INFO       - Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
s3g_1       | 2019-11-05 23:25:14,927 [qtp262445056-317] INFO       - Location is /bucket-46974
s3g_1       | 2019-11-05 23:25:15,762 [qtp262445056-317] INFO       - Location is /destbucket-87487
s3g_1       | 2019-11-05 23:26:08,069 [qtp262445056-183] INFO       - Location is /bucket-02226
s3g_1       | 2019-11-05 23:27:14,596 [qtp262445056-119] INFO       - Location is /bucket-74036
s3g_1       | 2019-11-05 23:27:30,181 [qtp262445056-187] INFO       - Location is /bucket-08271
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=221, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=353, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=369, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=257, target=172.18.0.3:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=285, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:711)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:163)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=193, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=377, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=181, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:563)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=237, target=172.18.0.3:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=213, target=172.18.0.3:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=273, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:711)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:163)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=217, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=361, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=253, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=201, target=172.18.0.3:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=365, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=373, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=177, target=172.18.0.3:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:563)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=357, target=172.18.0.3:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=381, target=172.18.0.3:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.s3.io.S3WrapperInputStream.read(S3WrapperInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$1(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=197, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=233, target=172.18.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=241, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at org.apache.commons.io.IOUtils.skip(IOUtils.java:2680)
s3g_1       | 	at org.apache.commons.io.IOUtils.skipFully(IOUtils.java:2787)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2209)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:558)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:135)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Nov 05, 2019 11:28:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=261, target=172.18.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:183)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:434)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:295)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:242)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:252)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2019-11-05 23:29:38,065 [qtp262445056-119] INFO       - Location is /bucket-68123
s3g_1       | 2019-11-05 23:29:46,444 [qtp262445056-187] ERROR      - Error: 
s3g_1       | java.lang.NullPointerException
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:78)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:71)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:840)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1780)
s3g_1       | 	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1609)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1767)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:539)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
s3g_1       | 	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
