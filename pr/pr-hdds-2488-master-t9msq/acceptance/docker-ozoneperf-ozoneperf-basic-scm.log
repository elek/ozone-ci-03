Attaching to ozoneperf_jaeger_1, ozoneperf_scm_1, ozoneperf_prometheus_1, ozoneperf_datanode_2, ozoneperf_datanode_3, ozoneperf_s3g_1, ozoneperf_om_1, ozoneperf_datanode_1, ozoneperf_grafana_1
jaeger_1      | 2019/11/15 20:36:06 maxprocs: Leaving GOMAXPROCS=32: CPU quota undefined
jaeger_1      | {"level":"info","ts":1573850166.6100018,"caller":"flags/service.go:115","msg":"Mounting metrics handler on admin server","route":"/metrics"}
jaeger_1      | {"level":"info","ts":1573850166.6103277,"caller":"flags/admin.go:108","msg":"Mounting health check on admin server","route":"/"}
jaeger_1      | {"level":"info","ts":1573850166.6104228,"caller":"flags/admin.go:114","msg":"Starting admin HTTP server","http-port":14269}
jaeger_1      | {"level":"info","ts":1573850166.6104443,"caller":"flags/admin.go:100","msg":"Admin server started","http-port":14269,"health-status":"unavailable"}
jaeger_1      | {"level":"info","ts":1573850166.6232502,"caller":"memory/factory.go:56","msg":"Memory storage initialized","configuration":{"MaxTraces":0}}
jaeger_1      | {"level":"info","ts":1573850166.636068,"caller":"all-in-one/main.go:242","msg":"Starting jaeger-collector TChannel server","port":14267}
jaeger_1      | {"level":"info","ts":1573850166.6364145,"caller":"grpcserver/grpc_server.go:64","msg":"Starting jaeger-collector gRPC server","grpc-port":"14250"}
jaeger_1      | {"level":"info","ts":1573850166.6365418,"caller":"all-in-one/main.go:260","msg":"Starting jaeger-collector HTTP server","http-port":14268}
prometheus_1  | level=info ts=2019-11-15T20:36:05.865Z caller=main.go:296 msg="no time or size retention was set so using the default time retention" duration=15d
jaeger_1      | {"level":"info","ts":1573850166.6365702,"caller":"grpc/builder.go:65","msg":"Agent requested insecure grpc connection to collector(s)"}
prometheus_1  | level=info ts=2019-11-15T20:36:05.865Z caller=main.go:332 msg="Starting Prometheus" version="(version=2.14.0, branch=HEAD, revision=edeb7a44cbf745f1d8be4ea6f215e79e651bfe19)"
scm_1         | 2019-11-15 20:36:07,834 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
jaeger_1      | {"level":"info","ts":1573850166.6383188,"caller":"all-in-one/main.go:199","msg":"Starting agent"}
datanode_2    | 2019-11-15 20:36:06,612 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
om_1          | 2019-11-15 20:36:05,789 INFO om.OzoneManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
jaeger_1      | {"level":"info","ts":1573850166.6385133,"caller":"querysvc/query_service.go:130","msg":"Archive storage not created","reason":"archive storage not supported"}
prometheus_1  | level=info ts=2019-11-15T20:36:05.865Z caller=main.go:333 build_context="(go=go1.13.4, user=root@df2327081015, date=20191111-14:27:12)"
datanode_2    | /************************************************************
om_1          | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
jaeger_1      | {"level":"info","ts":1573850166.638578,"caller":"all-in-one/main.go:342","msg":"Archive storage not initialized"}
prometheus_1  | level=info ts=2019-11-15T20:36:05.865Z caller=main.go:334 host_details="(Linux 3.10.0-957.12.2.el7.x86_64 #1 SMP Tue May 14 21:24:32 UTC 2019 x86_64 3d82b42159b4 (none))"
om_1          | STARTUP_MSG: Starting OzoneManager
scm_1         | STARTUP_MSG:   host = 72f2f0c6d8b9/172.19.0.9
jaeger_1      | {"level":"info","ts":1573850166.638524,"caller":"app/agent.go:69","msg":"Starting jaeger-agent HTTP server","http-port":5778}
prometheus_1  | level=info ts=2019-11-15T20:36:05.865Z caller=main.go:335 fd_limits="(soft=1048576, hard=1048576)"
om_1          | STARTUP_MSG:   host = 176b3ba12c61/172.19.0.3
datanode_2    | STARTUP_MSG: Starting HddsDatanodeService
scm_1         | STARTUP_MSG:   args = [--init]
jaeger_1      | {"level":"info","ts":1573850166.640086,"caller":"healthcheck/handler.go:128","msg":"Health Check state change","status":"ready"}
datanode_3    | 2019-11-15 20:36:06,688 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
s3g_1         | 2019-11-15 20:36:06,423 INFO hdfs.DFSUtil: Starting Web-server for s3gateway at: http://0.0.0.0:9878
prometheus_1  | level=info ts=2019-11-15T20:36:05.865Z caller=main.go:336 vm_limits="(soft=unlimited, hard=unlimited)"
om_1          | STARTUP_MSG:   args = [--init]
datanode_1    | 2019-11-15 20:36:06,015 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2    | STARTUP_MSG:   host = b2c85e27534f/172.19.0.7
scm_1         | STARTUP_MSG:   version = 3.2.0
jaeger_1      | {"level":"info","ts":1573850166.6401072,"caller":"app/server.go:112","msg":"Starting HTTP server","port":16686}
datanode_3    | /************************************************************
s3g_1         | 2019-11-15 20:36:06,458 INFO util.log: Logging initialized @1111ms
prometheus_1  | level=info ts=2019-11-15T20:36:05.867Z caller=main.go:657 msg="Starting TSDB ..."
datanode_1    | /************************************************************
om_1          | STARTUP_MSG:   version = 3.2.0
datanode_2    | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
datanode_3    | STARTUP_MSG: Starting HddsDatanodeService
jaeger_1      | {"level":"info","ts":1573850166.6401327,"caller":"app/server.go:125","msg":"Starting GRPC server","port":16686}
s3g_1         | 2019-11-15 20:36:06,601 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
prometheus_1  | level=info ts=2019-11-15T20:36:05.868Z caller=web.go:496 component=web msg="Start listening for connections" address=0.0.0.0:9090
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
datanode_1    | STARTUP_MSG: Starting HddsDatanodeService
datanode_2    | STARTUP_MSG:   version = 3.2.0
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3    | STARTUP_MSG:   host = 79a9423c1b6d/172.19.0.6
jaeger_1      | {"level":"info","ts":1573850166.6401546,"caller":"app/server.go:135","msg":"Starting CMUX server","port":16686}
s3g_1         | 2019-11-15 20:36:06,628 INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
prometheus_1  | level=info ts=2019-11-15T20:36:05.871Z caller=head.go:535 component=tsdb msg="replaying WAL, this may take awhile"
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Starting Grafana" logger=server version=6.4.4 commit=092e514 branch=HEAD compiled=2019-11-06T12:04:33+0000
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1    | STARTUP_MSG:   host = ca8a888e1739/172.19.0.4
datanode_2    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_3    | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   java = 11.0.3
jaeger_1      | {"level":"info","ts":1573850166.676917,"caller":"all-in-one/main.go:298","msg":"Listening for Zipkin HTTP traffic","zipkin.http-port":9411}
s3g_1         | 2019-11-15 20:36:06,640 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
prometheus_1  | level=info ts=2019-11-15T20:36:05.871Z caller=head.go:583 component=tsdb msg="WAL segment loaded" segment=0 maxSegment=0
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config loaded from" logger=settings file=/usr/share/grafana/conf/defaults.ini
om_1          | STARTUP_MSG:   java = 11.0.3
datanode_1    | STARTUP_MSG:   args = []
datanode_2    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3    | STARTUP_MSG:   version = 3.2.0
scm_1         | ************************************************************/
s3g_1         | 2019-11-15 20:36:06,643 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
prometheus_1  | level=info ts=2019-11-15T20:36:05.873Z caller=main.go:672 fs_type=EXT4_SUPER_MAGIC
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config loaded from" logger=settings file=/etc/grafana/grafana.ini
datanode_1    | STARTUP_MSG:   version = 3.2.0
om_1          | ************************************************************/
datanode_2    | STARTUP_MSG:   java = 11.0.3
datanode_3    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
scm_1         | 2019-11-15 20:36:07,843 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1         | 2019-11-15 20:36:06,643 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
prometheus_1  | level=info ts=2019-11-15T20:36:05.873Z caller=main.go:673 msg="TSDB started"
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.data=/var/lib/grafana"
datanode_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_2    | ************************************************************/
datanode_3    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1          | 2019-11-15 20:36:05,796 INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2019-11-15 20:36:07,897 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1         | 2019-11-15 20:36:06,643 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
prometheus_1  | level=info ts=2019-11-15T20:36:05.873Z caller=main.go:743 msg="Loading configuration file" filename=/etc/prometheus.yml
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.logs=/var/log/grafana"
datanode_1    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2    | 2019-11-15 20:36:06,621 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3    | STARTUP_MSG:   java = 11.0.3
om_1          | 2019-11-15 20:36:06,816 INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.19.0.3:9862
prometheus_1  | level=info ts=2019-11-15T20:36:05.875Z caller=main.go:771 msg="Completed loading of configuration file" filename=/etc/prometheus.yml
s3g_1         | 2019-11-15 20:36:06,665 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1    | STARTUP_MSG:   java = 11.0.3
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.plugins=/var/lib/grafana/plugins"
scm_1         | SCM initialization succeeded.Current cluster id for sd=/data/metadata/scm;cid=CID-c1abafb3-baeb-4b82-956e-8a557535fc40
datanode_3    | ************************************************************/
om_1          | 2019-11-15 20:36:06,817 INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
prometheus_1  | level=info ts=2019-11-15T20:36:05.875Z caller=main.go:626 msg="Server is ready to receive web requests."
datanode_2    | 2019-11-15 20:36:06,934 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1         | 2019-11-15 20:36:06,666 INFO s3.Gateway: Starting Ozone S3 gateway
datanode_1    | ************************************************************/
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.provisioning=/etc/grafana/provisioning"
datanode_3    | 2019-11-15 20:36:06,694 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2019-11-15 20:36:06,823 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1         | 2019-11-15 20:36:06,675 INFO http.HttpServer2: Jetty bound to port 9878
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.log.mode=console"
datanode_3    | 2019-11-15 20:36:07,051 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1    | 2019-11-15 20:36:06,023 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2019-11-15 20:36:08,066 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1         | 2019-11-15 20:36:06,677 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
scm_1         | 2019-11-15 20:36:07,966 INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_2    | 2019-11-15 20:36:07,143 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_DATA=/var/lib/grafana"
om_1          | 2019-11-15 20:36:09,067 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-15 20:36:07,275 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1         | 2019-11-15 20:36:06,724 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b919693{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2    | 2019-11-15 20:36:07,143 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
scm_1         | /************************************************************
datanode_1    | 2019-11-15 20:36:06,381 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_LOGS=/var/log/grafana"
datanode_3    | 2019-11-15 20:36:07,275 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
om_1          | 2019-11-15 20:36:10,068 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1         | 2019-11-15 20:36:06,726 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6933b6c6{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2    | 2019-11-15 20:36:07,295 INFO ozone.HddsDatanodeService: HddsDatanodeService host:b2c85e27534f ip:172.19.0.7
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at 72f2f0c6d8b9/172.19.0.9
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_PLUGINS=/var/lib/grafana/plugins"
datanode_1    | 2019-11-15 20:36:06,601 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3    | 2019-11-15 20:36:07,489 INFO ozone.HddsDatanodeService: HddsDatanodeService host:79a9423c1b6d ip:172.19.0.6
om_1          | 2019-11-15 20:36:11,069 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1         | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
scm_1         | ************************************************************/
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_PROVISIONING=/etc/grafana/provisioning"
datanode_1    | 2019-11-15 20:36:06,602 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3    | 2019-11-15 20:36:07,538 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
om_1          | 2019-11-15 20:36:12,072 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1         | WARNING: An illegal reflective access operation has occurred
datanode_2    | 2019-11-15 20:36:07,368 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
scm_1         | 2019-11-15 20:36:09,326 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Path Home" logger=settings path=/usr/share/grafana
datanode_1    | 2019-11-15 20:36:06,777 INFO ozone.HddsDatanodeService: HddsDatanodeService host:ca8a888e1739 ip:172.19.0.4
om_1          | 2019-11-15 20:36:13,073 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1         | WARNING: Illegal reflective access by org.jboss.classfilewriter.ClassFile$1 (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
datanode_3    | 2019-11-15 20:36:07,543 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2    | 2019-11-15 20:36:07,369 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
scm_1         | /************************************************************
datanode_1    | 2019-11-15 20:36:06,837 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Path Data" logger=settings path=/var/lib/grafana
om_1          | 2019-11-15 20:36:14,074 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1         | WARNING: Please consider reporting this to the maintainers of org.jboss.classfilewriter.ClassFile$1
datanode_2    | 2019-11-15 20:36:07,377 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
scm_1         | STARTUP_MSG: Starting StorageContainerManager
datanode_1    | 2019-11-15 20:36:06,838 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3    | 2019-11-15 20:36:07,550 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Path Logs" logger=settings path=/var/log/grafana
om_1          | 2019-11-15 20:36:15,075 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:07,401 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
s3g_1         | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
scm_1         | STARTUP_MSG:   host = 72f2f0c6d8b9/172.19.0.9
datanode_1    | 2019-11-15 20:36:06,846 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3    | 2019-11-15 20:36:07,576 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Path Plugins" logger=settings path=/var/lib/grafana/plugins
om_1          | 2019-11-15 20:36:16,077 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:08,459 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
s3g_1         | WARNING: All illegal access operations will be denied in a future release
scm_1         | STARTUP_MSG:   args = []
datanode_1    | 2019-11-15 20:36:06,870 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3    | 2019-11-15 20:36:08,588 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Path Provisioning" logger=settings path=/etc/grafana/provisioning
om_1          | 2019-11-15 20:36:17,079 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:08,486 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
s3g_1         | Nov 15, 2019 8:36:09 PM org.glassfish.jersey.internal.Errors logErrors
scm_1         | STARTUP_MSG:   version = 3.2.0
datanode_1    | 2019-11-15 20:36:08,026 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3    | 2019-11-15 20:36:08,621 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="App mode production" logger=settings
om_1          | 2019-11-15 20:36:17,082 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
datanode_2    | 2019-11-15 20:36:08,644 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
s3g_1         | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
datanode_1    | 2019-11-15 20:36:08,081 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3    | 2019-11-15 20:36:08,840 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Initializing SqlStore" logger=server
om_1          | 2019-11-15 20:36:23,085 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:08,658 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
s3g_1         | 
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1    | 2019-11-15 20:36:08,296 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_3    | 2019-11-15 20:36:08,841 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Connecting to DB" logger=sqlstore dbtype=sqlite3
om_1          | 2019-11-15 20:36:24,086 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:08,659 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1         | 2019-11-15 20:36:09,795 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6f25bf88{/,file:///tmp/jetty-0.0.0.0-9878-s3gateway-_-any-6600327143038184146.dir/webapp/,AVAILABLE}{/s3gateway}
datanode_1    | 2019-11-15 20:36:08,297 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_3    | 2019-11-15 20:36:08,843 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1          | 2019-11-15 20:36:25,087 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Starting DB migration" logger=migrator
scm_1         | STARTUP_MSG:   java = 11.0.3
datanode_2    | 2019-11-15 20:36:08,660 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
s3g_1         | 2019-11-15 20:36:09,802 INFO server.AbstractConnector: Started ServerConnector@36bed37a{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
datanode_1    | 2019-11-15 20:36:08,320 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3    | 2019-11-15 20:36:08,844 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1          | 2019-11-15 20:36:26,088 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Executing migration" logger=migrator id="create migration_log table"
scm_1         | ************************************************************/
datanode_2    | 2019-11-15 20:36:08,661 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
s3g_1         | 2019-11-15 20:36:09,802 INFO server.Server: Started @4457ms
datanode_1    | 2019-11-15 20:36:08,321 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1          | 2019-11-15 20:36:27,090 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-15 20:36:08,845 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Executing migration" logger=migrator id="create user table"
datanode_2    | 2019-11-15 20:36:08,809 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
s3g_1         | 2019-11-15 20:36:09,805 INFO server.BaseHttpServer: HTTP server of S3GATEWAY is listening at http://0.0.0.0:9878
datanode_1    | 2019-11-15 20:36:08,322 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om_1          | 2019-11-15 20:36:28,093 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:09,337 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user.login"
datanode_3    | 2019-11-15 20:36:09,010 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2    | 2019-11-15 20:36:08,962 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1    | 2019-11-15 20:36:08,487 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1          | 2019-11-15 20:36:29,094 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user.email"
datanode_3    | 2019-11-15 20:36:09,199 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1         | 2019-11-15 20:36:09,422 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2    | 2019-11-15 20:36:08,989 INFO util.log: Logging initialized @3353ms
datanode_1    | 2019-11-15 20:36:08,680 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
om_1          | 2019-11-15 20:36:30,096 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:04+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_user_login - v1"
datanode_3    | 2019-11-15 20:36:09,226 INFO util.log: Logging initialized @3523ms
scm_1         | 2019-11-15 20:36:09,433 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2    | 2019-11-15 20:36:09,111 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1    | 2019-11-15 20:36:08,705 INFO util.log: Logging initialized @3448ms
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_user_email - v1"
om_1          | 2019-11-15 20:36:31,097 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-15 20:36:09,341 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2019-11-15 20:36:09,465 INFO util.log: Logging initialized @1244ms
datanode_2    | 2019-11-15 20:36:09,115 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1    | 2019-11-15 20:36:08,812 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2019-11-15 20:36:32,098 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table user to user_v1 - v1"
scm_1         | 2019-11-15 20:36:09,573 INFO db.DBStoreBuilder: using custom profile for table: deletedBlocks
datanode_1    | 2019-11-15 20:36:08,816 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2    | 2019-11-15 20:36:09,125 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3    | 2019-11-15 20:36:09,345 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
om_1          | 2019-11-15 20:36:32,100 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create user table v2"
scm_1         | 2019-11-15 20:36:09,573 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedBlocks
datanode_1    | 2019-11-15 20:36:08,831 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3    | 2019-11-15 20:36:09,357 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_2    | 2019-11-15 20:36:09,128 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_user_login - v2"
om_1          | 2019-11-15 20:36:38,104 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-15 20:36:08,837 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2    | 2019-11-15 20:36:09,128 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_user_email - v2"
om_1          | 2019-11-15 20:36:39,105 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:09,573 INFO db.DBStoreBuilder: using custom profile for table: validCerts
datanode_3    | 2019-11-15 20:36:09,359 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1    | 2019-11-15 20:36:08,837 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2    | 2019-11-15 20:36:09,128 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="copy data_source v1 to v2"
om_1          | 2019-11-15 20:36:40,106 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:09,573 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:validCerts
datanode_3    | 2019-11-15 20:36:09,359 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2    | 2019-11-15 20:36:09,156 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1    | 2019-11-15 20:36:08,837 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table user_v1"
om_1          | 2019-11-15 20:36:41,107 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:09,574 INFO db.DBStoreBuilder: using custom profile for table: revokedCerts
datanode_3    | 2019-11-15 20:36:09,359 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2    | 2019-11-15 20:36:09,167 INFO http.HttpServer2: Jetty bound to port 9882
datanode_1    | 2019-11-15 20:36:08,871 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add column help_flags1 to user table"
om_1          | 2019-11-15 20:36:42,108 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:09,574 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:revokedCerts
datanode_3    | 2019-11-15 20:36:09,380 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2    | 2019-11-15 20:36:09,169 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_1    | 2019-11-15 20:36:08,885 INFO http.HttpServer2: Jetty bound to port 9882
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="Update user table charset"
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-c1abafb3-baeb-4b82-956e-8a557535fc40
datanode_3    | 2019-11-15 20:36:09,389 INFO http.HttpServer2: Jetty bound to port 9882
scm_1         | 2019-11-15 20:36:09,583 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_2    | 2019-11-15 20:36:09,203 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10a0fe30{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1    | 2019-11-15 20:36:08,887 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add last_seen_at column to user"
om_1          | 2019-11-15 20:36:42,275 INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
datanode_3    | 2019-11-15 20:36:09,390 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
scm_1         | 2019-11-15 20:36:09,583 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_2    | 2019-11-15 20:36:09,204 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6920614{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1    | 2019-11-15 20:36:08,938 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2127e66e{/logs,file:///var/log/hadoop/,AVAILABLE}
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add missing user data"
om_1          | /************************************************************
datanode_3    | 2019-11-15 20:36:09,418 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@262816a8{/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2019-11-15 20:36:09,584 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_2    | 2019-11-15 20:36:09,308 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3240b2a4{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-190384094593107591.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_1    | 2019-11-15 20:36:08,942 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@60f70249{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add is_disabled column to user"
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 176b3ba12c61/172.19.0.3
datanode_3    | 2019-11-15 20:36:09,419 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@433348bc{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2019-11-15 20:36:40,251 INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@651aed93
datanode_2    | 2019-11-15 20:36:09,319 INFO server.AbstractConnector: Started ServerConnector@110ff81{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1    | 2019-11-15 20:36:09,020 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2e645fbd{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-11208034403593454026.dir/webapp/,AVAILABLE}{/hddsDatanode}
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create temp user table v1-7"
om_1          | ************************************************************/
datanode_3    | 2019-11-15 20:36:09,500 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4adc663e{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-11569254543018405616.dir/webapp/,AVAILABLE}{/hddsDatanode}
scm_1         | 2019-11-15 20:36:40,252 INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_2    | 2019-11-15 20:36:09,319 INFO server.Server: Started @3683ms
datanode_1    | 2019-11-15 20:36:09,026 INFO server.AbstractConnector: Started ServerConnector@31ca9b6a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_email - v1-7"
om_1          | 2019-11-15 20:36:43,271 INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_3    | 2019-11-15 20:36:09,508 INFO server.AbstractConnector: Started ServerConnector@bfad7d8{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
scm_1         | 2019-11-15 20:36:40,333 INFO node.SCMNodeManager: Entering startup safe mode.
datanode_2    | 2019-11-15 20:36:09,324 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1    | 2019-11-15 20:36:09,029 INFO server.Server: Started @3772ms
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_org_id - v1-7"
om_1          | /************************************************************
datanode_3    | 2019-11-15 20:36:09,509 INFO server.Server: Started @3806ms
datanode_2    | 2019-11-15 20:36:09,324 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1    | 2019-11-15 20:36:09,034 INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2019-11-15 20:36:40,448 INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_code - v1-7"
om_1          | STARTUP_MSG: Starting OzoneManager
datanode_3    | 2019-11-15 20:36:09,513 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2    | 2019-11-15 20:36:09,327 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_1    | 2019-11-15 20:36:09,034 INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2019-11-15 20:36:40,460 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | STARTUP_MSG:   host = 176b3ba12c61/172.19.0.3
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_status - v1-7"
datanode_3    | 2019-11-15 20:36:09,513 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2    | 2019-11-15 20:36:09,342 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1    | 2019-11-15 20:36:09,036 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
scm_1         | 2019-11-15 20:36:40,652 INFO pipeline.SCMPipelineManager: No pipeline exists in current db
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="Update temp_user table charset"
om_1          | STARTUP_MSG:   args = []
datanode_3    | 2019-11-15 20:36:09,515 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_2    | 2019-11-15 20:36:09,495 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
scm_1         | 2019-11-15 20:36:40,655 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1    | 2019-11-15 20:36:09,050 INFO util.JvmPauseMonitor: Starting JVM pause monitor
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create star table"
om_1          | STARTUP_MSG:   version = 3.2.0
datanode_3    | 2019-11-15 20:36:09,530 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2    | 2019-11-15 20:36:12,413 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:40,883 INFO safemode.HealthyPipelineSafeModeRule:  Total pipeline count is 0, healthy pipeline threshold count is 1
datanode_1    | 2019-11-15 20:36:09,205 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index star.user_id_dashboard_id"
datanode_3    | 2019-11-15 20:36:09,669 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2    | 2019-11-15 20:36:13,415 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
scm_1         | 2019-11-15 20:36:40,885 INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
datanode_1    | 2019-11-15 20:36:12,127 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:05+0000 lvl=info msg="Executing migration" logger=migrator id="create org table v1"
datanode_3    | 2019-11-15 20:36:12,581 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:14,416 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1         | 2019-11-15 20:36:40,885 WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
datanode_1    | 2019-11-15 20:36:13,128 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_org_name - v1"
datanode_3    | 2019-11-15 20:36:13,582 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:15,417 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | STARTUP_MSG:   java = 11.0.3
scm_1         | 2019-11-15 20:36:41,428 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1    | 2019-11-15 20:36:14,129 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create org_user table v1"
datanode_3    | 2019-11-15 20:36:14,583 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:16,418 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | ************************************************************/
scm_1         | 2019-11-15 20:36:41,449 INFO ipc.Server: Starting Socket Reader #1 for port 9861
datanode_1    | 2019-11-15 20:36:15,130 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_org_user_org_id - v1"
datanode_3    | 2019-11-15 20:36:15,584 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:17,419 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:43,279 INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2019-11-15 20:36:41,480 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1    | 2019-11-15 20:36:16,131 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_org_user_org_id_user_id - v1"
datanode_3    | 2019-11-15 20:36:16,584 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:18,420 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,066 INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.19.0.3:9862
scm_1         | 2019-11-15 20:36:41,480 INFO ipc.Server: Starting Socket Reader #1 for port 9863
datanode_1    | 2019-11-15 20:36:17,132 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="Update org table charset"
datanode_3    | 2019-11-15 20:36:17,585 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:19,421 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,066 INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
scm_1         | 2019-11-15 20:36:41,492 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1    | 2019-11-15 20:36:18,133 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="Update org_user table charset"
datanode_3    | 2019-11-15 20:36:18,587 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:20,422 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,071 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2019-11-15 20:36:41,492 INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode_1    | 2019-11-15 20:36:19,136 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="Migrate all Read Only Viewers to Viewers"
datanode_3    | 2019-11-15 20:36:19,588 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:21,423 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,080 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2019-11-15 20:36:41,518 INFO hdfs.DFSUtil: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_1    | 2019-11-15 20:36:20,137 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard table"
datanode_3    | 2019-11-15 20:36:20,589 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:22,424 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,798 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2019-11-15 20:36:41,689 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1    | 2019-11-15 20:36:21,138 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard.account_id"
datanode_3    | 2019-11-15 20:36:21,590 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:23,425 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,824 INFO util.log: Logging initialized @2374ms
scm_1         | 2019-11-15 20:36:41,703 INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
datanode_1    | 2019-11-15 20:36:22,140 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_account_id_slug"
datanode_3    | 2019-11-15 20:36:22,591 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:24,426 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,985 INFO db.DBStoreBuilder: using custom profile for table: userTable
scm_1         | 2019-11-15 20:36:41,710 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1    | 2019-11-15 20:36:23,141 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_tag table"
datanode_3    | 2019-11-15 20:36:23,592 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:25,427 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,986 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:userTable
scm_1         | 2019-11-15 20:36:41,712 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
datanode_1    | 2019-11-15 20:36:24,142 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_tag.dasboard_id_term"
datanode_3    | 2019-11-15 20:36:24,593 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,986 INFO db.DBStoreBuilder: using custom profile for table: volumeTable
datanode_2    | 2019-11-15 20:36:26,428 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:41,712 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1    | 2019-11-15 20:36:25,143 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_dashboard_tag_dashboard_id_term - v1"
datanode_3    | 2019-11-15 20:36:25,594 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,986 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:volumeTable
datanode_2    | 2019-11-15 20:36:27,430 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:41,712 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table dashboard to dashboard_v1 - v1"
om_1          | 2019-11-15 20:36:44,986 INFO db.DBStoreBuilder: using custom profile for table: bucketTable
datanode_2    | 2019-11-15 20:36:28,430 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-15 20:36:26,595 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard v2"
om_1          | 2019-11-15 20:36:44,986 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:bucketTable
scm_1         | 2019-11-15 20:36:41,730 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2    | 2019-11-15 20:36:29,431 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_org_id - v2"
datanode_1    | 2019-11-15 20:36:26,145 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,987 INFO db.DBStoreBuilder: using custom profile for table: keyTable
datanode_3    | 2019-11-15 20:36:27,596 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:41,736 INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
datanode_2    | 2019-11-15 20:36:30,433 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_org_id_slug - v2"
datanode_1    | 2019-11-15 20:36:27,146 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,987 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:keyTable
datanode_3    | 2019-11-15 20:36:28,597 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:41,796 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2    | 2019-11-15 20:36:31,433 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="copy dashboard v1 to v2"
datanode_1    | 2019-11-15 20:36:28,147 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,987 INFO db.DBStoreBuilder: using custom profile for table: deletedTable
datanode_3    | 2019-11-15 20:36:29,598 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:41,829 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2    | 2019-11-15 20:36:32,434 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="drop table dashboard_v1"
datanode_1    | 2019-11-15 20:36:29,148 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,987 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedTable
datanode_3    | 2019-11-15 20:36:30,599 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-15 20:36:41,830 INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
datanode_2    | 2019-11-15 20:36:33,435 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-15 20:36:30,149 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard.data to mediumtext v1"
datanode_3    | 2019-11-15 20:36:31,600 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,987 INFO db.DBStoreBuilder: using custom profile for table: openKeyTable
scm_1         | 2019-11-15 20:36:42,020 INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
datanode_2    | 2019-11-15 20:36:34,437 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-15 20:36:31,150 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="Add column updated_by in dashboard - v2"
datanode_3    | 2019-11-15 20:36:32,601 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,987 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:openKeyTable
scm_1         | 2019-11-15 20:36:42,021 INFO ipc.Server: IPC Server Responder: starting
grafana_1     | t=2019-11-15T20:36:06+0000 lvl=info msg="Executing migration" logger=migrator id="Add column created_by in dashboard - v2"
datanode_2    | 2019-11-15 20:36:35,438 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-15 20:36:32,154 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,988 INFO db.DBStoreBuilder: using custom profile for table: s3Table
scm_1         | 2019-11-15 20:36:42,021 INFO ipc.Server: IPC Server listener on 9860: starting
datanode_3    | 2019-11-15 20:36:33,602 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column gnetId in dashboard"
datanode_2    | 2019-11-15 20:36:36,439 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-15 20:36:33,155 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,988 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3Table
scm_1         | 2019-11-15 20:36:42,024 INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_3    | 2019-11-15 20:36:34,603 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for gnetId in dashboard"
datanode_2    | 2019-11-15 20:36:37,440 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-15 20:36:34,156 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,988 INFO db.DBStoreBuilder: using custom profile for table: multipartInfoTable
scm_1         | 2019-11-15 20:36:42,024 INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
datanode_3    | 2019-11-15 20:36:35,605 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column plugin_id in dashboard"
datanode_2    | 2019-11-15 20:36:38,441 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-15 20:36:35,157 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,988 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:multipartInfoTable
scm_1         | 2019-11-15 20:36:42,025 INFO ipc.Server: IPC Server Responder: starting
datanode_3    | 2019-11-15 20:36:36,606 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for plugin_id in dashboard"
datanode_2    | 2019-11-15 20:36:39,443 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-15 20:36:36,158 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,988 INFO db.DBStoreBuilder: using custom profile for table: dTokenTable
scm_1         | 2019-11-15 20:36:42,027 INFO ipc.Server: IPC Server listener on 9863: starting
datanode_3    | 2019-11-15 20:36:37,607 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:40,444 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for dashboard_id in dashboard_tag"
datanode_1    | 2019-11-15 20:36:37,160 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,988 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:dTokenTable
scm_1         | 2019-11-15 20:36:42,029 INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
datanode_3    | 2019-11-15 20:36:38,608 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:41,445 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard table charset"
datanode_1    | 2019-11-15 20:36:38,163 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,989 INFO db.DBStoreBuilder: using custom profile for table: s3SecretTable
scm_1         | 2019-11-15 20:36:42,029 INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
datanode_3    | 2019-11-15 20:36:39,609 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:42,446 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 30 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard_tag table charset"
datanode_1    | 2019-11-15 20:36:39,164 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,989 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3SecretTable
scm_1         | 2019-11-15 20:36:42,030 INFO ipc.Server: IPC Server Responder: starting
datanode_3    | 2019-11-15 20:36:40,611 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:42,510 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column folder_id in dashboard"
datanode_1    | 2019-11-15 20:36:40,166 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,989 INFO db.DBStoreBuilder: using custom profile for table: prefixTable
scm_1         | 2019-11-15 20:36:42,030 INFO ipc.Server: IPC Server listener on 9861: starting
datanode_3    | 2019-11-15 20:36:41,612 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-15 20:36:42,511 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column isFolder in dashboard"
datanode_1    | 2019-11-15 20:36:41,167 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:44,989 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:prefixTable
scm_1         | 2019-11-15 20:36:42,036 INFO http.HttpServer2: Jetty bound to port 9876
datanode_3    | 2019-11-15 20:36:42,271 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column has_acl in dashboard"
datanode_2    | 2019-11-15 20:36:42,511 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 0da639d9-8110-428c-9b35-ccc8d6563a72 at port 9858
datanode_1    | 2019-11-15 20:36:42,169 INFO ipc.Client: Retrying connect to server: scm/172.19.0.9:9861. Already tried 30 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-15 20:36:45,000 INFO db.DBStoreBuilder: using custom profile for table: default
scm_1         | 2019-11-15 20:36:42,039 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3    | 2019-11-15 20:36:42,273 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column uid in dashboard"
datanode_2    | 2019-11-15 20:36:42,527 INFO impl.RaftServerProxy: 0da639d9-8110-428c-9b35-ccc8d6563a72: start RPC server
datanode_1    | 2019-11-15 20:36:42,270 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
om_1          | 2019-11-15 20:36:45,001 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_3    | 2019-11-15 20:36:42,273 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 00262ab3-1a02-4972-af0f-1fdc62478d5f at port 9858
scm_1         | 2019-11-15 20:36:42,072 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5da7cee2{/logs,file:///var/log/hadoop/,AVAILABLE}
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Update uid column values in dashboard"
datanode_2    | 2019-11-15 20:36:42,627 INFO server.GrpcService: 0da639d9-8110-428c-9b35-ccc8d6563a72: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1    | 2019-11-15 20:36:42,272 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
om_1          | 2019-11-15 20:36:45,002 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_3    | 2019-11-15 20:36:42,290 INFO impl.RaftServerProxy: 00262ab3-1a02-4972-af0f-1fdc62478d5f: start RPC server
scm_1         | 2019-11-15 20:36:42,073 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a9950f1{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index dashboard_org_id_uid"
datanode_2    | 2019-11-15 20:36:46,378 INFO impl.RaftServerProxy: 0da639d9-8110-428c-9b35-ccc8d6563a72: addNew group-F20F21FC5549:[0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858] returns group-F20F21FC5549:java.util.concurrent.CompletableFuture@43ecdac8[Not completed]
datanode_1    | 2019-11-15 20:36:42,272 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 77567471-a2f3-4d71-90b0-13adde9d29a7 at port 9858
om_1          | 2019-11-15 20:36:45,777 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3    | 2019-11-15 20:36:42,456 INFO server.GrpcService: 00262ab3-1a02-4972-af0f-1fdc62478d5f: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
scm_1         | 2019-11-15 20:36:42,154 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5d5c04f9{/,file:///tmp/jetty-0.0.0.0-9876-scm-_-any-15004038565224762089.dir/webapp/,AVAILABLE}{/scm}
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Remove unique index org_id_slug"
datanode_2    | 2019-11-15 20:36:46,390 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72: new RaftServerImpl for group-F20F21FC5549:[0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1    | 2019-11-15 20:36:42,287 INFO impl.RaftServerProxy: 77567471-a2f3-4d71-90b0-13adde9d29a7: start RPC server
om_1          | 2019-11-15 20:36:45,788 INFO ipc.Server: Starting Socket Reader #1 for port 9862
datanode_3    | 2019-11-15 20:36:46,568 INFO impl.RaftServerProxy: 00262ab3-1a02-4972-af0f-1fdc62478d5f: addNew group-F36CD5976476:[00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858] returns group-F36CD5976476:java.util.concurrent.CompletableFuture@ebe7872[Not completed]
scm_1         | 2019-11-15 20:36:42,160 INFO server.AbstractConnector: Started ServerConnector@1e469dfd{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard title length"
datanode_2    | 2019-11-15 20:36:46,392 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1    | 2019-11-15 20:36:42,450 INFO server.GrpcService: 77567471-a2f3-4d71-90b0-13adde9d29a7: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
om_1          | 2019-11-15 20:36:45,832 INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.19.0.3:9862
datanode_3    | 2019-11-15 20:36:46,617 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f: new RaftServerImpl for group-F36CD5976476:[00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858] with ContainerStateMachine:uninitialized
scm_1         | 2019-11-15 20:36:42,160 INFO server.Server: Started @33940ms
grafana_1     | t=2019-11-15T20:36:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index for dashboard_org_id_title_folder_id"
datanode_2    | 2019-11-15 20:36:46,392 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1    | 2019-11-15 20:36:46,083 INFO impl.RaftServerProxy: 77567471-a2f3-4d71-90b0-13adde9d29a7: addNew group-B88942933C9F:[77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858] returns group-B88942933C9F:java.util.concurrent.CompletableFuture@69882da[Not completed]
om_1          | 2019-11-15 20:36:45,915 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3    | 2019-11-15 20:36:46,619 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
grafana_1     | t=2019-11-15T20:36:08+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_provisioning"
datanode_2    | 2019-11-15 20:36:46,392 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1    | 2019-11-15 20:36:46,100 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7: new RaftServerImpl for group-B88942933C9F:[77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858] with ContainerStateMachine:uninitialized
scm_1         | 2019-11-15 20:36:42,163 INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2019-11-15 20:36:45,956 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
grafana_1     | t=2019-11-15T20:36:08+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table dashboard_provisioning to dashboard_provisioning_tmp_qwerty - v1"
datanode_2    | 2019-11-15 20:36:46,393 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1    | 2019-11-15 20:36:46,101 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1         | 2019-11-15 20:36:42,163 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3    | 2019-11-15 20:36:46,620 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1          | 2019-11-15 20:36:45,956 INFO impl.MetricsSystemImpl: OzoneManager metrics system started
grafana_1     | t=2019-11-15T20:36:08+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_provisioning v2"
datanode_2    | 2019-11-15 20:36:46,393 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1    | 2019-11-15 20:36:46,102 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1         | 2019-11-15 20:36:42,165 INFO server.BaseHttpServer: HTTP server of SCM is listening at http://0.0.0.0:9876
datanode_3    | 2019-11-15 20:36:46,620 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
om_1          | 2019-11-15 20:36:45,994 INFO ipc.Server: IPC Server Responder: starting
grafana_1     | t=2019-11-15T20:36:08+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_provisioning_dashboard_id - v2"
datanode_2    | 2019-11-15 20:36:46,399 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549: ConfigurationManager, init=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1    | 2019-11-15 20:36:46,102 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3    | 2019-11-15 20:36:46,620 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om_1          | 2019-11-15 20:36:45,993 INFO ipc.Server: IPC Server listener on 9862: starting
scm_1         | 2019-11-15 20:36:42,173 INFO util.JvmPauseMonitor: Starting JVM pause monitor
grafana_1     | t=2019-11-15T20:36:14+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_provisioning_dashboard_id_name - v2"
datanode_2    | 2019-11-15 20:36:46,399 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1    | 2019-11-15 20:36:46,102 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3    | 2019-11-15 20:36:46,621 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1          | 2019-11-15 20:36:46,022 INFO hdfs.DFSUtil: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
scm_1         | 2019-11-15 20:36:43,093 INFO net.NetworkTopology: Added a new node: /default-rack/77567471-a2f3-4d71-90b0-13adde9d29a7
grafana_1     | t=2019-11-15T20:36:24+0000 lvl=info msg="Executing migration" logger=migrator id="copy dashboard_provisioning v1 to v2"
datanode_2    | 2019-11-15 20:36:46,403 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1    | 2019-11-15 20:36:46,103 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3    | 2019-11-15 20:36:46,627 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476: ConfigurationManager, init=-1: [00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858], old=null, confs=<EMPTY_MAP>
om_1          | 2019-11-15 20:36:46,135 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2019-11-15 20:36:43,093 INFO node.SCMNodeManager: Registered Data node : 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:32+0000 lvl=info msg="Executing migration" logger=migrator id="drop dashboard_provisioning_tmp_qwerty"
datanode_2    | 2019-11-15 20:36:46,404 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ef7d7d79-38d4-4e0e-9767-f20f21fc5549 does not exist. Creating ...
datanode_1    | 2019-11-15 20:36:46,110 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F: ConfigurationManager, init=-1: [77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_3    | 2019-11-15 20:36:46,628 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1          | 2019-11-15 20:36:46,138 INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
scm_1         | 2019-11-15 20:36:43,097 INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_2    | 2019-11-15 20:36:46,426 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ef7d7d79-38d4-4e0e-9767-f20f21fc5549/in_use.lock acquired by nodename 7@b2c85e27534f
datanode_1    | 2019-11-15 20:36:46,110 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3    | 2019-11-15 20:36:46,633 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1         | 2019-11-15 20:36:43,097 INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
om_1          | 2019-11-15 20:36:46,144 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="Add check_sum column"
datanode_2    | 2019-11-15 20:36:46,454 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ef7d7d79-38d4-4e0e-9767-f20f21fc5549 has been successfully formatted.
datanode_1    | 2019-11-15 20:36:46,116 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3    | 2019-11-15 20:36:46,634 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/80a3da46-3032-4450-b67b-f36cd5976476 does not exist. Creating ...
scm_1         | 2019-11-15 20:36:43,099 INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
om_1          | 2019-11-15 20:36:46,146 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="create data_source table"
datanode_2    | 2019-11-15 20:36:46,469 INFO ratis.ContainerStateMachine: group-F20F21FC5549: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1    | 2019-11-15 20:36:46,117 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a287ef13-2b67-4c26-87a4-b88942933c9f does not exist. Creating ...
datanode_3    | 2019-11-15 20:36:46,679 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/80a3da46-3032-4450-b67b-f36cd5976476/in_use.lock acquired by nodename 7@79a9423c1b6d
scm_1         | 2019-11-15 20:36:43,101 INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=a287ef13-2b67-4c26-87a4-b88942933c9f create command to datanode 77567471-a2f3-4d71-90b0-13adde9d29a7
om_1          | 2019-11-15 20:36:46,146 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="add index data_source.account_id"
datanode_2    | 2019-11-15 20:36:46,470 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1    | 2019-11-15 20:36:46,141 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a287ef13-2b67-4c26-87a4-b88942933c9f/in_use.lock acquired by nodename 7@ca8a888e1739
datanode_3    | 2019-11-15 20:36:46,693 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/80a3da46-3032-4450-b67b-f36cd5976476 has been successfully formatted.
scm_1         | 2019-11-15 20:36:43,113 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a287ef13-2b67-4c26-87a4-b88942933c9f, Nodes: 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
om_1          | 2019-11-15 20:36:46,146 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index data_source.account_id_name"
datanode_2    | 2019-11-15 20:36:46,473 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1    | 2019-11-15 20:36:46,165 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a287ef13-2b67-4c26-87a4-b88942933c9f has been successfully formatted.
datanode_3    | 2019-11-15 20:36:46,697 INFO ratis.ContainerStateMachine: group-F36CD5976476: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1         | 2019-11-15 20:36:43,375 INFO net.NetworkTopology: Added a new node: /default-rack/0da639d9-8110-428c-9b35-ccc8d6563a72
om_1          | 2019-11-15 20:36:46,165 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_data_source_account_id - v1"
datanode_2    | 2019-11-15 20:36:46,477 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1    | 2019-11-15 20:36:46,168 INFO ratis.ContainerStateMachine: group-B88942933C9F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3    | 2019-11-15 20:36:46,697 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
scm_1         | 2019-11-15 20:36:43,375 INFO node.SCMNodeManager: Registered Data node : 0da639d9-8110-428c-9b35-ccc8d6563a72{ip: 172.19.0.7, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
om_1          | 2019-11-15 20:36:46,168 INFO http.HttpServer2: Jetty bound to port 9874
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_data_source_account_id_name - v1"
datanode_2    | 2019-11-15 20:36:46,477 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1    | 2019-11-15 20:36:46,168 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_3    | 2019-11-15 20:36:46,700 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1         | 2019-11-15 20:36:43,375 INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om_1          | 2019-11-15 20:36:46,169 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table data_source to data_source_v1 - v1"
datanode_2    | 2019-11-15 20:36:46,479 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1    | 2019-11-15 20:36:46,171 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3    | 2019-11-15 20:36:46,704 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1         | 2019-11-15 20:36:43,376 INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
om_1          | 2019-11-15 20:36:46,196 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4364712f{/logs,file:///var/log/hadoop/,AVAILABLE}
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="create data_source table v2"
datanode_2    | 2019-11-15 20:36:46,483 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1    | 2019-11-15 20:36:46,175 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3    | 2019-11-15 20:36:46,704 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1         | 2019-11-15 20:36:43,377 INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=ef7d7d79-38d4-4e0e-9767-f20f21fc5549 create command to datanode 0da639d9-8110-428c-9b35-ccc8d6563a72
om_1          | 2019-11-15 20:36:46,196 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6535117e{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_data_source_org_id - v2"
datanode_2    | 2019-11-15 20:36:46,486 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,175 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3    | 2019-11-15 20:36:46,706 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 2019-11-15 20:36:43,378 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ef7d7d79-38d4-4e0e-9767-f20f21fc5549, Nodes: 0da639d9-8110-428c-9b35-ccc8d6563a72{ip: 172.19.0.7, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_data_source_org_id_name - v2"
datanode_1    | 2019-11-15 20:36:46,176 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2    | 2019-11-15 20:36:46,490 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1          | 2019-11-15 20:36:46,277 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@58a2b917{/,file:///tmp/jetty-0.0.0.0-9874-ozoneManager-_-any-9836704678602966171.dir/webapp/,AVAILABLE}{/ozoneManager}
datanode_3    | 2019-11-15 20:36:46,710 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1         | 2019-11-15 20:36:43,568 INFO net.NetworkTopology: Added a new node: /default-rack/00262ab3-1a02-4972-af0f-1fdc62478d5f
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="copy data_source v1 to v2"
datanode_1    | 2019-11-15 20:36:46,181 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2    | 2019-11-15 20:36:46,494 INFO segmented.SegmentedRaftLogWorker: new 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ef7d7d79-38d4-4e0e-9767-f20f21fc5549
om_1          | 2019-11-15 20:36:46,283 INFO server.AbstractConnector: Started ServerConnector@5922d3e9{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
datanode_3    | 2019-11-15 20:36:46,712 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
scm_1         | 2019-11-15 20:36:43,568 INFO node.SCMNodeManager: Registered Data node : 00262ab3-1a02-4972-af0f-1fdc62478d5f{ip: 172.19.0.6, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table data_source_v1 #2"
datanode_1    | 2019-11-15 20:36:46,184 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1          | 2019-11-15 20:36:46,283 INFO server.Server: Started @3832ms
datanode_2    | 2019-11-15 20:36:46,495 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3    | 2019-11-15 20:36:46,716 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1         | 2019-11-15 20:36:43,568 INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="Add column with_credentials"
datanode_1    | 2019-11-15 20:36:46,189 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1          | 2019-11-15 20:36:46,286 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3    | 2019-11-15 20:36:46,720 INFO segmented.SegmentedRaftLogWorker: new 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/80a3da46-3032-4450-b67b-f36cd5976476
datanode_2    | 2019-11-15 20:36:46,495 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
grafana_1     | t=2019-11-15T20:36:40+0000 lvl=info msg="Executing migration" logger=migrator id="Add secure json data column"
scm_1         | 2019-11-15 20:36:43,569 INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
datanode_1    | 2019-11-15 20:36:46,194 INFO segmented.SegmentedRaftLogWorker: new 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a287ef13-2b67-4c26-87a4-b88942933c9f
om_1          | 2019-11-15 20:36:46,286 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3    | 2019-11-15 20:36:46,721 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2    | 2019-11-15 20:36:46,496 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Update data_source table charset"
scm_1         | 2019-11-15 20:36:43,570 INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=80a3da46-3032-4450-b67b-f36cd5976476 create command to datanode 00262ab3-1a02-4972-af0f-1fdc62478d5f
datanode_1    | 2019-11-15 20:36:46,194 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
om_1          | 2019-11-15 20:36:46,288 INFO server.BaseHttpServer: HTTP server of OZONEMANAGER is listening at http://0.0.0.0:9874
datanode_3    | 2019-11-15 20:36:46,721 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1         | 2019-11-15 20:36:43,571 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 80a3da46-3032-4450-b67b-f36cd5976476, Nodes: 00262ab3-1a02-4972-af0f-1fdc62478d5f{ip: 172.19.0.6, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Update initial version to 1"
datanode_2    | 2019-11-15 20:36:46,496 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1          | 2019-11-15 20:37:08,595 INFO volume.OMVolumeCreateRequest: created volume:vol-0-44116 for user:hadoop
scm_1         | 2019-11-15 20:36:43,572 INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa create command to datanode 77567471-a2f3-4d71-90b0-13adde9d29a7
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Add read_only data column"
datanode_2    | 2019-11-15 20:36:46,496 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
om_1          | 2019-11-15 20:37:08,644 INFO volume.OMVolumeCreateRequest: created volume:vol-1-46325 for user:hadoop
datanode_1    | 2019-11-15 20:36:46,195 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3    | 2019-11-15 20:36:46,722 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 2019-11-15 20:36:43,572 INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa create command to datanode 0da639d9-8110-428c-9b35-ccc8d6563a72
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Migrate logging ds to loki ds"
datanode_2    | 2019-11-15 20:36:46,497 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1          | 2019-11-15 20:37:08,665 INFO volume.OMVolumeCreateRequest: created volume:vol-2-60819 for user:hadoop
datanode_1    | 2019-11-15 20:36:46,196 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3    | 2019-11-15 20:36:46,722 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1         | 2019-11-15 20:36:43,573 INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa create command to datanode 00262ab3-1a02-4972-af0f-1fdc62478d5f
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Update json_data with nulls"
datanode_2    | 2019-11-15 20:36:46,498 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1    | 2019-11-15 20:36:46,196 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1          | 2019-11-15 20:37:08,691 INFO volume.OMVolumeCreateRequest: created volume:vol-3-50161 for user:hadoop
datanode_3    | 2019-11-15 20:36:46,722 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="create api_key table"
scm_1         | 2019-11-15 20:36:43,573 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fbba235a-0a21-4967-a2e1-2e58c2482bfa, Nodes: 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}0da639d9-8110-428c-9b35-ccc8d6563a72{ip: 172.19.0.7, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}00262ab3-1a02-4972-af0f-1fdc62478d5f{ip: 172.19.0.6, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED]
datanode_2    | 2019-11-15 20:36:46,498 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1    | 2019-11-15 20:36:46,196 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
om_1          | 2019-11-15 20:37:08,715 INFO volume.OMVolumeCreateRequest: created volume:vol-4-97035 for user:hadoop
datanode_3    | 2019-11-15 20:36:46,723 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.account_id"
scm_1         | 2019-11-15 20:36:46,359 INFO pipeline.PipelineReportHandler: Pipeline ONE PipelineID=a287ef13-2b67-4c26-87a4-b88942933c9f reported by 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
datanode_2    | 2019-11-15 20:36:46,498 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1    | 2019-11-15 20:36:46,196 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3    | 2019-11-15 20:36:46,724 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.key"
datanode_2    | 2019-11-15 20:36:46,505 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1         | 2019-11-15 20:36:46,359 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a287ef13-2b67-4c26-87a4-b88942933c9f, Nodes: 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED] moved to OPEN state
datanode_1    | 2019-11-15 20:36:46,197 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3    | 2019-11-15 20:36:46,724 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.account_id_name"
datanode_2    | 2019-11-15 20:36:46,509 INFO segmented.SegmentedRaftLogWorker: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1         | 2019-11-15 20:36:46,362 INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_1    | 2019-11-15 20:36:46,198 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3    | 2019-11-15 20:36:46,724 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_api_key_account_id - v1"
datanode_2    | 2019-11-15 20:36:46,514 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1    | 2019-11-15 20:36:46,198 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1         | 2019-11-15 20:36:46,362 INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_3    | 2019-11-15 20:36:46,731 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_api_key_key - v1"
datanode_2    | 2019-11-15 20:36:46,514 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1    | 2019-11-15 20:36:46,208 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1         | 2019-11-15 20:36:46,385 INFO pipeline.PipelineReportHandler: Pipeline THREE PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa reported by 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_api_key_account_id_name - v1"
datanode_2    | 2019-11-15 20:36:46,515 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1         | 2019-11-15 20:36:46,709 INFO pipeline.PipelineReportHandler: Pipeline ONE PipelineID=ef7d7d79-38d4-4e0e-9767-f20f21fc5549 reported by 0da639d9-8110-428c-9b35-ccc8d6563a72{ip: 172.19.0.7, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
datanode_1    | 2019-11-15 20:36:46,212 INFO segmented.SegmentedRaftLogWorker: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3    | 2019-11-15 20:36:46,735 INFO segmented.SegmentedRaftLogWorker: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table api_key to api_key_v1 - v1"
datanode_2    | 2019-11-15 20:36:46,515 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1    | 2019-11-15 20:36:46,216 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1         | 2019-11-15 20:36:46,710 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ef7d7d79-38d4-4e0e-9767-f20f21fc5549, Nodes: 0da639d9-8110-428c-9b35-ccc8d6563a72{ip: 172.19.0.7, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED] moved to OPEN state
datanode_3    | 2019-11-15 20:36:46,738 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="create api_key table v2"
datanode_2    | 2019-11-15 20:36:46,533 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,217 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1         | 2019-11-15 20:36:46,710 INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_api_key_org_id - v2"
datanode_3    | 2019-11-15 20:36:46,739 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2    | 2019-11-15 20:36:46,534 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,218 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1         | 2019-11-15 20:36:46,710 INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_api_key_key - v2"
datanode_3    | 2019-11-15 20:36:46,739 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2    | 2019-11-15 20:36:46,536 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549: start as a follower, conf=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858], old=null
datanode_1    | 2019-11-15 20:36:46,218 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1         | 2019-11-15 20:36:46,725 INFO pipeline.PipelineReportHandler: Pipeline THREE PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa reported by 0da639d9-8110-428c-9b35-ccc8d6563a72{ip: 172.19.0.7, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_api_key_org_id_name - v2"
datanode_3    | 2019-11-15 20:36:46,739 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2    | 2019-11-15 20:36:46,537 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1    | 2019-11-15 20:36:46,234 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
scm_1         | 2019-11-15 20:36:46,889 INFO pipeline.PipelineReportHandler: Pipeline ONE PipelineID=80a3da46-3032-4450-b67b-f36cd5976476 reported by 00262ab3-1a02-4972-af0f-1fdc62478d5f{ip: 172.19.0.6, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="copy api_key v1 to v2"
datanode_3    | 2019-11-15 20:36:46,754 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-15 20:36:46,538 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: start FollowerState
datanode_1    | 2019-11-15 20:36:46,236 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
scm_1         | 2019-11-15 20:36:46,889 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 80a3da46-3032-4450-b67b-f36cd5976476, Nodes: 00262ab3-1a02-4972-af0f-1fdc62478d5f{ip: 172.19.0.6, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED] moved to OPEN state
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table api_key_v1"
datanode_2    | 2019-11-15 20:36:46,541 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F20F21FC5549,id=0da639d9-8110-428c-9b35-ccc8d6563a72
datanode_3    | 2019-11-15 20:36:46,756 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,237 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F: start as a follower, conf=-1: [77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Update api_key table charset"
scm_1         | 2019-11-15 20:36:46,889 INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_3    | 2019-11-15 20:36:46,757 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476: start as a follower, conf=-1: [00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858], old=null
datanode_2    | 2019-11-15 20:36:46,542 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,238 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F: changes role from      null to FOLLOWER at term 0 for startAsFollower
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="Add expires to api_key table"
scm_1         | 2019-11-15 20:36:46,889 INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_2    | 2019-11-15 20:36:46,684 INFO commandhandler.CreatePipelineCommandHandler: Create Pipeline RATIS ONE #id: "ef7d7d79-38d4-4e0e-9767-f20f21fc5549"
datanode_3    | 2019-11-15 20:36:46,758 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1    | 2019-11-15 20:36:46,239 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: start FollowerState
grafana_1     | t=2019-11-15T20:36:41+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_snapshot table v4"
datanode_2    |  command succeed on datanode 0da639d9-8110-428c-9b35-ccc8d6563a72.
datanode_3    | 2019-11-15 20:36:46,759 INFO impl.RoleInfo: 00262ab3-1a02-4972-af0f-1fdc62478d5f: start FollowerState
datanode_1    | 2019-11-15 20:36:46,242 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B88942933C9F,id=77567471-a2f3-4d71-90b0-13adde9d29a7
scm_1         | 2019-11-15 20:36:46,922 INFO pipeline.PipelineReportHandler: Pipeline THREE PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa reported by 00262ab3-1a02-4972-af0f-1fdc62478d5f{ip: 172.19.0.6, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="drop table dashboard_snapshot_v4 #1"
datanode_2    | 2019-11-15 20:36:46,687 INFO impl.RaftServerProxy: 0da639d9-8110-428c-9b35-ccc8d6563a72: addNew group-2E58C2482BFA:[0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858] returns group-2E58C2482BFA:java.util.concurrent.CompletableFuture@46a0e837[Not completed]
datanode_3    | 2019-11-15 20:36:46,762 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F36CD5976476,id=00262ab3-1a02-4972-af0f-1fdc62478d5f
datanode_1    | 2019-11-15 20:36:46,243 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
scm_1         | 2019-11-15 20:36:51,353 INFO pipeline.PipelineReportHandler: Pipeline THREE PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa reported by 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_snapshot table v5 #2"
datanode_2    | 2019-11-15 20:36:46,688 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72: new RaftServerImpl for group-2E58C2482BFA:[0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858] with ContainerStateMachine:uninitialized
datanode_3    | 2019-11-15 20:36:46,763 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,333 INFO commandhandler.CreatePipelineCommandHandler: Create Pipeline RATIS ONE #id: "a287ef13-2b67-4c26-87a4-b88942933c9f"
scm_1         | 2019-11-15 20:36:51,629 INFO pipeline.PipelineReportHandler: Pipeline THREE PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa reported by 0da639d9-8110-428c-9b35-ccc8d6563a72{ip: 172.19.0.7, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_snapshot_key - v5"
datanode_2    | 2019-11-15 20:36:46,689 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3    | 2019-11-15 20:36:46,865 INFO commandhandler.CreatePipelineCommandHandler: Create Pipeline RATIS ONE #id: "80a3da46-3032-4450-b67b-f36cd5976476"
datanode_1    |  command succeed on datanode 77567471-a2f3-4d71-90b0-13adde9d29a7.
scm_1         | 2019-11-15 20:36:51,844 INFO pipeline.PipelineReportHandler: Pipeline THREE PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa reported by 00262ab3-1a02-4972-af0f-1fdc62478d5f{ip: 172.19.0.6, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_snapshot_delete_key - v5"
datanode_2    | 2019-11-15 20:36:46,689 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3    |  command succeed on datanode 00262ab3-1a02-4972-af0f-1fdc62478d5f.
datanode_1    | 2019-11-15 20:36:46,336 INFO impl.RaftServerProxy: 77567471-a2f3-4d71-90b0-13adde9d29a7: addNew group-2E58C2482BFA:[0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858] returns group-2E58C2482BFA:java.util.concurrent.CompletableFuture@4e29e4fd[Not completed]
scm_1         | 2019-11-15 20:36:52,029 INFO pipeline.PipelineReportHandler: Pipeline THREE PipelineID=fbba235a-0a21-4967-a2e1-2e58c2482bfa reported by 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_snapshot_user_id - v5"
datanode_2    | 2019-11-15 20:36:46,689 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3    | 2019-11-15 20:36:46,867 INFO impl.RaftServerProxy: 00262ab3-1a02-4972-af0f-1fdc62478d5f: addNew group-2E58C2482BFA:[0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858] returns group-2E58C2482BFA:java.util.concurrent.CompletableFuture@476e7d6c[Not completed]
scm_1         | 2019-11-15 20:36:52,029 INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: fbba235a-0a21-4967-a2e1-2e58c2482bfa, Nodes: 77567471-a2f3-4d71-90b0-13adde9d29a7{ip: 172.19.0.4, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}0da639d9-8110-428c-9b35-ccc8d6563a72{ip: 172.19.0.7, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}00262ab3-1a02-4972-af0f-1fdc62478d5f{ip: 172.19.0.6, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED] moved to OPEN state
datanode_1    | 2019-11-15 20:36:46,338 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7: new RaftServerImpl for group-2E58C2482BFA:[0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858] with ContainerStateMachine:uninitialized
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard_snapshot to mediumtext v2"
datanode_2    | 2019-11-15 20:36:46,689 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3    | 2019-11-15 20:36:46,870 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f: new RaftServerImpl for group-2E58C2482BFA:[0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858] with ContainerStateMachine:uninitialized
scm_1         | 2019-11-15 20:36:52,030 INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_1    | 2019-11-15 20:36:46,339 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard_snapshot table charset"
datanode_2    | 2019-11-15 20:36:46,689 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3    | 2019-11-15 20:36:46,870 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1    | 2019-11-15 20:36:46,339 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1         | 2019-11-15 20:36:52,030 INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Add column external_delete_url to dashboard_snapshots table"
datanode_3    | 2019-11-15 20:36:46,870 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2    | 2019-11-15 20:36:46,689 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA: ConfigurationManager, init=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1    | 2019-11-15 20:36:46,339 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
scm_1         | 2019-11-15 20:36:52,030 INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create quota table v1"
datanode_3    | 2019-11-15 20:36:46,870 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1    | 2019-11-15 20:36:46,339 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1         | 2019-11-15 20:36:52,030 INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode_2    | 2019-11-15 20:36:46,689 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_quota_org_id_user_id_target - v1"
datanode_3    | 2019-11-15 20:36:46,870 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1    | 2019-11-15 20:36:46,339 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1         | 2019-11-15 20:36:52,030 INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Update quota table charset"
datanode_3    | 2019-11-15 20:36:46,870 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1    | 2019-11-15 20:36:46,339 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA: ConfigurationManager, init=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2    | 2019-11-15 20:36:46,690 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create plugin_setting table"
datanode_3    | 2019-11-15 20:36:46,870 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA: ConfigurationManager, init=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1    | 2019-11-15 20:36:46,339 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2    | 2019-11-15 20:36:46,690 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa does not exist. Creating ...
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_plugin_setting_org_id_plugin_id - v1"
datanode_3    | 2019-11-15 20:36:46,871 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1    | 2019-11-15 20:36:46,340 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2    | 2019-11-15 20:36:46,693 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa/in_use.lock acquired by nodename 7@b2c85e27534f
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Add column plugin_version to plugin_settings"
datanode_1    | 2019-11-15 20:36:46,340 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa does not exist. Creating ...
datanode_2    | 2019-11-15 20:36:46,706 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa has been successfully formatted.
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Update plugin_setting table charset"
datanode_3    | 2019-11-15 20:36:46,871 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1    | 2019-11-15 20:36:46,353 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa/in_use.lock acquired by nodename 7@ca8a888e1739
datanode_2    | 2019-11-15 20:36:46,707 INFO ratis.ContainerStateMachine: group-2E58C2482BFA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create session table"
datanode_3    | 2019-11-15 20:36:46,871 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa does not exist. Creating ...
datanode_1    | 2019-11-15 20:36:46,376 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa has been successfully formatted.
datanode_2    | 2019-11-15 20:36:46,707 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table playlist table"
datanode_3    | 2019-11-15 20:36:46,899 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa/in_use.lock acquired by nodename 7@79a9423c1b6d
datanode_1    | 2019-11-15 20:36:46,377 INFO ratis.ContainerStateMachine: group-2E58C2482BFA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2    | 2019-11-15 20:36:46,707 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table playlist_item table"
datanode_3    | 2019-11-15 20:36:46,914 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa has been successfully formatted.
datanode_1    | 2019-11-15 20:36:46,377 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_2    | 2019-11-15 20:36:46,707 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create playlist table v2"
datanode_3    | 2019-11-15 20:36:46,915 INFO ratis.ContainerStateMachine: group-2E58C2482BFA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1    | 2019-11-15 20:36:46,377 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2    | 2019-11-15 20:36:46,707 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create playlist item table v2"
datanode_3    | 2019-11-15 20:36:46,915 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1    | 2019-11-15 20:36:46,377 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2    | 2019-11-15 20:36:46,708 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Update playlist table charset"
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3    | 2019-11-15 20:36:46,915 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2    | 2019-11-15 20:36:46,708 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Update playlist_item table charset"
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3    | 2019-11-15 20:36:46,915 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2    | 2019-11-15 20:36:46,708 INFO segmented.SegmentedRaftLogWorker: new 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3    | 2019-11-15 20:36:46,915 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="drop preferences table v2"
datanode_1    | 2019-11-15 20:36:46,378 INFO segmented.SegmentedRaftLogWorker: new 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa
datanode_2    | 2019-11-15 20:36:46,708 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3    | 2019-11-15 20:36:46,915 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="drop preferences table v3"
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2    | 2019-11-15 20:36:46,708 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3    | 2019-11-15 20:36:46,915 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="create preferences table v3"
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3    | 2019-11-15 20:36:46,916 INFO segmented.SegmentedRaftLogWorker: new 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa
datanode_2    | 2019-11-15 20:36:46,708 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2    | 2019-11-15 20:36:46,708 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
grafana_1     | t=2019-11-15T20:36:42+0000 lvl=info msg="Executing migration" logger=migrator id="Update preferences table charset"
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2    | 2019-11-15 20:36:46,709 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Add column team_id in preferences"
datanode_2    | 2019-11-15 20:36:46,709 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Update team_id column values in preferences"
datanode_2    | 2019-11-15 20:36:46,709 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1    | 2019-11-15 20:36:46,378 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="create alert table v1"
datanode_2    | 2019-11-15 20:36:46,709 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1    | 2019-11-15 20:36:46,379 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert org_id & id "
datanode_2    | 2019-11-15 20:36:46,709 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1    | 2019-11-15 20:36:46,379 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert state"
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2    | 2019-11-15 20:36:46,709 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1    | 2019-11-15 20:36:46,379 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert dashboard_id"
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2    | 2019-11-15 20:36:46,720 INFO segmented.SegmentedRaftLogWorker: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Create alert_rule_tag table v1"
datanode_1    | 2019-11-15 20:36:46,379 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2    | 2019-11-15 20:36:46,720 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index alert_rule_tag.alert_id_tag_id"
datanode_1    | 2019-11-15 20:36:46,380 INFO segmented.SegmentedRaftLogWorker: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3    | 2019-11-15 20:36:46,916 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2    | 2019-11-15 20:36:46,721 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="create alert_notification table v1"
datanode_1    | 2019-11-15 20:36:46,380 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2    | 2019-11-15 20:36:46,721 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3    | 2019-11-15 20:36:46,917 INFO segmented.SegmentedRaftLogWorker: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Add column is_default"
datanode_1    | 2019-11-15 20:36:46,380 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2    | 2019-11-15 20:36:46,721 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1    | 2019-11-15 20:36:46,380 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Add column frequency"
datanode_3    | 2019-11-15 20:36:46,917 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2    | 2019-11-15 20:36:46,721 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,381 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3    | 2019-11-15 20:36:46,917 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Add column send_reminder"
datanode_2    | 2019-11-15 20:36:46,721 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,381 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-15 20:36:46,917 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Add column disable_resolve_message"
datanode_2    | 2019-11-15 20:36:46,721 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA: start as a follower, conf=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
datanode_1    | 2019-11-15 20:36:46,381 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-15 20:36:46,917 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert_notification org_id & name"
datanode_2    | 2019-11-15 20:36:46,721 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3    | 2019-11-15 20:36:46,918 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,381 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA: start as a follower, conf=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert table charset"
datanode_2    | 2019-11-15 20:36:46,721 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: start FollowerState
datanode_3    | 2019-11-15 20:36:46,918 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,381 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA: changes role from      null to FOLLOWER at term 0 for startAsFollower
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert_notification table charset"
datanode_3    | 2019-11-15 20:36:46,918 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA: start as a follower, conf=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
datanode_2    | 2019-11-15 20:36:46,722 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E58C2482BFA,id=0da639d9-8110-428c-9b35-ccc8d6563a72
datanode_1    | 2019-11-15 20:36:46,381 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: start FollowerState
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="create notification_journal table v1"
datanode_3    | 2019-11-15 20:36:46,918 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2    | 2019-11-15 20:36:46,722 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-15 20:36:46,382 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E58C2482BFA,id=77567471-a2f3-4d71-90b0-13adde9d29a7
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="add index notification_journal org_id & alert_id & notifier_id"
datanode_3    | 2019-11-15 20:36:46,918 INFO impl.RoleInfo: 00262ab3-1a02-4972-af0f-1fdc62478d5f: start FollowerState
datanode_2    | 2019-11-15 20:36:46,722 INFO commandhandler.CreatePipelineCommandHandler: Create Pipeline RATIS THREE #id: "fbba235a-0a21-4967-a2e1-2e58c2482bfa"
datanode_1    | 2019-11-15 20:36:46,382 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-15 20:36:46,919 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E58C2482BFA,id=00262ab3-1a02-4972-af0f-1fdc62478d5f
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="drop alert_notification_journal"
datanode_2    |  command succeed on datanode 0da639d9-8110-428c-9b35-ccc8d6563a72.
datanode_1    | 2019-11-15 20:36:46,383 INFO commandhandler.CreatePipelineCommandHandler: Create Pipeline RATIS THREE #id: "fbba235a-0a21-4967-a2e1-2e58c2482bfa"
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="create alert_notification_state table v1"
datanode_3    | 2019-11-15 20:36:46,919 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-15 20:36:51,592 INFO impl.FollowerState: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549-FollowerState: change to CANDIDATE, lastRpcTime:5054ms, electionTimeout:5054ms
datanode_1    |  command succeed on datanode 77567471-a2f3-4d71-90b0-13adde9d29a7.
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert_notification_state org_id & alert_id & notifier_id"
datanode_3    | 2019-11-15 20:36:46,919 INFO commandhandler.CreatePipelineCommandHandler: Create Pipeline RATIS THREE #id: "fbba235a-0a21-4967-a2e1-2e58c2482bfa"
datanode_2    | 2019-11-15 20:36:51,594 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: shutdown FollowerState
datanode_1    | 2019-11-15 20:36:51,313 INFO impl.FollowerState: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F-FollowerState: change to CANDIDATE, lastRpcTime:5074ms, electionTimeout:5074ms
grafana_1     | t=2019-11-15T20:36:43+0000 lvl=info msg="Executing migration" logger=migrator id="Add for to alert table"
datanode_3    |  command succeed on datanode 00262ab3-1a02-4972-af0f-1fdc62478d5f.
datanode_1    | 2019-11-15 20:36:51,315 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: shutdown FollowerState
datanode_2    | 2019-11-15 20:36:51,594 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add column uid in alert_notification"
datanode_3    | 2019-11-15 20:36:51,797 INFO impl.FollowerState: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476-FollowerState: change to CANDIDATE, lastRpcTime:5037ms, electionTimeout:5037ms
datanode_1    | 2019-11-15 20:36:51,316 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2    | 2019-11-15 20:36:51,597 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: start LeaderElection
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Update uid column values in alert_notification"
datanode_3    | 2019-11-15 20:36:51,805 INFO impl.RoleInfo: 00262ab3-1a02-4972-af0f-1fdc62478d5f: shutdown FollowerState
datanode_1    | 2019-11-15 20:36:51,320 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: start LeaderElection
datanode_2    | 2019-11-15 20:36:51,623 INFO impl.LeaderElection: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549-LeaderElection1: begin an election at term 1 for -1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858], old=null
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index alert_notification_org_id_uid"
datanode_3    | 2019-11-15 20:36:51,806 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1    | 2019-11-15 20:36:51,345 INFO impl.LeaderElection: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F-LeaderElection1: begin an election at term 1 for -1: [77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
datanode_2    | 2019-11-15 20:36:51,624 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: shutdown LeaderElection
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Remove unique index org_id_name"
datanode_3    | 2019-11-15 20:36:51,809 INFO impl.RoleInfo: 00262ab3-1a02-4972-af0f-1fdc62478d5f: start LeaderElection
datanode_1    | 2019-11-15 20:36:51,346 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: shutdown LeaderElection
datanode_2    | 2019-11-15 20:36:51,625 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old annotation table v4"
datanode_3    | 2019-11-15 20:36:51,833 INFO impl.LeaderElection: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476-LeaderElection1: begin an election at term 1 for -1: [00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858], old=null
datanode_1    | 2019-11-15 20:36:51,347 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2    | 2019-11-15 20:36:51,625 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F20F21FC5549 with new leaderId: 0da639d9-8110-428c-9b35-ccc8d6563a72
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="create annotation table v5"
datanode_3    | 2019-11-15 20:36:51,835 INFO impl.RoleInfo: 00262ab3-1a02-4972-af0f-1fdc62478d5f: shutdown LeaderElection
datanode_1    | 2019-11-15 20:36:51,347 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B88942933C9F with new leaderId: 77567471-a2f3-4d71-90b0-13adde9d29a7
datanode_2    | 2019-11-15 20:36:51,626 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549: change Leader from null to 0da639d9-8110-428c-9b35-ccc8d6563a72 at term 1 for becomeLeader, leader elected after 5155ms
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 0 v3"
datanode_3    | 2019-11-15 20:36:51,836 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1    | 2019-11-15 20:36:51,348 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F: change Leader from null to 77567471-a2f3-4d71-90b0-13adde9d29a7 at term 1 for becomeLeader, leader elected after 5179ms
datanode_2    | 2019-11-15 20:36:51,631 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 1 v3"
datanode_3    | 2019-11-15 20:36:51,837 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F36CD5976476 with new leaderId: 00262ab3-1a02-4972-af0f-1fdc62478d5f
datanode_1    | 2019-11-15 20:36:51,355 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 2 v3"
datanode_2    | 2019-11-15 20:36:51,631 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3    | 2019-11-15 20:36:51,838 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476: change Leader from null to 00262ab3-1a02-4972-af0f-1fdc62478d5f at term 1 for becomeLeader, leader elected after 5139ms
datanode_1    | 2019-11-15 20:36:51,356 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 3 v3"
datanode_2    | 2019-11-15 20:36:51,634 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3    | 2019-11-15 20:36:51,842 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1    | 2019-11-15 20:36:51,360 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 4 v3"
datanode_3    | 2019-11-15 20:36:51,842 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2    | 2019-11-15 20:36:51,638 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_1    | 2019-11-15 20:36:51,365 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Update annotation table charset"
datanode_3    | 2019-11-15 20:36:51,846 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_2    | 2019-11-15 20:36:51,638 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1    | 2019-11-15 20:36:51,365 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3    | 2019-11-15 20:36:51,851 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add column region_id to annotation table"
datanode_2    | 2019-11-15 20:36:51,639 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1    | 2019-11-15 20:36:51,366 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3    | 2019-11-15 20:36:51,851 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Drop category_id index"
datanode_2    | 2019-11-15 20:36:51,644 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: start LeaderState
datanode_1    | 2019-11-15 20:36:51,373 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: start LeaderState
datanode_3    | 2019-11-15 20:36:51,852 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add column tags to annotation table"
datanode_2    | 2019-11-15 20:36:51,661 INFO segmented.SegmentedRaftLogWorker: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-15 20:36:51,392 INFO segmented.SegmentedRaftLogWorker: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3    | 2019-11-15 20:36:51,861 INFO impl.RoleInfo: 00262ab3-1a02-4972-af0f-1fdc62478d5f: start LeaderState
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Create annotation_tag table v2"
datanode_1    | WARNING: An illegal reflective access operation has occurred
datanode_2    | WARNING: An illegal reflective access operation has occurred
datanode_3    | 2019-11-15 20:36:51,879 INFO segmented.SegmentedRaftLogWorker: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476-SegmentedRaftLogWorker: Starting segment from index:0
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index annotation_tag.annotation_id_tag_id"
datanode_1    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
datanode_2    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
datanode_3    | WARNING: An illegal reflective access operation has occurred
datanode_1    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert annotations and set TEXT to empty"
datanode_2    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
datanode_3    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
datanode_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add created time to annotation table"
datanode_2    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_1    | WARNING: All illegal access operations will be denied in a future release
datanode_3    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add updated time to annotation table"
datanode_2    | WARNING: All illegal access operations will be denied in a future release
datanode_1    | 2019-11-15 20:36:51,407 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F: set configuration 0: [77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null at 0
datanode_3    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for created in annotation table"
datanode_1    | 2019-11-15 20:36:51,455 INFO impl.FollowerState: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA-FollowerState: change to CANDIDATE, lastRpcTime:5073ms, electionTimeout:5073ms
datanode_2    | 2019-11-15 20:36:51,678 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549: set configuration 0: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858], old=null at 0
datanode_3    | WARNING: All illegal access operations will be denied in a future release
grafana_1     | t=2019-11-15T20:36:44+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for updated in annotation table"
datanode_1    | 2019-11-15 20:36:51,455 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: shutdown FollowerState
datanode_2    | 2019-11-15 20:36:51,772 INFO impl.FollowerState: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA-FollowerState: change to CANDIDATE, lastRpcTime:5050ms, electionTimeout:5050ms
datanode_3    | 2019-11-15 20:36:51,911 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476: set configuration 0: [00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858], old=null at 0
datanode_1    | 2019-11-15 20:36:51,456 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3    | 2019-11-15 20:36:51,951 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:77567471-a2f3-4d71-90b0-13adde9d29a7
datanode_2    | 2019-11-15 20:36:51,772 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: shutdown FollowerState
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="Convert existing annotations from seconds to milliseconds"
datanode_1    | 2019-11-15 20:36:51,456 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: start LeaderElection
datanode_3    | 2019-11-15 20:36:51,951 INFO impl.RoleInfo: 00262ab3-1a02-4972-af0f-1fdc62478d5f: shutdown FollowerState
datanode_2    | 2019-11-15 20:36:51,772 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="Add epoch_end column"
datanode_1    | 2019-11-15 20:36:51,471 INFO impl.LeaderElection: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA-LeaderElection2: begin an election at term 1 for -1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
datanode_3    | 2019-11-15 20:36:51,952 INFO impl.RoleInfo: 00262ab3-1a02-4972-af0f-1fdc62478d5f: start FollowerState
datanode_2    | 2019-11-15 20:36:51,772 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: start LeaderElection
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for epoch_end"
datanode_1    | 2019-11-15 20:36:51,526 INFO segmented.SegmentedRaftLogWorker: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-B88942933C9F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a287ef13-2b67-4c26-87a4-b88942933c9f/current/log_inprogress_0
datanode_3    | 2019-11-15 20:36:51,952 INFO impl.FollowerState: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2    | 2019-11-15 20:36:51,794 INFO segmented.SegmentedRaftLogWorker: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-F20F21FC5549-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ef7d7d79-38d4-4e0e-9767-f20f21fc5549/current/log_inprogress_0
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="Make epoch_end the same as epoch"
datanode_3    | 2019-11-15 20:36:52,021 INFO segmented.SegmentedRaftLogWorker: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-F36CD5976476-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/80a3da46-3032-4450-b67b-f36cd5976476/current/log_inprogress_0
datanode_1    | 2019-11-15 20:36:52,025 INFO impl.LeaderElection: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA-LeaderElection2: Election PASSED; received 2 response(s) [77567471-a2f3-4d71-90b0-13adde9d29a7<-0da639d9-8110-428c-9b35-ccc8d6563a72#0:FAIL-t1, 77567471-a2f3-4d71-90b0-13adde9d29a7<-00262ab3-1a02-4972-af0f-1fdc62478d5f#0:OK-t1] and 0 exception(s); 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA:t1, leader=null, voted=77567471-a2f3-4d71-90b0-13adde9d29a7, raftlog=77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
datanode_2    | 2019-11-15 20:36:51,794 INFO impl.LeaderElection: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA-LeaderElection2: begin an election at term 1 for -1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="Move region to single row"
datanode_3    | 2019-11-15 20:36:52,089 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2E58C2482BFA with new leaderId: 77567471-a2f3-4d71-90b0-13adde9d29a7
datanode_1    | 2019-11-15 20:36:52,025 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: shutdown LeaderElection
datanode_2    | 2019-11-15 20:36:52,024 INFO impl.LeaderElection: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA-LeaderElection2: Election REJECTED; received 2 response(s) [0da639d9-8110-428c-9b35-ccc8d6563a72<-00262ab3-1a02-4972-af0f-1fdc62478d5f#0:FAIL-t1, 0da639d9-8110-428c-9b35-ccc8d6563a72<-77567471-a2f3-4d71-90b0-13adde9d29a7#0:FAIL-t1] and 0 exception(s); 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA:t1, leader=null, voted=0da639d9-8110-428c-9b35-ccc8d6563a72, raftlog=0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="create test_data table"
datanode_3    | 2019-11-15 20:36:52,090 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA: change Leader from null to 77567471-a2f3-4d71-90b0-13adde9d29a7 at term 1 for appendEntries, leader elected after 5174ms
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_version table v1"
datanode_2    | 2019-11-15 20:36:52,026 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_1    | 2019-11-15 20:36:52,026 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3    | 2019-11-15 20:36:52,106 INFO impl.RaftServerImpl: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA: set configuration 0: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null at 0
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard_version.dashboard_id"
datanode_2    | 2019-11-15 20:36:52,026 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: shutdown LeaderElection
datanode_1    | 2019-11-15 20:36:52,026 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2E58C2482BFA with new leaderId: 77567471-a2f3-4d71-90b0-13adde9d29a7
datanode_3    | 2019-11-15 20:36:52,106 INFO segmented.SegmentedRaftLogWorker: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2    | 2019-11-15 20:36:52,026 INFO impl.RoleInfo: 0da639d9-8110-428c-9b35-ccc8d6563a72: start FollowerState
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_version.dashboard_id and dashboard_version.version"
datanode_1    | 2019-11-15 20:36:52,026 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA: change Leader from null to 77567471-a2f3-4d71-90b0-13adde9d29a7 at term 1 for becomeLeader, leader elected after 5648ms
datanode_3    | 2019-11-15 20:36:52,158 INFO segmented.SegmentedRaftLogWorker: 00262ab3-1a02-4972-af0f-1fdc62478d5f@group-2E58C2482BFA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa/current/log_inprogress_0
datanode_2    | 2019-11-15 20:36:52,097 INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2E58C2482BFA with new leaderId: 77567471-a2f3-4d71-90b0-13adde9d29a7
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="Set dashboard version to 1 where 0"
datanode_1    | 2019-11-15 20:36:52,026 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="save existing dashboard data in dashboard_version table v1"
datanode_1    | 2019-11-15 20:36:52,027 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2    | 2019-11-15 20:36:52,098 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA: change Leader from null to 77567471-a2f3-4d71-90b0-13adde9d29a7 at term 1 for appendEntries, leader elected after 5390ms
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard_version.data to mediumtext v1"
datanode_1    | 2019-11-15 20:36:52,027 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_2    | 2019-11-15 20:36:52,113 INFO impl.RaftServerImpl: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA: set configuration 0: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null at 0
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="create team table"
datanode_2    | 2019-11-15 20:36:52,113 INFO segmented.SegmentedRaftLogWorker: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-15 20:36:52,027 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="add index team.org_id"
datanode_2    | 2019-11-15 20:36:52,158 INFO segmented.SegmentedRaftLogWorker: 0da639d9-8110-428c-9b35-ccc8d6563a72@group-2E58C2482BFA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa/current/log_inprogress_0
datanode_1    | 2019-11-15 20:36:52,027 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index team_org_id_name"
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="create team member table"
datanode_1    | 2019-11-15 20:36:52,028 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="add index team_member.org_id"
datanode_1    | 2019-11-15 20:36:52,029 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index team_member_org_id_team_id_user_id"
datanode_1    | 2019-11-15 20:36:52,030 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="Add column email to team table"
datanode_1    | 2019-11-15 20:36:52,030 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
grafana_1     | t=2019-11-15T20:36:45+0000 lvl=info msg="Executing migration" logger=migrator id="Add column external to team_member table"
datanode_1    | 2019-11-15 20:36:52,033 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="Add column permission to team_member table"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard acl table"
datanode_1    | 2019-11-15 20:36:52,033 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard_acl_dashboard_id"
datanode_1    | 2019-11-15 20:36:52,033 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_acl_dashboard_id_user_id"
datanode_1    | 2019-11-15 20:36:52,035 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_acl_dashboard_id_team_id"
datanode_1    | 2019-11-15 20:36:52,036 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="save default acl rules in dashboard_acl table"
datanode_1    | 2019-11-15 20:36:52,036 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="create tag table"
datanode_1    | 2019-11-15 20:36:52,036 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="add index tag.key_value"
datanode_1    | 2019-11-15 20:36:52,036 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1    | 2019-11-15 20:36:52,036 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="create login attempt table"
datanode_1    | 2019-11-15 20:36:52,036 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="add index login_attempt.username"
datanode_1    | 2019-11-15 20:36:52,038 INFO impl.RoleInfo: 77567471-a2f3-4d71-90b0-13adde9d29a7: start LeaderState
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_login_attempt_username - v1"
datanode_1    | 2019-11-15 20:36:52,039 INFO segmented.SegmentedRaftLogWorker: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA-SegmentedRaftLogWorker: Starting segment from index:0
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table login_attempt to login_attempt_tmp_qwerty - v1"
datanode_1    | 2019-11-15 20:36:52,040 INFO impl.RaftServerImpl: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA: set configuration 0: [0da639d9-8110-428c-9b35-ccc8d6563a72:172.19.0.7:9858, 00262ab3-1a02-4972-af0f-1fdc62478d5f:172.19.0.6:9858, 77567471-a2f3-4d71-90b0-13adde9d29a7:172.19.0.4:9858], old=null at 0
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="create login_attempt v2"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_login_attempt_username - v2"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="copy login_attempt v1 to v2"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="drop login_attempt_tmp_qwerty"
datanode_1    | 2019-11-15 20:36:52,088 INFO segmented.SegmentedRaftLogWorker: 77567471-a2f3-4d71-90b0-13adde9d29a7@group-2E58C2482BFA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fbba235a-0a21-4967-a2e1-2e58c2482bfa/current/log_inprogress_0
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="create user auth table"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_user_auth_auth_module_auth_id - v1"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="alter user_auth.auth_id to length 190"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth access token to user_auth"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth refresh token to user_auth"
grafana_1     | t=2019-11-15T20:36:46+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth token type to user_auth"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth expiry to user_auth"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="Add index to user_id column in user_auth"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="create server_lock table"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="add index server_lock.operation_uid"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="create user auth token table"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user_auth_token.auth_token"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user_auth_token.prev_auth_token"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="create cache_data table"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index cache_data.cache_key"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Created default admin" logger=sqlstore user=admin
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing HTTPServer" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing InternalMetricsService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing RemoteCache" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing QuotaService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing ServerLockService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing UserAuthTokenService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing PluginManager" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Starting plugin search" logger=plugins
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing RenderingService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing AlertEngine" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing DatasourceCacheService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing HooksService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing LoginService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing SearchService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing TracingService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing UsageStatsService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing CleanUpService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing NotificationService" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing provisioningServiceImpl" logger=server
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=warn msg="[Deprecated] the datasource provisioning config is outdated. please upgrade" logger=provisioning.datasources filename=/etc/grafana/provisioning/datasources/datasources.yml
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="inserting datasource from configuration " logger=provisioning.datasources name=Prometheus
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=eror msg="Can't read alert notification provisioning files from directory" logger=provisioning.notifiers path=/etc/grafana/provisioning/notifiers error="open /etc/grafana/provisioning/notifiers: no such file or directory"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=warn msg="[Deprecated] the dashboard provisioning config is outdated. please upgrade" logger=provisioning.dashboard filename=/etc/grafana/provisioning/dashboards/dashboards.yml
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=warn msg="[Deprecated] The folder property is deprecated. Please use path instead." logger=provisioning.dashboard type=file name=default
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Backend rendering via phantomJS" logger=rendering
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=warn msg="phantomJS is deprecated and will be removed in a future release. You should consider migrating from phantomJS to grafana-image-renderer plugin." logger=rendering
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="Initializing Stream Manager"
grafana_1     | t=2019-11-15T20:36:47+0000 lvl=info msg="HTTP Server Listen" logger=http.server address=0.0.0.0:3000 protocol=http subUrl= socket=
