2019-11-13 21:11:46,193 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:11:46,290 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:11:46,296 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:11:46,333 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @841ms
2019-11-13 21:11:46,435 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-13 21:11:46,436 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-13 21:11:46,436 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-13 21:11:46,436 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-13 21:11:46,437 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-13 21:11:46,437 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-13 21:11:46,448 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-13 21:11:46,448 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-13 21:11:46,449 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-13 21:11:46,723 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@4e7593f5
2019-11-13 21:11:46,725 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-13 21:11:46,782 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-13 21:11:46,783 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-13 21:11:46,785 [Thread-0] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-13 21:11:46,837 [Thread-0] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-13 21:11:46,849 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:11:46,912 [Thread-0] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-13 21:11:46,914 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:11:47,023 [Thread-0] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-11-13 21:11:47,364 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:11:47,389 [Socket Reader #1 for port 37577] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37577
2019-11-13 21:11:47,532 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:11:47,533 [Socket Reader #1 for port 41520] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41520
2019-11-13 21:11:47,543 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:11:47,544 [Socket Reader #1 for port 37324] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37324
2019-11-13 21:11:47,569 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-13 21:11:47,753 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:11:47,762 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:11:47,770 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:11:47,773 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-13 21:11:47,773 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:11:47,773 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:11:47,804 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(764)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37324
2019-11-13 21:11:47,871 [Thread-0] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-13 21:11:47,884 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-13 21:11:47,884 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-13 21:11:48,118 [Thread-0] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:37324
2019-11-13 21:11:48,119 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:11:48,119 [IPC Server listener on 37324] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37324: starting
2019-11-13 21:11:48,122 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(774)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:41520
2019-11-13 21:11:48,122 [Thread-0] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:41520
2019-11-13 21:11:48,123 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:11:48,123 [IPC Server listener on 41520] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41520: starting
2019-11-13 21:11:48,125 [Thread-0] INFO  server.StorageContainerManager (StorageContainerManager.java:start(778)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:37577
2019-11-13 21:11:48,125 [Thread-0] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:37577
2019-11-13 21:11:48,126 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:11:48,126 [IPC Server listener on 37577] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37577: starting
2019-11-13 21:11:48,129 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46256
2019-11-13 21:11:48,131 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:11:48,167 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@585d2e09{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:11:48,168 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4476dfc1{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-13 21:12:00,823 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f907ee5{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-13 21:12:00,830 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@49ec53c3{HTTP/1.1,[http/1.1]}{0.0.0.0:46256}
2019-11-13 21:12:00,830 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @15339ms
2019-11-13 21:12:00,832 [Thread-0] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-11-13 21:12:00,832 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-11-13 21:12:00,834 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:46256
2019-11-13 21:12:00,841 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@eab9cba] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-13 21:12:00,845 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:00,968 [Thread-0] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-11-13 21:12:00,968 [Thread-0] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-11-13 21:12:00,970 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:00,971 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:01,549 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:01,556 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-13 21:12:01,556 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-13 21:12:01,556 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-13 21:12:01,556 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-13 21:12:01,557 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-13 21:12:01,557 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-13 21:12:01,557 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-13 21:12:01,557 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-13 21:12:01,557 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-13 21:12:01,558 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-13 21:12:01,558 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-13 21:12:01,558 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-13 21:12:01,558 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-13 21:12:01,558 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-13 21:12:01,558 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-13 21:12:01,559 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-13 21:12:01,559 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-13 21:12:01,559 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-13 21:12:01,559 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-13 21:12:01,559 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-13 21:12:01,560 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-13 21:12:01,560 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-13 21:12:01,560 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-13 21:12:01,560 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-13 21:12:01,560 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-13 21:12:02,013 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:12:02,014 [Socket Reader #1 for port 45692] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45692
2019-11-13 21:12:02,034 [Thread-0] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45692
2019-11-13 21:12:02,035 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-13 21:12:02,043 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:12:02,043 [IPC Server listener on 45692] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45692: starting
2019-11-13 21:12:02,049 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-11-13 21:12:02,051 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:12:02,051 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:12:02,054 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:12:02,055 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-13 21:12:02,055 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:12:02,055 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:12:02,057 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38190
2019-11-13 21:12:02,057 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:12:02,059 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1bfa38ad{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:12:02,060 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@79800f24{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-13 21:12:02,066 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5ad639bd{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-13 21:12:02,067 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4e46532d{HTTP/1.1,[http/1.1]}{0.0.0.0:38190}
2019-11-13 21:12:02,067 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @16575ms
2019-11-13 21:12:02,067 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:02,068 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:38190
2019-11-13 21:12:02,305 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-13 21:12:02,353 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2471-xp76p-3136957074 ip:192.168.34.36
2019-11-13 21:12:02,385 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:12:02,387 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/containers/hdds to VolumeSet
2019-11-13 21:12:02,391 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/containers/hdds
2019-11-13 21:12:02,407 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/containers/hdds
2019-11-13 21:12:02,520 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:12:02,576 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:12:02,580 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:12:02,581 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:12:02,582 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:02,583 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:12:02,584 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:12:02,759 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis] (custom)
2019-11-13 21:12:02,802 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-13 21:12:02,804 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:12:02,804 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:12:02,806 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:12:02,806 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-13 21:12:02,806 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:12:02,807 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:12:02,807 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41085
2019-11-13 21:12:02,807 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:12:02,810 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@132d0084{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:12:02,810 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a961a1f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-13 21:12:02,841 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2023fdd6{/,file:///tmp/jetty-0.0.0.0-41085-hddsDatanode-_-any-7793148560136717847.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-13 21:12:02,841 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7655096e{HTTP/1.1,[http/1.1]}{0.0.0.0:41085}
2019-11-13 21:12:02,842 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @17350ms
2019-11-13 21:12:02,842 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:02,843 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41085
2019-11-13 21:12:02,844 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-13 21:12:02,847 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2471-xp76p-3136957074 ip:192.168.34.36
2019-11-13 21:12:02,850 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f5595aa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-13 21:12:02,855 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:12:02,856 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/containers/hdds to VolumeSet
2019-11-13 21:12:02,856 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/containers/hdds
2019-11-13 21:12:02,856 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/containers/hdds
2019-11-13 21:12:02,874 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:12:02,874 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:12:02,875 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:12:02,875 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:12:02,875 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:02,875 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:12:02,875 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:12:02,876 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis] (custom)
2019-11-13 21:12:02,879 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-13 21:12:02,881 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:12:02,881 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:12:02,883 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:12:02,884 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-13 21:12:02,884 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:12:02,884 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:12:02,885 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37465
2019-11-13 21:12:02,886 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:12:02,888 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@602c12e3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:12:02,889 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f07760c{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-13 21:12:02,919 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7e78caef{/,file:///tmp/jetty-0.0.0.0-37465-hddsDatanode-_-any-4974078036306865771.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-13 21:12:02,920 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@444aad14{HTTP/1.1,[http/1.1]}{0.0.0.0:37465}
2019-11-13 21:12:02,920 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @17429ms
2019-11-13 21:12:02,920 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:02,922 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37465
2019-11-13 21:12:02,922 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-13 21:12:02,925 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d16865a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-13 21:12:02,925 [Thread-0] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2471-xp76p-3136957074 ip:192.168.34.36
2019-11-13 21:12:02,933 [Thread-0] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:12:02,933 [Thread-0] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/containers/hdds to VolumeSet
2019-11-13 21:12:02,933 [Thread-0] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/containers/hdds
2019-11-13 21:12:02,934 [Thread-0] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/containers/hdds
2019-11-13 21:12:02,954 [Thread-0] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:12:02,954 [Thread-0] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:12:02,954 [Thread-0] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:12:02,954 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:12:02,955 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:02,955 [Thread-0] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:12:02,955 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:12:02,956 [Thread-0] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis] (custom)
2019-11-13 21:12:02,958 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-13 21:12:02,959 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:12:02,960 [Thread-0] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:12:02,962 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:12:02,963 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-13 21:12:02,963 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:12:02,963 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:12:02,964 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46535
2019-11-13 21:12:02,964 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:12:02,966 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4c764e45{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:12:02,967 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3eb13326{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-13 21:12:02,984 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/meta/datanode.id
2019-11-13 21:12:02,988 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/meta/datanode.id
2019-11-13 21:12:03,001 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6ae8031d{/,file:///tmp/jetty-0.0.0.0-46535-hddsDatanode-_-any-132471599747458640.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-13 21:12:03,002 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@28efa098{HTTP/1.1,[http/1.1]}{0.0.0.0:46535}
2019-11-13 21:12:03,002 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @17511ms
2019-11-13 21:12:03,002 [Thread-0] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:03,003 [Thread-0] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46535
2019-11-13 21:12:03,005 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-13 21:12:03,005 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@367c17d4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-13 21:12:03,007 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/meta/datanode.id
2019-11-13 21:12:04,005 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-13 21:12:04,919 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-13 21:12:04,921 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-13 21:12:04,921 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis 83d27baa-a595-4197-bc95-cb8c106ef314 at port 0
2019-11-13 21:12:04,937 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-13 21:12:04,943 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-13 21:12:04,943 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis 53201d18-a1e5-43a8-8953-92c0f3b7c0d4 at port 0
2019-11-13 21:12:04,947 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 83d27baa-a595-4197-bc95-cb8c106ef314: start RPC server
2019-11-13 21:12:04,954 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: start RPC server
2019-11-13 21:12:05,006 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-13 21:12:05,021 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-13 21:12:05,023 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-13 21:12:05,023 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis 0f40a9ab-a8fb-429a-9389-ae765353667d at port 0
2019-11-13 21:12:05,030 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: start RPC server
2019-11-13 21:12:05,093 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 83d27baa-a595-4197-bc95-cb8c106ef314: GrpcService started, listening on 0.0.0.0/0.0.0.0:35890
2019-11-13 21:12:05,093 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: GrpcService started, listening on 0.0.0.0/0.0.0.0:36311
2019-11-13 21:12:05,093 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: GrpcService started, listening on 0.0.0.0/0.0.0.0:42944
2019-11-13 21:12:05,094 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis 0f40a9ab-a8fb-429a-9389-ae765353667d is started using port 36311
2019-11-13 21:12:05,094 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis 83d27baa-a595-4197-bc95-cb8c106ef314 is started using port 35890
2019-11-13 21:12:05,094 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis 53201d18-a1e5-43a8-8953-92c0f3b7c0d4 is started using port 42944
2019-11-13 21:12:05,098 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 83d27baa-a595-4197-bc95-cb8c106ef314 is started using port 32790
2019-11-13 21:12:05,098 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 53201d18-a1e5-43a8-8953-92c0f3b7c0d4 is started using port 36376
2019-11-13 21:12:05,098 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 0f40a9ab-a8fb-429a-9389-ae765353667d is started using port 38431
2019-11-13 21:12:06,006 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-11-13 21:12:06,888 [IPC Server handler 17 on 37577] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/83d27baa-a595-4197-bc95-cb8c106ef314
2019-11-13 21:12:06,888 [IPC Server handler 17 on 37577] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : 83d27baa-a595-4197-bc95-cb8c106ef314{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}
2019-11-13 21:12:06,891 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-11-13 21:12:06,892 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-11-13 21:12:06,892 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-11-13 21:12:06,928 [IPC Server handler 13 on 37577] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/53201d18-a1e5-43a8-8953-92c0f3b7c0d4
2019-11-13 21:12:06,929 [IPC Server handler 13 on 37577] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : 53201d18-a1e5-43a8-8953-92c0f3b7c0d4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}
2019-11-13 21:12:07,008 [IPC Server handler 19 on 37577] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/0f40a9ab-a8fb-429a-9389-ae765353667d
2019-11-13 21:12:07,009 [IPC Server handler 19 on 37577] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : 0f40a9ab-a8fb-429a-9389-ae765353667d{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}
2019-11-13 21:12:07,372 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 83d27baa-a595-4197-bc95-cb8c106ef314: addNew group-DFB96B908DE4:[83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890] returns group-DFB96B908DE4:java.util.concurrent.CompletableFuture@3f8e8502[Not completed]
2019-11-13 21:12:07,386 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 83d27baa-a595-4197-bc95-cb8c106ef314: new RaftServerImpl for group-DFB96B908DE4:[83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890] with ContainerStateMachine:uninitialized
2019-11-13 21:12:07,389 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:07,390 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:07,390 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:07,391 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:07,392 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:07,402 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4: ConfigurationManager, init=-1: [83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:07,402 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis] (custom)
2019-11-13 21:12:07,410 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:07,412 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/2a88603b-10b4-457a-b101-dfb96b908de4 does not exist. Creating ...
2019-11-13 21:12:09,899 [Thread-179] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-11-13 21:12:09,901 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-11-13 21:12:10,079 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@4287a5c6 for 83d27baa-a595-4197-bc95-cb8c106ef314
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2962463015ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:220)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2962463015ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-11-13 21:12:10,110 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 83d27baa-a595-4197-bc95-cb8c106ef314: addNew group-89EA91871BF8:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] returns group-89EA91871BF8:java.util.concurrent.CompletableFuture@4f1f6fd7[Not completed]
2019-11-13 21:12:10,110 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: addNew group-89EA91871BF8:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] returns group-89EA91871BF8:java.util.concurrent.CompletableFuture@3a93d743[Not completed]
2019-11-13 21:12:10,125 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: new RaftServerImpl for group-89EA91871BF8:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] with ContainerStateMachine:uninitialized
2019-11-13 21:12:10,127 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:10,128 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:10,128 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:10,128 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:10,128 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:10,128 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8: ConfigurationManager, init=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:10,129 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis] (custom)
2019-11-13 21:12:10,130 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: addNew group-89EA91871BF8:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] returns group-89EA91871BF8:java.util.concurrent.CompletableFuture@b638901[Not completed]
2019-11-13 21:12:10,130 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:10,141 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: new RaftServerImpl for group-89EA91871BF8:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] with ContainerStateMachine:uninitialized
2019-11-13 21:12:10,142 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:10,142 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:10,142 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:10,142 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:10,142 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:10,142 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8: ConfigurationManager, init=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:10,143 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis] (custom)
2019-11-13 21:12:10,143 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:12,933 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8 does not exist. Creating ...
2019-11-13 21:12:12,933 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8 does not exist. Creating ...
2019-11-13 21:12:13,095 [RATISCREATEPIPELINE3] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@4d896397 for 0f40a9ab-a8fb-429a-9389-ae765353667d
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2998685418ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998685418ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
2019-11-13 21:12:13,096 [RATISCREATEPIPELINE2] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@4d896397 for 53201d18-a1e5-43a8-8953-92c0f3b7c0d4
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2998488218ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998488218ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
2019-11-13 21:12:13,096 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@4d896397 for 83d27baa-a595-4197-bc95-cb8c106ef314
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2998775573ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:220)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998775573ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-11-13 21:12:13,098 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-11-13 21:12:13,110 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: addNew group-7400C6767D61:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944] returns group-7400C6767D61:java.util.concurrent.CompletableFuture@77a21788[Not completed]
2019-11-13 21:12:16,107 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@e2a014b for 53201d18-a1e5-43a8-8953-92c0f3b7c0d4
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999760193ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:220)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999760193ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-11-13 21:12:16,134 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 83d27baa-a595-4197-bc95-cb8c106ef314: addNew group-A511C2F51256:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] returns group-A511C2F51256:java.util.concurrent.CompletableFuture@10c02f09[Not completed]
2019-11-13 21:12:16,138 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: addNew group-A511C2F51256:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] returns group-A511C2F51256:java.util.concurrent.CompletableFuture@723ec30d[Not completed]
2019-11-13 21:12:16,139 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: addNew group-A511C2F51256:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] returns group-A511C2F51256:java.util.concurrent.CompletableFuture@f88a1c6[Not completed]
2019-11-13 21:12:16,154 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(352)) - Shutting down the Mini Ozone Cluster
2019-11-13 21:12:16,155 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(368)) - Stopping the Mini Ozone Cluster
2019-11-13 21:12:16,155 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(438)) - Stopping the OzoneManager
2019-11-13 21:12:16,156 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45692
2019-11-13 21:12:16,159 [IPC Server listener on 45692] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45692
2019-11-13 21:12:16,159 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-13 21:12:16,160 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:12:16,162 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-13 21:12:16,165 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-13 21:12:18,345 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:18,345 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/2a88603b-10b4-457a-b101-dfb96b908de4/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:18,345 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:18,361 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5ad639bd{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-13 21:12:18,369 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4e46532d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-13 21:12:18,371 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@79800f24{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-13 21:12:18,372 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1bfa38ad{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:12:18,380 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(415)) - Stopping the HddsDatanodes
2019-11-13 21:12:18,852 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-13 21:12:18,926 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-13 21:12:19,118 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@125992e7 for 83d27baa-a595-4197-bc95-cb8c106ef314
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999051046ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:220)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999051046ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-11-13 21:12:19,122 [RATISCREATEPIPELINE2] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@125992e7 for 0f40a9ab-a8fb-429a-9389-ae765353667d
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2997719902ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2997719902ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
2019-11-13 21:12:19,122 [RATISCREATEPIPELINE3] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@125992e7 for 53201d18-a1e5-43a8-8953-92c0f3b7c0d4
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999057772ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999057772ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 15 more
2019-11-13 21:12:19,125 [Thread-0] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-11-13 21:12:19,133 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-11-13 21:12:19,139 [Thread-0] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:close(218)) - Unexpected exception while waiting for channel termination
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:277)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImpl.awaitTermination(ManagedChannelImpl.java:763)
	at org.apache.ratis.thirdparty.io.grpc.internal.ForwardingManagedChannel.awaitTermination(ForwardingManagedChannel.java:57)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.awaitTermination(ManagedChannelOrphanWrapper.java:70)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.close(XceiverClientGrpc.java:216)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testStartMultipleDatanodes(TestMiniOzoneCluster.java:123)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2019-11-13 21:12:19,221 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8 has been successfully formatted.
2019-11-13 21:12:19,221 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8 has been successfully formatted.
2019-11-13 21:12:19,223 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/2a88603b-10b4-457a-b101-dfb96b908de4 has been successfully formatted.
2019-11-13 21:12:19,226 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-DFB96B908DE4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:19,226 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-89EA91871BF8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:19,226 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-89EA91871BF8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:19,228 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:19,228 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:19,228 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:19,233 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:19,233 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:19,233 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:19,243 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:19,243 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:19,243 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:19,244 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:19,243 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:19,244 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:19,248 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,248 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,248 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,255 [pool-37-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-11-13 21:12:19,265 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,265 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,265 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,277 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:19,277 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:19,277 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:19,286 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8
2019-11-13 21:12:19,286 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/2a88603b-10b4-457a-b101-dfb96b908de4
2019-11-13 21:12:19,286 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8
2019-11-13 21:12:19,287 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:19,287 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:19,287 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:19,288 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:19,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:19,288 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:19,289 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,289 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,289 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,290 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:19,290 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:19,290 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:19,290 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:19,290 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:19,290 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:19,291 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:19,291 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:19,291 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:19,292 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:19,292 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:19,292 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:19,292 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:19,292 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:19,292 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:19,293 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:19,293 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:19,293 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:19,304 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:19,304 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:19,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:19,309 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:19,309 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:19,309 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:19,315 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:19,315 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:19,315 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:19,316 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:19,316 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:19,316 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:19,317 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:19,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:19,317 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:19,317 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:19,317 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:19,317 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:19,341 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,341 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,341 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,343 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,343 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,343 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,347 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: new RaftServerImpl for group-7400C6767D61:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944] with ContainerStateMachine:uninitialized
2019-11-13 21:12:19,347 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:19,347 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:19,348 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:19,348 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:19,348 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:19,348 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61: ConfigurationManager, init=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:19,348 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: new RaftServerImpl for group-A511C2F51256:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] with ContainerStateMachine:uninitialized
2019-11-13 21:12:19,348 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis] (custom)
2019-11-13 21:12:19,348 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:19,348 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:19,348 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:19,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:19,349 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/2c7df168-fd2a-4fc9-959a-7400c6767d61 does not exist. Creating ...
2019-11-13 21:12:19,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:19,349 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 83d27baa-a595-4197-bc95-cb8c106ef314: new RaftServerImpl for group-89EA91871BF8:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] with ContainerStateMachine:uninitialized
2019-11-13 21:12:19,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:19,349 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:19,349 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256: ConfigurationManager, init=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:19,349 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:19,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis] (custom)
2019-11-13 21:12:19,349 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:19,350 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:19,350 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:19,350 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:19,350 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8: ConfigurationManager, init=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:19,350 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256 does not exist. Creating ...
2019-11-13 21:12:19,350 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis] (custom)
2019-11-13 21:12:19,350 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:19,351 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8 does not exist. Creating ...
2019-11-13 21:12:19,363 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/2c7df168-fd2a-4fc9-959a-7400c6767d61/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:19,363 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:19,363 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:19,390 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/2c7df168-fd2a-4fc9-959a-7400c6767d61 has been successfully formatted.
2019-11-13 21:12:19,390 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8 has been successfully formatted.
2019-11-13 21:12:19,390 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256 has been successfully formatted.
2019-11-13 21:12:19,391 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-7400C6767D61: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:19,391 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-89EA91871BF8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:19,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:19,391 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-A511C2F51256: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:19,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:19,391 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:19,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:19,391 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:19,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:19,391 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:19,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:19,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:19,392 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:19,392 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/2c7df168-fd2a-4fc9-959a-7400c6767d61
2019-11-13 21:12:19,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:19,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:19,392 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:19,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:19,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:19,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,392 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:19,393 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:19,393 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:19,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:19,393 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:19,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:19,393 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/365d364c-37ec-47bf-a086-89ea91871bf8
2019-11-13 21:12:19,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:19,393 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256
2019-11-13 21:12:19,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:19,393 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:19,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:19,393 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:19,394 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:19,394 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:19,394 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:19,394 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,394 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:19,394 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,395 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:19,394 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:19,395 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:19,395 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:19,395 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:19,395 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:19,395 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:19,395 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:19,395 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,395 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:19,395 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:19,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:19,395 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:19,396 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:19,396 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:19,396 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:19,396 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:19,396 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:19,396 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:19,396 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:19,397 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:19,397 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:19,397 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:19,397 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:19,397 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:19,397 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:19,397 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:19,397 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:19,397 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,397 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,397 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: new RaftServerImpl for group-A511C2F51256:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] with ContainerStateMachine:uninitialized
2019-11-13 21:12:19,397 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,397 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:19,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:19,398 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8: start as a follower, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:19,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:19,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:19,398 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:19,398 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256: ConfigurationManager, init=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:19,399 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 83d27baa-a595-4197-bc95-cb8c106ef314: new RaftServerImpl for group-A511C2F51256:[53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311] with ContainerStateMachine:uninitialized
2019-11-13 21:12:19,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis] (custom)
2019-11-13 21:12:19,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:19,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:19,399 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:19,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:19,399 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:19,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:19,399 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256 does not exist. Creating ...
2019-11-13 21:12:19,399 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:19,399 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256: ConfigurationManager, init=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:19,400 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis] (custom)
2019-11-13 21:12:19,400 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:19,400 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256 does not exist. Creating ...
2019-11-13 21:12:19,400 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: start FollowerState
2019-11-13 21:12:19,402 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-89EA91871BF8,id=0f40a9ab-a8fb-429a-9389-ae765353667d
2019-11-13 21:12:19,403 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,404 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:19,404 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:19,411 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256: start as a follower, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:19,411 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:19,411 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: start FollowerState
2019-11-13 21:12:19,411 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A511C2F51256,id=0f40a9ab-a8fb-429a-9389-ae765353667d
2019-11-13 21:12:19,412 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,413 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256 has been successfully formatted.
2019-11-13 21:12:19,413 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256 has been successfully formatted.
2019-11-13 21:12:19,413 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-A511C2F51256: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:19,413 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-A511C2F51256: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:19,413 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:19,413 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:19,413 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:19,413 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:19,413 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:19,413 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:19,414 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:19,414 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:19,414 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,414 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,414 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:19,414 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:19,414 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256
2019-11-13 21:12:19,414 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/ratis/e95cde42-6f38-402c-a03d-a511c2f51256
2019-11-13 21:12:19,414 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:19,414 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:19,415 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:19,415 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:19,415 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,415 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:19,415 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:19,415 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:19,415 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:19,415 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:19,415 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:19,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:19,416 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:19,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:19,416 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:19,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:19,416 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:19,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:19,416 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:19,416 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:19,417 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:19,417 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:19,417 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:19,417 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:19,417 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:19,417 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:19,417 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:19,417 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:19,418 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:19,418 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:19,418 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,418 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,418 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,418 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,418 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4: start as a follower, conf=-1: [83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890], old=null
2019-11-13 21:12:19,418 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8: start as a follower, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:19,418 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:19,418 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:19,419 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 83d27baa-a595-4197-bc95-cb8c106ef314: start FollowerState
2019-11-13 21:12:19,419 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: start FollowerState
2019-11-13 21:12:19,420 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFB96B908DE4,id=83d27baa-a595-4197-bc95-cb8c106ef314
2019-11-13 21:12:19,420 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,420 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-89EA91871BF8,id=53201d18-a1e5-43a8-8953-92c0f3b7c0d4
2019-11-13 21:12:19,421 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,421 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8: start as a follower, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:19,421 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:19,421 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61: start as a follower, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944], old=null
2019-11-13 21:12:19,421 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 83d27baa-a595-4197-bc95-cb8c106ef314: start FollowerState
2019-11-13 21:12:19,423 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:19,423 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: start FollowerState
2019-11-13 21:12:19,423 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-89EA91871BF8,id=83d27baa-a595-4197-bc95-cb8c106ef314
2019-11-13 21:12:19,423 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,424 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7400C6767D61,id=53201d18-a1e5-43a8-8953-92c0f3b7c0d4
2019-11-13 21:12:19,424 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,424 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256: start as a follower, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:19,424 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:19,424 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256: start as a follower, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:19,424 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:19,424 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 83d27baa-a595-4197-bc95-cb8c106ef314: start FollowerState
2019-11-13 21:12:19,424 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: start FollowerState
2019-11-13 21:12:19,425 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A511C2F51256,id=83d27baa-a595-4197-bc95-cb8c106ef314
2019-11-13 21:12:19,425 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:19,425 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A511C2F51256,id=53201d18-a1e5-43a8-8953-92c0f3b7c0d4
2019-11-13 21:12:19,425 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:23,384 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:12:23,384 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:12:23,385 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 83d27baa-a595-4197-bc95-cb8c106ef314: close
2019-11-13 21:12:23,385 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: close
2019-11-13 21:12:23,387 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4: shutdown
2019-11-13 21:12:23,387 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8: shutdown
2019-11-13 21:12:23,388 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFB96B908DE4,id=83d27baa-a595-4197-bc95-cb8c106ef314
2019-11-13 21:12:23,388 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-89EA91871BF8,id=53201d18-a1e5-43a8-8953-92c0f3b7c0d4
2019-11-13 21:12:23,388 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 83d27baa-a595-4197-bc95-cb8c106ef314: shutdown FollowerState
2019-11-13 21:12:23,388 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: shutdown FollowerState
2019-11-13 21:12:23,389 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(120)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:23,389 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:23,390 [Thread-194] INFO  impl.FollowerState (FollowerState.java:run(120)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:23,393 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4: closes. applyIndex: -1
2019-11-13 21:12:23,389 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:23,394 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8: closes. applyIndex: -1
2019-11-13 21:12:23,398 [83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:23,398 [53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:23,399 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-DFB96B908DE4-SegmentedRaftLogWorker close()
2019-11-13 21:12:23,399 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-89EA91871BF8-SegmentedRaftLogWorker close()
2019-11-13 21:12:23,401 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8: shutdown
2019-11-13 21:12:23,402 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256: shutdown
2019-11-13 21:12:23,403 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-89EA91871BF8,id=83d27baa-a595-4197-bc95-cb8c106ef314
2019-11-13 21:12:23,403 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A511C2F51256,id=53201d18-a1e5-43a8-8953-92c0f3b7c0d4
2019-11-13 21:12:23,403 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: shutdown FollowerState
2019-11-13 21:12:23,403 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 83d27baa-a595-4197-bc95-cb8c106ef314: shutdown FollowerState
2019-11-13 21:12:23,404 [Thread-202] INFO  impl.FollowerState (FollowerState.java:run(120)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:23,405 [Thread-197] INFO  impl.FollowerState (FollowerState.java:run(120)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:23,404 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:23,404 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:23,406 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256: closes. applyIndex: -1
2019-11-13 21:12:23,406 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8: closes. applyIndex: -1
2019-11-13 21:12:23,407 [53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:23,407 [83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:23,407 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-A511C2F51256-SegmentedRaftLogWorker close()
2019-11-13 21:12:23,407 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-89EA91871BF8-SegmentedRaftLogWorker close()
2019-11-13 21:12:23,410 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61: shutdown
2019-11-13 21:12:23,412 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256: shutdown
2019-11-13 21:12:23,412 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7400C6767D61,id=53201d18-a1e5-43a8-8953-92c0f3b7c0d4
2019-11-13 21:12:23,412 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A511C2F51256,id=83d27baa-a595-4197-bc95-cb8c106ef314
2019-11-13 21:12:23,413 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: shutdown FollowerState
2019-11-13 21:12:23,413 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 83d27baa-a595-4197-bc95-cb8c106ef314: shutdown FollowerState
2019-11-13 21:12:23,413 [Thread-198] INFO  impl.FollowerState (FollowerState.java:run(120)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:23,414 [Thread-201] INFO  impl.FollowerState (FollowerState.java:run(120)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:23,413 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:23,416 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61: closes. applyIndex: -1
2019-11-13 21:12:23,414 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:23,417 [53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:23,417 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256: closes. applyIndex: -1
2019-11-13 21:12:23,417 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4@group-7400C6767D61-SegmentedRaftLogWorker close()
2019-11-13 21:12:23,417 [83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:23,419 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 83d27baa-a595-4197-bc95-cb8c106ef314@group-A511C2F51256-SegmentedRaftLogWorker close()
2019-11-13 21:12:23,421 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 83d27baa-a595-4197-bc95-cb8c106ef314: shutdown server with port 35890 now
2019-11-13 21:12:23,421 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: shutdown server with port 42944 now
2019-11-13 21:12:23,426 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 53201d18-a1e5-43a8-8953-92c0f3b7c0d4: shutdown server with port 42944 successfully
2019-11-13 21:12:23,426 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 83d27baa-a595-4197-bc95-cb8c106ef314: shutdown server with port 35890 successfully
2019-11-13 21:12:23,433 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:12:23,433 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:12:23,449 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:12:23,451 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-13 21:12:23,454 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2023fdd6{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-13 21:12:23,455 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7655096e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-13 21:12:23,455 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a961a1f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-13 21:12:23,456 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@132d0084{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:12:23,457 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:12:23,459 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-13 21:12:23,461 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7e78caef{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-13 21:12:23,461 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@444aad14{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-13 21:12:23,462 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f07760c{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-13 21:12:23,463 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@602c12e3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:12:24,007 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-13 21:12:24,497 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(111)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-FollowerState: change to CANDIDATE, lastRpcTime:5097ms, electionTimeout:5096ms
2019-11-13 21:12:24,498 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: shutdown FollowerState
2019-11-13 21:12:24,499 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-13 21:12:24,501 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: start LeaderElection
2019-11-13 21:12:24,516 [Thread-189] INFO  impl.FollowerState (FollowerState.java:run(111)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-FollowerState: change to CANDIDATE, lastRpcTime:5104ms, electionTimeout:5104ms
2019-11-13 21:12:24,516 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: shutdown FollowerState
2019-11-13 21:12:24,516 [Thread-189] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-13 21:12:24,516 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: start LeaderElection
2019-11-13 21:12:24,518 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1: begin an election at term 1 for -1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:24,541 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.34.36:35890
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-13 21:12:24,542 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.34.36:42944
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-13 21:12:24,544 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1: Election REJECTED; received 0 response(s) [] and 2 exception(s); 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8:t1, leader=null, voted=0f40a9ab-a8fb-429a-9389-ae765353667d, raftlog=0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:24,545 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.34.36:35890
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-13 21:12:24,545 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 1: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.34.36:42944
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-13 21:12:24,547 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-11-13 21:12:24,547 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: shutdown LeaderElection
2019-11-13 21:12:24,548 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: start FollowerState
2019-11-13 21:12:24,556 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2: begin an election at term 1 for -1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:24,558 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.34.36:42944
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-13 21:12:24,560 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.34.36:35890
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-13 21:12:24,561 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2: Election REJECTED; received 0 response(s) [] and 2 exception(s); 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256:t1, leader=null, voted=0f40a9ab-a8fb-429a-9389-ae765353667d, raftlog=0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [53201d18-a1e5-43a8-8953-92c0f3b7c0d4:192.168.34.36:42944, 83d27baa-a595-4197-bc95-cb8c106ef314:192.168.34.36:35890, 0f40a9ab-a8fb-429a-9389-ae765353667d:192.168.34.36:36311], old=null
2019-11-13 21:12:24,561 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.34.36:42944
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-13 21:12:24,562 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 1: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.34.36:35890
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-11-13 21:12:24,562 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-11-13 21:12:24,563 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: shutdown LeaderElection
2019-11-13 21:12:24,563 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: start FollowerState
2019-11-13 21:12:28,458 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:12:28,459 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: close
2019-11-13 21:12:28,459 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8: shutdown
2019-11-13 21:12:28,460 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-89EA91871BF8,id=0f40a9ab-a8fb-429a-9389-ae765353667d
2019-11-13 21:12:28,460 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: shutdown FollowerState
2019-11-13 21:12:28,460 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:28,460 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(120)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:28,460 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8: closes. applyIndex: -1
2019-11-13 21:12:28,461 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:28,461 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-89EA91871BF8-SegmentedRaftLogWorker close()
2019-11-13 21:12:28,462 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256: shutdown
2019-11-13 21:12:28,463 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A511C2F51256,id=0f40a9ab-a8fb-429a-9389-ae765353667d
2019-11-13 21:12:28,463 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: shutdown FollowerState
2019-11-13 21:12:28,463 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:28,463 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(120)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:28,464 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256: closes. applyIndex: -1
2019-11-13 21:12:28,464 [0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:28,464 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 0f40a9ab-a8fb-429a-9389-ae765353667d@group-A511C2F51256-SegmentedRaftLogWorker close()
2019-11-13 21:12:28,465 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: shutdown server with port 36311 now
2019-11-13 21:12:28,467 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 0f40a9ab-a8fb-429a-9389-ae765353667d: shutdown server with port 36311 successfully
2019-11-13 21:12:28,472 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6ab5ed07-0608-480c-a48b-a62a007c3075/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:12:28,485 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:12:28,486 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-13 21:12:28,488 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6ae8031d{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-13 21:12:28,489 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@28efa098{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-13 21:12:28,489 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3eb13326{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-13 21:12:28,490 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4c764e45{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:12:28,491 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(430)) - Stopping the StorageContainerManager
2019-11-13 21:12:28,491 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(802)) - Stopping Replication Manager Service.
2019-11-13 21:12:28,491 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-11-13 21:12:28,491 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(809)) - Stopping Lease Manager of the command watchers
2019-11-13 21:12:28,492 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping datanode service RPC server
2019-11-13 21:12:28,492 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-13 21:12:28,492 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37577
2019-11-13 21:12:28,493 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:12:28,493 [IPC Server listener on 37577] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37577
2019-11-13 21:12:28,563 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-11-13 21:12:28,564 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping block service RPC server
2019-11-13 21:12:28,564 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-13 21:12:28,564 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41520
2019-11-13 21:12:28,565 [IPC Server listener on 41520] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41520
2019-11-13 21:12:28,565 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:12:28,565 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-13 21:12:28,566 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-11-13 21:12:28,566 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37324
2019-11-13 21:12:28,567 [IPC Server listener on 37324] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37324
2019-11-13 21:12:28,567 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping Storage Container Manager HTTP server.
2019-11-13 21:12:28,567 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:12:28,569 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2f907ee5{/,null,UNAVAILABLE}{/scm}
2019-11-13 21:12:28,569 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@49ec53c3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-13 21:12:28,570 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4476dfc1{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-13 21:12:28,570 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@585d2e09{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:12:28,572 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(849)) - Stopping Block Manager Service.
2019-11-13 21:12:28,572 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-13 21:12:28,572 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-13 21:12:28,573 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping SCM Event Queue.
2019-11-13 21:12:28,580 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping XceiverClientMetrics metrics system...
2019-11-13 21:12:28,584 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-11-13 21:12:28,584 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - XceiverClientMetrics metrics system stopped.
2019-11-13 21:12:28,625 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:28,641 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:28,641 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:28,642 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-13 21:12:28,642 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-13 21:12:28,643 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-13 21:12:28,643 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-13 21:12:28,643 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-13 21:12:28,643 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-13 21:12:28,644 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-13 21:12:28,644 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-13 21:12:28,644 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-13 21:12:28,791 [Thread-213] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@6aa3f9eb
2019-11-13 21:12:28,791 [Thread-213] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-13 21:12:28,796 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-13 21:12:28,796 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-13 21:12:28,796 [Thread-213] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-13 21:12:28,797 [Thread-213] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-13 21:12:28,797 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:28,857 [Thread-213] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-13 21:12:28,857 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:28,923 [Thread-213] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-13 21:12:28,924 [Thread-213] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:12:28,925 [Socket Reader #1 for port 40150] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40150
2019-11-13 21:12:28,926 [Thread-213] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:12:28,927 [Socket Reader #1 for port 41940] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41940
2019-11-13 21:12:28,928 [Thread-213] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:12:28,928 [Socket Reader #1 for port 40705] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40705
2019-11-13 21:12:28,930 [Thread-213] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-11-13 21:12:28,932 [Thread-213] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:12:28,932 [Thread-213] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:12:28,934 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:12:28,935 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-13 21:12:28,935 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:12:28,935 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:12:28,937 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:start(764)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:40705
2019-11-13 21:12:28,939 [Thread-213] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-13 21:12:28,940 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-13 21:12:28,940 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-13 21:12:28,950 [Thread-213] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:28,959 [Thread-213] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:40705
2019-11-13 21:12:28,959 [IPC Server listener on 40705] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40705: starting
2019-11-13 21:12:28,959 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:12:28,962 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:start(774)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:41940
2019-11-13 21:12:28,963 [Thread-213] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:41940
2019-11-13 21:12:28,963 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:12:28,963 [IPC Server listener on 41940] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41940: starting
2019-11-13 21:12:28,966 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:start(778)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:40150
2019-11-13 21:12:28,966 [Thread-213] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:40150
2019-11-13 21:12:28,966 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:12:28,966 [IPC Server listener on 40150] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40150: starting
2019-11-13 21:12:28,972 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38980
2019-11-13 21:12:28,972 [Thread-213] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:12:28,974 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17504828{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:12:28,974 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@baf0299{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-13 21:12:28,979 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3b7bf0bf{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-13 21:12:28,980 [Thread-213] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a2fb4be{HTTP/1.1,[http/1.1]}{0.0.0.0:38980}
2019-11-13 21:12:28,980 [Thread-213] INFO  server.Server (Server.java:doStart(419)) - Started @43489ms
2019-11-13 21:12:28,980 [Thread-213] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:28,981 [Thread-213] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:38980
2019-11-13 21:12:28,982 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:28,982 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@484e1e83] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-13 21:12:28,991 [Thread-213] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-11-13 21:12:28,991 [Thread-213] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-11-13 21:12:28,992 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:28,992 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:29,000 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:12:29,001 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: userTable
2019-11-13 21:12:29,001 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-11-13 21:12:29,001 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: volumeTable
2019-11-13 21:12:29,001 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: bucketTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: keyTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: openKeyTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-11-13 21:12:29,002 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3Table
2019-11-13 21:12:29,003 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-11-13 21:12:29,003 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: multipartInfoTable
2019-11-13 21:12:29,003 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-11-13 21:12:29,003 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: dTokenTable
2019-11-13 21:12:29,003 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-11-13 21:12:29,003 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: s3SecretTable
2019-11-13 21:12:29,003 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-11-13 21:12:29,003 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: prefixTable
2019-11-13 21:12:29,004 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-11-13 21:12:29,004 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-13 21:12:29,004 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-13 21:12:29,004 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-13 21:12:29,351 [Thread-213] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:12:29,352 [Socket Reader #1 for port 42718] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42718
2019-11-13 21:12:29,366 [Thread-213] INFO  om.OzoneManager (OzoneManager.java:start(1077)) - OzoneManager RPC server is listening at localhost/127.0.0.1:42718
2019-11-13 21:12:29,366 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-11-13 21:12:29,367 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:12:29,367 [IPC Server listener on 42718] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42718: starting
2019-11-13 21:12:29,371 [Thread-213] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-11-13 21:12:29,373 [Thread-213] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:12:29,374 [Thread-213] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:12:29,376 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:12:29,377 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-11-13 21:12:29,377 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:12:29,378 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:12:29,379 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34299
2019-11-13 21:12:29,379 [Thread-213] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:12:29,382 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@647d443e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:12:29,382 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57ef3d5e{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-13 21:12:29,388 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6f9edf1c{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-11-13 21:12:29,389 [Thread-213] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@413ca981{HTTP/1.1,[http/1.1]}{0.0.0.0:34299}
2019-11-13 21:12:29,390 [Thread-213] INFO  server.Server (Server.java:doStart(419)) - Started @43898ms
2019-11-13 21:12:29,390 [Thread-213] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:29,391 [Thread-213] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:34299
2019-11-13 21:12:29,396 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-11-13 21:12:29,398 [Thread-213] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2471-xp76p-3136957074 ip:192.168.34.36
2019-11-13 21:12:29,405 [Thread-213] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:12:29,405 [Thread-213] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers/hdds to VolumeSet
2019-11-13 21:12:29,405 [Thread-213] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers/hdds
2019-11-13 21:12:29,406 [Thread-213] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers/hdds
2019-11-13 21:12:29,420 [Thread-213] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:12:29,420 [Thread-213] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:12:29,421 [Thread-213] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:12:29,421 [Thread-213] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:12:29,421 [Thread-213] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:29,421 [Thread-213] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:12:29,421 [Thread-213] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:12:29,422 [Thread-213] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis] (custom)
2019-11-13 21:12:29,424 [Thread-213] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-11-13 21:12:29,425 [Thread-213] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:12:29,426 [Thread-213] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:12:29,427 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:12:29,427 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-13 21:12:29,427 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:12:29,428 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:12:29,428 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46054
2019-11-13 21:12:29,428 [Thread-213] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:12:29,430 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a962468{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:12:29,430 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4707af00{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-13 21:12:29,458 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33fac1df{/,file:///tmp/jetty-0.0.0.0-46054-hddsDatanode-_-any-8027931501492447389.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-13 21:12:29,460 [Thread-213] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4ae8e00b{HTTP/1.1,[http/1.1]}{0.0.0.0:46054}
2019-11-13 21:12:29,460 [Thread-213] INFO  server.Server (Server.java:doStart(419)) - Started @43968ms
2019-11-13 21:12:29,460 [Thread-213] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:29,461 [Thread-213] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46054
2019-11-13 21:12:29,461 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:29,464 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7cbe787d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-13 21:12:29,466 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/meta/datanode.id
2019-11-13 21:12:30,462 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:31,462 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:32,463 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:33,463 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:34,463 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:35,464 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:36,464 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:37,465 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:38,465 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:39,060 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-13 21:12:39,062 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-13 21:12:39,062 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis 29583b98-1758-46ab-9f2b-3fd37412daa4 at port 0
2019-11-13 21:12:39,070 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: start RPC server
2019-11-13 21:12:39,075 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: GrpcService started, listening on 0.0.0.0/0.0.0.0:41483
2019-11-13 21:12:39,075 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis 29583b98-1758-46ab-9f2b-3fd37412daa4 is started using port 41483
2019-11-13 21:12:39,076 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 29583b98-1758-46ab-9f2b-3fd37412daa4 is started using port 39767
2019-11-13 21:12:39,467 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:12:39,469 [IPC Server handler 0 on 40150] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:12:39,470 [IPC Server handler 0 on 40150] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : 29583b98-1758-46ab-9f2b-3fd37412daa4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}
2019-11-13 21:12:39,471 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-11-13 21:12:39,472 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-11-13 21:12:39,472 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-11-13 21:12:39,487 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: addNew group-86BBF7607A21:[29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483] returns group-86BBF7607A21:java.util.concurrent.CompletableFuture@674a3cbc[Not completed]
2019-11-13 21:12:39,489 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: new RaftServerImpl for group-86BBF7607A21:[29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483] with ContainerStateMachine:uninitialized
2019-11-13 21:12:39,489 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:39,490 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:39,490 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:39,490 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:39,490 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:39,490 [pool-77-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: ConfigurationManager, init=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:39,490 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis] (custom)
2019-11-13 21:12:39,490 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:39,491 [pool-77-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/b6c333e2-c68b-48ae-9be4-86bbf7607a21 does not exist. Creating ...
2019-11-13 21:12:42,474 [Thread-355] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-11-13 21:12:42,476 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-11-13 21:12:42,480 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@48dd3771 for 29583b98-1758-46ab-9f2b-3fd37412daa4
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999150821ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:220)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999150821ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-11-13 21:12:42,494 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: addNew group-9EBE94559A43:[29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483] returns group-9EBE94559A43:java.util.concurrent.CompletableFuture@62de9fbc[Not completed]
2019-11-13 21:12:45,492 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(230)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$189/1030196737@2d561da for 29583b98-1758-46ab-9f2b-3fd37412daa4
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2998985378ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:184)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:153)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:278)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:205)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:191)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:226)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:220)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2998985378ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:155)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:182)
	... 25 more
2019-11-13 21:12:45,494 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-11-13 21:12:45,494 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(802)) - Stopping Replication Manager Service.
2019-11-13 21:12:45,495 [Thread-213] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-11-13 21:12:45,495 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(809)) - Stopping Lease Manager of the command watchers
2019-11-13 21:12:45,495 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping datanode service RPC server
2019-11-13 21:12:45,495 [Thread-213] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-13 21:12:45,495 [Thread-213] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40150
2019-11-13 21:12:45,498 [IPC Server listener on 40150] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40150
2019-11-13 21:12:45,499 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:12:45,520 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-11-13 21:12:45,520 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping block service RPC server
2019-11-13 21:12:45,520 [Thread-213] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-13 21:12:45,520 [Thread-213] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41940
2019-11-13 21:12:45,521 [IPC Server listener on 41940] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41940
2019-11-13 21:12:45,521 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:12:45,521 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-13 21:12:45,522 [Thread-213] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-11-13 21:12:45,523 [Thread-213] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40705
2019-11-13 21:12:45,523 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping Storage Container Manager HTTP server.
2019-11-13 21:12:45,524 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:12:45,523 [IPC Server listener on 40705] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40705
2019-11-13 21:12:45,525 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3b7bf0bf{/,null,UNAVAILABLE}{/scm}
2019-11-13 21:12:45,526 [Thread-213] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1a2fb4be{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-13 21:12:45,526 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@baf0299{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-13 21:12:45,526 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17504828{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:12:45,527 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(849)) - Stopping Block Manager Service.
2019-11-13 21:12:45,527 [Thread-213] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-13 21:12:45,527 [Thread-213] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-13 21:12:45,527 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping SCM Event Queue.
2019-11-13 21:12:46,469 [Datanode State Machine Thread - 3] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:40150 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "pr-hdds-2471-xp76p-3136957074/192.168.34.36"; destination host is: "0.0.0.0":40150; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy34.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:143)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-11-13 21:12:46,982 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-11-13 21:12:46,987 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2019-11-13 21:12:47,465 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-13 21:12:48,438 [pool-77-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/b6c333e2-c68b-48ae-9be4-86bbf7607a21/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:51,408 [pool-77-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/b6c333e2-c68b-48ae-9be4-86bbf7607a21 has been successfully formatted.
2019-11-13 21:12:51,409 [pool-77-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-86BBF7607A21: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:51,409 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:51,409 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:51,409 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:51,409 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:51,410 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:51,410 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:51,410 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:51,410 [pool-77-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/b6c333e2-c68b-48ae-9be4-86bbf7607a21
2019-11-13 21:12:51,410 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:51,410 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:51,410 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:51,411 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:51,411 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:51,411 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:51,411 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:51,411 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:51,411 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:51,411 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:51,412 [pool-77-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:51,412 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:51,412 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:51,412 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:51,413 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:51,413 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:51,413 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:51,414 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: new RaftServerImpl for group-9EBE94559A43:[29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483] with ContainerStateMachine:uninitialized
2019-11-13 21:12:51,414 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:51,414 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:51,414 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:51,415 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:51,415 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:51,415 [pool-77-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: ConfigurationManager, init=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:51,415 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis] (custom)
2019-11-13 21:12:51,415 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:51,415 [pool-77-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/0d455ca7-a471-46ed-b046-9ebe94559a43 does not exist. Creating ...
2019-11-13 21:12:51,562 [pool-77-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/0d455ca7-a471-46ed-b046-9ebe94559a43/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:51,572 [pool-77-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/0d455ca7-a471-46ed-b046-9ebe94559a43 has been successfully formatted.
2019-11-13 21:12:51,572 [pool-77-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-9EBE94559A43: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:51,572 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:51,573 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:51,573 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:51,573 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:51,573 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:51,573 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:51,573 [pool-77-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/0d455ca7-a471-46ed-b046-9ebe94559a43
2019-11-13 21:12:51,573 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:51,573 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:51,574 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:51,574 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:51,574 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:51,574 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:51,574 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:51,574 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:51,574 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:51,575 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:51,575 [pool-77-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:51,575 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:51,575 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:51,575 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:51,576 [pool-77-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:51,576 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:51,576 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:51,576 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: start as a follower, conf=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null
2019-11-13 21:12:51,576 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:51,576 [pool-77-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: start FollowerState
2019-11-13 21:12:51,577 [pool-77-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-86BBF7607A21,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:12:51,577 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:51,578 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: start as a follower, conf=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null
2019-11-13 21:12:51,578 [pool-77-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:12:51,578 [pool-77-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: start FollowerState
2019-11-13 21:12:51,578 [pool-77-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9EBE94559A43,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:12:51,578 [pool-77-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:12:51,988 [Thread-213] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:12:51,988 [Thread-213] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: close
2019-11-13 21:12:51,989 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: shutdown
2019-11-13 21:12:51,989 [Thread-213] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9EBE94559A43,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:12:51,989 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: shutdown
2019-11-13 21:12:51,989 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown FollowerState
2019-11-13 21:12:51,989 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-86BBF7607A21,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:12:51,990 [Thread-361] INFO  impl.FollowerState (FollowerState.java:run(120)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:51,990 [Thread-213] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:51,990 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown FollowerState
2019-11-13 21:12:51,991 [Thread-213] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: closes. applyIndex: -1
2019-11-13 21:12:51,991 [Thread-359] INFO  impl.FollowerState (FollowerState.java:run(120)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:12:51,991 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:12:51,992 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:51,992 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: closes. applyIndex: -1
2019-11-13 21:12:51,992 [Thread-213] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker close()
2019-11-13 21:12:51,993 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:12:51,993 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker close()
2019-11-13 21:12:51,994 [Thread-213] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown server with port 41483 now
2019-11-13 21:12:51,995 [Thread-213] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown server with port 41483 successfully
2019-11-13 21:12:51,996 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:12:52,014 [Thread-213] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:12:52,016 [Thread-213] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-13 21:12:52,017 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33fac1df{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-13 21:12:52,017 [Thread-213] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4ae8e00b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-13 21:12:52,018 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4707af00{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-13 21:12:52,018 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a962468{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:12:52,024 [Thread-213] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-hddsdatanode.properties,hadoop-metrics2.properties
2019-11-13 21:12:52,025 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-13 21:12:52,025 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - HddsDatanode metrics system started
2019-11-13 21:12:52,042 [Thread-213] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:52,099 [Thread-213] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(186)) - HddsDatanodeService host:pr-hdds-2471-xp76p-3136957074 ip:192.168.34.36
2019-11-13 21:12:52,103 [Thread-213] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers : 4096 
2019-11-13 21:12:52,103 [Thread-213] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:12:52,104 [Thread-213] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers/hdds to VolumeSet
2019-11-13 21:12:52,104 [Thread-213] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers/hdds
2019-11-13 21:12:52,105 [Thread-213] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers/hdds
2019-11-13 21:12:52,123 [Thread-213] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:12:52,123 [Thread-213] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:12:52,123 [Thread-213] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 41483 (custom)
2019-11-13 21:12:52,123 [Thread-213] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:12:52,123 [Thread-213] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:52,123 [Thread-213] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:12:52,124 [Thread-213] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:12:52,124 [Thread-213] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis] (custom)
2019-11-13 21:12:52,124 [Thread-213] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$null$0(191)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: found a subdirectory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/b6c333e2-c68b-48ae-9be4-86bbf7607a21
2019-11-13 21:12:52,126 [Thread-213] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: addNew group-86BBF7607A21:[] returns group-86BBF7607A21:java.util.concurrent.CompletableFuture@6d3b53a4[Not completed]
2019-11-13 21:12:52,126 [Thread-213] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$null$0(191)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: found a subdirectory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/0d455ca7-a471-46ed-b046-9ebe94559a43
2019-11-13 21:12:52,126 [Thread-213] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: addNew group-9EBE94559A43:[] returns group-9EBE94559A43:java.util.concurrent.CompletableFuture@305aff5f[Not completed]
2019-11-13 21:12:52,128 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: new RaftServerImpl for group-86BBF7607A21:[] with ContainerStateMachine:uninitialized
2019-11-13 21:12:52,128 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:52,128 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:52,128 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:52,128 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:52,129 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:52,129 [pool-89-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:52,129 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis] (custom)
2019-11-13 21:12:52,129 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:52,129 [Thread-213] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:46054
2019-11-13 21:12:52,131 [Thread-213] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:12:52,132 [Thread-213] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:12:52,134 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:12:52,135 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-11-13 21:12:52,135 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:12:52,135 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:12:52,136 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46054
2019-11-13 21:12:52,136 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/b6c333e2-c68b-48ae-9be4-86bbf7607a21/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:52,136 [Thread-213] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:12:52,138 [pool-89-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-86BBF7607A21: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:52,138 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:52,138 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:52,138 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:52,138 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:52,138 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40758314{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:12:52,138 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:52,139 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:52,139 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/b6c333e2-c68b-48ae-9be4-86bbf7607a21
2019-11-13 21:12:52,139 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:52,139 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a7c7098{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-11-13 21:12:52,139 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:52,139 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:52,139 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:52,139 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:52,140 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:52,140 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:52,140 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:52,140 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:52,140 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:52,140 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:52,141 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:52,141 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:52,141 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:52,141 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:52,143 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: new RaftServerImpl for group-9EBE94559A43:[] with ContainerStateMachine:uninitialized
2019-11-13 21:12:52,143 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:12:52,143 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:12:52,143 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:12:52,143 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:12:52,143 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:12:52,143 [pool-89-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
2019-11-13 21:12:52,144 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis] (custom)
2019-11-13 21:12:52,144 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:12:52,150 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/0d455ca7-a471-46ed-b046-9ebe94559a43/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:12:52,151 [pool-89-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-9EBE94559A43: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:12:52,151 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:12:52,151 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:12:52,151 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:12:52,151 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:12:52,151 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:52,151 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:12:52,151 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/0d455ca7-a471-46ed-b046-9ebe94559a43
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:12:52,152 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:12:52,153 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:12:52,153 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:12:52,153 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:12:52,153 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:12:52,153 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:12:52,154 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:12:52,176 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5f39f495{/,file:///tmp/jetty-0.0.0.0-46054-hddsDatanode-_-any-3833900137782407985.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-11-13 21:12:52,176 [Thread-213] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4dd02068{HTTP/1.1,[http/1.1]}{0.0.0.0:46054}
2019-11-13 21:12:52,177 [Thread-213] INFO  server.Server (Server.java:doStart(419)) - Started @66685ms
2019-11-13 21:12:52,177 [Thread-213] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:12:52,178 [Thread-213] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46054
2019-11-13 21:12:52,179 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@18a42381] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-13 21:12:55,183 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:12:56,184 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:12:57,185 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:12:58,186 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:12:59,187 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:00,188 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:01,189 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:02,190 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:03,191 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:04,192 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:05,194 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:06,195 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:07,196 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:08,201 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:09,203 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:10,204 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:11,206 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:12,181 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(802)) - Stopping Replication Manager Service.
2019-11-13 21:13:12,182 [Thread-213] INFO  container.ReplicationManager (ReplicationManager.java:stop(209)) - Replication Monitor Thread is not running.
2019-11-13 21:13:12,182 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(809)) - Stopping Lease Manager of the command watchers
2019-11-13 21:13:12,183 [Thread-213] ERROR server.StorageContainerManager (StorageContainerManager.java:stop(812)) - Lease Manager of the command watchers stop failed
2019-11-13 21:13:12,183 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping datanode service RPC server
2019-11-13 21:13:12,183 [Thread-213] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-13 21:13:12,183 [Thread-213] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40150
2019-11-13 21:13:12,184 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping block service RPC server
2019-11-13 21:13:12,184 [Thread-213] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-13 21:13:12,184 [Thread-213] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41940
2019-11-13 21:13:12,184 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-13 21:13:12,185 [Thread-213] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-11-13 21:13:12,185 [Thread-213] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40705
2019-11-13 21:13:12,185 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping Storage Container Manager HTTP server.
2019-11-13 21:13:12,185 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(849)) - Stopping Block Manager Service.
2019-11-13 21:13:12,185 [Thread-213] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-13 21:13:12,186 [Thread-213] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-13 21:13:12,186 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping SCM Event Queue.
2019-11-13 21:13:12,187 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-11-13 21:13:27,177 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:27,180 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@18a42381] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(201)) - Detected pause in JVM or host machine (eg GC): pause of approximately 14492ms
No GCs detected
2019-11-13 21:13:27,184 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2019-11-13 21:13:27,186 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:13:27,188 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:13:27,191 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-13 21:13:27,192 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-13 21:13:27,192 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-13 21:13:27,193 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-13 21:13:27,193 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-13 21:13:27,194 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-13 21:13:27,195 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-13 21:13:27,195 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-13 21:13:27,196 [Thread-213] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-13 21:13:28,180 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:29,182 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:29,814 [Thread-213] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@219a7d0b
2019-11-13 21:13:29,814 [Thread-213] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-13 21:13:29,822 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-13 21:13:29,822 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-13 21:13:29,823 [Thread-213] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-13 21:13:29,825 [Thread-213] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-13 21:13:29,825 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:13:29,894 [Thread-213] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-13 21:13:29,894 [Thread-213] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-13 21:13:29,991 [Thread-213] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-13 21:13:29,992 [Thread-213] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:13:29,994 [Socket Reader #1 for port 40150] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40150
2019-11-13 21:13:29,996 [Thread-213] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:13:29,997 [Socket Reader #1 for port 41940] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41940
2019-11-13 21:13:29,999 [Thread-213] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-13 21:13:30,000 [Socket Reader #1 for port 40705] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40705
2019-11-13 21:13:30,003 [Thread-213] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:38980
2019-11-13 21:13:30,007 [Thread-213] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-11-13 21:13:30,009 [Thread-213] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-11-13 21:13:30,012 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 21:13:30,013 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-11-13 21:13:30,013 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 21:13:30,013 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 21:13:30,017 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:start(764)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:40705
2019-11-13 21:13:30,021 [Thread-213] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-11-13 21:13:30,023 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-11-13 21:13:30,023 [Thread-213] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-11-13 21:13:30,042 [Thread-213] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:13:30,058 [Thread-213] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:40705
2019-11-13 21:13:30,059 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:13:30,059 [IPC Server listener on 40705] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40705: starting
2019-11-13 21:13:30,121 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:start(774)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:41940
2019-11-13 21:13:30,122 [Thread-213] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:41940
2019-11-13 21:13:30,123 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:13:30,123 [IPC Server listener on 41940] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41940: starting
2019-11-13 21:13:30,130 [Thread-213] INFO  server.StorageContainerManager (StorageContainerManager.java:start(778)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:40150
2019-11-13 21:13:30,130 [Thread-213] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:40150
2019-11-13 21:13:30,131 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-11-13 21:13:30,131 [IPC Server listener on 40150] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40150: starting
2019-11-13 21:13:30,135 [Thread-213] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38980
2019-11-13 21:13:30,136 [Thread-213] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-11-13 21:13:30,140 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70f137d6{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-11-13 21:13:30,140 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7083df0d{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-11-13 21:13:30,146 [Thread-213] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5d1a794d{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-11-13 21:13:30,147 [Thread-213] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19cf3a7e{HTTP/1.1,[http/1.1]}{0.0.0.0:38980}
2019-11-13 21:13:30,147 [Thread-213] INFO  server.Server (Server.java:doStart(419)) - Started @104656ms
2019-11-13 21:13:30,147 [Thread-213] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-11-13 21:13:30,148 [Thread-213] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:38980
2019-11-13 21:13:30,149 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@799b0afc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-11-13 21:13:30,149 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:13:30,183 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:40150. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
2019-11-13 21:13:30,188 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(230)) - Attempting to start container services.
2019-11-13 21:13:30,188 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(194)) - Background container scanner has been disabled.
2019-11-13 21:13:30,188 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis 29583b98-1758-46ab-9f2b-3fd37412daa4 at port 41483
2019-11-13 21:13:30,199 [Datanode State Machine Thread - 0] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(187)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: start with initializing state, conf=-1: [], old=null
2019-11-13 21:13:30,199 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(187)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: start with initializing state, conf=-1: [], old=null
2019-11-13 21:13:30,199 [Datanode State Machine Thread - 0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: changes role from      null to FOLLOWER at term 0 for startInitializing
2019-11-13 21:13:30,200 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: changes role from      null to FOLLOWER at term 0 for startInitializing
2019-11-13 21:13:30,201 [Datanode State Machine Thread - 0] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-86BBF7607A21,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:30,201 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9EBE94559A43,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:30,203 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: start RPC server
2019-11-13 21:13:30,206 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: GrpcService started, listening on 0.0.0.0/0.0.0.0:41483
2019-11-13 21:13:31,150 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-11-13 21:13:31,186 [IPC Server handler 0 on 40150] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:31,187 [IPC Server handler 0 on 40150] INFO  node.SCMNodeManager (SCMNodeManager.java:register(267)) - Registered Data node : 29583b98-1758-46ab-9f2b-3fd37412daa4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}
2019-11-13 21:13:31,188 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-11-13 21:13:31,189 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-11-13 21:13:31,189 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-11-13 21:13:31,205 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: addNew group-C7DE63360F87:[29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483] returns group-C7DE63360F87:java.util.concurrent.CompletableFuture@161add40[Not completed]
2019-11-13 21:13:31,207 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: new RaftServerImpl for group-C7DE63360F87:[29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483] with ContainerStateMachine:uninitialized
2019-11-13 21:13:31,208 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:13:31,208 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:13:31,209 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:13:31,209 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:13:31,209 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:13:31,209 [pool-89-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87: ConfigurationManager, init=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null, confs=<EMPTY_MAP>
2019-11-13 21:13:31,210 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis] (custom)
2019-11-13 21:13:31,210 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:13:31,211 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/6175d54d-6584-4d8d-bc86-c7de63360f87 does not exist. Creating ...
2019-11-13 21:13:31,218 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/6175d54d-6584-4d8d-bc86-c7de63360f87/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:13:31,226 [pool-89-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/6175d54d-6584-4d8d-bc86-c7de63360f87 has been successfully formatted.
2019-11-13 21:13:31,226 [pool-89-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-C7DE63360F87: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:13:31,226 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:13:31,226 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/6175d54d-6584-4d8d-bc86-c7de63360f87
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:13:31,227 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:13:31,228 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:13:31,228 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:13:31,228 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:13:31,228 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:13:31,228 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:13:31,228 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:13:31,228 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:13:31,229 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:13:31,229 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:13:31,229 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:13:31,229 [pool-89-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:13:31,229 [pool-89-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:13:31,229 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87: start as a follower, conf=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null
2019-11-13 21:13:31,229 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:13:31,230 [pool-89-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: start FollowerState
2019-11-13 21:13:31,230 [pool-89-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7DE63360F87,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:31,230 [pool-89-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:13:31,260 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(55)) - Created pipeline Pipeline[ Id: 6175d54d-6584-4d8d-bc86-c7de63360f87, Nodes: 29583b98-1758-46ab-9f2b-3fd37412daa4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
2019-11-13 21:13:31,275 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: remove  FOLLOWER 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43:t0, leader=null, voted=null, raftlog=29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [], old=null STARTING
2019-11-13 21:13:31,277 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: shutdown
2019-11-13 21:13:31,278 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9EBE94559A43,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:31,278 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:13:31,278 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43: closes. applyIndex: -1
2019-11-13 21:13:31,279 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:13:31,279 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-9EBE94559A43-SegmentedRaftLogWorker close()
2019-11-13 21:13:31,295 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: remove  FOLLOWER 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21:t0, leader=null, voted=null, raftlog=29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [], old=null STARTING
2019-11-13 21:13:31,295 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: shutdown
2019-11-13 21:13:31,295 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-86BBF7607A21,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:31,295 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:13:31,295 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21: closes. applyIndex: -1
2019-11-13 21:13:31,296 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:13:31,296 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-86BBF7607A21-SegmentedRaftLogWorker close()
2019-11-13 21:13:32,152 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-13 21:13:33,152 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-13 21:13:34,153 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-13 21:13:34,194 [Thread-470] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-11-13 21:13:34,195 [Thread-470] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 6175d54d-6584-4d8d-bc86-c7de63360f87, Nodes: 29583b98-1758-46ab-9f2b-3fd37412daa4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
2019-11-13 21:13:34,195 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-11-13 21:13:34,196 [Thread-470] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(121)) - Pipeline Pipeline[ Id: 6175d54d-6584-4d8d-bc86-c7de63360f87, Nodes: 29583b98-1758-46ab-9f2b-3fd37412daa4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-11-13 21:13:34,205 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: remove  FOLLOWER 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87:t0, leader=null, voted=null, raftlog=29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null RUNNING
2019-11-13 21:13:34,205 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87: shutdown
2019-11-13 21:13:34,206 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7DE63360F87,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:34,206 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown FollowerState
2019-11-13 21:13:34,206 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87-StateMachineUpdater: set stopIndex = -1
2019-11-13 21:13:34,206 [Thread-472] INFO  impl.FollowerState (FollowerState.java:run(120)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-11-13 21:13:34,207 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87: closes. applyIndex: -1
2019-11-13 21:13:34,208 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:13:34,208 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-C7DE63360F87-SegmentedRaftLogWorker close()
2019-11-13 21:13:34,214 [Thread-470] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:removePipeline(106)) - Pipeline Pipeline[ Id: 6175d54d-6584-4d8d-bc86-c7de63360f87, Nodes: 29583b98-1758-46ab-9f2b-3fd37412daa4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] removed from db
2019-11-13 21:13:34,221 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: addNew group-BA63DE123001:[29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483] returns group-BA63DE123001:java.util.concurrent.CompletableFuture@786fac53[Not completed]
2019-11-13 21:13:34,222 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: new RaftServerImpl for group-BA63DE123001:[29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483] with ContainerStateMachine:uninitialized
2019-11-13 21:13:34,222 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-11-13 21:13:34,222 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-11-13 21:13:34,223 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-11-13 21:13:34,223 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-11-13 21:13:34,223 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-11-13 21:13:34,223 [pool-89-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: ConfigurationManager, init=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null, confs=<EMPTY_MAP>
2019-11-13 21:13:34,223 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis] (custom)
2019-11-13 21:13:34,223 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-11-13 21:13:34,223 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/125375ca-e074-4611-9512-ba63de123001 does not exist. Creating ...
2019-11-13 21:13:34,237 [pool-89-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/125375ca-e074-4611-9512-ba63de123001/in_use.lock acquired by nodename 1384@pr-hdds-2471-xp76p-3136957074
2019-11-13 21:13:34,250 [pool-89-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/125375ca-e074-4611-9512-ba63de123001 has been successfully formatted.
2019-11-13 21:13:34,250 [pool-89-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(223)) - group-BA63DE123001: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-11-13 21:13:34,250 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-11-13 21:13:34,251 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-11-13 21:13:34,251 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-11-13 21:13:34,251 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:13:34,251 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:13:34,251 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-11-13 21:13:34,251 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/125375ca-e074-4611-9512-ba63de123001
2019-11-13 21:13:34,251 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-11-13 21:13:34,251 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-11-13 21:13:34,252 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-11-13 21:13:34,252 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-11-13 21:13:34,252 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-11-13 21:13:34,252 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-11-13 21:13:34,252 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-11-13 21:13:34,252 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-11-13 21:13:34,252 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-11-13 21:13:34,252 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-11-13 21:13:34,253 [pool-89-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-11-13 21:13:34,253 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-11-13 21:13:34,253 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-11-13 21:13:34,253 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-11-13 21:13:34,253 [pool-89-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-11-13 21:13:34,253 [pool-89-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:13:34,254 [pool-89-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:13:34,254 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: start as a follower, conf=-1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null
2019-11-13 21:13:34,254 [pool-89-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-11-13 21:13:34,254 [pool-89-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: start FollowerState
2019-11-13 21:13:34,254 [pool-89-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BA63DE123001,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:34,255 [pool-89-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-11-13 21:13:34,260 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(55)) - Created pipeline Pipeline[ Id: 125375ca-e074-4611-9512-ba63de123001, Nodes: 29583b98-1758-46ab-9f2b-3fd37412daa4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED]
2019-11-13 21:13:35,153 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-13 21:13:36,154 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-13 21:13:37,155 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-13 21:13:38,155 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-13 21:13:39,156 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(163)) - Waiting for 1 number of pipelines out of 1, to report a leader.
2019-11-13 21:13:39,445 [Thread-479] INFO  impl.FollowerState (FollowerState.java:run(111)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-FollowerState: change to CANDIDATE, lastRpcTime:5191ms, electionTimeout:5191ms
2019-11-13 21:13:39,446 [Thread-479] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown FollowerState
2019-11-13 21:13:39,446 [Thread-479] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-11-13 21:13:39,446 [Thread-479] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: start LeaderElection
2019-11-13 21:13:39,511 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3: begin an election at term 1 for -1: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null
2019-11-13 21:13:39,511 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown LeaderElection
2019-11-13 21:13:39,511 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-11-13 21:13:39,512 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(697)) - Leader change notification received for group: group-BA63DE123001 with new leaderId: 29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:39,513 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: change Leader from null to 29583b98-1758-46ab-9f2b-3fd37412daa4 at term 1 for becomeLeader, leader elected after 5261ms
2019-11-13 21:13:39,520 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-11-13 21:13:39,520 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-11-13 21:13:39,523 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-11-13 21:13:39,526 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-11-13 21:13:39,526 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-11-13 21:13:39,527 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-11-13 21:13:39,528 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:openPipeline(134)) - Pipeline Pipeline[ Id: 125375ca-e074-4611-9512-ba63de123001, Nodes: 29583b98-1758-46ab-9f2b-3fd37412daa4{ip: 192.168.34.36, host: pr-hdds-2471-xp76p-3136957074, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN] moved to OPEN state
2019-11-13 21:13:39,533 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: start LeaderState
2019-11-13 21:13:39,545 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-SegmentedRaftLogWorker: Starting segment from index:0
2019-11-13 21:13:39,554 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: set configuration 0: [29583b98-1758-46ab-9f2b-3fd37412daa4:192.168.34.36:41483], old=null at 0
2019-11-13 21:13:39,683 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/ratis/125375ca-e074-4611-9512-ba63de123001/current/log_inprogress_0
2019-11-13 21:13:40,156 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-11-13 21:13:40,157 [Thread-213] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$2(171)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-11-13 21:13:40,157 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(352)) - Shutting down the Mini Ozone Cluster
2019-11-13 21:13:40,158 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(368)) - Stopping the Mini Ozone Cluster
2019-11-13 21:13:40,158 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(438)) - Stopping the OzoneManager
2019-11-13 21:13:40,159 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42718
2019-11-13 21:13:40,161 [IPC Server listener on 42718] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42718
2019-11-13 21:13:40,161 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:13:40,161 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(261)) - Stopping OMDoubleBuffer flush thread
2019-11-13 21:13:40,163 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(199)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-11-13 21:13:40,164 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-11-13 21:13:40,167 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6f9edf1c{/,null,UNAVAILABLE}{/ozoneManager}
2019-11-13 21:13:40,167 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@413ca981{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-11-13 21:13:40,168 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57ef3d5e{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-13 21:13:40,169 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@647d443e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:13:40,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(415)) - Stopping the HddsDatanodes
2019-11-13 21:13:40,513 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-11-13 21:13:45,173 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:13:45,174 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: close
2019-11-13 21:13:45,174 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: shutdown
2019-11-13 21:13:45,174 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BA63DE123001,id=29583b98-1758-46ab-9f2b-3fd37412daa4
2019-11-13 21:13:45,175 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown LeaderState
2019-11-13 21:13:45,176 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-PendingRequests: sendNotLeaderResponses
2019-11-13 21:13:45,177 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-StateMachineUpdater: set stopIndex = 0
2019-11-13 21:13:45,179 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001: closes. applyIndex: 0
2019-11-13 21:13:45,179 [29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-11-13 21:13:45,180 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 29583b98-1758-46ab-9f2b-3fd37412daa4@group-BA63DE123001-SegmentedRaftLogWorker close()
2019-11-13 21:13:45,181 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown server with port 41483 now
2019-11-13 21:13:45,182 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 29583b98-1758-46ab-9f2b-3fd37412daa4: shutdown server with port 41483 successfully
2019-11-13 21:13:45,184 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-63e5f0aa-5bd2-4784-a818-95677fc61cc2/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:13:45,196 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:13:45,198 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-11-13 21:13:45,200 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5f39f495{/,null,UNAVAILABLE}{/hddsDatanode}
2019-11-13 21:13:45,201 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4dd02068{HTTP/1.1,[http/1.1]}{0.0.0.0:46054}
2019-11-13 21:13:45,201 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a7c7098{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-11-13 21:13:45,202 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40758314{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:13:45,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(430)) - Stopping the StorageContainerManager
2019-11-13 21:13:45,202 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(802)) - Stopping Replication Manager Service.
2019-11-13 21:13:45,203 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-11-13 21:13:45,203 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(809)) - Stopping Lease Manager of the command watchers
2019-11-13 21:13:45,203 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping datanode service RPC server
2019-11-13 21:13:45,203 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-11-13 21:13:45,203 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40150
2019-11-13 21:13:45,205 [IPC Server listener on 40150] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40150
2019-11-13 21:13:45,205 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:13:45,247 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-11-13 21:13:45,248 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping block service RPC server
2019-11-13 21:13:45,249 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-11-13 21:13:45,249 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41940
2019-11-13 21:13:45,250 [IPC Server listener on 41940] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41940
2019-11-13 21:13:45,250 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:13:45,250 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping the StorageContainerLocationProtocol RPC server
2019-11-13 21:13:45,251 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-11-13 21:13:45,251 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40705
2019-11-13 21:13:45,252 [IPC Server listener on 40705] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40705
2019-11-13 21:13:45,252 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping Storage Container Manager HTTP server.
2019-11-13 21:13:45,253 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-11-13 21:13:45,254 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5d1a794d{/,null,UNAVAILABLE}{/scm}
2019-11-13 21:13:45,254 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19cf3a7e{HTTP/1.1,[http/1.1]}{0.0.0.0:38980}
2019-11-13 21:13:45,255 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7083df0d{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-11-13 21:13:45,255 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70f137d6{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-11-13 21:13:45,256 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(849)) - Stopping Block Manager Service.
2019-11-13 21:13:45,256 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-13 21:13:45,256 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-11-13 21:13:45,257 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping SCM Event Queue.
2019-11-13 21:13:45,260 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2019-11-13 21:13:45,262 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2019-11-13 21:13:45,276 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/read/malformed.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:173)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: Can't construct a java object for tag:yaml.org,2002:org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml; exception=No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
 in 'reader', line 1, column 1:
    malformed
    ^

	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:349)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:182)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:141)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:127)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:450)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
Caused by: org.yaml.snakeyaml.error.YAMLException: No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
	at org.yaml.snakeyaml.constructor.Constructor$ConstructScalar.construct(Constructor.java:396)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:345)
	... 36 more
2019-11-13 21:13:45,279 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/write/valid-proto.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: unacceptable character '' (0x12) special characters are not allowed
in "'reader'", position 38
	at org.yaml.snakeyaml.reader.StreamReader.checkPrintable(StreamReader.java:93)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:192)
	at org.yaml.snakeyaml.reader.StreamReader.<init>(StreamReader.java:60)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
2019-11-13 21:13:45,304 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:13:45,304 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds to VolumeSet
2019-11-13 21:13:45,304 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,305 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,320 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-13 21:13:45,321 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:13:45,321 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:13:45,321 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:13:45,321 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:13:45,322 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:13:45,322 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:13:45,322 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:13:45,322 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-13 21:13:45,327 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:13:45,327 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds to VolumeSet
2019-11-13 21:13:45,328 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,328 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,339 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-13 21:13:45,339 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:13:45,339 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:13:45,339 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:13:45,340 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:13:45,340 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:13:45,340 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:13:45,340 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:13:45,341 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-13 21:13:45,346 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:13:45,346 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds to VolumeSet
2019-11-13 21:13:45,346 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,346 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,357 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-13 21:13:45,358 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:13:45,358 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:13:45,358 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:13:45,358 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:13:45,359 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:13:45,359 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:13:45,359 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:13:45,359 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-13 21:13:45,361 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 2376f319-708d-42cc-9b4c-15e9c92e625f is started using port 41871
2019-11-13 21:13:45,361 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis 2376f319-708d-42cc-9b4c-15e9c92e625f at port 0
2019-11-13 21:13:45,367 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 2376f319-708d-42cc-9b4c-15e9c92e625f: start RPC server
2019-11-13 21:13:45,369 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 2376f319-708d-42cc-9b4c-15e9c92e625f: GrpcService started, listening on 0.0.0.0/0.0.0.0:41517
2019-11-13 21:13:45,369 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis 2376f319-708d-42cc-9b4c-15e9c92e625f is started using port 41517
2019-11-13 21:13:45,370 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc cb7fcb22-a7fe-4d23-aacf-dc41878d6c57 is started using port 39334
2019-11-13 21:13:45,370 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis cb7fcb22-a7fe-4d23-aacf-dc41878d6c57 at port 0
2019-11-13 21:13:45,376 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - cb7fcb22-a7fe-4d23-aacf-dc41878d6c57: start RPC server
2019-11-13 21:13:45,377 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - cb7fcb22-a7fe-4d23-aacf-dc41878d6c57: GrpcService started, listening on 0.0.0.0/0.0.0.0:40288
2019-11-13 21:13:45,377 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis cb7fcb22-a7fe-4d23-aacf-dc41878d6c57 is started using port 40288
2019-11-13 21:13:45,378 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc e25e39f3-f775-4896-a0a8-2f24a96fea96 is started using port 39515
2019-11-13 21:13:45,378 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - Starting XceiverServerRatis e25e39f3-f775-4896-a0a8-2f24a96fea96 at port 0
2019-11-13 21:13:45,382 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e25e39f3-f775-4896-a0a8-2f24a96fea96: start RPC server
2019-11-13 21:13:45,385 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - e25e39f3-f775-4896-a0a8-2f24a96fea96: GrpcService started, listening on 0.0.0.0/0.0.0.0:33942
2019-11-13 21:13:45,385 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(431)) - XceiverServerRatis e25e39f3-f775-4896-a0a8-2f24a96fea96 is started using port 33942
2019-11-13 21:13:45,385 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 2376f319-708d-42cc-9b4c-15e9c92e625f: close
2019-11-13 21:13:45,385 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 2376f319-708d-42cc-9b4c-15e9c92e625f: shutdown server with port 41517 now
2019-11-13 21:13:45,386 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 2376f319-708d-42cc-9b4c-15e9c92e625f: shutdown server with port 41517 successfully
2019-11-13 21:13:45,388 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - cb7fcb22-a7fe-4d23-aacf-dc41878d6c57: close
2019-11-13 21:13:45,389 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - cb7fcb22-a7fe-4d23-aacf-dc41878d6c57: shutdown server with port 40288 now
2019-11-13 21:13:45,389 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - cb7fcb22-a7fe-4d23-aacf-dc41878d6c57: shutdown server with port 40288 successfully
2019-11-13 21:13:45,390 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - e25e39f3-f775-4896-a0a8-2f24a96fea96: close
2019-11-13 21:13:45,390 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - e25e39f3-f775-4896-a0a8-2f24a96fea96: shutdown server with port 33942 now
2019-11-13 21:13:45,390 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - e25e39f3-f775-4896-a0a8-2f24a96fea96: shutdown server with port 33942 successfully
2019-11-13 21:13:45,391 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:13:45,392 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:13:45,403 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:13:45,403 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:13:45,404 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:13:45,416 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:13:45,416 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:13:45,417 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:13:45,428 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:13:45,431 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur : 8192 
2019-11-13 21:13:45,432 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:13:45,432 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds to VolumeSet
2019-11-13 21:13:45,432 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,433 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,447 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-13 21:13:45,447 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:13:45,448 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:13:45,448 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:13:45,448 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:13:45,448 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:13:45,449 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:13:45,449 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:13:45,450 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-13 21:13:45,452 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur : 8192 
2019-11-13 21:13:45,453 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:13:45,453 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds to VolumeSet
2019-11-13 21:13:45,453 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,453 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,463 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-13 21:13:45,464 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:13:45,464 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:13:45,464 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:13:45,464 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:13:45,465 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:13:45,465 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:13:45,465 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:13:45,465 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-13 21:13:45,467 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur : 8192 
2019-11-13 21:13:45,468 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-13 21:13:45,468 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds to VolumeSet
2019-11-13 21:13:45,468 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,468 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur/hdds
2019-11-13 21:13:45,478 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-13 21:13:45,479 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-13 21:13:45,479 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-13 21:13:45,479 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-13 21:13:45,479 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-13 21:13:45,479 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-13 21:13:45,480 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-13 21:13:45,480 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-13 21:13:45,480 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-13 21:13:45,481 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:13:45,482 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:13:45,495 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:13:45,495 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:13:45,495 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:13:45,504 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-13 21:13:45,504 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(244)) - Attempting to stop container services.
2019-11-13 21:13:45,505 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/RPDdKNQbur] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-13 21:13:45,512 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
