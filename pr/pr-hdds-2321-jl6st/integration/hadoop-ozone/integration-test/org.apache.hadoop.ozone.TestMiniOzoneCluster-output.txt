2019-11-01 20:53:45,566 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:45,701 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:45,704 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:45,730 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @890ms
2019-11-01 20:53:45,824 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-01 20:53:45,825 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-01 20:53:45,825 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-01 20:53:45,825 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-01 20:53:45,826 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-01 20:53:45,826 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-01 20:53:45,837 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-01 20:53:45,837 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-01 20:53:45,838 [Thread-0] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-01 20:53:46,130 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@4e7593f5
2019-11-01 20:53:46,131 [Thread-0] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-01 20:53:46,186 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-01 20:53:46,187 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-01 20:53:46,190 [Thread-0] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-01 20:53:46,250 [Thread-0] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-01 20:53:46,263 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:46,376 [Thread-0] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-01 20:53:46,379 [Thread-0] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:46,544 [Thread-0] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-11-01 20:53:46,909 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-01 20:53:46,932 [Socket Reader #1 for port 46215] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46215
2019-11-01 20:53:47,064 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-01 20:53:47,065 [Socket Reader #1 for port 36541] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36541
2019-11-01 20:53:47,076 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-01 20:53:47,077 [Socket Reader #1 for port 34122] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34122
2019-11-01 20:53:47,121 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:47,147 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:47,148 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:47,149 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: deletedBlocks
2019-11-01 20:53:47,149 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-11-01 20:53:47,149 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: validCerts
2019-11-01 20:53:47,150 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-11-01 20:53:47,150 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: revokedCerts
2019-11-01 20:53:47,150 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(183)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-11-01 20:53:47,151 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(127)) - using custom profile for table: default
2019-11-01 20:53:47,151 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(189)) - Using default column profile:DBProfile.DISK for Table:default
2019-11-01 20:53:47,151 [Thread-12] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(220)) - Using default options. DBProfile.DISK
2019-11-01 20:53:47,372 [Thread-12] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@dd3314
2019-11-01 20:53:47,373 [Thread-12] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-11-01 20:53:47,379 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-01 20:53:47,379 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-11-01 20:53:47,379 [Thread-12] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-11-01 20:53:47,382 [Thread-12] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-11-01 20:53:47,382 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:47,433 [Thread-12] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-11-01 20:53:47,433 [Thread-12] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-11-01 20:53:47,489 [Thread-12] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-11-01 20:53:47,490 [Thread-12] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-01 20:53:47,491 [Socket Reader #1 for port 35792] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35792
2019-11-01 20:53:47,493 [Thread-12] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-01 20:53:47,494 [Socket Reader #1 for port 44077] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44077
2019-11-01 20:53:47,496 [Thread-12] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-11-01 20:53:47,498 [Socket Reader #1 for port 41224] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41224
2019-11-01 20:53:47,684 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/read/malformed.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:173)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: Can't construct a java object for tag:yaml.org,2002:org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml; exception=No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
 in 'reader', line 1, column 1:
    malformed
    ^

	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:349)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:182)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:141)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:127)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:450)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
Caused by: org.yaml.snakeyaml.error.YAMLException: No single argument constructor found for class org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml$DatanodeDetailsYaml
	at org.yaml.snakeyaml.constructor.Constructor$ConstructScalar.construct(Constructor.java:396)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:345)
	... 36 more
2019-11-01 20:53:47,700 [main] WARN  helpers.ContainerUtils (ContainerUtils.java:readDatanodeDetailsFrom(229)) - Error loading DatanodeDetails yaml from /workdir/hadoop-ozone/integration-test/target/test-dir/write/valid-proto.id
java.io.IOException: Unable to parse yaml file.
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:77)
	at org.apache.hadoop.ozone.container.common.helpers.ContainerUtils.readDatanodeDetailsFrom(ContainerUtils.java:227)
	at org.apache.hadoop.ozone.TestMiniOzoneCluster.testDatanodeIDPersistent(TestMiniOzoneCluster.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: unacceptable character '' (0x12) special characters are not allowed
in "'reader'", position 38
	at org.yaml.snakeyaml.reader.StreamReader.checkPrintable(StreamReader.java:93)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:192)
	at org.yaml.snakeyaml.reader.StreamReader.<init>(StreamReader.java:60)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:444)
	at org.apache.hadoop.ozone.container.common.helpers.DatanodeIdYaml.readDatanodeIdFile(DatanodeIdYaml.java:75)
	... 30 more
2019-11-01 20:53:47,771 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-01 20:53:47,773 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds to VolumeSet
2019-11-01 20:53:47,783 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:47,800 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,249 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-01 20:53:48,275 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-01 20:53:48,337 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-01 20:53:48,342 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-01 20:53:48,343 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-01 20:53:48,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-01 20:53:48,345 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-01 20:53:48,346 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-01 20:53:48,501 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-01 20:53:48,560 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-01 20:53:48,561 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds to VolumeSet
2019-11-01 20:53:48,561 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,561 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,574 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-01 20:53:48,575 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-01 20:53:48,575 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-01 20:53:48,575 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-01 20:53:48,576 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-01 20:53:48,576 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-01 20:53:48,576 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-01 20:53:48,576 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-01 20:53:48,577 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-01 20:53:48,585 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-01 20:53:48,585 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds to VolumeSet
2019-11-01 20:53:48,585 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,586 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,597 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-01 20:53:48,598 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-01 20:53:48,598 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-01 20:53:48,598 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-01 20:53:48,599 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-01 20:53:48,599 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-01 20:53:48,599 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-01 20:53:48,599 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-01 20:53:48,600 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-01 20:53:48,694 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc b11f69f0-e372-4b64-b3de-2fde55bfef81 is started using port 39558
2019-11-01 20:53:48,694 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis b11f69f0-e372-4b64-b3de-2fde55bfef81 at port 0
2019-11-01 20:53:48,710 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b11f69f0-e372-4b64-b3de-2fde55bfef81: start RPC server
2019-11-01 20:53:48,712 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b11f69f0-e372-4b64-b3de-2fde55bfef81: GrpcService started, listening on 0.0.0.0/0.0.0.0:39342
2019-11-01 20:53:48,712 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis b11f69f0-e372-4b64-b3de-2fde55bfef81 is started using port 39342
2019-11-01 20:53:48,713 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 0afff789-3ae8-440a-a714-9d8e025e09ad is started using port 42135
2019-11-01 20:53:48,713 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis 0afff789-3ae8-440a-a714-9d8e025e09ad at port 0
2019-11-01 20:53:48,721 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0afff789-3ae8-440a-a714-9d8e025e09ad: start RPC server
2019-11-01 20:53:48,722 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0afff789-3ae8-440a-a714-9d8e025e09ad: GrpcService started, listening on 0.0.0.0/0.0.0.0:46727
2019-11-01 20:53:48,722 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis 0afff789-3ae8-440a-a714-9d8e025e09ad is started using port 46727
2019-11-01 20:53:48,723 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc a53800f2-987e-4b61-969b-58cb965ff912 is started using port 33516
2019-11-01 20:53:48,723 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - Starting XceiverServerRatis a53800f2-987e-4b61-969b-58cb965ff912 at port 0
2019-11-01 20:53:48,730 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - a53800f2-987e-4b61-969b-58cb965ff912: start RPC server
2019-11-01 20:53:48,731 [main] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - a53800f2-987e-4b61-969b-58cb965ff912: GrpcService started, listening on 0.0.0.0/0.0.0.0:34922
2019-11-01 20:53:48,731 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(424)) - XceiverServerRatis a53800f2-987e-4b61-969b-58cb965ff912 is started using port 34922
2019-11-01 20:53:48,732 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - b11f69f0-e372-4b64-b3de-2fde55bfef81: close
2019-11-01 20:53:48,734 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - b11f69f0-e372-4b64-b3de-2fde55bfef81: shutdown server with port 39342 now
2019-11-01 20:53:48,741 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - b11f69f0-e372-4b64-b3de-2fde55bfef81: shutdown server with port 39342 successfully
2019-11-01 20:53:48,742 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0afff789-3ae8-440a-a714-9d8e025e09ad: close
2019-11-01 20:53:48,742 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 0afff789-3ae8-440a-a714-9d8e025e09ad: shutdown server with port 46727 now
2019-11-01 20:53:48,742 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 0afff789-3ae8-440a-a714-9d8e025e09ad: shutdown server with port 46727 successfully
2019-11-01 20:53:48,743 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - a53800f2-987e-4b61-969b-58cb965ff912: close
2019-11-01 20:53:48,744 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - a53800f2-987e-4b61-969b-58cb965ff912: shutdown server with port 34922 now
2019-11-01 20:53:48,744 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - a53800f2-987e-4b61-969b-58cb965ff912: shutdown server with port 34922 successfully
2019-11-01 20:53:48,786 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-01 20:53:48,788 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-01 20:53:48,799 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-01 20:53:48,799 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-01 20:53:48,800 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-01 20:53:48,809 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-01 20:53:48,810 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-01 20:53:48,810 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-01 20:53:48,820 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-01 20:53:48,823 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN : 8192 
2019-11-01 20:53:48,824 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-01 20:53:48,824 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds to VolumeSet
2019-11-01 20:53:48,824 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,825 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,836 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-01 20:53:48,836 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-01 20:53:48,837 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-01 20:53:48,837 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-01 20:53:48,837 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-01 20:53:48,837 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-01 20:53:48,838 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-01 20:53:48,838 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-01 20:53:48,838 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-01 20:53:48,841 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN : 8192 
2019-11-01 20:53:48,842 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-01 20:53:48,842 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds to VolumeSet
2019-11-01 20:53:48,842 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,843 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,853 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-01 20:53:48,853 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-01 20:53:48,853 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-01 20:53:48,854 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-01 20:53:48,854 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-01 20:53:48,854 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-01 20:53:48,854 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-01 20:53:48,855 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-01 20:53:48,855 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-01 20:53:48,858 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN : 8192 
2019-11-01 20:53:48,858 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds of  storage type : DISK and capacity : 1482555576320
2019-11-01 20:53:48,858 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds to VolumeSet
2019-11-01 20:53:48,859 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,859 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN/hdds
2019-11-01 20:53:48,869 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-11-01 20:53:48,870 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-11-01 20:53:48,870 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-11-01 20:53:48,870 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-11-01 20:53:48,870 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-11-01 20:53:48,871 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-11-01 20:53:48,871 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-11-01 20:53:48,871 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-11-01 20:53:48,872 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/ratis] (custom)
2019-11-01 20:53:48,873 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-01 20:53:48,873 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-01 20:53:48,882 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-01 20:53:48,882 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-01 20:53:48,883 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-01 20:53:48,891 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-11-01 20:53:48,891 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(232)) - Attempting to stop container services.
2019-11-01 20:53:48,892 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/UWe2xdC7bN] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-11-01 20:53:48,900 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
