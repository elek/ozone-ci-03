2019-10-23 19:59:23,521 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:23,640 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:23,643 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:23,666 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @828ms
2019-10-23 19:59:23,743 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedBlocks
2019-10-23 19:59:23,743 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-10-23 19:59:23,743 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: validCerts
2019-10-23 19:59:23,744 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-10-23 19:59:23,744 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: revokedCerts
2019-10-23 19:59:23,744 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-10-23 19:59:23,753 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-23 19:59:23,753 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-23 19:59:23,754 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-23 19:59:23,970 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@78691363
2019-10-23 19:59:23,971 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-10-23 19:59:24,014 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-23 19:59:24,015 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-10-23 19:59:24,017 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2019-10-23 19:59:24,068 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-10-23 19:59:24,079 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:24,137 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-10-23 19:59:24,138 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:24,221 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-10-23 19:59:24,537 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-23 19:59:24,670 [Socket Reader #1 for port 42434] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42434
2019-10-23 19:59:24,707 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-23 19:59:24,708 [Socket Reader #1 for port 42955] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42955
2019-10-23 19:59:24,719 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-23 19:59:24,719 [Socket Reader #1 for port 33718] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33718
2019-10-23 19:59:24,744 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-10-23 19:59:24,872 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-23 19:59:24,880 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-23 19:59:24,886 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-23 19:59:24,888 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-10-23 19:59:24,889 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-23 19:59:24,889 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-23 19:59:24,914 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(772)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:33718
2019-10-23 19:59:24,964 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-10-23 19:59:24,974 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-10-23 19:59:24,974 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-10-23 19:59:25,159 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(159)) - RPC server for Client  is listening at /0.0.0.0:33718
2019-10-23 19:59:25,160 [IPC Server listener on 33718] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33718: starting
2019-10-23 19:59:25,160 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-23 19:59:25,163 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(782)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:42955
2019-10-23 19:59:25,163 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:42955
2019-10-23 19:59:25,164 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-23 19:59:25,164 [IPC Server listener on 42955] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42955: starting
2019-10-23 19:59:25,166 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(786)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:42434
2019-10-23 19:59:25,166 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(169)) - RPC server for DataNodes is listening at /0.0.0.0:42434
2019-10-23 19:59:25,167 [IPC Server listener on 42434] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42434: starting
2019-10-23 19:59:25,167 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-23 19:59:25,170 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43933
2019-10-23 19:59:25,172 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-23 19:59:25,220 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f48b3d2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-23 19:59:25,221 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@753432a2{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-23 19:59:25,261 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@23a9ba52{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-10-23 19:59:25,267 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7927bd9f{HTTP/1.1,[http/1.1]}{0.0.0.0:43933}
2019-10-23 19:59:25,267 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2429ms
2019-10-23 19:59:25,270 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-10-23 19:59:25,270 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-10-23 19:59:25,271 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:43933
2019-10-23 19:59:25,278 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d3f761a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-23 19:59:25,280 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:25,380 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(190)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-10-23 19:59:25,381 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(220)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-10-23 19:59:25,382 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:25,383 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:25,933 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-10-23 19:59:25,939 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: userTable
2019-10-23 19:59:25,939 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-10-23 19:59:25,939 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: volumeTable
2019-10-23 19:59:25,939 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-10-23 19:59:25,939 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: bucketTable
2019-10-23 19:59:25,940 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-10-23 19:59:25,940 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: keyTable
2019-10-23 19:59:25,940 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-10-23 19:59:25,940 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: deletedTable
2019-10-23 19:59:25,940 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-10-23 19:59:25,940 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: openKeyTable
2019-10-23 19:59:25,941 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-10-23 19:59:25,941 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3Table
2019-10-23 19:59:25,941 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-10-23 19:59:25,941 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: multipartInfoTable
2019-10-23 19:59:25,941 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-10-23 19:59:25,941 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: dTokenTable
2019-10-23 19:59:25,942 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-10-23 19:59:25,942 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: s3SecretTable
2019-10-23 19:59:25,942 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-10-23 19:59:25,942 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: prefixTable
2019-10-23 19:59:25,942 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(168)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-10-23 19:59:25,943 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(117)) - using custom profile for table: default
2019-10-23 19:59:25,943 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(174)) - Using default column profile:DBProfile.DISK for Table:default
2019-10-23 19:59:25,943 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(205)) - Using default options. DBProfile.DISK
2019-10-23 19:59:26,316 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-10-23 19:59:26,317 [Socket Reader #1 for port 42158] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42158
2019-10-23 19:59:26,337 [main] INFO  om.OzoneManager (OzoneManager.java:start(1074)) - OzoneManager RPC server is listening at localhost/127.0.0.1:42158
2019-10-23 19:59:26,337 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-10-23 19:59:26,344 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-10-23 19:59:26,344 [IPC Server listener on 42158] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42158: starting
2019-10-23 19:59:26,349 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-10-23 19:59:26,351 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-23 19:59:26,352 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-23 19:59:26,356 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-23 19:59:26,357 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-10-23 19:59:26,357 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-23 19:59:26,358 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-23 19:59:26,361 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46856
2019-10-23 19:59:26,362 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-23 19:59:26,364 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@40ab8a8{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-23 19:59:26,365 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65cc8228{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-10-23 19:59:26,373 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5d235104{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-10-23 19:59:26,374 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4e8e8621{HTTP/1.1,[http/1.1]}{0.0.0.0:46856}
2019-10-23 19:59:26,374 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3536ms
2019-10-23 19:59:26,374 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-23 19:59:26,375 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:46856
2019-10-23 19:59:26,594 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-23 19:59:26,628 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2344-6v5ld-3773743899 ip:192.168.164.213
2019-10-23 19:59:26,653 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-23 19:59:26,654 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/containers/hdds to VolumeSet
2019-10-23 19:59:26,656 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/containers/hdds
2019-10-23 19:59:26,669 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/containers/hdds
2019-10-23 19:59:26,750 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-23 19:59:26,798 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-23 19:59:26,801 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-23 19:59:26,802 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-23 19:59:26,803 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:26,804 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-23 19:59:26,804 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 19:59:26,921 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis] (custom)
2019-10-23 19:59:26,959 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-23 19:59:26,962 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-23 19:59:26,963 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-23 19:59:26,965 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-23 19:59:26,967 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-23 19:59:26,967 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-23 19:59:26,967 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-23 19:59:26,969 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43039
2019-10-23 19:59:26,969 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-23 19:59:26,972 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c008c24{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-23 19:59:26,973 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21079a12{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-23 19:59:27,022 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@673919a7{/,file:///tmp/jetty-0.0.0.0-43039-hddsDatanode-_-any-2670173893617058.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-23 19:59:27,023 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@25d93198{HTTP/1.1,[http/1.1]}{0.0.0.0:43039}
2019-10-23 19:59:27,023 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4186ms
2019-10-23 19:59:27,024 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-23 19:59:27,025 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43039
2019-10-23 19:59:27,026 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-23 19:59:27,028 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2344-6v5ld-3773743899 ip:192.168.164.213
2019-10-23 19:59:27,032 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3157bc8f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-23 19:59:27,038 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-23 19:59:27,039 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/containers/hdds to VolumeSet
2019-10-23 19:59:27,039 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/containers/hdds
2019-10-23 19:59:27,039 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/containers/hdds
2019-10-23 19:59:27,054 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-23 19:59:27,055 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-23 19:59:27,055 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-23 19:59:27,055 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-23 19:59:27,055 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:27,056 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-23 19:59:27,056 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 19:59:27,056 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis] (custom)
2019-10-23 19:59:27,058 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-23 19:59:27,060 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-23 19:59:27,061 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-23 19:59:27,063 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-23 19:59:27,064 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-23 19:59:27,064 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-23 19:59:27,065 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-23 19:59:27,066 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46551
2019-10-23 19:59:27,066 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-23 19:59:27,069 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30364216{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-23 19:59:27,069 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e8ab90f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-23 19:59:27,112 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@60325987{/,file:///tmp/jetty-0.0.0.0-46551-hddsDatanode-_-any-4092053102981080113.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-23 19:59:27,113 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2f37f1f9{HTTP/1.1,[http/1.1]}{0.0.0.0:46551}
2019-10-23 19:59:27,114 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4276ms
2019-10-23 19:59:27,114 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-23 19:59:27,116 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46551
2019-10-23 19:59:27,116 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-23 19:59:27,119 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@577fee9b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-23 19:59:27,120 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2344-6v5ld-3773743899 ip:192.168.164.213
2019-10-23 19:59:27,131 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-23 19:59:27,132 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers/hdds to VolumeSet
2019-10-23 19:59:27,132 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers/hdds
2019-10-23 19:59:27,133 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers/hdds
2019-10-23 19:59:27,153 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-23 19:59:27,153 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-23 19:59:27,154 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-10-23 19:59:27,154 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-23 19:59:27,154 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:27,155 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-23 19:59:27,155 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 19:59:27,156 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis] (custom)
2019-10-23 19:59:27,159 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-10-23 19:59:27,160 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-23 19:59:27,161 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-23 19:59:27,163 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-23 19:59:27,164 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-23 19:59:27,164 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-23 19:59:27,164 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-23 19:59:27,165 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39777
2019-10-23 19:59:27,165 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-23 19:59:27,169 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e5cbff2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-23 19:59:27,169 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/meta/datanode.id
2019-10-23 19:59:27,170 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4fc3c165{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-23 19:59:27,174 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/meta/datanode.id
2019-10-23 19:59:27,204 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70228253{/,file:///tmp/jetty-0.0.0.0-39777-hddsDatanode-_-any-1020527179936163668.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-23 19:59:27,204 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63c12e52{HTTP/1.1,[http/1.1]}{0.0.0.0:39777}
2019-10-23 19:59:27,205 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4367ms
2019-10-23 19:59:27,206 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-23 19:59:27,207 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39777
2019-10-23 19:59:27,208 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-23 19:59:27,210 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d92b649] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-23 19:59:27,213 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/meta/datanode.id
2019-10-23 19:59:28,209 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-23 19:59:29,123 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-23 19:59:29,125 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-23 19:59:29,126 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 6db3bc75-fe19-4010-b9b4-a3ce262b192b at port 0
2019-10-23 19:59:29,137 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-23 19:59:29,145 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-23 19:59:29,146 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 76af9f5a-76ac-4564-8b4a-32ca0c573f92 at port 0
2019-10-23 19:59:29,154 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start RPC server
2019-10-23 19:59:29,157 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start RPC server
2019-10-23 19:59:29,209 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-23 19:59:29,225 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-23 19:59:29,227 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-23 19:59:29,227 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 729d0bb6-2410-4cc8-96f0-e80551772f93 at port 0
2019-10-23 19:59:29,239 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start RPC server
2019-10-23 19:59:29,289 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: GrpcService started, listening on 0.0.0.0/0.0.0.0:46766
2019-10-23 19:59:29,289 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: GrpcService started, listening on 0.0.0.0/0.0.0.0:43640
2019-10-23 19:59:29,289 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: GrpcService started, listening on 0.0.0.0/0.0.0.0:43238
2019-10-23 19:59:29,290 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 76af9f5a-76ac-4564-8b4a-32ca0c573f92 is started using port 43640
2019-10-23 19:59:29,290 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 729d0bb6-2410-4cc8-96f0-e80551772f93 is started using port 46766
2019-10-23 19:59:29,290 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 6db3bc75-fe19-4010-b9b4-a3ce262b192b is started using port 43238
2019-10-23 19:59:29,297 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 729d0bb6-2410-4cc8-96f0-e80551772f93 is started using port 35399
2019-10-23 19:59:29,297 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 76af9f5a-76ac-4564-8b4a-32ca0c573f92 is started using port 45196
2019-10-23 19:59:29,297 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 6db3bc75-fe19-4010-b9b4-a3ce262b192b is started using port 37306
2019-10-23 19:59:30,210 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-10-23 19:59:31,072 [IPC Server handler 1 on 42434] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 19:59:31,072 [IPC Server handler 1 on 42434] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}
2019-10-23 19:59:31,077 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-10-23 19:59:31,077 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-10-23 19:59:31,077 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-10-23 19:59:31,122 [IPC Server handler 3 on 42434] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 19:59:31,123 [IPC Server handler 3 on 42434] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}
2019-10-23 19:59:31,210 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-10-23 19:59:31,213 [IPC Server handler 1 on 42434] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 19:59:31,214 [IPC Server handler 1 on 42434] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}
2019-10-23 19:59:31,575 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: addNew group-54E6D0CEFDD4:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238] returns group-54E6D0CEFDD4:java.util.concurrent.CompletableFuture@1a2ea6b1[Not completed]
2019-10-23 19:59:31,591 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: new RaftServerImpl for group-54E6D0CEFDD4:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238] with ContainerStateMachine:uninitialized
2019-10-23 19:59:31,594 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 19:59:31,594 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 19:59:31,594 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 19:59:31,595 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 19:59:31,596 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 19:59:31,606 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: ConfigurationManager, init=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238], old=null, confs=<EMPTY_MAP>
2019-10-23 19:59:31,607 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis] (custom)
2019-10-23 19:59:31,615 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 19:59:31,617 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/3fb1b780-7cb9-467c-b790-54e6d0cefdd4 does not exist. Creating ...
2019-10-23 19:59:31,635 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/3fb1b780-7cb9-467c-b790-54e6d0cefdd4/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 19:59:31,651 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/3fb1b780-7cb9-467c-b790-54e6d0cefdd4 has been successfully formatted.
2019-10-23 19:59:31,653 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-54E6D0CEFDD4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 19:59:31,653 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 19:59:31,655 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 19:59:31,661 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 19:59:31,661 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:31,664 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:31,669 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-10-23 19:59:31,673 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,679 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 19:59:31,684 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/3fb1b780-7cb9-467c-b790-54e6d0cefdd4
2019-10-23 19:59:31,685 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 19:59:31,685 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 19:59:31,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:31,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 19:59:31,688 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 19:59:31,688 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 19:59:31,689 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 19:59:31,689 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 19:59:31,690 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 19:59:31,699 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 19:59:31,704 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 19:59:31,708 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 19:59:31,709 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 19:59:31,710 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 19:59:31,710 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 19:59:31,729 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,731 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,732 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: start as a follower, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238], old=null
2019-10-23 19:59:31,733 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 19:59:31,734 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start FollowerState
2019-10-23 19:59:31,736 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-54E6D0CEFDD4,id=6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 19:59:31,738 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,806 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3fb1b780-7cb9-467c-b790-54e6d0cefdd4, Nodes: 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-23 19:59:31,827 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: addNew group-77421D29F832:[729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766] returns group-77421D29F832:java.util.concurrent.CompletableFuture@740e7133[Not completed]
2019-10-23 19:59:31,856 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: new RaftServerImpl for group-77421D29F832:[729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766] with ContainerStateMachine:uninitialized
2019-10-23 19:59:31,858 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 19:59:31,858 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 19:59:31,858 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 19:59:31,858 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 19:59:31,859 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 19:59:31,859 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: ConfigurationManager, init=-1: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null, confs=<EMPTY_MAP>
2019-10-23 19:59:31,859 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis] (custom)
2019-10-23 19:59:31,860 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 19:59:31,860 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832 does not exist. Creating ...
2019-10-23 19:59:31,874 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 19:59:31,887 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832 has been successfully formatted.
2019-10-23 19:59:31,888 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-77421D29F832: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 19:59:31,889 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 19:59:31,890 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 19:59:31,890 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 19:59:31,890 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:31,890 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:31,891 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,892 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 19:59:31,892 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832
2019-10-23 19:59:31,893 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 19:59:31,893 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 19:59:31,893 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:31,893 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 19:59:31,894 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 19:59:31,894 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 19:59:31,894 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 19:59:31,894 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 19:59:31,894 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 19:59:31,895 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 19:59:31,895 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 19:59:31,896 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 19:59:31,896 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 19:59:31,896 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 19:59:31,897 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 19:59:31,897 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,897 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,897 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: start as a follower, conf=-1: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null
2019-10-23 19:59:31,898 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 19:59:31,898 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 19:59:31,899 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-77421D29F832,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 19:59:31,900 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,913 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0dd550b4-7c36-4453-9b1a-77421d29f832, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-23 19:59:31,933 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: addNew group-343663B493C6:[76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] returns group-343663B493C6:java.util.concurrent.CompletableFuture@5d13f210[Not completed]
2019-10-23 19:59:31,950 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: new RaftServerImpl for group-343663B493C6:[76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] with ContainerStateMachine:uninitialized
2019-10-23 19:59:31,951 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 19:59:31,951 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 19:59:31,951 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 19:59:31,951 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 19:59:31,951 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 19:59:31,952 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: ConfigurationManager, init=-1: [76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null, confs=<EMPTY_MAP>
2019-10-23 19:59:31,952 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis] (custom)
2019-10-23 19:59:31,952 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 19:59:31,953 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/3ae4964a-d62d-4022-b9b3-343663b493c6 does not exist. Creating ...
2019-10-23 19:59:31,965 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/3ae4964a-d62d-4022-b9b3-343663b493c6/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 19:59:31,979 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/3ae4964a-d62d-4022-b9b3-343663b493c6 has been successfully formatted.
2019-10-23 19:59:31,979 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-343663B493C6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 19:59:31,979 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 19:59:31,980 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 19:59:31,980 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 19:59:31,980 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:31,980 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:31,980 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,981 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 19:59:31,981 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/3ae4964a-d62d-4022-b9b3-343663b493c6
2019-10-23 19:59:31,981 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 19:59:31,981 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 19:59:31,981 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:31,982 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 19:59:31,982 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 19:59:31,982 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 19:59:31,982 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 19:59:31,982 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 19:59:31,983 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 19:59:31,983 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 19:59:31,984 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 19:59:31,984 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 19:59:31,984 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 19:59:31,984 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 19:59:31,985 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 19:59:31,985 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,985 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,986 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: start as a follower, conf=-1: [76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:31,986 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 19:59:31,986 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start FollowerState
2019-10-23 19:59:31,987 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-343663B493C6,id=76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 19:59:31,987 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:31,997 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3ae4964a-d62d-4022-b9b3-343663b493c6, Nodes: 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-23 19:59:32,029 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: addNew group-72C5A45DCE01:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] returns group-72C5A45DCE01:java.util.concurrent.CompletableFuture@6b740744[Not completed]
2019-10-23 19:59:32,032 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: addNew group-72C5A45DCE01:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] returns group-72C5A45DCE01:java.util.concurrent.CompletableFuture@2e76844e[Not completed]
2019-10-23 19:59:32,032 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: addNew group-72C5A45DCE01:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] returns group-72C5A45DCE01:java.util.concurrent.CompletableFuture@3219abca[Not completed]
2019-10-23 19:59:32,034 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: new RaftServerImpl for group-72C5A45DCE01:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] with ContainerStateMachine:uninitialized
2019-10-23 19:59:32,034 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 19:59:32,034 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 19:59:32,034 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 19:59:32,035 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 19:59:32,035 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 19:59:32,035 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: ConfigurationManager, init=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null, confs=<EMPTY_MAP>
2019-10-23 19:59:32,035 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis] (custom)
2019-10-23 19:59:32,035 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: new RaftServerImpl for group-72C5A45DCE01:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] with ContainerStateMachine:uninitialized
2019-10-23 19:59:32,036 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 19:59:32,036 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 19:59:32,036 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01 does not exist. Creating ...
2019-10-23 19:59:32,036 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 19:59:32,036 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: new RaftServerImpl for group-72C5A45DCE01:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] with ContainerStateMachine:uninitialized
2019-10-23 19:59:32,036 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 19:59:32,036 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 19:59:32,037 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 19:59:32,037 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 19:59:32,037 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 19:59:32,037 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 19:59:32,037 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: ConfigurationManager, init=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null, confs=<EMPTY_MAP>
2019-10-23 19:59:32,037 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 19:59:32,038 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis] (custom)
2019-10-23 19:59:32,038 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 19:59:32,038 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: ConfigurationManager, init=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null, confs=<EMPTY_MAP>
2019-10-23 19:59:32,038 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 19:59:32,038 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis] (custom)
2019-10-23 19:59:32,038 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01 does not exist. Creating ...
2019-10-23 19:59:32,039 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 19:59:32,039 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01 does not exist. Creating ...
2019-10-23 19:59:32,049 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 19:59:32,049 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 19:59:32,050 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 19:59:32,064 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01 has been successfully formatted.
2019-10-23 19:59:32,064 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01 has been successfully formatted.
2019-10-23 19:59:32,064 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01 has been successfully formatted.
2019-10-23 19:59:32,064 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-72C5A45DCE01: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 19:59:32,064 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-72C5A45DCE01: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 19:59:32,065 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 19:59:32,065 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-72C5A45DCE01: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 19:59:32,065 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 19:59:32,065 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 19:59:32,065 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 19:59:32,065 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 19:59:32,066 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:32,065 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 19:59:32,066 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:32,066 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 19:59:32,067 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 19:59:32,066 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 19:59:32,067 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01
2019-10-23 19:59:32,067 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 19:59:32,067 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 19:59:32,067 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:32,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 19:59:32,067 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:32,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:32,068 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:32,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 19:59:32,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:32,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 19:59:32,068 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 19:59:32,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 19:59:32,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 19:59:32,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 19:59:32,069 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01
2019-10-23 19:59:32,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 19:59:32,070 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01
2019-10-23 19:59:32,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 19:59:32,070 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 19:59:32,071 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 19:59:32,070 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 19:59:32,071 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 19:59:32,071 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 19:59:32,071 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 19:59:32,071 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:32,072 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 19:59:32,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 19:59:32,072 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 19:59:32,072 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 19:59:32,073 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 19:59:32,072 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 19:59:32,073 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 19:59:32,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 19:59:32,073 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 19:59:32,073 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 19:59:32,074 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 19:59:32,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 19:59:32,074 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 19:59:32,074 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 19:59:32,074 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 19:59:32,074 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,074 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 19:59:32,075 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,075 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 19:59:32,075 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: start as a follower, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:32,075 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 19:59:32,075 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 19:59:32,075 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 19:59:32,076 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start FollowerState
2019-10-23 19:59:32,076 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 19:59:32,076 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 19:59:32,076 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 19:59:32,077 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C5A45DCE01,id=6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 19:59:32,077 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 19:59:32,077 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,077 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 19:59:32,077 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 19:59:32,078 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 19:59:32,078 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 19:59:32,078 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: start as a follower, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:32,078 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 19:59:32,078 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 19:59:32,079 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 19:59:32,079 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start FollowerState
2019-10-23 19:59:32,080 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,081 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,081 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C5A45DCE01,id=76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 19:59:32,081 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: start as a follower, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:32,081 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,082 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 19:59:32,083 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 19:59:32,085 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C5A45DCE01,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 19:59:32,086 [pool-47-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:32,102 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 664f0c07-df88-4aad-8cc3-72c5a45dce01, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-10-23 19:59:32,211 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-10-23 19:59:32,727 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(272)) - Creating Volume: testcontainerstatemachinefailures, with jenkins1000 as owner.
2019-10-23 19:59:32,820 [IPC Server handler 3 on 42158] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(194)) - created volume:testcontainerstatemachinefailures for user:jenkins1000
2019-10-23 19:59:32,845 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(411)) - Creating Bucket: testcontainerstatemachinefailures/testcontainerstatemachinefailures, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-10-23 19:59:33,222 [IPC Server handler 0 on 42955] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:allocateBlock(179)) - Allocating 1 blocks of size 4194304, with ExcludeList {datanodes = [], containerIds = [], pipelineIds = []}
2019-10-23 19:59:33,330 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-10-23 19:59:34,083 [Thread-181] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-10-23 19:59:34,089 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 5 milliseconds for processing 1 containers.
2019-10-23 19:59:36,846 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(111)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-FollowerState: change to CANDIDATE, lastRpcTime:5112ms, electionTimeout:5111ms
2019-10-23 19:59:36,848 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown FollowerState
2019-10-23 19:59:36,848 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-10-23 19:59:36,853 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start LeaderElection
2019-10-23 19:59:36,871 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1: begin an election at term 1 for -1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238], old=null
2019-10-23 19:59:36,873 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown LeaderElection
2019-10-23 19:59:36,874 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-10-23 19:59:36,874 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: change Leader from null to 6db3bc75-fe19-4010-b9b4-a3ce262b192b at term 1 for becomeLeader, leader elected after 5220ms
2019-10-23 19:59:36,881 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-23 19:59:36,881 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-23 19:59:36,886 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-23 19:59:36,891 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-23 19:59:36,891 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-23 19:59:36,892 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-23 19:59:36,901 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start LeaderState
2019-10-23 19:59:36,922 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 19:59:36,928 [Thread-189] INFO  impl.FollowerState (FollowerState.java:run(111)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-FollowerState: change to CANDIDATE, lastRpcTime:5030ms, electionTimeout:5029ms
2019-10-23 19:59:36,930 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 19:59:36,930 [Thread-189] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-10-23 19:59:36,930 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderElection
2019-10-23 19:59:36,936 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238], old=null at 0
2019-10-23 19:59:36,946 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2: begin an election at term 1 for -1: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null
2019-10-23 19:59:36,947 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderElection
2019-10-23 19:59:36,947 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-10-23 19:59:36,947 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: change Leader from null to 729d0bb6-2410-4cc8-96f0-e80551772f93 at term 1 for becomeLeader, leader elected after 5057ms
2019-10-23 19:59:36,948 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-23 19:59:36,948 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-23 19:59:36,948 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-23 19:59:36,948 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-23 19:59:36,948 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-23 19:59:36,948 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-23 19:59:36,949 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderState
2019-10-23 19:59:36,949 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 19:59:36,950 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: set configuration 0: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null at 0
2019-10-23 19:59:36,993 [Thread-192] INFO  impl.FollowerState (FollowerState.java:run(111)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-FollowerState: change to CANDIDATE, lastRpcTime:5006ms, electionTimeout:5006ms
2019-10-23 19:59:36,993 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown FollowerState
2019-10-23 19:59:36,993 [Thread-192] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-10-23 19:59:36,993 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start LeaderElection
2019-10-23 19:59:37,009 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3: begin an election at term 1 for -1: [76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:37,009 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown LeaderElection
2019-10-23 19:59:37,009 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-10-23 19:59:37,009 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: change Leader from null to 76af9f5a-76ac-4564-8b4a-32ca0c573f92 at term 1 for becomeLeader, leader elected after 5029ms
2019-10-23 19:59:37,009 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-23 19:59:37,010 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-23 19:59:37,010 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-23 19:59:37,010 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-23 19:59:37,010 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-23 19:59:37,010 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-23 19:59:37,011 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start LeaderState
2019-10-23 19:59:37,011 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 19:59:37,011 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: set configuration 0: [76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 19:59:37,084 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/3ae4964a-d62d-4022-b9b3-343663b493c6/current/log_inprogress_0
2019-10-23 19:59:37,084 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832/current/log_inprogress_0
2019-10-23 19:59:37,084 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/3fb1b780-7cb9-467c-b790-54e6d0cefdd4/current/log_inprogress_0
2019-10-23 19:59:37,087 [Thread-195] INFO  impl.FollowerState (FollowerState.java:run(111)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-FollowerState: change to CANDIDATE, lastRpcTime:5010ms, electionTimeout:5010ms
2019-10-23 19:59:37,087 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown FollowerState
2019-10-23 19:59:37,087 [Thread-195] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-10-23 19:59:37,087 [Thread-195] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start LeaderElection
2019-10-23 19:59:37,098 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4: begin an election at term 1 for -1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:37,103 [Thread-200] INFO  impl.FollowerState (FollowerState.java:run(111)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-FollowerState: change to CANDIDATE, lastRpcTime:5020ms, electionTimeout:5018ms
2019-10-23 19:59:37,103 [Thread-200] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 19:59:37,104 [Thread-200] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-10-23 19:59:37,104 [Thread-200] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderElection
2019-10-23 19:59:37,119 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection5: begin an election at term 1 for -1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:37,125 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 19:59:37,126 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown FollowerState
2019-10-23 19:59:37,126 [Thread-199] INFO  impl.FollowerState (FollowerState.java:run(120)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 19:59:37,126 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start FollowerState
2019-10-23 19:59:37,155 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection5: Election REJECTED; received 2 response(s) [729d0bb6-2410-4cc8-96f0-e80551772f93<-6db3bc75-fe19-4010-b9b4-a3ce262b192b#0:FAIL-t1, 729d0bb6-2410-4cc8-96f0-e80551772f93<-76af9f5a-76ac-4564-8b4a-32ca0c573f92#0:FAIL-t1] and 0 exception(s); 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01:t1, leader=null, voted=729d0bb6-2410-4cc8-96f0-e80551772f93, raftlog=729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:37,155 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4: Election PASSED; received 2 response(s) [6db3bc75-fe19-4010-b9b4-a3ce262b192b<-729d0bb6-2410-4cc8-96f0-e80551772f93#0:FAIL-t1, 6db3bc75-fe19-4010-b9b4-a3ce262b192b<-76af9f5a-76ac-4564-8b4a-32ca0c573f92#0:OK-t1] and 0 exception(s); 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01:t1, leader=null, voted=6db3bc75-fe19-4010-b9b4-a3ce262b192b, raftlog=6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 19:59:37,155 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-10-23 19:59:37,156 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderElection
2019-10-23 19:59:37,156 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown LeaderElection
2019-10-23 19:59:37,156 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 19:59:37,159 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-10-23 19:59:37,160 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: change Leader from null to 6db3bc75-fe19-4010-b9b4-a3ce262b192b at term 1 for becomeLeader, leader elected after 5094ms
2019-10-23 19:59:37,160 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-23 19:59:37,160 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-23 19:59:37,160 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-23 19:59:37,160 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-23 19:59:37,160 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-23 19:59:37,161 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-23 19:59:37,163 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-23 19:59:37,163 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:37,164 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-23 19:59:37,167 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-23 19:59:37,167 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 19:59:37,167 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 19:59:37,169 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 19:59:37,170 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-23 19:59:37,170 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 19:59:37,170 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-23 19:59:37,170 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-23 19:59:37,170 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 19:59:37,171 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 19:59:37,172 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start LeaderState
2019-10-23 19:59:37,172 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 19:59:37,173 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 19:59:37,217 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/current/log_inprogress_0
2019-10-23 19:59:37,227 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: change Leader from null to 6db3bc75-fe19-4010-b9b4-a3ce262b192b at term 1 for appendEntries, leader elected after 5162ms
2019-10-23 19:59:37,227 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: change Leader from null to 6db3bc75-fe19-4010-b9b4-a3ce262b192b at term 1 for appendEntries, leader elected after 5162ms
2019-10-23 19:59:37,254 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 19:59:37,254 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 19:59:37,254 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 19:59:37,254 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 19:59:37,294 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/current/log_inprogress_0
2019-10-23 19:59:37,294 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/current/log_inprogress_0
2019-10-23 19:59:37,948 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-23 19:59:42,928 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-23 19:59:42,929 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: close
2019-10-23 19:59:42,931 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: shutdown
2019-10-23 19:59:42,932 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-77421D29F832,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 19:59:42,932 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderState
2019-10-23 19:59:42,933 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-PendingRequests: sendNotLeaderResponses
2019-10-23 19:59:42,935 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-StateMachineUpdater: set stopIndex = 0
2019-10-23 19:59:42,937 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: closes. applyIndex: 0
2019-10-23 19:59:42,940 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 19:59:42,942 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker close()
2019-10-23 19:59:42,944 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: shutdown
2019-10-23 19:59:42,944 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C5A45DCE01,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 19:59:42,945 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 19:59:42,945 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater: set stopIndex = 4
2019-10-23 19:59:42,945 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-72C5A45DCE01: Taking a snapshot at:(t:1, i:3) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_3
2019-10-23 19:59:42,945 [Thread-244] INFO  impl.FollowerState (FollowerState.java:run(120)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 19:59:43,055 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(305)) - group-72C5A45DCE01: Finished taking a snapshot at:(t:1, i:3) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_3 time:111
2019-10-23 19:59:43,057 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater: Took a snapshot at index 3
2019-10-23 19:59:43,058 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2019-10-23 19:59:43,061 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-72C5A45DCE01: Taking a snapshot at:(t:1, i:3) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_3
2019-10-23 19:59:43,089 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(305)) - group-72C5A45DCE01: Finished taking a snapshot at:(t:1, i:3) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_3 time:27
2019-10-23 19:59:43,089 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater: Took a snapshot at index 3
2019-10-23 19:59:43,089 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater: snapshotIndex: updateIncreasingly 3 -> 3
2019-10-23 19:59:43,090 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: closes. applyIndex: 4
2019-10-23 19:59:43,090 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 19:59:43,092 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker close()
2019-10-23 19:59:43,095 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown server with port 46766 now
2019-10-23 19:59:43,106 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown server with port 46766 successfully
2019-10-23 19:59:43,106 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: installSnapshot onError, lastRequest: 6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#7-t1, previous=(t:1, i:4), leaderCommit=4, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-10-23 19:59:43,109 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-10-23 19:59:43,111 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
Oct 23, 2019 7:59:43 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@6646dc6a
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Oct 23, 2019 7:59:43 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed@1b79c143
java.lang.NullPointerException
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onError(GrpcLogAppender.java:303)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-10-23 19:59:43,135 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-23 19:59:43,140 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-23 19:59:43,163 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70228253{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-23 19:59:43,170 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63c12e52{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-23 19:59:43,170 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4fc3c165{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-23 19:59:43,171 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e5cbff2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-23 19:59:46,179 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#8-t1, previous=(t:1, i:4), leaderCommit=4, initializing? false, entries: size=1, first=(t:1, i:5), STATEMACHINELOGENTRY, client-DEA5B0C810ED, cid=8
2019-10-23 19:59:46,180 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#9-t1, previous=(t:1, i:5), leaderCommit=4, initializing? false, entries: size=1, first=(t:1, i:6), STATEMACHINELOGENTRY, client-DEA5B0C810ED, cid=9
2019-10-23 19:59:46,193 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#10-t1, previous=(t:1, i:6), leaderCommit=6, initializing? false, entries: size=1, first=(t:1, i:7), METADATAENTRY(c5)
2019-10-23 19:59:46,194 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#11-t1, previous=(t:1, i:7), leaderCommit=6, initializing? false, entries: size=1, first=(t:1, i:8), METADATAENTRY(c6)
2019-10-23 19:59:48,695 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#12-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 19:59:51,197 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#13-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 19:59:52,231 [Thread-290] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c8, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c8, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 19:59:53,686 [Thread-294] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c8, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c8]
2019-10-23 19:59:53,701 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#14-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 19:59:56,202 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#15-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 19:59:58,703 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#16-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 20:00:01,204 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#17-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 20:00:01,257 [Thread-300] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c8, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c8, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:00:02,683 [Thread-303] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c8, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c8]
2019-10-23 20:00:03,705 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#18-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 20:00:06,208 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#19-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 20:00:08,711 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#20-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 20:00:10,299 [Thread-309] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c8, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c8, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:00:11,214 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#21-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 20:00:11,685 [Thread-313] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c8, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c8]
2019-10-23 20:00:13,211 [main] WARN  scm.XceiverClientRatis (XceiverClientRatis.java:watchForCommit(277)) - 3 way commit failed on pipeline Pipeline[ Id: 664f0c07-df88-4aad-8cc3-72c5a45dce01, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
java.util.concurrent.TimeoutException
	at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:274)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:198)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:161)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:346)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:482)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.testDeleteKeyWithSlowFollower(TestDeleteWithSlowFollower.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-10-23 20:00:13,232 [main] INFO  scm.XceiverClientRatis (XceiverClientRatis.java:lambda$watchForCommit$5(295)) - Could not commit index 6 on pipeline Pipeline[ Id: 664f0c07-df88-4aad-8cc3-72c5a45dce01, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN] to all the nodes. Server 729d0bb6-2410-4cc8-96f0-e80551772f93 has failed. Committed by majority.
2019-10-23 20:00:13,233 [main] WARN  storage.BlockOutputStream (BlockOutputStream.java:watchForCommit(352)) - Failed to commit BlockId conID: 1 locID: 103013467634991104 bcsId: 6 on Pipeline[ Id: 664f0c07-df88-4aad-8cc3-72c5a45dce01, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. Failed nodes: [729d0bb6-2410-4cc8-96f0-e80551772f93{ip: null, host: null, networkLocation: /default-rack, certSerialId: null}]
2019-10-23 20:00:13,715 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#22-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 20:00:14,336 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSING replica.
2019-10-23 20:00:14,347 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:flushAndSyncDB(386)) - Container 1 is synced with bcsId 6.
2019-10-23 20:00:14,347 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:flushAndSyncDB(386)) - Container 1 is synced with bcsId 6.
2019-10-23 20:00:14,361 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:close(335)) - Container 1 is closed with bcsId 6.
2019-10-23 20:00:14,362 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:flushAndSyncDB(386)) - Container 1 is synced with bcsId 6.
2019-10-23 20:00:14,363 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:flushAndSyncDB(386)) - Container 1 is synced with bcsId 6.
2019-10-23 20:00:14,364 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSING replica.
2019-10-23 20:00:14,364 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSING replica.
2019-10-23 20:00:14,365 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:14,379 [RatisApplyTransactionExecutor 1] INFO  interfaces.Container (KeyValueContainer.java:close(335)) - Container 1 is closed with bcsId 6.
2019-10-23 20:00:14,380 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:14,480 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:14,562 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:14,863 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:14,881 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:15,081 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:15,163 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:15,331 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:15,331 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:15,383 [IPC Server handler 3 on 42955] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:deleteKeyBlocks(214)) - SCM is informed by OM to delete 1 blocks
2019-10-23 20:00:15,383 [IPC Server handler 3 on 42955] INFO  block.BlockManagerImpl (BlockManagerImpl.java:deleteBlocks(285)) - Deleting blocks conID: 1 locID: 103013467634991104 bcsId: 0
2019-10-23 20:00:15,463 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:15,482 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:15,782 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:15,863 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:16,082 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:16,162 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:16,220 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#23-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: <empty>
2019-10-23 20:00:16,282 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:16,333 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:16,333 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:16,362 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:16,664 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:16,681 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:16,867 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:17,085 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:17,266 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:17,284 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:17,309 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#24-t1, previous=(t:1, i:8), leaderCommit=8, initializing? false, entries: size=1, first=(t:1, i:9), STATEMACHINELOGENTRY, client-0542F753E882, cid=12
2019-10-23 20:00:17,322 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#25-t1, previous=(t:1, i:9), leaderCommit=9, initializing? false, entries: size=1, first=(t:1, i:10), METADATAENTRY(c9)
2019-10-23 20:00:17,336 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:17,336 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:17,666 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:17,685 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:17,887 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:17,966 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:18,086 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:18,167 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:18,339 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:18,339 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:18,485 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:18,568 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:18,685 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:18,868 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:19,068 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:19,085 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:19,340 [Thread-338] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:00:19,342 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:19,342 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:19,367 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:19,487 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:19,668 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:19,687 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:19,825 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#26-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:19,887 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:19,968 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:20,187 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:20,345 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:20,346 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:20,372 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:20,489 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:20,572 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:20,683 [Thread-346] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:00:20,791 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:20,971 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:20,990 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:21,190 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:21,347 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:21,347 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:21,372 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:21,490 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:21,572 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:21,772 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:21,790 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:22,073 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:22,090 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:22,291 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:22,331 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#27-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:22,352 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:22,352 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:22,473 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:22,591 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:22,673 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:22,791 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:23,073 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:23,091 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:23,354 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:23,354 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:23,374 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:23,391 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:23,692 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:23,775 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:23,891 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:24,175 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:24,191 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:24,356 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:24,356 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:24,475 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:24,492 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:24,796 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:24,834 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#28-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:24,876 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:25,093 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:25,176 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:25,359 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:25,359 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:25,394 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:25,577 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:25,794 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:25,877 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:26,094 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:26,176 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:26,361 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:26,361 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:26,376 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:26,394 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:26,777 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:26,793 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:26,977 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:26,993 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:27,278 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:27,335 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#29-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:27,362 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:27,362 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:27,393 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:27,479 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:27,679 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:27,794 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:27,979 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:28,094 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:28,364 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:28,364 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:28,379 [Thread-369] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:00:28,379 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:28,394 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:28,580 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:28,779 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:28,793 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:29,079 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:29,095 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:29,365 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:29,366 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:29,395 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:29,480 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:29,680 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:29,682 [Thread-375] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:00:29,695 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:29,836 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#30-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:29,880 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:30,095 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:30,280 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:30,367 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:30,368 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:30,396 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:30,581 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:30,598 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:30,781 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:30,998 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:31,181 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:31,297 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:31,369 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:31,369 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:31,381 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:31,581 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:31,598 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:31,898 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:31,982 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:32,199 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:32,337 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#31-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:32,371 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:32,371 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:32,382 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:32,498 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:32,681 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:32,799 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:32,982 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:33,099 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:33,299 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:33,374 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:33,374 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:33,381 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:33,599 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:33,781 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:33,801 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:34,081 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:34,099 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:34,376 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:34,376 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:34,399 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:34,482 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:34,599 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:34,682 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:34,838 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#32-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:34,999 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:35,082 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:35,377 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:35,377 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:35,382 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:35,401 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:35,701 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:35,782 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:36,001 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:36,081 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:36,281 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:36,301 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:36,379 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:36,379 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:36,500 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:36,581 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:36,801 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:36,983 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:37,201 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:37,340 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#33-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:37,381 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:37,381 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:37,383 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:37,415 [Thread-397] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:00:37,500 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:37,783 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:37,800 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:38,184 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:38,200 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:38,386 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:38,386 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:38,484 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:38,601 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:38,683 [Thread-402] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:00:38,783 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:38,900 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:39,101 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:39,184 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:39,392 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:39,392 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:39,484 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:39,501 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:39,784 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:39,802 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:39,841 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#34-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:39,984 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:40,101 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:40,184 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:40,384 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:40,397 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:40,397 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:40,402 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:40,684 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:40,701 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:41,001 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:41,088 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:41,401 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:41,401 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:41,402 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:41,485 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:41,603 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:41,686 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:41,903 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:42,086 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:42,104 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:42,342 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#35-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:42,403 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:42,403 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:42,486 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:42,504 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:42,803 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:42,886 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:43,003 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:43,087 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:43,204 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:43,388 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:43,406 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:43,406 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:43,604 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:43,788 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:43,803 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:44,004 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:44,088 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:44,303 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:44,387 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:44,408 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:44,408 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:44,705 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:44,789 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:44,844 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#36-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:45,005 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:45,189 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:45,305 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:45,390 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:45,410 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:45,410 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:45,604 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:45,692 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:45,993 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:46,004 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:46,193 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:46,305 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:46,413 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:46,413 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:46,494 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:46,605 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:46,895 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:47,006 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:47,095 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:47,306 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:47,346 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#37-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:47,415 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:47,415 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:47,465 [Thread-429] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:00:47,495 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:47,608 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:47,682 [Thread-432] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:00:47,795 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:47,908 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:48,195 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:48,208 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:48,395 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:48,417 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:48,417 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:48,608 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:48,798 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:48,808 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:48,998 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:49,209 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:49,298 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:49,420 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:49,420 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:49,509 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:49,598 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:49,797 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:49,808 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:49,849 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#38-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:49,997 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:50,208 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:50,398 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:50,408 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:50,424 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:50,424 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:50,599 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:50,799 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:50,810 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:51,011 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:51,099 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:51,299 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:51,410 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:51,426 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:51,426 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:51,702 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:51,811 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:52,002 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:52,110 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:52,350 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#39-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:52,402 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:52,410 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:52,428 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:52,428 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:52,703 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:52,712 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:53,003 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:53,111 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:53,205 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:53,406 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:53,411 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:53,431 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:53,431 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:53,712 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:53,806 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:54,106 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:54,112 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:54,405 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:54,411 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:54,433 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:54,433 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:54,711 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:54,805 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:54,852 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#40-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:55,011 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:55,207 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:55,213 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:55,435 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:55,435 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:55,506 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:55,612 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:55,807 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:55,812 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:56,012 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:56,106 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:56,406 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:56,413 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:56,437 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:56,437 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:56,497 [Thread-456] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:00:56,606 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:56,713 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:56,807 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:57,015 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:57,108 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:57,308 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:57,315 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:57,355 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#41-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:00:57,439 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:57,439 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:57,607 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:57,615 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:57,683 [Thread-462] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:00:57,907 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:57,916 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:58,108 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:58,315 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:58,409 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:58,441 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:58,442 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:58,616 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:58,709 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:58,917 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:59,008 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:59,217 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:59,309 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:59,446 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:59,446 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:00:59,508 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:59,516 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:59,716 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:59,808 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:00:59,856 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#42-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:00,017 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:00,209 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:00,416 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:00,449 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:00,449 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:00,509 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:00,618 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:00,810 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:00,918 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:01,009 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:01,318 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:01,410 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:01,452 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:01,452 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:01,621 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:01,711 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:01,911 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:01,920 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:02,120 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:02,311 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:02,359 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#43-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:02,420 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:02,453 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:02,453 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:02,712 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:02,820 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:02,912 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:03,122 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:03,212 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:03,422 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:03,455 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:03,455 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:03,612 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:03,722 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:03,813 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:04,022 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:04,213 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:04,321 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:04,457 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:04,457 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:04,516 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:04,521 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:04,816 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:04,861 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#44-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:04,921 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:05,216 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:05,223 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:05,423 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:05,460 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:05,460 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:05,518 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:05,530 [Thread-484] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:01:05,718 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:05,822 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:06,017 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:06,122 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:06,217 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:06,423 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:06,463 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:06,465 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:06,518 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:06,682 [Thread-489] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:01:06,723 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:06,918 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:07,123 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:07,218 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:07,364 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#45-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:07,423 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:07,467 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:07,467 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:07,620 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:07,722 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:07,920 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:08,124 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:08,320 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:08,325 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:08,470 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:08,470 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:08,520 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:08,525 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:08,824 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:08,922 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:09,125 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:09,126 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:09,426 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:09,473 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:09,473 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:09,526 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:09,725 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:09,826 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:09,865 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#46-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:10,125 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:10,225 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:10,425 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:10,425 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:10,475 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:10,475 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:10,725 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:10,827 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:11,127 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:11,127 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:11,327 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:11,427 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:11,477 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:11,477 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:11,627 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:11,827 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:11,927 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:12,127 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:12,230 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:12,369 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#47-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:12,479 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:12,479 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:12,529 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:12,530 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:12,729 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:12,829 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:13,030 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:13,129 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:13,429 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:13,430 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:13,480 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:13,480 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:13,829 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:13,830 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:14,229 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:14,229 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:14,482 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:14,482 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:14,529 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:14,630 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:14,830 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:14,870 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#48-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:14,932 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:15,129 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:15,229 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:15,485 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:15,485 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:15,531 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:15,573 [Thread-516] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:01:15,631 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:15,682 [Thread-519] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:01:15,831 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:15,931 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:16,231 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:16,333 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:16,431 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:16,487 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:16,487 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:16,632 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:16,733 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:16,933 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:16,933 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:17,333 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:17,335 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:17,371 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#49-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:17,490 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:17,490 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:17,534 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:17,635 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:17,735 [EventQueue-ContainerReportForContainerReportHandler] WARN  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(145)) - Container #1 is in OPEN state, but the datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reports an CLOSED replica.
2019-10-23 20:01:17,863 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines [PipelineID=0dd550b4-7c36-4453-9b1a-77421d29f832, PipelineID=664f0c07-df88-4aad-8cc3-72c5a45dce01]
2019-10-23 20:01:17,865 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 0dd550b4-7c36-4453-9b1a-77421d29f832, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-23 20:01:17,870 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 0dd550b4-7c36-4453-9b1a-77421d29f832, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:CLOSED] moved to CLOSED state
2019-10-23 20:01:17,873 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:finalizeAndDestroyPipeline(315)) - destroying pipeline:Pipeline[ Id: 664f0c07-df88-4aad-8cc3-72c5a45dce01, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-10-23 20:01:17,873 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:finalizePipeline(123)) - Pipeline Pipeline[ Id: 664f0c07-df88-4aad-8cc3-72c5a45dce01, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED] moved to CLOSED state
2019-10-23 20:01:17,874 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(61)) - Close container Event triggered for container : #1
2019-10-23 20:01:17,936 [EventQueue-ContainerReportForContainerReportHandler] INFO  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(178)) - Moving container #1 to CLOSED state, datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null} reported CLOSED replica.
2019-10-23 20:01:18,359 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 3 delete blocks command for 3 datanodes, task elapsed time: 6ms
2019-10-23 20:01:18,437 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:18,493 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:18,493 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:18,636 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:18,736 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 76af9f5a-76ac-4564-8b4a-32ca0c573f92 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:18,836 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:18,838 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:19,233 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:19,235 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 6db3bc75-fe19-4010-b9b4-a3ce262b192b for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:19,361 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 1ms
2019-10-23 20:01:19,362 [pool-7-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878358 timed out. Retrying.
2019-10-23 20:01:19,404 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-10-23 20:01:19,449 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2344-6v5ld-3773743899 ip:192.168.164.213
2019-10-23 20:01:19,453 [main] INFO  volume.VolumeUsage (VolumeUsage.java:loadScmUsed(144)) - Cached ScmUsed found for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers : 4096 
2019-10-23 20:01:19,454 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-10-23 20:01:19,454 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers/hdds to VolumeSet
2019-10-23 20:01:19,454 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers/hdds
2019-10-23 20:01:19,455 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(204)) - Scheduled health check for volume /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers/hdds
2019-10-23 20:01:19,494 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:19,494 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:19,501 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-10-23 20:01:19,501 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-10-23 20:01:19,502 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 46766 (custom)
2019-10-23 20:01:19,502 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-10-23 20:01:19,502 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:19,502 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-10-23 20:01:19,502 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 20:01:19,503 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis] (custom)
2019-10-23 20:01:19,503 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$null$0(191)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: found a subdirectory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832
2019-10-23 20:01:19,504 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: addNew group-77421D29F832:[] returns group-77421D29F832:java.util.concurrent.CompletableFuture@76b47204[Not completed]
2019-10-23 20:01:19,504 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$null$0(191)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: found a subdirectory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01
2019-10-23 20:01:19,505 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: addNew group-72C5A45DCE01:[] returns group-72C5A45DCE01:java.util.concurrent.CompletableFuture@4d6ccc97[Not completed]
2019-10-23 20:01:19,508 [pool-59-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: new RaftServerImpl for group-77421D29F832:[] with ContainerStateMachine:uninitialized
2019-10-23 20:01:19,508 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:39777
2019-10-23 20:01:19,509 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 20:01:19,509 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 20:01:19,510 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 20:01:19,510 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 20:01:19,510 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:19,510 [pool-59-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
2019-10-23 20:01:19,510 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis] (custom)
2019-10-23 20:01:19,511 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 20:01:19,512 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-10-23 20:01:19,513 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-10-23 20:01:19,515 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-23 20:01:19,517 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-10-23 20:01:19,517 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-23 20:01:19,518 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-23 20:01:19,520 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39777
2019-10-23 20:01:19,520 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-10-23 20:01:19,523 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5740ff5e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-10-23 20:01:19,523 [pool-59-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 20:01:19,524 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67f77f6e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-10-23 20:01:19,525 [pool-59-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-77421D29F832: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 20:01:19,525 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 20:01:19,525 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 20:01:19,526 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 20:01:19,526 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:19,526 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:19,526 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 20:01:19,526 [pool-59-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832
2019-10-23 20:01:19,526 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 20:01:19,526 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 20:01:19,527 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:19,527 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 20:01:19,527 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 20:01:19,527 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 20:01:19,527 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 20:01:19,527 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 20:01:19,527 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 20:01:19,528 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 20:01:19,535 [pool-59-thread-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: set configuration 0: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null at 0
2019-10-23 20:01:19,535 [pool-59-thread-1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(140)) - Successfully read 1 entries from segment file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832/current/log_inprogress_0
2019-10-23 20:01:19,535 [pool-59-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
2019-10-23 20:01:19,563 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 20:01:19,564 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 20:01:19,564 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 20:01:19,564 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 20:01:19,566 [pool-59-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: new RaftServerImpl for group-72C5A45DCE01:[] with ContainerStateMachine:uninitialized
2019-10-23 20:01:19,566 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 20:01:19,566 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 20:01:19,566 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 20:01:19,567 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 20:01:19,567 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:19,567 [pool-59-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
2019-10-23 20:01:19,567 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis] (custom)
2019-10-23 20:01:19,567 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 20:01:19,575 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@34332b8d{/,file:///tmp/jetty-0.0.0.0-39777-hddsDatanode-_-any-2381511756369851967.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-10-23 20:01:19,576 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@724b939e{HTTP/1.1,[http/1.1]}{0.0.0.0:39777}
2019-10-23 20:01:19,577 [main] INFO  server.Server (Server.java:doStart(419)) - Started @116739ms
2019-10-23 20:01:19,577 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-10-23 20:01:19,579 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39777
2019-10-23 20:01:19,580 [pool-59-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 20:01:19,581 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5d0e0742] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-10-23 20:01:19,582 [pool-59-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-72C5A45DCE01: Setting the last applied index to (t:1, i:3)
2019-10-23 20:01:19,587 [pool-59-thread-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 20:01:19,588 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 20:01:19,589 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:19,589 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 20:01:19,589 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 20:01:19,589 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 20:01:19,589 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 20:01:19,589 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 20:01:19,589 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 20:01:19,589 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 20:01:19,590 [pool-59-thread-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 20:01:19,590 [pool-59-thread-1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(140)) - Successfully read 5 entries from segment file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/current/log_inprogress_0
2019-10-23 20:01:19,590 [pool-59-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
2019-10-23 20:01:19,613 [pool-59-thread-1] INFO  raftlog.RaftLog (RaftLog.java:lambda$new$0(61)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLog: commitIndex: updateToMax old=3, new=3, updated? false
2019-10-23 20:01:19,613 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 20:01:19,613 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 20:01:19,613 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 20:01:19,614 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 20:01:19,872 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#50-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:20,361 [pool-7-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878361 timed out. Retrying.
2019-10-23 20:01:20,362 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 1ms
2019-10-23 20:01:20,362 [pool-7-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878358 timed out. Retrying.
2019-10-23 20:01:20,496 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:20,496 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:21,362 [pool-7-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878362 timed out. Retrying.
2019-10-23 20:01:21,362 [pool-7-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878361 timed out. Retrying.
2019-10-23 20:01:21,363 [pool-7-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878358 timed out. Retrying.
2019-10-23 20:01:21,363 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 1ms
2019-10-23 20:01:21,498 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:21,498 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:21,585 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(213)) - Attempting to start container services.
2019-10-23 20:01:21,585 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(177)) - Background container scanner has been disabled.
2019-10-23 20:01:21,585 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 729d0bb6-2410-4cc8-96f0-e80551772f93 at port 46766
2019-10-23 20:01:21,597 [Datanode State Machine Thread - 0] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: start as a follower, conf=0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:21,598 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: start as a follower, conf=0: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null
2019-10-23 20:01:21,598 [Datanode State Machine Thread - 0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from      null to FOLLOWER at term 1 for startAsFollower
2019-10-23 20:01:21,598 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: changes role from      null to FOLLOWER at term 1 for startAsFollower
2019-10-23 20:01:21,599 [Datanode State Machine Thread - 0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:21,599 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:21,600 [Datanode State Machine Thread - 0] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C5A45DCE01,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:21,600 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-77421D29F832,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:21,602 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start RPC server
2019-10-23 20:01:21,604 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: GrpcService started, listening on 0.0.0.0/0.0.0.0:46766
2019-10-23 20:01:22,364 [pool-7-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878362 timed out. Retrying.
2019-10-23 20:01:22,365 [pool-7-thread-4] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878358 timed out. Retrying.
2019-10-23 20:01:22,365 [pool-7-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878363 timed out. Retrying.
2019-10-23 20:01:22,366 [pool-7-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878361 timed out. Retrying.
2019-10-23 20:01:22,366 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 2ms
2019-10-23 20:01:22,373 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#51-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:22,500 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:22,500 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:23,366 [pool-7-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878361 timed out. Retrying.
2019-10-23 20:01:23,366 [pool-7-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878364 timed out. Retrying.
2019-10-23 20:01:23,366 [pool-7-thread-4] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878363 timed out. Retrying.
2019-10-23 20:01:23,367 [pool-7-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878362 timed out. Retrying.
2019-10-23 20:01:23,367 [pool-7-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878358 timed out. Retrying.
2019-10-23 20:01:23,367 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 0ms
2019-10-23 20:01:23,502 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:23,502 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:23,586 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:24,365 [pool-7-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878364 timed out. Retrying.
2019-10-23 20:01:24,366 [pool-7-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878361 timed out. Retrying.
2019-10-23 20:01:24,367 [pool-7-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878363 timed out. Retrying.
2019-10-23 20:01:24,367 [pool-7-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878358 timed out. Retrying.
2019-10-23 20:01:24,368 [pool-7-thread-4] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878365 timed out. Retrying.
2019-10-23 20:01:24,368 [pool-7-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878362 timed out. Retrying.
2019-10-23 20:01:24,368 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 0ms
2019-10-23 20:01:24,503 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:24,503 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:24,607 [Thread-573] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader 6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:01:24,875 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#52-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:25,366 [pool-7-thread-4] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878364 timed out. Retrying.
2019-10-23 20:01:25,367 [pool-7-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878361 timed out. Retrying.
2019-10-23 20:01:25,368 [pool-7-thread-4] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878363 timed out. Retrying.
2019-10-23 20:01:25,368 [pool-7-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878358 timed out. Retrying.
2019-10-23 20:01:25,368 [pool-7-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878366 timed out. Retrying.
2019-10-23 20:01:25,369 [pool-7-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878362 timed out. Retrying.
2019-10-23 20:01:25,369 [pool-7-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878365 timed out. Retrying.
2019-10-23 20:01:25,369 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 1ms
2019-10-23 20:01:25,505 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:25,505 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:25,583 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:25,683 [Thread-581] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 10 and log index 6 is not yet replicated to ALL_COMMITTED, logIndex=6, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:01:25,687 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:25,690 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: addNew group-6DD33E37F9EC:[729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766] returns group-6DD33E37F9EC:java.util.concurrent.CompletableFuture@6a4342d0[Not completed]
2019-10-23 20:01:25,696 [pool-59-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: new RaftServerImpl for group-6DD33E37F9EC:[729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766] with ContainerStateMachine:uninitialized
2019-10-23 20:01:25,696 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 20:01:25,696 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 20:01:25,697 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 20:01:25,697 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 20:01:25,697 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:25,697 [pool-59-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: ConfigurationManager, init=-1: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null, confs=<EMPTY_MAP>
2019-10-23 20:01:25,698 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis] (custom)
2019-10-23 20:01:25,698 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 20:01:25,698 [pool-59-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/1d0ce1a9-93a0-4ea6-8b13-6dd33e37f9ec does not exist. Creating ...
2019-10-23 20:01:25,724 [pool-59-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/1d0ce1a9-93a0-4ea6-8b13-6dd33e37f9ec/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 20:01:25,737 [pool-59-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/1d0ce1a9-93a0-4ea6-8b13-6dd33e37f9ec has been successfully formatted.
2019-10-23 20:01:25,738 [pool-59-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-6DD33E37F9EC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 20:01:25,738 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 20:01:25,738 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 20:01:25,738 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 20:01:25,738 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:25,739 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:25,739 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 20:01:25,739 [pool-59-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/1d0ce1a9-93a0-4ea6-8b13-6dd33e37f9ec
2019-10-23 20:01:25,739 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 20:01:25,739 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 20:01:25,739 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:25,740 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 20:01:25,740 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 20:01:25,740 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 20:01:25,740 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 20:01:25,740 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 20:01:25,740 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 20:01:25,741 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 20:01:25,741 [pool-59-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 20:01:25,741 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 20:01:25,742 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 20:01:25,742 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 20:01:25,742 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 20:01:25,742 [pool-59-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,743 [pool-59-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,743 [pool-59-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: start as a follower, conf=-1: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null
2019-10-23 20:01:25,743 [pool-59-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 20:01:25,743 [pool-59-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:25,744 [pool-59-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6DD33E37F9EC,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:25,744 [pool-59-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,752 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1d0ce1a9-93a0-4ea6-8b13-6dd33e37f9ec, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-10-23 20:01:25,770 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: addNew group-9D70E690E19C:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] returns group-9D70E690E19C:java.util.concurrent.CompletableFuture@590d29f2[Not completed]
2019-10-23 20:01:25,770 [grpc-default-executor-3] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: addNew group-9D70E690E19C:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] returns group-9D70E690E19C:java.util.concurrent.CompletableFuture@693a0430[Not completed]
2019-10-23 20:01:25,772 [grpc-default-executor-4] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: addNew group-9D70E690E19C:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] returns group-9D70E690E19C:java.util.concurrent.CompletableFuture@77719b4f[Not completed]
2019-10-23 20:01:25,773 [pool-59-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: new RaftServerImpl for group-9D70E690E19C:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] with ContainerStateMachine:uninitialized
2019-10-23 20:01:25,773 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 20:01:25,773 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 20:01:25,774 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 20:01:25,774 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 20:01:25,774 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:25,774 [pool-59-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C: ConfigurationManager, init=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null, confs=<EMPTY_MAP>
2019-10-23 20:01:25,774 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis] (custom)
2019-10-23 20:01:25,774 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: new RaftServerImpl for group-9D70E690E19C:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] with ContainerStateMachine:uninitialized
2019-10-23 20:01:25,774 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 20:01:25,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 20:01:25,775 [pool-59-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c does not exist. Creating ...
2019-10-23 20:01:25,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 20:01:25,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 20:01:25,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 20:01:25,775 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:25,775 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: new RaftServerImpl for group-9D70E690E19C:[6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640] with ContainerStateMachine:uninitialized
2019-10-23 20:01:25,775 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: ConfigurationManager, init=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null, confs=<EMPTY_MAP>
2019-10-23 20:01:25,775 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-10-23 20:01:25,776 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis] (custom)
2019-10-23 20:01:25,776 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-10-23 20:01:25,776 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-10-23 20:01:25,776 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 20:01:25,776 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-10-23 20:01:25,776 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:25,776 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c does not exist. Creating ...
2019-10-23 20:01:25,776 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C: ConfigurationManager, init=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null, confs=<EMPTY_MAP>
2019-10-23 20:01:25,776 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis] (custom)
2019-10-23 20:01:25,777 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.corruption.policy = EXCEPTION (default)
2019-10-23 20:01:25,777 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c does not exist. Creating ...
2019-10-23 20:01:25,788 [pool-59-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 20:01:25,788 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 20:01:25,788 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c/in_use.lock acquired by nodename 19112@pr-hdds-2344-6v5ld-3773743899
2019-10-23 20:01:25,802 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c has been successfully formatted.
2019-10-23 20:01:25,802 [pool-59-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c has been successfully formatted.
2019-10-23 20:01:25,802 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-9D70E690E19C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 20:01:25,802 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c has been successfully formatted.
2019-10-23 20:01:25,803 [pool-59-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-9D70E690E19C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 20:01:25,803 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 20:01:25,803 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 20:01:25,803 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(231)) - group-9D70E690E19C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-10-23 20:01:25,803 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 20:01:25,803 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 20:01:25,803 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 20:01:25,803 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-10-23 20:01:25,803 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:25,803 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 20:01:25,804 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:25,804 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-10-23 20:01:25,804 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 20:01:25,804 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:25,804 [pool-59-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c
2019-10-23 20:01:25,804 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-10-23 20:01:25,804 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 20:01:25,805 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 20:01:25,804 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:25,805 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:25,805 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 20:01:25,804 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:25,805 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c
2019-10-23 20:01:25,805 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 20:01:25,805 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 20:01:25,805 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:25,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 20:01:25,805 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 20:01:25,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:25,806 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-10-23 20:01:25,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 20:01:25,806 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 20:01:25,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 20:01:25,806 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(173)) - new 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c
2019-10-23 20:01:25,806 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 20:01:25,806 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 20:01:25,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 20:01:25,806 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-10-23 20:01:25,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 20:01:25,807 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 20:01:25,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 20:01:25,807 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-10-23 20:01:25,807 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 20:01:25,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 20:01:25,807 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-10-23 20:01:25,807 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 20:01:25,808 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-10-23 20:01:25,808 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 20:01:25,808 [pool-59-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 20:01:25,808 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-10-23 20:01:25,808 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-10-23 20:01:25,808 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 20:01:25,808 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 20:01:25,808 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-10-23 20:01:25,808 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 20:01:25,808 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 20:01:25,809 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 20:01:25,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-10-23 20:01:25,809 [pool-59-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 20:01:25,809 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 20:01:25,809 [pool-59-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,809 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 20:01:25,809 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-10-23 20:01:25,809 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,810 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-10-23 20:01:25,809 [pool-59-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,810 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,810 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(128)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-10-23 20:01:25,810 [pool-59-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C: start as a follower, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:25,810 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C: start as a follower, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:25,810 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-10-23 20:01:25,810 [pool-59-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 20:01:25,810 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-10-23 20:01:25,810 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 20:01:25,810 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.file.num = 5 (custom)
2019-10-23 20:01:25,810 [pool-59-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:25,811 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-10-23 20:01:25,811 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start FollowerState
2019-10-23 20:01:25,811 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,811 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,811 [pool-59-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D70E690E19C,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:25,811 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: start as a follower, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:25,811 [pool-59-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,811 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-10-23 20:01:25,811 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D70E690E19C,id=6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 20:01:25,812 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start FollowerState
2019-10-23 20:01:25,812 [pool-27-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,812 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D70E690E19C,id=76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 20:01:25,812 [pool-37-thread-1] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:25,823 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 612e24d6-74c8-4c0f-b3c6-9d70e690e19c, Nodes: 729d0bb6-2410-4cc8-96f0-e80551772f93{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}6db3bc75-fe19-4010-b9b4-a3ce262b192b{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}76af9f5a-76ac-4564-8b4a-32ca0c573f92{ip: 192.168.164.213, host: pr-hdds-2344-6v5ld-3773743899, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-10-23 20:01:25,885 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:26,186 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:26,368 [pool-7-thread-2] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878361 timed out. Retrying.
2019-10-23 20:01:26,370 [pool-7-thread-6] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878366 timed out. Retrying.
2019-10-23 20:01:26,370 [pool-7-thread-5] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878362 timed out. Retrying.
2019-10-23 20:01:26,370 [pool-7-thread-1] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878365 timed out. Retrying.
2019-10-23 20:01:26,370 [pool-7-thread-3] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878364 timed out. Retrying.
2019-10-23 20:01:26,370 [SCMBlockDeletingService#1] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:call(184)) - Totally added 1 delete blocks command for 1 datanodes, task elapsed time: 1ms
2019-10-23 20:01:26,371 [pool-7-thread-4] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878363 timed out. Retrying.
2019-10-23 20:01:26,371 [pool-7-thread-8] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878358 timed out. Retrying.
2019-10-23 20:01:26,371 [pool-7-thread-7] INFO  commands.RetriableDatanodeEventWatcher (RetriableDatanodeEventWatcher.java:onTimeout(47)) - RetriableDatanodeCommand type=deleteBlocksCommand with id=1571860878367 timed out. Retrying.
2019-10-23 20:01:26,488 [EventQueue-PendingDeleteStatusForPendingDeleteHandler] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:handlePendingDeletes(115)) - Block deletion txnID mismatch in datanode 729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID 1. Datanode delete txnID: 0, SCM txnID: 1
2019-10-23 20:01:26,506 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:26,506 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:26,602 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,602 [Thread-558] INFO  impl.FollowerState (FollowerState.java:run(111)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-FollowerState: change to CANDIDATE, lastRpcTime:5003ms, electionTimeout:5003ms
2019-10-23 20:01:26,603 [Thread-558] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:26,603 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,603 [Thread-558] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-10-23 20:01:26,603 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,603 [Thread-558] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderElection
2019-10-23 20:01:26,603 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,604 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,605 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,605 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,606 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,606 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,606 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,607 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,607 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,607 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,607 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,607 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,608 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,608 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,608 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,608 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,609 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,609 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,609 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,609 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,610 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,610 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,610 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,610 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,611 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,611 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,611 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,611 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,612 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,612 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,612 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,612 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,612 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,613 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,613 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,613 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,613 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(38)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,614 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,614 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,614 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,614 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,614 [Command processor thread] INFO  commandhandler.DeleteBlocksCommandHandler (DeleteBlocksCommandHandler.java:handle(106)) - Start to delete container blocks, TXIDs=[1(2)], numOfContainers=1, numOfBlocks=1
2019-10-23 20:01:26,618 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection6: begin an election at term 2 for 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:26,627 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: change Leader from 6db3bc75-fe19-4010-b9b4-a3ce262b192b to null at term 2 for updateCurrentTerm
2019-10-23 20:01:26,627 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: change Leader from 6db3bc75-fe19-4010-b9b4-a3ce262b192b to null at term 2 for updateCurrentTerm
2019-10-23 20:01:26,627 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:26,628 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: changes role from    LEADER to FOLLOWER at term 2 for recognizeCandidate:729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:26,628 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown FollowerState
2019-10-23 20:01:26,628 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown LeaderState
2019-10-23 20:01:26,628 [Thread-243] INFO  impl.FollowerState (FollowerState.java:run(120)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:26,628 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start FollowerState
2019-10-23 20:01:26,630 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@2c5d30ff] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(149)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-10-23 20:01:26,630 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@18d21319] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(149)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->76af9f5a-76ac-4564-8b4a-32ca0c573f92-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-10-23 20:01:26,630 [grpc-default-executor-4] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-PendingRequests: sendNotLeaderResponses
2019-10-23 20:01:26,635 [Thread-601] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01 is not the leader, logIndex=0, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:01:26,635 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start FollowerState
2019-10-23 20:01:26,635 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: Completed APPEND_ENTRIES, lastRequest: 6db3bc75-fe19-4010-b9b4-a3ce262b192b->76af9f5a-76ac-4564-8b4a-32ca0c573f92#53-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:26,638 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->76af9f5a-76ac-4564-8b4a-32ca0c573f92-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-10-23 20:01:26,650 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->76af9f5a-76ac-4564-8b4a-32ca0c573f92: nextIndex: updateUnconditionally 11 -> 10
2019-10-23 20:01:26,651 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection6: Election REJECTED; received 2 response(s) [729d0bb6-2410-4cc8-96f0-e80551772f93<-6db3bc75-fe19-4010-b9b4-a3ce262b192b#0:FAIL-t2, 729d0bb6-2410-4cc8-96f0-e80551772f93<-76af9f5a-76ac-4564-8b4a-32ca0c573f92#0:FAIL-t2] and 0 exception(s); 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01:t2, leader=null, voted=729d0bb6-2410-4cc8-96f0-e80551772f93, raftlog=729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLog:OPENED:c3,f4,i4, conf=0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:26,651 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
2019-10-23 20:01:26,652 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderElection
2019-10-23 20:01:26,652 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:26,773 [Thread-559] INFO  impl.FollowerState (FollowerState.java:run(111)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-FollowerState: change to CANDIDATE, lastRpcTime:5173ms, electionTimeout:5173ms
2019-10-23 20:01:26,773 [Thread-559] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:26,773 [Thread-559] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-10-23 20:01:26,774 [Thread-559] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderElection
2019-10-23 20:01:26,788 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7: begin an election at term 2 for 0: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null
2019-10-23 20:01:26,788 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderElection
2019-10-23 20:01:26,788 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-10-23 20:01:26,788 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: change Leader from null to 729d0bb6-2410-4cc8-96f0-e80551772f93 at term 2 for becomeLeader, leader elected after 7263ms
2019-10-23 20:01:26,789 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-23 20:01:26,789 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-23 20:01:26,789 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-23 20:01:26,789 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-23 20:01:26,790 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-23 20:01:26,790 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-23 20:01:26,790 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderState
2019-10-23 20:01:26,791 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(390)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2019-10-23 20:01:26,794 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: set configuration 1: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null at 1
2019-10-23 20:01:26,795 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(533)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832/current/log_inprogress_0 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832/current/log_0-0
2019-10-23 20:01:26,804 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID=#1 failed. Corresponding entry not found.
2019-10-23 20:01:26,804 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID=#1 failed. Corresponding entry not found.
2019-10-23 20:01:26,804 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID=#1 failed. Corresponding entry not found.
2019-10-23 20:01:26,804 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID=#1 failed. Corresponding entry not found.
2019-10-23 20:01:26,805 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID=#1 failed. Corresponding entry not found.
2019-10-23 20:01:26,805 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID=#1 failed. Corresponding entry not found.
2019-10-23 20:01:26,805 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID=#1 failed. Corresponding entry not found.
2019-10-23 20:01:26,805 [EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] WARN  block.DeletedBlockLogImpl (DeletedBlockLogImpl.java:commitTransactions(205)) - Transaction txId=1 commit by dnId=729d0bb6-2410-4cc8-96f0-e80551772f93 for containerID=#1 failed. Corresponding entry not found.
2019-10-23 20:01:26,842 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/0dd550b4-7c36-4453-9b1a-77421d29f832/current/log_inprogress_1
2019-10-23 20:01:27,376 [java.util.concurrent.ThreadPoolExecutor$Worker@21345514[State = -1, empty queue]] WARN  server.GrpcLogAppender (GrpcLogAppender.java:timeoutAppendRequest(209)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: appendEntries Timeout, request=6db3bc75-fe19-4010-b9b4-a3ce262b192b->729d0bb6-2410-4cc8-96f0-e80551772f93#53-t1, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:27,508 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:27,508 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:27,656 [Thread-611] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:01:28,509 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:28,509 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:28,672 [Thread-617] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01 is not the leader, logIndex=0, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:01:29,511 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:29,512 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:29,597 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-10-23 20:01:29,598 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-10-23 20:01:29,598 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-10-23 20:01:29,598 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42158
2019-10-23 20:01:29,600 [IPC Server listener on 42158] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42158
2019-10-23 20:01:29,600 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(250)) - Stopping OMDoubleBuffer flush thread
2019-10-23 20:01:29,600 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-23 20:01:29,601 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(193)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-10-23 20:01:29,601 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service KeyDeletingService
2019-10-23 20:01:29,614 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5d235104{/,null,UNAVAILABLE}{/ozoneManager}
2019-10-23 20:01:29,615 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4e8e8621{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-23 20:01:29,616 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65cc8228{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-10-23 20:01:29,616 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@40ab8a8{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-23 20:01:29,620 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-10-23 20:01:29,641 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-23 20:01:29,651 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-23 20:01:29,689 [Thread-623] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01 is not the leader, logIndex=0, commits[729d0bb6-2410-4cc8-96f0-e80551772f93:c3]
2019-10-23 20:01:30,512 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:30,515 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:30,706 [Thread-628] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:01:30,824 [Thread-590] INFO  impl.FollowerState (FollowerState.java:run(111)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-FollowerState: change to CANDIDATE, lastRpcTime:5012ms, electionTimeout:5012ms
2019-10-23 20:01:30,824 [Thread-590] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown FollowerState
2019-10-23 20:01:30,825 [Thread-590] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-10-23 20:01:30,825 [Thread-590] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start LeaderElection
2019-10-23 20:01:30,830 [Thread-583] INFO  impl.FollowerState (FollowerState.java:run(111)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-FollowerState: change to CANDIDATE, lastRpcTime:5086ms, electionTimeout:5086ms
2019-10-23 20:01:30,830 [Thread-583] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:30,831 [Thread-583] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-10-23 20:01:30,831 [Thread-583] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderElection
2019-10-23 20:01:30,853 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9: begin an election at term 1 for -1: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null
2019-10-23 20:01:30,853 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8: begin an election at term 1 for -1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:30,853 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderElection
2019-10-23 20:01:30,853 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-10-23 20:01:30,854 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: change Leader from null to 729d0bb6-2410-4cc8-96f0-e80551772f93 at term 1 for becomeLeader, leader elected after 5115ms
2019-10-23 20:01:30,854 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-23 20:01:30,854 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-23 20:01:30,854 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-23 20:01:30,855 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-23 20:01:30,856 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-23 20:01:30,856 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-23 20:01:30,857 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderState
2019-10-23 20:01:30,857 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 20:01:30,858 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: set configuration 0: [729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766], old=null at 0
2019-10-23 20:01:30,899 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 20:01:30,899 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 20:01:30,900 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown FollowerState
2019-10-23 20:01:30,900 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:30,900 [Thread-588] INFO  impl.FollowerState (FollowerState.java:run(120)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:30,900 [Thread-587] INFO  impl.FollowerState (FollowerState.java:run(120)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:30,900 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start FollowerState
2019-10-23 20:01:30,901 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:30,907 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/1d0ce1a9-93a0-4ea6-8b13-6dd33e37f9ec/current/log_inprogress_0
2019-10-23 20:01:30,910 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8: Election PASSED; received 1 response(s) [76af9f5a-76ac-4564-8b4a-32ca0c573f92<-6db3bc75-fe19-4010-b9b4-a3ce262b192b#0:OK-t1] and 0 exception(s); 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C:t1, leader=null, voted=76af9f5a-76ac-4564-8b4a-32ca0c573f92, raftlog=76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:30,910 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown LeaderElection
2019-10-23 20:01:30,911 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-10-23 20:01:30,911 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: change Leader from null to 76af9f5a-76ac-4564-8b4a-32ca0c573f92 at term 1 for becomeLeader, leader elected after 5108ms
2019-10-23 20:01:30,912 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-23 20:01:30,912 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-23 20:01:30,912 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-23 20:01:30,912 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-23 20:01:30,912 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-23 20:01:30,913 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-23 20:01:30,913 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-23 20:01:30,913 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:30,913 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-23 20:01:30,914 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-23 20:01:30,914 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 20:01:30,914 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:30,914 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:30,915 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-23 20:01:30,915 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:30,915 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-23 20:01:30,916 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-23 20:01:30,916 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 20:01:30,916 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:30,916 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start LeaderState
2019-10-23 20:01:30,917 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 20:01:30,918 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 20:01:30,957 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C: change Leader from null to 76af9f5a-76ac-4564-8b4a-32ca0c573f92 at term 1 for appendEntries, leader elected after 5154ms
2019-10-23 20:01:30,957 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C: change Leader from null to 76af9f5a-76ac-4564-8b4a-32ca0c573f92 at term 1 for appendEntries, leader elected after 5154ms
2019-10-23 20:01:30,962 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 20:01:30,962 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C: set configuration 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 0
2019-10-23 20:01:30,963 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 20:01:30,963 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(385)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-SegmentedRaftLogWorker: Starting segment from index:0
2019-10-23 20:01:30,966 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c/current/log_inprogress_0
2019-10-23 20:01:31,016 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c/current/log_inprogress_0
2019-10-23 20:01:31,016 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/612e24d6-74c8-4c0f-b3c6-9d70e690e19c/current/log_inprogress_0
2019-10-23 20:01:31,514 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:31,517 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:31,641 [Thread-600] INFO  impl.FollowerState (FollowerState.java:run(111)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-FollowerState: change to CANDIDATE, lastRpcTime:5013ms, electionTimeout:5010ms
2019-10-23 20:01:31,642 [Thread-600] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown FollowerState
2019-10-23 20:01:31,642 [Thread-600] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-10-23 20:01:31,642 [Thread-600] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start LeaderElection
2019-10-23 20:01:31,657 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10: begin an election at term 3 for 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:31,661 [Thread-602] INFO  impl.FollowerState (FollowerState.java:run(111)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-FollowerState: change to CANDIDATE, lastRpcTime:5026ms, electionTimeout:5024ms
2019-10-23 20:01:31,663 [Thread-602] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown FollowerState
2019-10-23 20:01:31,663 [Thread-602] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2019-10-23 20:01:31,663 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 20:01:31,663 [Thread-602] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start LeaderElection
2019-10-23 20:01:31,663 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:31,665 [Thread-604] INFO  impl.FollowerState (FollowerState.java:run(120)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:31,665 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: changes role from CANDIDATE to FOLLOWER at term 3 for recognizeCandidate:76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 20:01:31,666 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:31,666 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown LeaderElection
2019-10-23 20:01:31,666 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: start FollowerState
2019-10-23 20:01:31,681 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10: Election PASSED; received 2 response(s) [76af9f5a-76ac-4564-8b4a-32ca0c573f92<-6db3bc75-fe19-4010-b9b4-a3ce262b192b#0:FAIL-t3, 76af9f5a-76ac-4564-8b4a-32ca0c573f92<-729d0bb6-2410-4cc8-96f0-e80551772f93#0:OK-t3] and 0 exception(s); 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01:t3, leader=null, voted=76af9f5a-76ac-4564-8b4a-32ca0c573f92, raftlog=76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLog:OPENED:c10,f10,i10, conf=0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:31,681 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown LeaderElection
2019-10-23 20:01:31,682 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
2019-10-23 20:01:31,682 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: change Leader from null to 76af9f5a-76ac-4564-8b4a-32ca0c573f92 at term 3 for becomeLeader, leader elected after 5054ms
2019-10-23 20:01:31,682 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-10-23 20:01:31,682 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-10-23 20:01:31,683 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-10-23 20:01:31,683 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-10-23 20:01:31,683 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-10-23 20:01:31,683 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-10-23 20:01:31,684 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-23 20:01:31,684 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:31,684 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-23 20:01:31,684 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-23 20:01:31,684 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 20:01:31,685 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:31,685 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:lambda$create$1(61)) - First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
2019-10-23 20:01:31,685 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-23 20:01:31,685 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:31,685 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-23 20:01:31,686 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-23 20:01:31,686 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 20:01:31,686 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:31,686 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start LeaderState
2019-10-23 20:01:31,687 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(390)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker: Rolling segment log-0_10 to index:10
2019-10-23 20:01:31,687 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: set configuration 11: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null at 11
2019-10-23 20:01:31,687 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(533)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/current/log_inprogress_0 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/current/log_0-10
2019-10-23 20:01:31,690 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: change Leader from null to 76af9f5a-76ac-4564-8b4a-32ca0c573f92 at term 3 for appendEntries, leader elected after 12102ms
2019-10-23 20:01:31,690 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(1023)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: Failed appendEntries as previous log entry ((t:1, i:10)) is not found
2019-10-23 20:01:31,691 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:checkInconsistentAppendEntries(996)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: inconsistency entries. Reply:76af9f5a-76ac-4564-8b4a-32ca0c573f92<-729d0bb6-2410-4cc8-96f0-e80551772f93#0:FAIL,INCONSISTENCY,nextIndex:5,term:3,followerCommit:3
2019-10-23 20:01:31,693 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93: nextIndex: updateUnconditionally 11 -> 5
2019-10-23 20:01:31,725 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection11: begin an election at term 4 for 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:31,727 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-LeaderElection11: Election REJECTED; received 0 response(s) [] and 0 exception(s); 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01:t4, leader=null, voted=6db3bc75-fe19-4010-b9b4-a3ce262b192b, raftlog=6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLog:OPENED:c10,f10,i10, conf=0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:31,733 [Thread-654] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: change Leader from 76af9f5a-76ac-4564-8b4a-32ca0c573f92 to null at term 4 for updateCurrentTerm
2019-10-23 20:01:31,734 [Thread-654] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: changes role from    LEADER to FOLLOWER at term 4 for stepDown
2019-10-23 20:01:31,734 [Thread-654] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown LeaderState
2019-10-23 20:01:31,738 [Thread-654] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-PendingRequests: sendNotLeaderResponses
2019-10-23 20:01:31,738 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(576)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/current/log_inprogress_11
2019-10-23 20:01:31,738 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] ERROR raftlog.RaftLog (RaftLog.java:getEntry(478)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLog: Failed readStateMachineData for (t:1, i:5), STATEMACHINELOGENTRY, client-DEA5B0C810ED, cid=8
java.lang.InterruptedException
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:347)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
	at org.apache.ratis.server.raftlog.RaftLog$EntryWithData.getEntry(RaftLog.java:472)
	at org.apache.ratis.util.DataQueue.pollList(DataQueue.java:134)
	at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:220)
	at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:175)
	at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:119)
	at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:76)
	at java.lang.Thread.run(Thread.java:748)
2019-10-23 20:01:31,739 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@64e6eaf3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(149)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->6db3bc75-fe19-4010-b9b4-a3ce262b192b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-10-23 20:01:31,740 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] ERROR impl.LogAppender (LogAppender.java:run(80)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender-AppenderDaemon failed RaftLog
org.apache.ratis.server.raftlog.RaftLogIOException: 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLog: Failed readStateMachineData for (t:1, i:5), STATEMACHINELOGENTRY, client-DEA5B0C810ED, cid=8
	at org.apache.ratis.server.raftlog.RaftLog$EntryWithData.getEntry(RaftLog.java:479)
	at org.apache.ratis.util.DataQueue.pollList(DataQueue.java:134)
	at org.apache.ratis.server.impl.LogAppender.createRequest(LogAppender.java:220)
	at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:175)
	at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:119)
	at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:76)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:347)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
	at org.apache.ratis.server.raftlog.RaftLog$EntryWithData.getEntry(RaftLog.java:472)
	... 6 more
2019-10-23 20:01:31,739 [Thread-654] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start FollowerState
2019-10-23 20:01:31,742 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] INFO  impl.RaftServerImpl (LeaderState.java:restartSender(408)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderState: Restarting GrpcLogAppender for 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:31,742 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-10-23 20:01:31,742 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: Completed APPEND_ENTRIES, lastRequest: 76af9f5a-76ac-4564-8b4a-32ca0c573f92->6db3bc75-fe19-4010-b9b4-a3ce262b192b#0-t3, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>
2019-10-23 20:01:31,742 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-10-23 20:01:31,744 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-10-23 20:01:31,744 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->6db3bc75-fe19-4010-b9b4-a3ce262b192b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-10-23 20:01:31,744 [grpc-default-executor-5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: change Leader from 76af9f5a-76ac-4564-8b4a-32ca0c573f92 to null at term 4 for updateCurrentTerm
2019-10-23 20:01:31,744 [Thread-663] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01 is not the leader 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640, logIndex=0, commits[729d0bb6-2410-4cc8-96f0-e80551772f93:c3]
2019-10-23 20:01:31,744 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-10-23 20:01:31,746 [grpc-default-executor-5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from  FOLLOWER to FOLLOWER at term 4 for recognizeCandidate:6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 20:01:31,750 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:31,750 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-10-23 20:01:31,750 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:31,750 [Thread-652] INFO  impl.FollowerState (FollowerState.java:run(120)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:31,750 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-10-23 20:01:31,756 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: changes role from  FOLLOWER to FOLLOWER at term 4 for recognizeCandidate:6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 20:01:31,756 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown FollowerState
Exception in thread "org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@21e4780b" 2019-10-23 20:01:31,756 [Thread-662] INFO  impl.FollowerState (FollowerState.java:run(120)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
java.lang.IllegalStateException: ILLEGAL TRANSITION: In 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender-AppenderDaemon, CLOSING -> EXCEPTION
	at org.apache.ratis.util.Preconditions.assertTrue(Preconditions.java:63)
	at org.apache.ratis.util.LifeCycle$State.validate(LifeCycle.java:123)
	at org.apache.ratis.util.LifeCycle.transition(LifeCycle.java:143)
	at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:81)
	at java.lang.Thread.run(Thread.java:748)
2019-10-23 20:01:31,756 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: start FollowerState
2019-10-23 20:01:31,780 [Thread-670] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01 is not the leader, logIndex=0, commits[76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10, 6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4]
2019-10-23 20:01:32,515 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:32,518 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:32,798 [Thread-675] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01 is not the leader, logIndex=0, commits[6db3bc75-fe19-4010-b9b4-a3ce262b192b:c10, 729d0bb6-2410-4cc8-96f0-e80551772f93:c4, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:c10]
2019-10-23 20:01:33,516 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:33,522 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:33,814 [Thread-682] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01 is not the leader, logIndex=0, commits[729d0bb6-2410-4cc8-96f0-e80551772f93:c3]
2019-10-23 20:01:34,518 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:34,525 [BlockDeletingService#2] WARN  background.BlockDeletingService (BlockDeletingService.java:isDeletionAllowed(187)) - Close Container log Index 6 is not replicated across allthe servers in the pipeline 664f0c07-df88-4aad-8cc3-72c5a45dce01 as the min replicated index is 4. Deletion is not allowed in this container yet.
2019-10-23 20:01:34,622 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-23 20:01:34,622 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-23 20:01:34,623 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: close
2019-10-23 20:01:34,623 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: close
2019-10-23 20:01:34,623 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C: shutdown
2019-10-23 20:01:34,623 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: shutdown
2019-10-23 20:01:34,624 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D70E690E19C,id=6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 20:01:34,624 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D70E690E19C,id=76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 20:01:34,624 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown FollowerState
2019-10-23 20:01:34,624 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown LeaderState
2019-10-23 20:01:34,624 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-StateMachineUpdater: set stopIndex = 0
2019-10-23 20:01:34,625 [Thread-635] INFO  impl.FollowerState (FollowerState.java:run(120)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:34,626 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C: closes. applyIndex: 0
2019-10-23 20:01:34,626 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@56c15af3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(149)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C->6db3bc75-fe19-4010-b9b4-a3ce262b192b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-10-23 20:01:34,630 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:34,626 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@13c3de4f] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(149)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-10-23 20:01:34,626 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-PendingRequests: sendNotLeaderResponses
2019-10-23 20:01:34,632 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-9D70E690E19C-SegmentedRaftLogWorker close()
2019-10-23 20:01:34,633 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-StateMachineUpdater: set stopIndex = 0
2019-10-23 20:01:34,634 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: shutdown
2019-10-23 20:01:34,634 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C: closes. applyIndex: 0
2019-10-23 20:01:34,634 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: Completed APPEND_ENTRIES, lastRequest: 76af9f5a-76ac-4564-8b4a-32ca0c573f92->6db3bc75-fe19-4010-b9b4-a3ce262b192b#2-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-23 20:01:34,634 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: Completed APPEND_ENTRIES, lastRequest: 76af9f5a-76ac-4564-8b4a-32ca0c573f92->729d0bb6-2410-4cc8-96f0-e80551772f93#2-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-10-23 20:01:34,635 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:34,634 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C5A45DCE01,id=6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 20:01:34,636 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C-SegmentedRaftLogWorker close()
2019-10-23 20:01:34,640 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C->6db3bc75-fe19-4010-b9b4-a3ce262b192b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-10-23 20:01:34,640 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C->729d0bb6-2410-4cc8-96f0-e80551772f93-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-10-23 20:01:34,636 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown FollowerState
2019-10-23 20:01:34,643 [grpc-default-executor-5] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C->6db3bc75-fe19-4010-b9b4-a3ce262b192b: nextIndex: updateUnconditionally 1 -> 0
2019-10-23 20:01:34,643 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->6db3bc75-fe19-4010-b9b4-a3ce262b192b: nextIndex: updateUnconditionally 11 -> 1
2019-10-23 20:01:34,642 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: shutdown
2019-10-23 20:01:34,644 [Thread-653] INFO  impl.FollowerState (FollowerState.java:run(120)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:34,644 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-72C5A45DCE01: Taking a snapshot at:(t:1, i:10) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_10
2019-10-23 20:01:34,644 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-StateMachineUpdater: set stopIndex = 10
2019-10-23 20:01:34,645 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-343663B493C6,id=76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 20:01:34,646 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown LeaderState
2019-10-23 20:01:34,646 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-PendingRequests: sendNotLeaderResponses
2019-10-23 20:01:34,647 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-StateMachineUpdater: set stopIndex = 0
2019-10-23 20:01:34,647 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6: closes. applyIndex: 0
2019-10-23 20:01:34,647 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:34,649 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-343663B493C6-SegmentedRaftLogWorker close()
2019-10-23 20:01:34,650 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: shutdown
2019-10-23 20:01:34,650 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C5A45DCE01,id=76af9f5a-76ac-4564-8b4a-32ca0c573f92
2019-10-23 20:01:34,651 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown FollowerState
2019-10-23 20:01:34,651 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater: set stopIndex = 10
2019-10-23 20:01:34,651 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-72C5A45DCE01: Taking a snapshot at:(t:1, i:9) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_9
2019-10-23 20:01:34,651 [Thread-666] INFO  impl.FollowerState (FollowerState.java:run(120)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:34,659 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(305)) - group-72C5A45DCE01: Finished taking a snapshot at:(t:1, i:10) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_10 time:15
2019-10-23 20:01:34,659 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(305)) - group-72C5A45DCE01: Finished taking a snapshot at:(t:1, i:9) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_9 time:8
2019-10-23 20:01:34,659 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-StateMachineUpdater: Took a snapshot at index 10
2019-10-23 20:01:34,659 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater: Took a snapshot at index 9
2019-10-23 20:01:34,659 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 10
2019-10-23 20:01:34,659 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 9
2019-10-23 20:01:34,660 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-72C5A45DCE01: Taking a snapshot at:(t:1, i:9) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_9
2019-10-23 20:01:34,660 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01: closes. applyIndex: 10
2019-10-23 20:01:34,660 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:34,661 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-72C5A45DCE01-SegmentedRaftLogWorker close()
2019-10-23 20:01:34,663 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: shutdown
2019-10-23 20:01:34,663 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-54E6D0CEFDD4,id=6db3bc75-fe19-4010-b9b4-a3ce262b192b
2019-10-23 20:01:34,663 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown LeaderState
2019-10-23 20:01:34,664 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-PendingRequests: sendNotLeaderResponses
2019-10-23 20:01:34,664 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-StateMachineUpdater: set stopIndex = 0
2019-10-23 20:01:34,664 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4: closes. applyIndex: 0
2019-10-23 20:01:34,665 [6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:34,666 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b@group-54E6D0CEFDD4-SegmentedRaftLogWorker close()
2019-10-23 20:01:34,667 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown server with port 43238 now
2019-10-23 20:01:34,672 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 6db3bc75-fe19-4010-b9b4-a3ce262b192b: shutdown server with port 43238 successfully
2019-10-23 20:01:34,672 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(305)) - group-72C5A45DCE01: Finished taking a snapshot at:(t:1, i:9) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/ratis/664f0c07-df88-4aad-8cc3-72c5a45dce01/sm/snapshot.1_9 time:13
2019-10-23 20:01:34,673 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(269)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater: Took a snapshot at index 9
2019-10-23 20:01:34,673 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(84)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-StateMachineUpdater: snapshotIndex: updateIncreasingly 9 -> 9
2019-10-23 20:01:34,673 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01: closes. applyIndex: 10
2019-10-23 20:01:34,674 [76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:34,675 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLogWorker close()
2019-10-23 20:01:34,676 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown server with port 43640 now
2019-10-23 20:01:34,677 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92: shutdown server with port 43640 successfully
2019-10-23 20:01:34,683 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-23 20:01:34,687 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-10-23 20:01:34,701 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-23 20:01:34,704 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-23 20:01:34,705 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-23 20:01:34,708 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-23 20:01:34,718 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@60325987{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-23 20:01:34,718 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@673919a7{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-23 20:01:34,719 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2f37f1f9{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-23 20:01:34,719 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@25d93198{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-23 20:01:34,719 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e8ab90f{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-23 20:01:34,720 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21079a12{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-23 20:01:34,720 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30364216{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-23 20:01:34,721 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c008c24{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-23 20:01:34,730 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-10-23 20:01:35,841 [Thread-689] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01 is not the leader, logIndex=0, commits[729d0bb6-2410-4cc8-96f0-e80551772f93:c3]
2019-10-23 20:01:36,777 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@4ba5291c] ERROR impl.LogAppender (LogAppender.java:run(86)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender-AppenderDaemon unexpected exception
java.lang.IllegalArgumentException: 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLog is expected to be opened but it is CLOSED
	at org.apache.ratis.util.OpenCloseState.assertOpen(OpenCloseState.java:63)
	at org.apache.ratis.server.raftlog.RaftLog.checkLogState(RaftLog.java:102)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getLastEntryTermIndex(SegmentedRaftLog.java:345)
	at org.apache.ratis.server.raftlog.RaftLog.getNextIndex(RaftLog.java:148)
	at org.apache.ratis.server.impl.LogAppender.shouldAppendEntries(LogAppender.java:544)
	at org.apache.ratis.server.impl.LogAppender.shouldSendRequest(LogAppender.java:540)
	at org.apache.ratis.grpc.server.GrpcLogAppender.shouldSendRequest(GrpcLogAppender.java:156)
	at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:103)
	at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:76)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.util.OpenCloseState$CloseTrace: Close 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLog
	at org.apache.ratis.util.OpenCloseState.lambda$close$1(OpenCloseState.java:109)
	at java.util.concurrent.atomic.AtomicReference.getAndUpdate(AtomicReference.java:160)
	at org.apache.ratis.util.OpenCloseState.close(OpenCloseState.java:109)
	at org.apache.ratis.server.raftlog.RaftLog.close(RaftLog.java:437)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.close(SegmentedRaftLog.java:500)
	at org.apache.ratis.server.impl.ServerState.close(ServerState.java:389)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$shutdown$3(RaftServerImpl.java:272)
	at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
	at org.apache.ratis.server.impl.RaftServerImpl.shutdown(RaftServerImpl.java:249)
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.lambda$close$0(RaftServerProxy.java:107)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.concurrent.ConcurrentHashMap$ValueSpliterator.forEachRemaining(ConcurrentHashMap.java:3566)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.close(RaftServerProxy.java:107)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$close$4(RaftServerProxy.java:315)
	at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
	at org.apache.ratis.server.impl.RaftServerProxy.close(RaftServerProxy.java:313)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.stop(XceiverServerRatis.java:448)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.stop(OzoneContainer.java:229)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.close(DatanodeStateMachine.java:270)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.stopDaemon(DatanodeStateMachine.java:394)
	at org.apache.hadoop.ozone.HddsDatanodeService.stop(HddsDatanodeService.java:457)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stopDatanode(MiniOzoneClusterImpl.java:385)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stopDatanodes(MiniOzoneClusterImpl.java:379)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stop(MiniOzoneClusterImpl.java:332)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.shutdown(MiniOzoneClusterImpl.java:319)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.shutdown(TestDeleteWithSlowFollower.java:136)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-10-23 20:01:36,782 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@4ba5291c] INFO  impl.RaftServerImpl (LeaderState.java:restartSender(408)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-LeaderState: Restarting GrpcLogAppender for 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93
Exception in thread "org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$567/568847175@4ba5291c" java.lang.IllegalArgumentException: 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLog is expected to be opened but it is CLOSED
	at org.apache.ratis.util.OpenCloseState.assertOpen(OpenCloseState.java:63)
	at org.apache.ratis.server.raftlog.RaftLog.checkLogState(RaftLog.java:102)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getLastEntryTermIndex(SegmentedRaftLog.java:345)
	at org.apache.ratis.server.raftlog.RaftLog.getNextIndex(RaftLog.java:148)
	at org.apache.ratis.server.impl.LeaderState.addAndStartSenders(LeaderState.java:384)
	at org.apache.ratis.server.impl.LeaderState.restartSender(LeaderState.java:410)
	at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:93)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.util.OpenCloseState$CloseTrace: Close 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01-SegmentedRaftLog
	at org.apache.ratis.util.OpenCloseState.lambda$close$1(OpenCloseState.java:109)
	at java.util.concurrent.atomic.AtomicReference.getAndUpdate(AtomicReference.java:160)
	at org.apache.ratis.util.OpenCloseState.close(OpenCloseState.java:109)
	at org.apache.ratis.server.raftlog.RaftLog.close(RaftLog.java:437)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.close(SegmentedRaftLog.java:500)
	at org.apache.ratis.server.impl.ServerState.close(ServerState.java:389)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$shutdown$3(RaftServerImpl.java:272)
	at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
	at org.apache.ratis.server.impl.RaftServerImpl.shutdown(RaftServerImpl.java:249)
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.lambda$close$0(RaftServerProxy.java:107)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.concurrent.ConcurrentHashMap$ValueSpliterator.forEachRemaining(ConcurrentHashMap.java:3566)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.close(RaftServerProxy.java:107)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$close$4(RaftServerProxy.java:315)
	at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$2(LifeCycle.java:231)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:251)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:229)
	at org.apache.ratis.server.impl.RaftServerProxy.close(RaftServerProxy.java:313)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.stop(XceiverServerRatis.java:448)
	at org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer.stop(OzoneContainer.java:229)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.close(DatanodeStateMachine.java:270)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.stopDaemon(DatanodeStateMachine.java:394)
	at org.apache.hadoop.ozone.HddsDatanodeService.stop(HddsDatanodeService.java:457)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stopDatanode(MiniOzoneClusterImpl.java:385)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stopDatanodes(MiniOzoneClusterImpl.java:379)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stop(MiniOzoneClusterImpl.java:332)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.shutdown(MiniOzoneClusterImpl.java:319)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.shutdown(TestDeleteWithSlowFollower.java:136)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-10-23 20:01:36,951 [Thread-665] INFO  impl.FollowerState (FollowerState.java:run(111)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-FollowerState: change to CANDIDATE, lastRpcTime:5200ms, electionTimeout:5197ms
2019-10-23 20:01:36,952 [Thread-665] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:36,952 [Thread-665] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2019-10-23 20:01:36,952 [Thread-665] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start LeaderElection
2019-10-23 20:01:36,967 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(178)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12: begin an election at term 5 for 0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:36,972 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.164.213:43640
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-10-23 20:01:36,974 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.164.213:43238
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-10-23 20:01:36,975 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12: Election REJECTED; received 0 response(s) [] and 2 exception(s); 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01:t5, leader=null, voted=729d0bb6-2410-4cc8-96f0-e80551772f93, raftlog=729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLog:OPENED:c3,f4,i4, conf=0: [6db3bc75-fe19-4010-b9b4-a3ce262b192b:192.168.164.213:43238, 729d0bb6-2410-4cc8-96f0-e80551772f93:192.168.164.213:46766, 76af9f5a-76ac-4564-8b4a-32ca0c573f92:192.168.164.213:43640], old=null
2019-10-23 20:01:36,976 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.164.213:43640
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-10-23 20:01:36,976 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 1: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:259)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:197)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:99)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:234)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.164.213:43238
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-10-23 20:01:36,977 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: changes role from CANDIDATE to FOLLOWER at term 5 for DISCOVERED_A_NEW_TERM
2019-10-23 20:01:36,977 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderElection
2019-10-23 20:01:36,977 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: start FollowerState
2019-10-23 20:01:38,876 [Thread-700] INFO  client.GrpcClientProtocolService (GrpcClientProtocolService.java:lambda$processClientRequest$0(279)) - Failed RaftClientRequest:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, seq=0, Watch-ALL_COMMITTED(6), Message:<EMPTY>, reply=RaftClientReply:client-DEA5B0C810ED->729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01, cid=10, FAILED org.apache.ratis.protocol.NotLeaderException: Server 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01 is not the leader, logIndex=0, commits[729d0bb6-2410-4cc8-96f0-e80551772f93:c3]
2019-10-23 20:01:39,644 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-9D70E690E19C->729d0bb6-2410-4cc8-96f0-e80551772f93: nextIndex: updateUnconditionally 1 -> 0
2019-10-23 20:01:39,723 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(227)) - Attempting to stop container services.
2019-10-23 20:01:39,725 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: close
2019-10-23 20:01:39,726 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C: shutdown
2019-10-23 20:01:39,726 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: shutdown
2019-10-23 20:01:39,726 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D70E690E19C,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:39,726 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6DD33E37F9EC,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:39,727 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:39,727 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderState
2019-10-23 20:01:39,727 [Thread-636] INFO  impl.FollowerState (FollowerState.java:run(120)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:39,727 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-StateMachineUpdater: set stopIndex = 0
2019-10-23 20:01:39,727 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-PendingRequests: sendNotLeaderResponses
2019-10-23 20:01:39,728 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C: closes. applyIndex: 0
2019-10-23 20:01:39,728 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-StateMachineUpdater: set stopIndex = 0
2019-10-23 20:01:39,729 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:39,729 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC: closes. applyIndex: 0
2019-10-23 20:01:39,730 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-9D70E690E19C-SegmentedRaftLogWorker close()
2019-10-23 20:01:39,730 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:39,731 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: shutdown
2019-10-23 20:01:39,733 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-6DD33E37F9EC-SegmentedRaftLogWorker close()
2019-10-23 20:01:39,734 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-77421D29F832,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:39,734 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown LeaderState
2019-10-23 20:01:39,735 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(206)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-PendingRequests: sendNotLeaderResponses
2019-10-23 20:01:39,737 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-StateMachineUpdater: set stopIndex = 2
2019-10-23 20:01:39,737 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832: closes. applyIndex: 2
2019-10-23 20:01:39,738 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:39,738 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-77421D29F832-SegmentedRaftLogWorker close()
2019-10-23 20:01:39,739 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: shutdown
2019-10-23 20:01:39,739 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-72C5A45DCE01,id=729d0bb6-2410-4cc8-96f0-e80551772f93
2019-10-23 20:01:39,740 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown FollowerState
2019-10-23 20:01:39,740 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(136)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-StateMachineUpdater: set stopIndex = 3
2019-10-23 20:01:39,740 [Thread-696] INFO  impl.FollowerState (FollowerState.java:run(120)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-10-23 20:01:39,740 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01: closes. applyIndex: 3
2019-10-23 20:01:39,741 [729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(316)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-10-23 20:01:39,742 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(224)) - 729d0bb6-2410-4cc8-96f0-e80551772f93@group-72C5A45DCE01-SegmentedRaftLogWorker close()
2019-10-23 20:01:39,743 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown server with port 46766 now
2019-10-23 20:01:39,744 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: installSnapshot onError, lastRequest: 76af9f5a-76ac-4564-8b4a-32ca0c573f92->729d0bb6-2410-4cc8-96f0-e80551772f93#0-t3, previous=(t:1, i:10), leaderCommit=10, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-10-23 20:01:39,744 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: shutdown server with port 46766 successfully
2019-10-23 20:01:39,744 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 729d0bb6-2410-4cc8-96f0-e80551772f93: installSnapshot onError, lastRequest: 76af9f5a-76ac-4564-8b4a-32ca0c573f92->729d0bb6-2410-4cc8-96f0-e80551772f93#1-t3, previous=(t:3, i:11), leaderCommit=10, initializing? true, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-10-23 20:01:39,746 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(297)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender is stopped
2019-10-23 20:01:39,745 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(297)) - 76af9f5a-76ac-4564-8b4a-32ca0c573f92@group-72C5A45DCE01->729d0bb6-2410-4cc8-96f0-e80551772f93-GrpcLogAppender is stopped
Oct 23, 2019 8:01:39 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@36f59412
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-10-23 20:01:39,749 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-cafa468d-53e0-4c27-9a5c-714cf6458f58/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
Oct 23, 2019 8:01:39 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@236baff4
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-10-23 20:01:39,771 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service BlockDeletingService
2019-10-23 20:01:39,774 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-10-23 20:01:39,775 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@34332b8d{/,null,UNAVAILABLE}{/hddsDatanode}
2019-10-23 20:01:39,776 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@724b939e{HTTP/1.1,[http/1.1]}{0.0.0.0:39777}
2019-10-23 20:01:39,777 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67f77f6e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-10-23 20:01:39,777 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5740ff5e{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-23 20:01:39,779 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-10-23 20:01:39,779 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(810)) - Stopping Replication Manager Service.
2019-10-23 20:01:39,779 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-10-23 20:01:39,779 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(817)) - Stopping Lease Manager of the command watchers
2019-10-23 20:01:39,780 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping datanode service RPC server
2019-10-23 20:01:39,780 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(346)) - Stopping the RPC server for DataNodes
2019-10-23 20:01:39,780 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42434
2019-10-23 20:01:39,781 [IPC Server listener on 42434] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42434
2019-10-23 20:01:39,782 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-23 20:01:39,837 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-10-23 20:01:39,837 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(832)) - Stopping block service RPC server
2019-10-23 20:01:39,838 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-10-23 20:01:39,838 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42955
2019-10-23 20:01:39,839 [IPC Server listener on 42955] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42955
2019-10-23 20:01:39,839 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(839)) - Stopping the StorageContainerLocationProtocol RPC server
2019-10-23 20:01:39,840 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(168)) - Stopping the RPC server for Client Protocol
2019-10-23 20:01:39,840 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-23 20:01:39,840 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33718
2019-10-23 20:01:39,841 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(846)) - Stopping Storage Container Manager HTTP server.
2019-10-23 20:01:39,841 [IPC Server listener on 33718] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33718
2019-10-23 20:01:39,972 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-10-23 20:01:40,048 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@23a9ba52{/,null,UNAVAILABLE}{/scm}
2019-10-23 20:01:40,063 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7927bd9f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-10-23 20:01:40,064 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@753432a2{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-10-23 20:01:40,066 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f48b3d2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-10-23 20:01:40,067 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(857)) - Stopping Block Manager Service.
2019-10-23 20:01:40,068 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-23 20:01:40,068 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(151)) - Shutting down service SCMBlockDeletingService
2019-10-23 20:01:40,069 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(879)) - Stopping SCM Event Queue.
2019-10-23 20:01:40,083 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-10-23 20:01:40,088 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-10-23 20:01:40,088 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
