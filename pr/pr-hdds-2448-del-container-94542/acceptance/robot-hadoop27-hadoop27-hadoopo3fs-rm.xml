<?xml version="1.0" encoding="UTF-8"?>
<robot rpa="false" generated="20191115 11:37:50.689" generator="Robot 3.1.2 (Python 2.7.15 on linux2)">
<suite source="/opt/ozone/smoketest/ozonefs/hadoopo3fs.robot" id="s1" name="hadoop27-hadoopo3fs">
<test id="s1-t1" name="Test hadoop dfs">
<kw name="Generate Random String" library="String">
<doc>Generates a string with a desired ``length`` from the given ``chars``.</doc>
<arguments>
<arg>5</arg>
<arg>[NUMBERS]</arg>
</arguments>
<assign>
<var>${random}</var>
</assign>
<msg timestamp="20191115 11:37:50.746" level="INFO">${random} = 02526</msg>
<status status="PASS" endtime="20191115 11:37:50.746" starttime="20191115 11:37:50.746"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>hdfs dfs -put /opt/hadoop/NOTICE.txt o3fs://bucket1.vol1/${PREFIX}-${random}</arg>
</arguments>
<assign>
<var>${result}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191115 11:37:50.748" level="INFO">Running command 'hdfs dfs -put /opt/hadoop/NOTICE.txt o3fs://bucket1.vol1/ozone-02526 2&gt;&amp;1'.</msg>
<msg timestamp="20191115 11:38:30.429" level="INFO">${rc} = 0</msg>
<msg timestamp="20191115 11:38:30.429" level="INFO">${output} = 2019-11-15 11:37:52 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 11:37:53 INFO  MetricsConfig:118 - Load...</msg>
<status status="PASS" endtime="20191115 11:38:30.429" starttime="20191115 11:37:50.747"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191115 11:38:30.430" level="INFO">2019-11-15 11:37:52 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 11:37:53 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-15 11:37:53 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-11-15 11:37:53 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
2019-11-15 11:38:24 WARN  XceiverClientRatis:277 - 3 way commit failed on pipeline Pipeline[ Id: 706b4e4a-6409-46b7-b51a-7c81448582e8, Nodes: f57c2c36-f228-4c00-96bc-34b668100828{ip: 172.18.0.6, host: hadoop27_datanode_1.hadoop27_default, networkLocation: /default-rack, certSerialId: null}d2840986-56a1-47ec-8c67-370ae490beb3{ip: 172.18.0.7, host: hadoop27_datanode_2.hadoop27_default, networkLocation: /default-rack, certSerialId: null}b3c73770-3f3e-422a-8bef-059ff5b64128{ip: 172.18.0.9, host: hadoop27_datanode_3.hadoop27_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
java.util.concurrent.TimeoutException
	at java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1771)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:274)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:198)
	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:161)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:346)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:482)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:496)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:143)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:435)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:473)
	at org.apache.hadoop.fs.ozone.OzoneFSOutputStream.close(OzoneFSOutputStream.java:56)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:62)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:120)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:466)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:391)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:328)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:263)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:248)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:317)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:289)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:243)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:271)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:255)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:220)
	at org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:267)
	at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:201)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:165)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:287)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:340)
2019-11-15 11:38:24 INFO  XceiverClientRatis:295 - Could not commit index 6 on pipeline Pipeline[ Id: 706b4e4a-6409-46b7-b51a-7c81448582e8, Nodes: f57c2c36-f228-4c00-96bc-34b668100828{ip: 172.18.0.6, host: hadoop27_datanode_1.hadoop27_default, networkLocation: /default-rack, certSerialId: null}d2840986-56a1-47ec-8c67-370ae490beb3{ip: 172.18.0.7, host: hadoop27_datanode_2.hadoop27_default, networkLocation: /default-rack, certSerialId: null}b3c73770-3f3e-422a-8bef-059ff5b64128{ip: 172.18.0.9, host: hadoop27_datanode_3.hadoop27_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN] to all the nodes. Server f57c2c36-f228-4c00-96bc-34b668100828 has failed. Committed by majority.
2019-11-15 11:38:24 WARN  BlockOutputStream:352 - Failed to commit BlockId conID: 2 locID: 103141728155467777 bcsId: 6 on Pipeline[ Id: 706b4e4a-6409-46b7-b51a-7c81448582e8, Nodes: f57c2c36-f228-4c00-96bc-34b668100828{ip: 172.18.0.6, host: hadoop27_datanode_1.hadoop27_default, networkLocation: /default-rack, certSerialId: null}d2840986-56a1-47ec-8c67-370ae490beb3{ip: 172.18.0.7, host: hadoop27_datanode_2.hadoop27_default, networkLocation: /default-rack, certSerialId: null}b3c73770-3f3e-422a-8bef-059ff5b64128{ip: 172.18.0.9, host: hadoop27_datanode_3.hadoop27_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]. Failed nodes: [f57c2c36-f228-4c00-96bc-34b668100828{ip: null, host: null, networkLocation: /default-rack, certSerialId: null}]
2019-11-15 11:38:26 ERROR GrpcClientRpc:82 - client-973D4ED25F50: XXX Failed RaftClientRequest:client-973D4ED25F50-&gt;f57c2c36-f228-4c00-96bc-34b668100828@group-7C81448582E8, cid=3, seq=0, Watch-ALL_COMMITTED(6), null
org.apache.ratis.protocol.AlreadyClosedException: client-973D4ED25F50 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:59)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:109)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsyncUnordered(GrpcClientRpc.java:78)
	at org.apache.ratis.client.impl.UnorderedAsync.sendRequestWithRetry(UnorderedAsync.java:75)
	at org.apache.ratis.client.impl.UnorderedAsync.lambda$null$2(UnorderedAsync.java:120)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:50)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:91)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)</msg>
<status status="PASS" endtime="20191115 11:38:30.431" starttime="20191115 11:38:30.429"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191115 11:38:30.431" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<status status="PASS" endtime="20191115 11:38:30.431" starttime="20191115 11:38:30.431"></status>
</kw>
<msg timestamp="20191115 11:38:30.432" level="INFO">${result} = 2019-11-15 11:37:52 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-15 11:37:53 INFO  MetricsConfig:118 - Load...</msg>
<status status="PASS" endtime="20191115 11:38:30.432" starttime="20191115 11:37:50.747"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>hdfs dfs -ls o3fs://bucket1.vol1/</arg>
</arguments>
<assign>
<var>${result}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191115 11:38:30.434" level="INFO">Running command 'hdfs dfs -ls o3fs://bucket1.vol1/ 2&gt;&amp;1'.</msg>
<msg timestamp="20191115 11:38:33.111" level="INFO">${rc} = 0</msg>
<msg timestamp="20191115 11:38:33.112" level="INFO">${output} = 2019-11-15 11:38:32 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18...</msg>
<status status="PASS" endtime="20191115 11:38:33.112" starttime="20191115 11:38:30.433"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191115 11:38:33.113" level="INFO">2019-11-15 11:38:32 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18189 2019-11-15 11:37 o3fs://bucket1.vol1/key1
-rw-rw-rw-   3 hadoop hadoop      14978 2019-11-15 11:38 o3fs://bucket1.vol1/ozone-02526
drwxrwxrwx   - hadoop hadoop          0 2019-11-15 11:38 o3fs://bucket1.vol1/user</msg>
<status status="PASS" endtime="20191115 11:38:33.113" starttime="20191115 11:38:33.112"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191115 11:38:33.113" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<status status="PASS" endtime="20191115 11:38:33.113" starttime="20191115 11:38:33.113"></status>
</kw>
<msg timestamp="20191115 11:38:33.114" level="INFO">${result} = 2019-11-15 11:38:32 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-rw-rw-   3 hadoop hadoop      18...</msg>
<status status="PASS" endtime="20191115 11:38:33.114" starttime="20191115 11:38:30.432"></status>
</kw>
<kw name="Should Contain" library="BuiltIn">
<doc>Fails if ``container`` does not contain ``item`` one or more times.</doc>
<arguments>
<arg>${result}</arg>
<arg>${PREFIX}-${random}</arg>
</arguments>
<status status="PASS" endtime="20191115 11:38:33.114" starttime="20191115 11:38:33.114"></status>
</kw>
<status status="PASS" endtime="20191115 11:38:33.115" critical="yes" starttime="20191115 11:37:50.745"></status>
</test>
<doc>Test ozone fs with hadoopfs</doc>
<status status="PASS" endtime="20191115 11:38:33.115" starttime="20191115 11:37:50.690"></status>
</suite>
<statistics>
<total>
<stat fail="0" pass="1">Critical Tests</stat>
<stat fail="0" pass="1">All Tests</stat>
</total>
<tag>
</tag>
<suite>
<stat fail="0" id="s1" name="hadoop27-hadoopo3fs" pass="1">hadoop27-hadoopo3fs</stat>
</suite>
</statistics>
<errors>
</errors>
</robot>
