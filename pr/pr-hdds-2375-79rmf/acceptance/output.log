Distribution dir is missing. Doing a full build
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Detecting the operating system and CPU architecture
[INFO] ------------------------------------------------------------------------
[INFO] os.detected.name: linux
[INFO] os.detected.arch: x86_64
[INFO] os.detected.version: 3.10
[INFO] os.detected.version.major: 3
[INFO] os.detected.version.minor: 10
[INFO] os.detected.release: centos
[INFO] os.detected.release.version: 7
[INFO] os.detected.release.like.centos: true
[INFO] os.detected.release.like.rhel: true
[INFO] os.detected.release.like.fedora: true
[INFO] os.detected.classifier: linux-x86_64
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Apache Hadoop Ozone Main                                           [pom]
[INFO] Apache Hadoop HDDS                                                 [pom]
[INFO] Apache Hadoop HDDS Config                                          [jar]
[INFO] Apache Hadoop HDDS Common                                          [jar]
[INFO] Apache Hadoop HDDS Client                                          [jar]
[INFO] Apache Hadoop HDDS Server Framework                                [jar]
[INFO] Apache Hadoop HDDS Container Service                               [jar]
[INFO] Apache Hadoop HDDS/Ozone Documentation                             [jar]
[INFO] Apache Hadoop HDDS SCM Server                                      [jar]
[INFO] Apache Hadoop HDDS Tools                                           [jar]
[INFO] Apache Hadoop Ozone                                                [pom]
[INFO] Apache Hadoop Ozone Common                                         [jar]
[INFO] Apache Hadoop Ozone Client                                         [jar]
[INFO] Apache Hadoop Ozone Manager Server                                 [jar]
[INFO] Apache Hadoop Ozone S3 Gateway                                     [jar]
[INFO] Apache Hadoop Ozone CSI service                                    [jar]
[INFO] Apache Hadoop Ozone Recon CodeGen                                  [jar]
[INFO] Apache Hadoop Ozone Recon                                          [jar]
[INFO] Apache Hadoop Ozone Integration Tests                              [jar]
[INFO] Apache Hadoop Ozone FileSystem                                     [jar]
[INFO] Apache Hadoop Ozone Tools                                          [jar]
[INFO] Apache Hadoop Ozone Datanode                                       [jar]
[INFO] Apache Hadoop Ozone In-Place Upgrade                               [jar]
[INFO] Apache Hadoop Ozone Insight Tool                                   [jar]
[INFO] Apache Hadoop Ozone FileSystem Single Jar Library                  [jar]
[INFO] Apache Hadoop Ozone FileSystem Legacy Jar Library                  [jar]
[INFO] Apache Hadoop Ozone Distribution                                   [pom]
[INFO] Apache Hadoop Ozone Fault Injection Tests                          [pom]
[INFO] Apache Hadoop Ozone Network Tests                                  [jar]
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-main-ozone >-----------------
[INFO] Building Apache Hadoop Ozone Main 0.5.0-SNAPSHOT                  [1/29]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-main-ozone ---
[INFO] Deleting /workdir/target
[INFO] Deleting /workdir (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-main-ozone ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-main-ozone ---
[INFO] 
[INFO] --- animal-sniffer-maven-plugin:1.16:check (signature-check) @ hadoop-main-ozone ---
[INFO] Checking unresolved references to org.codehaus.mojo.signature:java18:1.0
[INFO] 
[INFO] --- maven-install-plugin:2.5.1:install (default-install) @ hadoop-main-ozone ---
[INFO] Installing /workdir/pom.xml to /home/user/.m2/repository/org/apache/hadoop/hadoop-main-ozone/0.5.0-SNAPSHOT/hadoop-main-ozone-0.5.0-SNAPSHOT.pom
[INFO] 
[INFO] -------------------< org.apache.hadoop:hadoop-hdds >--------------------
[INFO] Building Apache Hadoop HDDS 0.5.0-SNAPSHOT                        [2/29]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdds ---
[INFO] Deleting /workdir/hadoop-hdds/target
[INFO] Deleting /workdir/hadoop-hdds (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds ---
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:build-classpath (add-classpath-descriptor) @ hadoop-hdds ---
[INFO] Wrote classpath file '/workdir/hadoop-hdds/target/classpath'.
[INFO] 
[INFO] --- build-helper-maven-plugin:1.9:attach-artifact (attach-classpath-artifact) @ hadoop-hdds ---
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-hdds ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /workdir/hadoop-hdds/target/hadoop-hdds-0.5.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- animal-sniffer-maven-plugin:1.16:check (signature-check) @ hadoop-hdds ---
[INFO] Checking unresolved references to org.codehaus.mojo.signature:java18:1.0
[INFO] 
[INFO] --- maven-install-plugin:2.5.1:install (default-install) @ hadoop-hdds ---
[INFO] Installing /workdir/hadoop-hdds/pom.xml to /home/user/.m2/repository/org/apache/hadoop/hadoop-hdds/0.5.0-SNAPSHOT/hadoop-hdds-0.5.0-SNAPSHOT.pom
[INFO] Installing /workdir/hadoop-hdds/target/classpath to /home/user/.m2/repository/org/apache/hadoop/hadoop-hdds/0.5.0-SNAPSHOT/hadoop-hdds-0.5.0-SNAPSHOT-classpath.cp
[INFO] Installing /workdir/hadoop-hdds/target/hadoop-hdds-0.5.0-SNAPSHOT-tests.jar to /home/user/.m2/repository/org/apache/hadoop/hadoop-hdds/0.5.0-SNAPSHOT/hadoop-hdds-0.5.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-hdds-config >----------------
[INFO] Building Apache Hadoop HDDS Config 0.5.0-SNAPSHOT                 [3/29]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdds-config ---
[INFO] Deleting /workdir/hadoop-hdds/config/target
[INFO] Deleting /workdir/hadoop-hdds/config (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-config ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-config ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-config ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /workdir/hadoop-hdds/config/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-config ---
[INFO] Compiling 8 source files to /workdir/hadoop-hdds/config/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hadoop-hdds-config ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hadoop-hdds-config ---
[INFO] Compiling 3 source files to /workdir/hadoop-hdds/config/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M1:test (default-test) @ hadoop-hdds-config ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.5:jar (default-jar) @ hadoop-hdds-config ---
[INFO] Building jar: /workdir/hadoop-hdds/config/target/hadoop-hdds-config-0.5.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.2:build-classpath (add-classpath-descriptor) @ hadoop-hdds-config ---
[INFO] Wrote classpath file '/workdir/hadoop-hdds/config/target/classpath'.
[INFO] 
[INFO] --- build-helper-maven-plugin:1.9:attach-artifact (attach-classpath-artifact) @ hadoop-hdds-config ---
[INFO] 
[INFO] --- maven-jar-plugin:2.5:test-jar (default) @ hadoop-hdds-config ---
[INFO] Building jar: /workdir/hadoop-hdds/config/target/hadoop-hdds-config-0.5.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- animal-sniffer-maven-plugin:1.16:check (signature-check) @ hadoop-hdds-config ---
[INFO] Checking unresolved references to org.codehaus.mojo.signature:java18:1.0
[INFO] 
[INFO] --- maven-install-plugin:2.5.1:install (default-install) @ hadoop-hdds-config ---
[INFO] Installing /workdir/hadoop-hdds/config/target/hadoop-hdds-config-0.5.0-SNAPSHOT.jar to /home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar
[INFO] Installing /workdir/hadoop-hdds/config/pom.xml to /home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.pom
[INFO] Installing /workdir/hadoop-hdds/config/target/classpath to /home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT-classpath.cp
[INFO] Installing /workdir/hadoop-hdds/config/target/hadoop-hdds-config-0.5.0-SNAPSHOT-tests.jar to /home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] ----------------< org.apache.hadoop:hadoop-hdds-common >----------------
[INFO] Building Apache Hadoop HDDS Common 0.5.0-SNAPSHOT                 [4/29]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hadoop-hdds-common ---
[INFO] Deleting /workdir/hadoop-hdds/common/target
[INFO] Deleting /workdir/hadoop-hdds/common (includes = [dependency-reduced-pom.xml], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (create-testdirs) @ hadoop-hdds-common ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- protobuf-maven-plugin:0.5.1:compile (compile-protoc) @ hadoop-hdds-common ---
[INFO] Compiling 1 proto file(s) to /workdir/hadoop-hdds/common/target/generated-sources/java
[INFO] 
[INFO] --- protobuf-maven-plugin:0.5.1:compile-custom (compile-protoc) @ hadoop-hdds-common ---
[INFO] Compiling 1 proto file(s) to /workdir/hadoop-hdds/common/target/generated-sources/java
[INFO] 
[INFO] --- maven-antrun-plugin:1.3:run (default) @ hadoop-hdds-common ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- hadoop-maven-plugins:3.2.0:protoc (compile-protoc) @ hadoop-hdds-common ---
[INFO] Wrote protoc checksums to file /workdir/hadoop-hdds/common/target/hadoop-maven-plugins-protoc-checksums.json
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hadoop-hdds-common ---
[INFO] 
[INFO] --- hadoop-maven-plugins:3.2.0:version-info (version-info) @ hadoop-hdds-common ---
[INFO] SCM: GIT
[INFO] Computed MD5: 96522683f55dd6a493a389de9a67b65
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hadoop-hdds-common ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 5 resources
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hadoop-hdds-common ---
[INFO] Compiling 243 source files to /workdir/hadoop-hdds/common/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/DBProfile.java: Some input files use or override a deprecated API.
[WARNING] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/DBProfile.java: Recompile with -Xlint:deprecation for details.
[WARNING] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/CodecRegistry.java: Some input files use unchecked or unsafe operations.
[WARNING] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/db/CodecRegistry.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/common/Checksum.java:[164,39] cannot find symbol
  symbol:   method warp(java.nio.ByteBuffer)
  location: interface org.apache.hadoop.ozone.common.ChunkBuffer
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for Apache Hadoop Ozone Main 0.5.0-SNAPSHOT:
[INFO] 
[INFO] Apache Hadoop Ozone Main ........................... SUCCESS [  2.748 s]
[INFO] Apache Hadoop HDDS ................................. SUCCESS [  5.642 s]
[INFO] Apache Hadoop HDDS Config .......................... SUCCESS [  5.024 s]
[INFO] Apache Hadoop HDDS Common .......................... FAILURE [ 13.299 s]
[INFO] Apache Hadoop HDDS Client .......................... SKIPPED
[INFO] Apache Hadoop HDDS Server Framework ................ SKIPPED
[INFO] Apache Hadoop HDDS Container Service ............... SKIPPED
[INFO] Apache Hadoop HDDS/Ozone Documentation ............. SKIPPED
[INFO] Apache Hadoop HDDS SCM Server ...................... SKIPPED
[INFO] Apache Hadoop HDDS Tools ........................... SKIPPED
[INFO] Apache Hadoop Ozone ................................ SKIPPED
[INFO] Apache Hadoop Ozone Common ......................... SKIPPED
[INFO] Apache Hadoop Ozone Client ......................... SKIPPED
[INFO] Apache Hadoop Ozone Manager Server ................. SKIPPED
[INFO] Apache Hadoop Ozone S3 Gateway ..................... SKIPPED
[INFO] Apache Hadoop Ozone CSI service .................... SKIPPED
[INFO] Apache Hadoop Ozone Recon CodeGen .................. SKIPPED
[INFO] Apache Hadoop Ozone Recon .......................... SKIPPED
[INFO] Apache Hadoop Ozone Integration Tests .............. SKIPPED
[INFO] Apache Hadoop Ozone FileSystem ..................... SKIPPED
[INFO] Apache Hadoop Ozone Tools .......................... SKIPPED
[INFO] Apache Hadoop Ozone Datanode ....................... SKIPPED
[INFO] Apache Hadoop Ozone In-Place Upgrade ............... SKIPPED
[INFO] Apache Hadoop Ozone Insight Tool ................... SKIPPED
[INFO] Apache Hadoop Ozone FileSystem Single Jar Library .. SKIPPED
[INFO] Apache Hadoop Ozone FileSystem Legacy Jar Library .. SKIPPED
[INFO] Apache Hadoop Ozone Distribution ................... SKIPPED
[INFO] Apache Hadoop Ozone Fault Injection Tests .......... SKIPPED
[INFO] Apache Hadoop Ozone Network Tests .................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  27.368 s
[INFO] Finished at: 2019-11-05T21:23:11Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hadoop-hdds-common: Compilation failure
[ERROR] /workdir/hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/common/Checksum.java:[164,39] cannot find symbol
[ERROR]   symbol:   method warp(java.nio.ByteBuffer)
[ERROR]   location: interface org.apache.hadoop.ozone.common.ChunkBuffer
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <args> -rf :hadoop-hdds-common
/workdir/hadoop-ozone/dev-support/checks/acceptance.sh: line 30: cd: /workdir/hadoop-ozone/dev-support/checks/../../dist/target/ozone-0.5.0-SNAPSHOT/compose: No such file or directory
