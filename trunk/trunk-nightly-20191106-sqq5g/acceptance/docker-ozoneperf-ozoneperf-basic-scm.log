Attaching to ozoneperf_datanode_3, ozoneperf_datanode_2, ozoneperf_datanode_1, ozoneperf_s3g_1, ozoneperf_grafana_1, ozoneperf_scm_1, ozoneperf_om_1, ozoneperf_prometheus_1, ozoneperf_jaeger_1
datanode_3    | 2019-11-06 03:54:14,705 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3    | /************************************************************
datanode_3    | STARTUP_MSG: Starting HddsDatanodeService
datanode_1    | 2019-11-06 03:54:14,524 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3    | STARTUP_MSG:   host = e05679a42f3d/172.19.0.10
datanode_1    | /************************************************************
datanode_1    | STARTUP_MSG: Starting HddsDatanodeService
datanode_3    | STARTUP_MSG:   args = []
datanode_1    | STARTUP_MSG:   host = 84fe8a1e2e5b/172.19.0.9
datanode_3    | STARTUP_MSG:   version = 3.2.0
datanode_3    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_1    | STARTUP_MSG:   args = []
datanode_2    | 2019-11-06 03:54:14,360 INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1    | STARTUP_MSG:   version = 3.2.0
datanode_2    | /************************************************************
datanode_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
datanode_3    | STARTUP_MSG:   java = 11.0.3
datanode_2    | STARTUP_MSG: Starting HddsDatanodeService
datanode_1    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3    | ************************************************************/
datanode_2    | STARTUP_MSG:   host = e603cf941a98/172.19.0.8
datanode_1    | STARTUP_MSG:   java = 11.0.3
datanode_3    | 2019-11-06 03:54:14,718 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2019-11-06 03:54:12,909 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_2    | STARTUP_MSG:   args = []
om_1          | 2019-11-06 03:54:12,338 INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_1    | ************************************************************/
s3g_1         | 2019-11-06 03:54:13,208 INFO hdfs.DFSUtil: Starting Web-server for s3gateway at: http://0.0.0.0:9878
datanode_3    | 2019-11-06 03:54:15,025 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Starting Grafana" logger=server version=6.4.3 commit=3a2bfb7 branch=HEAD compiled=2019-10-16T09:32:09+0000
scm_1         | /************************************************************
datanode_2    | STARTUP_MSG:   version = 3.2.0
om_1          | /************************************************************
datanode_1    | 2019-11-06 03:54:14,533 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1         | 2019-11-06 03:54:13,233 INFO util.log: Logging initialized @1134ms
prometheus_1  | level=info ts=2019-11-06T03:54:11.573Z caller=main.go:296 msg="no time or size retention was set so using the default time retention" duration=15d
datanode_3    | 2019-11-06 03:54:15,206 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config loaded from" logger=settings file=/usr/share/grafana/conf/defaults.ini
scm_1         | STARTUP_MSG: Starting StorageContainerManager
datanode_2    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-SNAPSHOT.jar
om_1          | STARTUP_MSG: Starting OzoneManager
datanode_1    | 2019-11-06 03:54:14,851 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1         | 2019-11-06 03:54:13,325 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
prometheus_1  | level=info ts=2019-11-06T03:54:11.573Z caller=main.go:332 msg="Starting Prometheus" version="(version=2.13.1, branch=HEAD, revision=6f92ce56053866194ae5937012c1bec40f1dd1d9)"
datanode_3    | 2019-11-06 03:54:15,206 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
jaeger_1      | 2019/11/06 03:54:11 maxprocs: Leaving GOMAXPROCS=32: CPU quota undefined
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config loaded from" logger=settings file=/etc/grafana/grafana.ini
scm_1         | STARTUP_MSG:   host = 318839e16936/172.19.0.5
datanode_2    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1    | 2019-11-06 03:54:15,031 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1         | 2019-11-06 03:54:13,347 INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
om_1          | STARTUP_MSG:   host = a52d73221389/172.19.0.4
prometheus_1  | level=info ts=2019-11-06T03:54:11.573Z caller=main.go:333 build_context="(go=go1.13.1, user=root@88e419aa1676, date=20191017-13:15:01)"
datanode_3    | 2019-11-06 03:54:15,362 INFO ozone.HddsDatanodeService: HddsDatanodeService host:e05679a42f3d ip:172.19.0.10
jaeger_1      | {"level":"info","ts":1573012451.5388885,"caller":"flags/service.go:115","msg":"Mounting metrics handler on admin server","route":"/metrics"}
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.data=/var/lib/grafana"
scm_1         | STARTUP_MSG:   args = [--init]
datanode_2    | STARTUP_MSG:   java = 11.0.3
s3g_1         | 2019-11-06 03:54:13,355 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1    | 2019-11-06 03:54:15,031 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
om_1          | STARTUP_MSG:   args = [--init]
prometheus_1  | level=info ts=2019-11-06T03:54:11.573Z caller=main.go:334 host_details="(Linux 3.10.0-957.12.2.el7.x86_64 #1 SMP Tue May 14 21:24:32 UTC 2019 x86_64 e595a99951db (none))"
datanode_3    | 2019-11-06 03:54:15,482 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
jaeger_1      | {"level":"info","ts":1573012451.5392258,"caller":"flags/admin.go:108","msg":"Mounting health check on admin server","route":"/"}
scm_1         | STARTUP_MSG:   version = 3.2.0
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.logs=/var/log/grafana"
datanode_2    | ************************************************************/
s3g_1         | 2019-11-06 03:54:13,357 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
om_1          | STARTUP_MSG:   version = 3.2.0
prometheus_1  | level=info ts=2019-11-06T03:54:11.573Z caller=main.go:335 fd_limits="(soft=1048576, hard=1048576)"
datanode_1    | 2019-11-06 03:54:15,172 INFO ozone.HddsDatanodeService: HddsDatanodeService host:84fe8a1e2e5b ip:172.19.0.9
jaeger_1      | {"level":"info","ts":1573012451.5393188,"caller":"flags/admin.go:114","msg":"Starting admin HTTP server","http-port":14269}
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.plugins=/var/lib/grafana/plugins"
datanode_3    | 2019-11-06 03:54:15,484 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2    | 2019-11-06 03:54:14,367 INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1         | 2019-11-06 03:54:13,357 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
prometheus_1  | level=info ts=2019-11-06T03:54:11.573Z caller=main.go:336 vm_limits="(soft=unlimited, hard=unlimited)"
datanode_1    | 2019-11-06 03:54:15,325 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
jaeger_1      | {"level":"info","ts":1573012451.5393412,"caller":"flags/admin.go:100","msg":"Admin server started","http-port":14269,"health-status":"unavailable"}
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.paths.provisioning=/etc/grafana/provisioning"
datanode_3    | 2019-11-06 03:54:15,492 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2    | 2019-11-06 03:54:14,671 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1         | 2019-11-06 03:54:13,358 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
prometheus_1  | level=info ts=2019-11-06T03:54:11.576Z caller=main.go:657 msg="Starting TSDB ..."
datanode_1    | 2019-11-06 03:54:15,409 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
jaeger_1      | {"level":"info","ts":1573012451.6061444,"caller":"memory/factory.go:56","msg":"Memory storage initialized","configuration":{"MaxTraces":0}}
scm_1         | STARTUP_MSG:   java = 11.0.3
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from command line" logger=settings arg="default.log.mode=console"
datanode_3    | 2019-11-06 03:54:15,523 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
s3g_1         | 2019-11-06 03:54:13,376 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2    | 2019-11-06 03:54:14,846 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | STARTUP_MSG:   java = 11.0.3
prometheus_1  | level=info ts=2019-11-06T03:54:11.576Z caller=web.go:450 component=web msg="Start listening for connections" address=0.0.0.0:9090
datanode_1    | 2019-11-06 03:54:15,417 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
jaeger_1      | {"level":"info","ts":1573012451.6169686,"caller":"all-in-one/main.go:242","msg":"Starting jaeger-collector TChannel server","port":14267}
scm_1         | ************************************************************/
datanode_3    | 2019-11-06 03:54:16,399 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
s3g_1         | 2019-11-06 03:54:13,377 INFO s3.Gateway: Starting Ozone S3 gateway
datanode_2    | 2019-11-06 03:54:14,847 INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_DATA=/var/lib/grafana"
om_1          | ************************************************************/
prometheus_1  | level=info ts=2019-11-06T03:54:11.581Z caller=head.go:514 component=tsdb msg="replaying WAL, this may take awhile"
jaeger_1      | {"level":"info","ts":1573012451.6170964,"caller":"grpcserver/grpc_server.go:64","msg":"Starting jaeger-collector gRPC server","grpc-port":"14250"}
scm_1         | 2019-11-06 03:54:12,916 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3    | 2019-11-06 03:54:16,437 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
s3g_1         | 2019-11-06 03:54:13,386 INFO http.HttpServer2: Jetty bound to port 9878
datanode_2    | 2019-11-06 03:54:14,970 INFO ozone.HddsDatanodeService: HddsDatanodeService host:e603cf941a98 ip:172.19.0.8
datanode_1    | 2019-11-06 03:54:15,439 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_LOGS=/var/log/grafana"
om_1          | 2019-11-06 03:54:12,345 INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
prometheus_1  | level=info ts=2019-11-06T03:54:11.582Z caller=head.go:562 component=tsdb msg="WAL segment loaded" segment=0 maxSegment=0
jaeger_1      | {"level":"info","ts":1573012451.6171737,"caller":"all-in-one/main.go:260","msg":"Starting jaeger-collector HTTP server","http-port":14268}
scm_1         | 2019-11-06 03:54:13,041 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3    | 2019-11-06 03:54:16,625 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
s3g_1         | 2019-11-06 03:54:13,388 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2    | 2019-11-06 03:54:15,002 INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of  storage type : DISK and capacity : 10908285698048
datanode_1    | 2019-11-06 03:54:16,265 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_PLUGINS=/var/lib/grafana/plugins"
prometheus_1  | level=info ts=2019-11-06T03:54:11.584Z caller=main.go:672 fs_type=EXT4_SUPER_MAGIC
om_1          | 2019-11-06 03:54:13,245 INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.19.0.4:9862
jaeger_1      | {"level":"info","ts":1573012451.6171968,"caller":"grpc/builder.go:65","msg":"Agent requested insecure grpc connection to collector(s)"}
scm_1         | SCM initialization succeeded.Current cluster id for sd=/data/metadata/scm;cid=CID-7d7542ac-002b-409d-a05f-b9d738794e99
datanode_3    | 2019-11-06 03:54:16,637 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_2    | 2019-11-06 03:54:15,081 INFO volume.VolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
s3g_1         | 2019-11-06 03:54:13,418 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5276d6ee{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1    | 2019-11-06 03:54:16,291 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Config overridden from Environment variable" logger=settings var="GF_PATHS_PROVISIONING=/etc/grafana/provisioning"
prometheus_1  | level=info ts=2019-11-06T03:54:11.584Z caller=main.go:673 msg="TSDB started"
jaeger_1      | {"level":"info","ts":1573012451.618525,"caller":"all-in-one/main.go:199","msg":"Starting agent"}
scm_1         | 2019-11-06 03:54:13,358 INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_3    | 2019-11-06 03:54:16,640 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2    | 2019-11-06 03:54:15,090 INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
s3g_1         | 2019-11-06 03:54:13,418 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7dfd3c81{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1    | 2019-11-06 03:54:16,408 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
om_1          | 2019-11-06 03:54:13,245 INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
prometheus_1  | level=info ts=2019-11-06T03:54:11.584Z caller=main.go:743 msg="Loading configuration file" filename=/etc/prometheus.yml
jaeger_1      | {"level":"info","ts":1573012451.618625,"caller":"querysvc/query_service.go:130","msg":"Archive storage not created","reason":"archive storage not supported"}
scm_1         | /************************************************************
datanode_3    | 2019-11-06 03:54:16,641 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_2    | 2019-11-06 03:54:15,118 INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
s3g_1         | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
datanode_1    | 2019-11-06 03:54:16,408 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Path Home" logger=settings path=/usr/share/grafana
om_1          | 2019-11-06 03:54:13,250 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
prometheus_1  | level=info ts=2019-11-06T03:54:11.585Z caller=main.go:771 msg="Completed loading of configuration file" filename=/etc/prometheus.yml
jaeger_1      | {"level":"info","ts":1573012451.6186404,"caller":"app/agent.go:69","msg":"Starting jaeger-agent HTTP server","http-port":5778}
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at 318839e16936/172.19.0.5
datanode_3    | 2019-11-06 03:54:16,643 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_2    | 2019-11-06 03:54:15,995 WARN scm.HddsServerUtil: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
s3g_1         | WARNING: An illegal reflective access operation has occurred
datanode_1    | 2019-11-06 03:54:16,410 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Path Data" logger=settings path=/var/lib/grafana
om_1          | 2019-11-06 03:54:14,454 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
prometheus_1  | level=info ts=2019-11-06T03:54:11.585Z caller=main.go:626 msg="Server is ready to receive web requests."
jaeger_1      | {"level":"info","ts":1573012451.6186526,"caller":"all-in-one/main.go:342","msg":"Archive storage not initialized"}
scm_1         | ************************************************************/
datanode_3    | 2019-11-06 03:54:16,798 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2    | 2019-11-06 03:54:16,270 INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
s3g_1         | WARNING: Illegal reflective access by org.jboss.classfilewriter.ClassFile$1 (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
datanode_1    | 2019-11-06 03:54:16,411 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Path Logs" logger=settings path=/var/log/grafana
om_1          | 2019-11-06 03:54:15,455 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
jaeger_1      | {"level":"info","ts":1573012451.6194983,"caller":"healthcheck/handler.go:128","msg":"Health Check state change","status":"ready"}
datanode_3    | 2019-11-06 03:54:16,938 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
s3g_1         | WARNING: Please consider reporting this to the maintainers of org.jboss.classfilewriter.ClassFile$1
datanode_2    | 2019-11-06 03:54:16,410 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.port = 9858 (custom)
datanode_1    | 2019-11-06 03:54:16,412 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Path Plugins" logger=settings path=/var/lib/grafana/plugins
scm_1         | 2019-11-06 03:54:14,349 INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om_1          | 2019-11-06 03:54:16,456 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
jaeger_1      | {"level":"info","ts":1573012451.6195326,"caller":"app/server.go:135","msg":"Starting CMUX server","port":16686}
s3g_1         | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3    | 2019-11-06 03:54:16,959 INFO util.log: Logging initialized @3066ms
datanode_2    | 2019-11-06 03:54:16,411 INFO server.GrpcService: raft.grpc.message.size.max = 33570816 (custom)
datanode_1    | 2019-11-06 03:54:16,610 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Path Provisioning" logger=settings path=/etc/grafana/provisioning
scm_1         | /************************************************************
om_1          | 2019-11-06 03:54:17,458 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
jaeger_1      | {"level":"info","ts":1573012451.619557,"caller":"app/server.go:125","msg":"Starting GRPC server","port":16686}
s3g_1         | WARNING: All illegal access operations will be denied in a future release
datanode_3    | 2019-11-06 03:54:17,039 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2    | 2019-11-06 03:54:16,414 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1    | 2019-11-06 03:54:16,769 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="App mode production" logger=settings
om_1          | 2019-11-06 03:54:18,459 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
jaeger_1      | {"level":"info","ts":1573012451.6195138,"caller":"app/server.go:112","msg":"Starting HTTP server","port":16686}
s3g_1         | Nov 06, 2019 3:54:16 AM org.glassfish.jersey.internal.Errors logErrors
scm_1         | STARTUP_MSG: Starting StorageContainerManager
datanode_1    | 2019-11-06 03:54:16,789 INFO util.log: Logging initialized @3027ms
datanode_2    | 2019-11-06 03:54:16,463 INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Initializing SqlStore" logger=server
om_1          | 2019-11-06 03:54:19,460 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
jaeger_1      | {"level":"info","ts":1573012451.6413286,"caller":"all-in-one/main.go:298","msg":"Listening for Zipkin HTTP traffic","zipkin.http-port":9411}
datanode_3    | 2019-11-06 03:54:17,044 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
s3g_1         | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
datanode_2    | 2019-11-06 03:54:16,464 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1         | STARTUP_MSG:   host = 318839e16936/172.19.0.5
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Connecting to DB" logger=sqlstore dbtype=sqlite3
om_1          | 2019-11-06 03:54:20,462 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-06 03:54:17,050 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_1    | 2019-11-06 03:54:16,868 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1         | 
datanode_2    | 2019-11-06 03:54:16,627 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1         | STARTUP_MSG:   args = []
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Starting DB migration" logger=migrator
om_1          | 2019-11-06 03:54:21,463 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-06 03:54:17,052 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1    | 2019-11-06 03:54:16,872 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
s3g_1         | 2019-11-06 03:54:16,115 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@77cb452c{/,file:///tmp/jetty-0.0.0.0-9878-s3gateway-_-any-5797116044717820040.dir/webapp/,AVAILABLE}{/s3gateway}
datanode_2    | 2019-11-06 03:54:16,778 INFO hdfs.DFSUtil: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1         | STARTUP_MSG:   version = 3.2.0
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Executing migration" logger=migrator id="create migration_log table"
datanode_3    | 2019-11-06 03:54:17,052 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2019-11-06 03:54:22,464 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1         | 2019-11-06 03:54:16,122 INFO server.AbstractConnector: Started ServerConnector@3ba1308d{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
datanode_2    | 2019-11-06 03:54:16,801 INFO util.log: Logging initialized @3149ms
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hamcrest-all-1.3.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar
datanode_1    | 2019-11-06 03:54:16,880 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Executing migration" logger=migrator id="create user table"
datanode_3    | 2019-11-06 03:54:17,053 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2019-11-06 03:54:23,466 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
s3g_1         | 2019-11-06 03:54:16,122 INFO server.Server: Started @4025ms
datanode_2    | 2019-11-06 03:54:16,891 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1    | 2019-11-06 03:54:16,882 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
grafana_1     | t=2019-11-06T03:54:13+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user.login"
datanode_3    | 2019-11-06 03:54:17,071 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2019-11-06 03:54:23,470 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
s3g_1         | 2019-11-06 03:54:16,125 INFO server.BaseHttpServer: HTTP server of S3GATEWAY is listening at http://0.0.0.0:9878
datanode_2    | 2019-11-06 03:54:16,894 INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1    | 2019-11-06 03:54:16,883 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
grafana_1     | t=2019-11-06T03:54:14+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user.email"
om_1          | 2019-11-06 03:54:29,474 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-06 03:54:17,079 INFO http.HttpServer2: Jetty bound to port 9882
scm_1         | STARTUP_MSG:   java = 11.0.3
datanode_1    | 2019-11-06 03:54:16,883 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
grafana_1     | t=2019-11-06T03:54:14+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_user_login - v1"
om_1          | 2019-11-06 03:54:30,475 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:16,901 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3    | 2019-11-06 03:54:17,080 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
scm_1         | ************************************************************/
datanode_1    | 2019-11-06 03:54:16,904 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
grafana_1     | t=2019-11-06T03:54:14+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_user_email - v1"
om_1          | 2019-11-06 03:54:31,477 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:16,903 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3    | 2019-11-06 03:54:17,115 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ac86d6a{/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2019-11-06 03:54:14,356 INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2019-11-06 03:54:32,478 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:17+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table user to user_v1 - v1"
datanode_2    | 2019-11-06 03:54:16,903 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1    | 2019-11-06 03:54:16,912 INFO http.HttpServer2: Jetty bound to port 9882
datanode_3    | 2019-11-06 03:54:17,116 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@23b8d9f3{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2019-11-06 03:54:14,569 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2019-11-06 03:54:33,480 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:24+0000 lvl=info msg="Executing migration" logger=migrator id="create user table v2"
datanode_2    | 2019-11-06 03:54:16,903 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1    | 2019-11-06 03:54:16,914 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
scm_1         | 2019-11-06 03:54:14,580 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2019-11-06 03:54:34,481 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:16,922 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
grafana_1     | t=2019-11-06T03:54:33+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_user_login - v2"
datanode_3    | 2019-11-06 03:54:17,181 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7f5538a1{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-4094670973203591755.dir/webapp/,AVAILABLE}{/hddsDatanode}
datanode_1    | 2019-11-06 03:54:16,943 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@76563d26{/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2019-11-06 03:54:14,604 INFO util.log: Logging initialized @1037ms
om_1          | 2019-11-06 03:54:35,483 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:44+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_user_email - v2"
datanode_2    | 2019-11-06 03:54:16,930 INFO http.HttpServer2: Jetty bound to port 9882
datanode_3    | 2019-11-06 03:54:17,187 INFO server.AbstractConnector: Started ServerConnector@64db4967{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
scm_1         | 2019-11-06 03:54:14,726 INFO db.DBStoreBuilder: using custom profile for table: deletedBlocks
om_1          | 2019-11-06 03:54:36,484 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:16,944 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@22a736d7{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
grafana_1     | t=2019-11-06T03:54:53+0000 lvl=info msg="Executing migration" logger=migrator id="copy data_source v1 to v2"
datanode_2    | 2019-11-06 03:54:16,931 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_3    | 2019-11-06 03:54:17,187 INFO server.Server: Started @3294ms
scm_1         | 2019-11-06 03:54:14,727 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedBlocks
om_1          | 2019-11-06 03:54:37,485 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:17,011 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3b920bdc{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-6877343125487814273.dir/webapp/,AVAILABLE}{/hddsDatanode}
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table user_v1"
datanode_2    | 2019-11-06 03:54:16,960 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ac86d6a{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3    | 2019-11-06 03:54:17,190 INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2019-11-06 03:54:14,727 INFO db.DBStoreBuilder: using custom profile for table: validCerts
datanode_1    | 2019-11-06 03:54:17,018 INFO server.AbstractConnector: Started ServerConnector@3e3315d9{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add column help_flags1 to user table"
datanode_2    | 2019-11-06 03:54:16,961 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@23b8d9f3{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2019-11-06 03:54:38,487 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-06 03:54:17,190 INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2019-11-06 03:54:14,727 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:validCerts
datanode_1    | 2019-11-06 03:54:17,018 INFO server.Server: Started @3256ms
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="Update user table charset"
datanode_2    | 2019-11-06 03:54:17,026 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7f5538a1{/,file:///tmp/jetty-0.0.0.0-9882-hddsDatanode-_-any-12464118336687330867.dir/webapp/,AVAILABLE}{/hddsDatanode}
om_1          | 2019-11-06 03:54:38,489 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
datanode_3    | 2019-11-06 03:54:17,192 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
scm_1         | 2019-11-06 03:54:14,727 INFO db.DBStoreBuilder: using custom profile for table: revokedCerts
datanode_1    | 2019-11-06 03:54:17,022 INFO impl.MetricsSinkAdapter: Sink prometheus started
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add last_seen_at column to user"
datanode_2    | 2019-11-06 03:54:17,033 INFO server.AbstractConnector: Started ServerConnector@64db4967{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3    | 2019-11-06 03:54:17,207 INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2019-11-06 03:54:44,493 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:17,022 INFO impl.MetricsSystemImpl: Registered sink prometheus
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add missing user data"
datanode_2    | 2019-11-06 03:54:17,033 INFO server.Server: Started @3381ms
datanode_3    | 2019-11-06 03:54:17,367 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
scm_1         | 2019-11-06 03:54:14,727 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:revokedCerts
om_1          | 2019-11-06 03:54:45,495 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:17,024 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="Add is_disabled column to user"
datanode_2    | 2019-11-06 03:54:17,036 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3    | 2019-11-06 03:54:20,291 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:14,738 INFO db.DBStoreBuilder: using custom profile for table: default
om_1          | 2019-11-06 03:54:46,496 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:17,036 INFO util.JvmPauseMonitor: Starting JVM pause monitor
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="create temp user table v1-7"
datanode_2    | 2019-11-06 03:54:17,036 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3    | 2019-11-06 03:54:21,292 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:14,738 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
om_1          | 2019-11-06 03:54:47,497 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:17,220 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_email - v1-7"
datanode_2    | 2019-11-06 03:54:17,039 INFO server.BaseHttpServer: HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
datanode_3    | 2019-11-06 03:54:22,293 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:14,740 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
om_1          | 2019-11-06 03:54:48,499 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:20,108 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_org_id - v1-7"
datanode_3    | 2019-11-06 03:54:23,294 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:54,201 INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@1b266842
om_1          | 2019-11-06 03:54:49,500 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:17,049 INFO util.JvmPauseMonitor: Starting JVM pause monitor
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_code - v1-7"
datanode_3    | 2019-11-06 03:54:24,295 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-06 03:54:50,502 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:54,202 INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_1    | 2019-11-06 03:54:21,109 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:17,204 INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_temp_user_status - v1-7"
datanode_3    | 2019-11-06 03:54:25,297 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-06 03:54:51,504 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:54,302 INFO node.SCMNodeManager: Entering startup safe mode.
datanode_1    | 2019-11-06 03:54:22,111 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:20,143 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="Update temp_user table charset"
datanode_3    | 2019-11-06 03:54:26,298 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-06 03:54:52,505 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:54,427 INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
datanode_2    | 2019-11-06 03:54:21,144 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:54+0000 lvl=info msg="Executing migration" logger=migrator id="create star table"
datanode_1    | 2019-11-06 03:54:23,112 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-06 03:54:27,299 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:22,145 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index star.user_id_dashboard_id"
om_1          | 2019-11-06 03:54:53,507 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:54,439 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3    | 2019-11-06 03:54:28,301 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:23,147 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="create org table v1"
datanode_1    | 2019-11-06 03:54:24,113 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-06 03:54:53,508 INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
scm_1         | 2019-11-06 03:54:54,620 INFO pipeline.SCMPipelineManager: No pipeline exists in current db
datanode_3    | 2019-11-06 03:54:29,302 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:24,148 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_org_name - v1"
datanode_1    | 2019-11-06 03:54:25,115 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-7d7542ac-002b-409d-a05f-b9d738794e99
scm_1         | 2019-11-06 03:54:54,623 WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3    | 2019-11-06 03:54:30,303 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:25,149 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="create org_user table v1"
datanode_1    | 2019-11-06 03:54:26,116 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-06 03:54:58,709 INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
scm_1         | 2019-11-06 03:54:54,809 WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
datanode_3    | 2019-11-06 03:54:31,304 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:26,150 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_org_user_org_id - v1"
datanode_1    | 2019-11-06 03:54:27,117 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | /************************************************************
scm_1         | 2019-11-06 03:54:55,345 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3    | 2019-11-06 03:54:32,305 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_org_user_org_id_user_id - v1"
datanode_2    | 2019-11-06 03:54:27,151 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:28,119 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at a52d73221389/172.19.0.4
scm_1         | 2019-11-06 03:54:55,377 INFO ipc.Server: Starting Socket Reader #1 for port 9861
datanode_2    | 2019-11-06 03:54:28,152 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:29,120 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="Update org table charset"
om_1          | ************************************************************/
scm_1         | 2019-11-06 03:54:55,423 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1    | 2019-11-06 03:54:30,121 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="Update org_user table charset"
datanode_3    | 2019-11-06 03:54:33,307 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-06 03:54:59,696 INFO om.OzoneManagerStarter: STARTUP_MSG: 
scm_1         | 2019-11-06 03:54:55,424 INFO ipc.Server: Starting Socket Reader #1 for port 9863
datanode_1    | 2019-11-06 03:54:31,123 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:29,154 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-06 03:54:34,308 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="Migrate all Read Only Viewers to Viewers"
om_1          | /************************************************************
scm_1         | 2019-11-06 03:54:55,440 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1    | 2019-11-06 03:54:32,124 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-06 03:54:35,309 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:30,155 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard table"
om_1          | STARTUP_MSG: Starting OzoneManager
scm_1         | 2019-11-06 03:54:55,441 INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode_1    | 2019-11-06 03:54:33,125 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3    | 2019-11-06 03:54:36,310 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:31,156 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard.account_id"
om_1          | STARTUP_MSG:   host = a52d73221389/172.19.0.4
datanode_1    | 2019-11-06 03:54:34,126 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,466 INFO hdfs.DFSUtil: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_3    | 2019-11-06 03:54:37,312 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:32,157 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_account_id_slug"
om_1          | STARTUP_MSG:   args = []
datanode_1    | 2019-11-06 03:54:35,128 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,633 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3    | 2019-11-06 03:54:38,313 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:33,160 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:55+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_tag table"
datanode_1    | 2019-11-06 03:54:36,129 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,647 INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
datanode_3    | 2019-11-06 03:54:39,314 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_tag.dasboard_id_term"
om_1          | STARTUP_MSG:   version = 3.2.0
datanode_2    | 2019-11-06 03:54:34,161 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:37,130 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,655 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode_3    | 2019-11-06 03:54:40,316 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_dashboard_tag_dashboard_id_term - v1"
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/guava-11.0.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0-d6d58d0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar
datanode_2    | 2019-11-06 03:54:35,162 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:38,132 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,657 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
datanode_3    | 2019-11-06 03:54:41,317 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table dashboard to dashboard_v1 - v1"
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2    | 2019-11-06 03:54:36,163 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:39,133 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,657 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3    | 2019-11-06 03:54:42,318 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:37,164 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,657 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | STARTUP_MSG:   java = 11.0.3
datanode_1    | 2019-11-06 03:54:40,134 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard v2"
datanode_3    | 2019-11-06 03:54:43,320 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:38,165 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,675 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | ************************************************************/
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_org_id - v2"
datanode_3    | 2019-11-06 03:54:44,321 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:41,135 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,682 INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
datanode_2    | 2019-11-06 03:54:39,166 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2019-11-06 03:54:59,706 INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_org_id_slug - v2"
datanode_3    | 2019-11-06 03:54:45,323 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:42,136 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,744 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2019-11-06 03:55:00,698 INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.19.0.4:9862
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="copy dashboard v1 to v2"
datanode_2    | 2019-11-06 03:54:40,167 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 20 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:43,138 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,789 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2019-11-06 03:55:00,698 INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
datanode_3    | 2019-11-06 03:54:46,324 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="drop table dashboard_v1"
datanode_2    | 2019-11-06 03:54:41,168 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 21 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:44,139 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:55,790 INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
om_1          | 2019-11-06 03:55:00,702 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3    | 2019-11-06 03:54:47,326 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard.data to mediumtext v1"
datanode_2    | 2019-11-06 03:54:42,169 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:45,140 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,025 INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
om_1          | 2019-11-06 03:55:00,711 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3    | 2019-11-06 03:54:48,327 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="Add column updated_by in dashboard - v2"
datanode_2    | 2019-11-06 03:54:43,171 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 23 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:46,142 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,026 INFO ipc.Server: IPC Server Responder: starting
om_1          | 2019-11-06 03:55:01,585 WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3    | 2019-11-06 03:54:49,329 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="Add column created_by in dashboard - v2"
datanode_2    | 2019-11-06 03:54:44,172 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 24 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:47,143 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,027 INFO ipc.Server: IPC Server listener on 9860: starting
om_1          | 2019-11-06 03:55:01,619 INFO util.log: Logging initialized @2712ms
datanode_3    | 2019-11-06 03:54:50,330 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 30 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:56+0000 lvl=info msg="Executing migration" logger=migrator id="Add column gnetId in dashboard"
datanode_2    | 2019-11-06 03:54:45,173 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 25 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:48,145 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,032 INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
om_1          | 2019-11-06 03:55:01,741 INFO db.DBStoreBuilder: using custom profile for table: userTable
datanode_3    | 2019-11-06 03:54:51,332 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 31 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for gnetId in dashboard"
datanode_2    | 2019-11-06 03:54:46,174 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 26 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:49,146 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,033 INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
om_1          | 2019-11-06 03:55:01,741 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:userTable
datanode_3    | 2019-11-06 03:54:52,333 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 32 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add column plugin_id in dashboard"
datanode_2    | 2019-11-06 03:54:47,175 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 27 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:50,147 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 30 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,034 INFO ipc.Server: IPC Server Responder: starting
om_1          | 2019-11-06 03:55:01,741 INFO db.DBStoreBuilder: using custom profile for table: volumeTable
datanode_3    | 2019-11-06 03:54:53,334 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 33 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for plugin_id in dashboard"
datanode_2    | 2019-11-06 03:54:48,177 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 28 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:51,148 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 31 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,034 INFO ipc.Server: IPC Server listener on 9863: starting
om_1          | 2019-11-06 03:55:01,741 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:volumeTable
datanode_3    | 2019-11-06 03:54:54,336 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 34 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for dashboard_id in dashboard_tag"
datanode_2    | 2019-11-06 03:54:49,178 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 29 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1    | 2019-11-06 03:54:52,150 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 32 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,036 INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
om_1          | 2019-11-06 03:55:01,742 INFO db.DBStoreBuilder: using custom profile for table: bucketTable
datanode_3    | 2019-11-06 03:54:55,337 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 35 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard table charset"
datanode_1    | 2019-11-06 03:54:53,152 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 33 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:50,179 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 30 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,036 INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
om_1          | 2019-11-06 03:55:01,742 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:bucketTable
datanode_3    | 2019-11-06 03:54:56,338 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 36 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard_tag table charset"
datanode_1    | 2019-11-06 03:54:54,154 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 34 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:51,180 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 31 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,038 INFO ipc.Server: IPC Server Responder: starting
om_1          | 2019-11-06 03:55:01,742 INFO db.DBStoreBuilder: using custom profile for table: keyTable
datanode_3    | 2019-11-06 03:54:56,486 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add column folder_id in dashboard"
datanode_1    | 2019-11-06 03:54:55,155 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 35 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:52,182 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 32 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2019-11-06 03:54:56,038 INFO ipc.Server: IPC Server listener on 9861: starting
om_1          | 2019-11-06 03:55:01,742 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:keyTable
datanode_3    | 2019-11-06 03:54:56,488 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add column isFolder in dashboard"
scm_1         | 2019-11-06 03:54:56,045 INFO http.HttpServer2: Jetty bound to port 9876
om_1          | 2019-11-06 03:55:01,742 INFO db.DBStoreBuilder: using custom profile for table: deletedTable
datanode_1    | 2019-11-06 03:54:56,156 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 36 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2    | 2019-11-06 03:54:53,183 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 33 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add column has_acl in dashboard"
scm_1         | 2019-11-06 03:54:56,047 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
om_1          | 2019-11-06 03:55:01,742 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:deletedTable
datanode_1    | 2019-11-06 03:54:56,486 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2    | 2019-11-06 03:54:54,184 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 34 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add column uid in dashboard"
scm_1         | 2019-11-06 03:54:56,085 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6818d900{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3    | 2019-11-06 03:54:56,488 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 407c79ba-7a2c-49fa-93d7-ec61e39fb159 at port 9858
om_1          | 2019-11-06 03:55:01,742 INFO db.DBStoreBuilder: using custom profile for table: openKeyTable
datanode_1    | 2019-11-06 03:54:56,488 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2    | 2019-11-06 03:54:55,185 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 35 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Update uid column values in dashboard"
datanode_3    | 2019-11-06 03:54:56,507 INFO impl.RaftServerProxy: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start RPC server
om_1          | 2019-11-06 03:55:01,742 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:openKeyTable
scm_1         | 2019-11-06 03:54:56,086 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3b36e000{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1    | 2019-11-06 03:54:56,488 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd at port 9858
datanode_2    | 2019-11-06 03:54:56,186 INFO ipc.Client: Retrying connect to server: scm/172.19.0.5:9861. Already tried 36 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index dashboard_org_id_uid"
datanode_3    | 2019-11-06 03:54:56,641 INFO server.GrpcService: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
om_1          | 2019-11-06 03:55:01,743 INFO db.DBStoreBuilder: using custom profile for table: s3Table
scm_1         | 2019-11-06 03:54:56,204 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@582a764a{/,file:///tmp/jetty-0.0.0.0-9876-scm-_-any-2963281541591118131.dir/webapp/,AVAILABLE}{/scm}
datanode_1    | 2019-11-06 03:54:56,506 INFO impl.RaftServerProxy: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start RPC server
datanode_2    | 2019-11-06 03:54:56,450 INFO ozoneimpl.OzoneContainer: Attempting to start container services.
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Remove unique index org_id_slug"
datanode_3    | WARNING: An illegal reflective access operation has occurred
om_1          | 2019-11-06 03:55:01,743 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3Table
scm_1         | 2019-11-06 03:54:56,210 INFO server.AbstractConnector: Started ServerConnector@2819c460{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
datanode_2    | 2019-11-06 03:54:56,451 INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1    | 2019-11-06 03:54:56,609 INFO server.GrpcService: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard title length"
om_1          | 2019-11-06 03:55:01,743 INFO db.DBStoreBuilder: using custom profile for table: multipartInfoTable
datanode_3    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
scm_1         | 2019-11-06 03:54:56,210 INFO server.Server: Started @42643ms
datanode_2    | 2019-11-06 03:54:56,452 INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87 at port 9858
datanode_1    | WARNING: An illegal reflective access operation has occurred
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index for dashboard_org_id_title_folder_id"
om_1          | 2019-11-06 03:55:01,743 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:multipartInfoTable
scm_1         | 2019-11-06 03:54:56,214 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
datanode_2    | 2019-11-06 03:54:56,469 INFO impl.RaftServerProxy: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: start RPC server
datanode_1    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_provisioning"
om_1          | 2019-11-06 03:55:01,743 INFO db.DBStoreBuilder: using custom profile for table: dTokenTable
scm_1         | 2019-11-06 03:54:56,214 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2    | 2019-11-06 03:54:56,571 INFO server.GrpcService: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table dashboard_provisioning to dashboard_provisioning_tmp_qwerty - v1"
om_1          | 2019-11-06 03:55:01,743 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:dTokenTable
scm_1         | 2019-11-06 03:54:56,216 INFO server.BaseHttpServer: HTTP server of SCM is listening at http://0.0.0.0:9876
datanode_3    | WARNING: All illegal access operations will be denied in a future release
datanode_2    | WARNING: An illegal reflective access operation has occurred
datanode_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_provisioning v2"
om_1          | 2019-11-06 03:55:01,743 INFO db.DBStoreBuilder: using custom profile for table: s3SecretTable
scm_1         | 2019-11-06 03:54:56,232 INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3    | 2019-11-06 03:54:58,703 INFO impl.RaftServerProxy: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: addNew group-CCA881BF2C5D:[407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858] returns group-CCA881BF2C5D:java.util.concurrent.CompletableFuture@127bc6e2[Not completed]
datanode_2    | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
datanode_1    | WARNING: All illegal access operations will be denied in a future release
grafana_1     | t=2019-11-06T03:54:57+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_provisioning_dashboard_id - v2"
om_1          | 2019-11-06 03:55:01,743 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:s3SecretTable
datanode_2    | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
datanode_3    | 2019-11-06 03:54:58,719 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: new RaftServerImpl for group-CCA881BF2C5D:[407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858] with ContainerStateMachine:uninitialized
datanode_1    | 2019-11-06 03:54:58,045 INFO impl.RaftServerProxy: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: addNew group-1CFC7A583412:[8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858] returns group-1CFC7A583412:java.util.concurrent.CompletableFuture@30bdc47f[Not completed]
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_provisioning_dashboard_id_name - v2"
scm_1         | 2019-11-06 03:54:57,164 INFO net.NetworkTopology: Added a new node: /default-rack/8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd
om_1          | 2019-11-06 03:55:01,744 INFO db.DBStoreBuilder: using custom profile for table: prefixTable
datanode_2    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3    | 2019-11-06 03:54:58,721 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1    | 2019-11-06 03:54:58,069 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: new RaftServerImpl for group-1CFC7A583412:[8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858] with ContainerStateMachine:uninitialized
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="copy dashboard_provisioning v1 to v2"
scm_1         | 2019-11-06 03:54:57,164 INFO node.SCMNodeManager: Registered Data node : 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd{ip: 172.19.0.9, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
om_1          | 2019-11-06 03:55:01,744 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:prefixTable
datanode_2    | WARNING: All illegal access operations will be denied in a future release
datanode_3    | 2019-11-06 03:54:58,721 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1    | 2019-11-06 03:54:58,071 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="drop dashboard_provisioning_tmp_qwerty"
scm_1         | 2019-11-06 03:54:57,167 INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
om_1          | 2019-11-06 03:55:01,753 INFO db.DBStoreBuilder: using custom profile for table: default
datanode_2    | 2019-11-06 03:54:59,326 INFO impl.RaftServerProxy: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: addNew group-C41898DB61F7:[544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858] returns group-C41898DB61F7:java.util.concurrent.CompletableFuture@bdc0064[Not completed]
datanode_3    | 2019-11-06 03:54:58,721 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_1    | 2019-11-06 03:54:58,072 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="Add check_sum column"
scm_1         | 2019-11-06 03:54:57,170 INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
om_1          | 2019-11-06 03:55:01,754 INFO db.DBStoreBuilder: Using default column profile:DBProfile.DISK for Table:default
datanode_2    | 2019-11-06 03:54:59,341 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: new RaftServerImpl for group-C41898DB61F7:[544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858] with ContainerStateMachine:uninitialized
datanode_3    | 2019-11-06 03:54:58,722 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1    | 2019-11-06 03:54:58,072 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="create data_source table"
scm_1         | 2019-11-06 03:54:57,170 INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
om_1          | 2019-11-06 03:55:01,755 INFO db.DBStoreBuilder: Using default options. DBProfile.DISK
datanode_2    | 2019-11-06 03:54:59,342 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3    | 2019-11-06 03:54:58,722 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1    | 2019-11-06 03:54:58,073 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1         | 2019-11-06 03:54:57,172 INFO net.NetworkTopology: Added a new node: /default-rack/544cbf7c-62ca-4a7d-9a1b-834cf9fbed87
om_1          | 2019-11-06 03:55:02,647 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="add index data_source.account_id"
datanode_2    | 2019-11-06 03:54:59,343 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3    | 2019-11-06 03:54:58,728 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D: ConfigurationManager, init=-1: [407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858], old=null, confs=<EMPTY_MAP>
datanode_1    | 2019-11-06 03:54:58,073 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1         | 2019-11-06 03:54:57,173 INFO node.SCMNodeManager: Registered Data node : 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87{ip: 172.19.0.8, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
om_1          | 2019-11-06 03:55:02,662 INFO ipc.Server: Starting Socket Reader #1 for port 9862
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index data_source.account_id_name"
datanode_2    | 2019-11-06 03:54:59,343 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3    | 2019-11-06 03:54:58,728 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1    | 2019-11-06 03:54:58,082 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412: ConfigurationManager, init=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858], old=null, confs=<EMPTY_MAP>
scm_1         | 2019-11-06 03:54:57,255 INFO net.NetworkTopology: Added a new node: /default-rack/407c79ba-7a2c-49fa-93d7-ec61e39fb159
om_1          | 2019-11-06 03:55:02,712 INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.19.0.4:9862
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_data_source_account_id - v1"
datanode_2    | 2019-11-06 03:54:59,344 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1    | 2019-11-06 03:54:58,082 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1          | 2019-11-06 03:55:02,794 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
grafana_1     | t=2019-11-06T03:54:58+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_data_source_account_id_name - v1"
datanode_2    | 2019-11-06 03:54:59,344 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3    | 2019-11-06 03:54:58,733 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1         | 2019-11-06 03:54:57,255 INFO node.SCMNodeManager: Registered Data node : 407c79ba-7a2c-49fa-93d7-ec61e39fb159{ip: 172.19.0.10, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}
datanode_1    | 2019-11-06 03:54:58,088 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1          | 2019-11-06 03:55:02,834 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
grafana_1     | t=2019-11-06T03:54:59+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table data_source to data_source_v1 - v1"
datanode_2    | 2019-11-06 03:54:59,352 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7: ConfigurationManager, init=-1: [544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_3    | 2019-11-06 03:54:58,734 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e1d9d096-32aa-4d4d-9808-cca881bf2c5d does not exist. Creating ...
scm_1         | WARNING: An illegal reflective access operation has occurred
datanode_1    | 2019-11-06 03:54:58,090 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d86ed64d-b074-4b09-bdd7-1cfc7a583412 does not exist. Creating ...
grafana_1     | t=2019-11-06T03:54:59+0000 lvl=info msg="Executing migration" logger=migrator id="create data_source table v2"
datanode_2    | 2019-11-06 03:54:59,352 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1          | 2019-11-06 03:55:02,834 INFO impl.MetricsSystemImpl: OzoneManager metrics system started
datanode_3    | 2019-11-06 03:54:58,821 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e1d9d096-32aa-4d4d-9808-cca881bf2c5d/in_use.lock acquired by nodename 7@e05679a42f3d
scm_1         | WARNING: Illegal reflective access by org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil (file:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.2.0.jar) to field java.nio.Buffer.address
datanode_1    | 2019-11-06 03:54:58,138 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d86ed64d-b074-4b09-bdd7-1cfc7a583412/in_use.lock acquired by nodename 7@84fe8a1e2e5b
grafana_1     | t=2019-11-06T03:54:59+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_data_source_org_id - v2"
datanode_2    | 2019-11-06 03:54:59,357 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1          | 2019-11-06 03:55:02,898 INFO ipc.Server: IPC Server Responder: starting
datanode_3    | 2019-11-06 03:54:58,881 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e1d9d096-32aa-4d4d-9808-cca881bf2c5d has been successfully formatted.
scm_1         | WARNING: Please consider reporting this to the maintainers of org.apache.ratis.thirdparty.com.google.protobuf.UnsafeUtil
grafana_1     | t=2019-11-06T03:54:59+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_data_source_org_id_name - v2"
datanode_2    | 2019-11-06 03:54:59,358 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ad64214d-69cc-4265-aed4-c41898db61f7 does not exist. Creating ...
datanode_3    | 2019-11-06 03:54:58,885 INFO ratis.ContainerStateMachine: group-CCA881BF2C5D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
grafana_1     | t=2019-11-06T03:54:59+0000 lvl=info msg="Executing migration" logger=migrator id="copy data_source v1 to v2"
datanode_1    | 2019-11-06 03:54:58,163 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d86ed64d-b074-4b09-bdd7-1cfc7a583412 has been successfully formatted.
om_1          | 2019-11-06 03:55:02,900 INFO ipc.Server: IPC Server listener on 9862: starting
scm_1         | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2    | 2019-11-06 03:54:59,412 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ad64214d-69cc-4265-aed4-c41898db61f7/in_use.lock acquired by nodename 7@e603cf941a98
datanode_3    | 2019-11-06 03:54:58,885 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
grafana_1     | t=2019-11-06T03:54:59+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table data_source_v1 #2"
datanode_1    | 2019-11-06 03:54:58,168 INFO ratis.ContainerStateMachine: group-1CFC7A583412: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om_1          | 2019-11-06 03:55:02,938 INFO hdfs.DFSUtil: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
scm_1         | WARNING: All illegal access operations will be denied in a future release
datanode_2    | 2019-11-06 03:54:59,505 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ad64214d-69cc-4265-aed4-c41898db61f7 has been successfully formatted.
datanode_3    | 2019-11-06 03:54:58,889 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-06T03:54:59+0000 lvl=info msg="Executing migration" logger=migrator id="Add column with_credentials"
datanode_1    | 2019-11-06 03:54:58,168 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1          | 2019-11-06 03:55:03,059 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2019-11-06 03:54:58,361 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d86ed64d-b074-4b09-bdd7-1cfc7a583412, Nodes: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd{ip: 172.19.0.9, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_2    | 2019-11-06 03:54:59,509 INFO ratis.ContainerStateMachine: group-C41898DB61F7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3    | 2019-11-06 03:54:58,893 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="Add secure json data column"
datanode_1    | 2019-11-06 03:54:58,172 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1          | 2019-11-06 03:55:03,063 INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
scm_1         | 2019-11-06 03:54:59,052 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e1d9d096-32aa-4d4d-9808-cca881bf2c5d, Nodes: 407c79ba-7a2c-49fa-93d7-ec61e39fb159{ip: 172.19.0.10, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_2    | 2019-11-06 03:54:59,510 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="Update data_source table charset"
datanode_3    | 2019-11-06 03:54:58,893 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1    | 2019-11-06 03:54:58,176 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1          | 2019-11-06 03:55:03,070 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
scm_1         | 2019-11-06 03:54:59,655 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ad64214d-69cc-4265-aed4-c41898db61f7, Nodes: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87{ip: 172.19.0.8, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
datanode_2    | 2019-11-06 03:54:59,512 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="Update initial version to 1"
datanode_1    | 2019-11-06 03:54:58,176 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1          | 2019-11-06 03:55:03,073 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
datanode_3    | 2019-11-06 03:54:58,894 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 2019-11-06 03:54:59,887 INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6a1176e0-1e20-4270-bd8a-2e0b3439f29c, Nodes: 407c79ba-7a2c-49fa-93d7-ec61e39fb159{ip: 172.19.0.10, host: ozoneperf_datanode_3.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd{ip: 172.19.0.9, host: ozoneperf_datanode_1.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}544cbf7c-62ca-4a7d-9a1b-834cf9fbed87{ip: 172.19.0.8, host: ozoneperf_datanode_2.ozoneperf_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
datanode_2    | 2019-11-06 03:54:59,516 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="Add read_only data column"
datanode_1    | 2019-11-06 03:54:58,178 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1          | 2019-11-06 03:55:03,073 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3    | 2019-11-06 03:54:58,899 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2    | 2019-11-06 03:54:59,516 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="Migrate logging ds to loki ds"
datanode_1    | 2019-11-06 03:54:58,183 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1          | 2019-11-06 03:55:03,073 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3    | 2019-11-06 03:54:58,902 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-06 03:54:59,518 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="Update json_data with nulls"
datanode_1    | 2019-11-06 03:54:58,186 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
om_1          | 2019-11-06 03:55:03,093 WARN server.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2    | 2019-11-06 03:54:59,522 INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3    | 2019-11-06 03:54:58,906 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="create api_key table"
datanode_1    | 2019-11-06 03:54:58,190 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1          | 2019-11-06 03:55:03,095 INFO http.HttpServer2: Jetty bound to port 9874
datanode_2    | 2019-11-06 03:54:59,525 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-06 03:54:58,911 INFO segmented.SegmentedRaftLogWorker: new 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e1d9d096-32aa-4d4d-9808-cca881bf2c5d
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.account_id"
datanode_1    | 2019-11-06 03:54:58,195 INFO segmented.SegmentedRaftLogWorker: new 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d86ed64d-b074-4b09-bdd7-1cfc7a583412
om_1          | 2019-11-06 03:55:03,097 INFO server.Server: jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
datanode_2    | 2019-11-06 03:54:59,529 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3    | 2019-11-06 03:54:58,911 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.key"
datanode_1    | 2019-11-06 03:54:58,195 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
om_1          | 2019-11-06 03:55:03,129 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@429f7919{/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2    | 2019-11-06 03:54:59,533 INFO segmented.SegmentedRaftLogWorker: new 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ad64214d-69cc-4265-aed4-c41898db61f7
datanode_3    | 2019-11-06 03:54:58,911 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="add index api_key.account_id_name"
datanode_1    | 2019-11-06 03:54:58,195 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
om_1          | 2019-11-06 03:55:03,130 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4f5b08d{/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2    | 2019-11-06 03:54:59,533 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3    | 2019-11-06 03:54:58,912 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_api_key_account_id - v1"
datanode_1    | 2019-11-06 03:54:58,196 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1          | 2019-11-06 03:55:03,206 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1bb740f2{/,file:///tmp/jetty-0.0.0.0-9874-ozoneManager-_-any-6524113954061372873.dir/webapp/,AVAILABLE}{/ozoneManager}
datanode_2    | 2019-11-06 03:54:59,533 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3    | 2019-11-06 03:54:58,912 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_api_key_key - v1"
datanode_1    | 2019-11-06 03:54:58,197 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1          | 2019-11-06 03:55:03,213 INFO server.AbstractConnector: Started ServerConnector@5edc70ed{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
datanode_2    | 2019-11-06 03:54:59,534 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3    | 2019-11-06 03:54:58,913 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
grafana_1     | t=2019-11-06T03:55:00+0000 lvl=info msg="Executing migration" logger=migrator id="drop index UQE_api_key_account_id_name - v1"
datanode_1    | 2019-11-06 03:54:58,197 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_2    | 2019-11-06 03:54:59,535 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3    | 2019-11-06 03:54:58,913 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table api_key to api_key_v1 - v1"
datanode_1    | 2019-11-06 03:54:58,197 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2    | 2019-11-06 03:54:59,535 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3    | 2019-11-06 03:54:58,914 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create api_key table v2"
om_1          | 2019-11-06 03:55:03,213 INFO server.Server: Started @4306ms
datanode_1    | 2019-11-06 03:54:58,198 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2    | 2019-11-06 03:54:59,535 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3    | 2019-11-06 03:54:58,914 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_api_key_org_id - v2"
om_1          | 2019-11-06 03:55:03,217 INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1    | 2019-11-06 03:54:58,198 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2    | 2019-11-06 03:54:59,536 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3    | 2019-11-06 03:54:58,914 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_api_key_key - v2"
om_1          | 2019-11-06 03:55:03,217 INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1    | 2019-11-06 03:54:58,198 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2    | 2019-11-06 03:54:59,536 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3    | 2019-11-06 03:54:58,921 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_api_key_org_id_name - v2"
datanode_1    | 2019-11-06 03:54:58,206 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
om_1          | 2019-11-06 03:55:03,219 INFO server.BaseHttpServer: HTTP server of OZONEMANAGER is listening at http://0.0.0.0:9874
datanode_2    | 2019-11-06 03:54:59,536 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3    | 2019-11-06 03:54:58,947 INFO segmented.SegmentedRaftLogWorker: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1    | 2019-11-06 03:54:58,209 INFO segmented.SegmentedRaftLogWorker: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1          | 2019-11-06 03:55:14,407 INFO volume.OMVolumeCreateRequest: created volume:vol-0-73242 for user:hadoop
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="copy api_key v1 to v2"
datanode_2    | 2019-11-06 03:54:59,543 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3    | 2019-11-06 03:54:58,952 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1    | 2019-11-06 03:54:58,216 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1          | 2019-11-06 03:55:14,498 INFO volume.OMVolumeCreateRequest: created volume:vol-1-77524 for user:hadoop
datanode_2    | 2019-11-06 03:54:59,547 INFO segmented.SegmentedRaftLogWorker: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table api_key_v1"
datanode_3    | 2019-11-06 03:54:58,953 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1          | 2019-11-06 03:55:14,543 INFO volume.OMVolumeCreateRequest: created volume:vol-2-96282 for user:hadoop
datanode_1    | 2019-11-06 03:54:58,217 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2    | 2019-11-06 03:54:59,553 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="Update api_key table charset"
datanode_3    | 2019-11-06 03:54:58,954 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1          | 2019-11-06 03:55:14,579 INFO volume.OMVolumeCreateRequest: created volume:vol-3-89469 for user:hadoop
datanode_1    | 2019-11-06 03:54:58,218 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="Add expires to api_key table"
datanode_2    | 2019-11-06 03:54:59,554 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3    | 2019-11-06 03:54:58,954 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1          | 2019-11-06 03:55:14,612 INFO volume.OMVolumeCreateRequest: created volume:vol-4-03262 for user:hadoop
datanode_1    | 2019-11-06 03:54:58,218 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_snapshot table v4"
datanode_2    | 2019-11-06 03:54:59,555 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3    | 2019-11-06 03:54:58,976 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-06 03:54:58,243 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="drop table dashboard_snapshot_v4 #1"
datanode_2    | 2019-11-06 03:54:59,555 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3    | 2019-11-06 03:54:58,978 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-06 03:54:58,246 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_snapshot table v5 #2"
datanode_2    | 2019-11-06 03:54:59,579 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-06 03:54:58,980 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D: start as a follower, conf=-1: [407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858], old=null
datanode_1    | 2019-11-06 03:54:58,247 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412: start as a follower, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858], old=null
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_snapshot_key - v5"
datanode_2    | 2019-11-06 03:54:59,581 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-06 03:54:58,982 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1    | 2019-11-06 03:54:58,249 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412: changes role from      null to FOLLOWER at term 0 for startAsFollower
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_dashboard_snapshot_delete_key - v5"
datanode_2    | 2019-11-06 03:54:59,583 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7: start as a follower, conf=-1: [544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_1    | 2019-11-06 03:54:58,250 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start FollowerState
datanode_3    | 2019-11-06 03:54:58,983 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start FollowerState
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_dashboard_snapshot_user_id - v5"
datanode_2    | 2019-11-06 03:54:59,585 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1    | 2019-11-06 03:54:58,255 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1CFC7A583412,id=8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd
datanode_3    | 2019-11-06 03:54:58,988 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CCA881BF2C5D,id=407c79ba-7a2c-49fa-93d7-ec61e39fb159
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard_snapshot to mediumtext v2"
datanode_1    | 2019-11-06 03:54:58,257 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-06 03:54:59,586 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: start FollowerState
datanode_3    | 2019-11-06 03:54:58,990 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="Update dashboard_snapshot table charset"
datanode_1    | 2019-11-06 03:54:59,697 INFO impl.RaftServerProxy: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: addNew group-2E0B3439F29C:[8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858] returns group-2E0B3439F29C:java.util.concurrent.CompletableFuture@7424ed7d[Not completed]
datanode_3    | 2019-11-06 03:54:59,710 INFO impl.RaftServerProxy: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: addNew group-2E0B3439F29C:[8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858] returns group-2E0B3439F29C:java.util.concurrent.CompletableFuture@8d4f461[Not completed]
datanode_2    | 2019-11-06 03:54:59,591 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C41898DB61F7,id=544cbf7c-62ca-4a7d-9a1b-834cf9fbed87
datanode_1    | 2019-11-06 03:54:59,699 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: new RaftServerImpl for group-2E0B3439F29C:[8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858] with ContainerStateMachine:uninitialized
datanode_3    | 2019-11-06 03:54:59,713 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: new RaftServerImpl for group-2E0B3439F29C:[8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858] with ContainerStateMachine:uninitialized
datanode_2    | 2019-11-06 03:54:59,593 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-06 03:54:59,700 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
grafana_1     | t=2019-11-06T03:55:01+0000 lvl=info msg="Executing migration" logger=migrator id="Add column external_delete_url to dashboard_snapshots table"
datanode_3    | 2019-11-06 03:54:59,714 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2    | 2019-11-06 03:54:59,711 INFO impl.RaftServerProxy: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: addNew group-2E0B3439F29C:[8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858] returns group-2E0B3439F29C:java.util.concurrent.CompletableFuture@76bac552[Not completed]
datanode_1    | 2019-11-06 03:54:59,700 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3    | 2019-11-06 03:54:59,714 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="create quota table v1"
datanode_2    | 2019-11-06 03:54:59,714 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: new RaftServerImpl for group-2E0B3439F29C:[8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858] with ContainerStateMachine:uninitialized
datanode_1    | 2019-11-06 03:54:59,700 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3    | 2019-11-06 03:54:59,714 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_quota_org_id_user_id_target - v1"
datanode_2    | 2019-11-06 03:54:59,715 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1    | 2019-11-06 03:54:59,700 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3    | 2019-11-06 03:54:59,715 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="Update quota table charset"
datanode_2    | 2019-11-06 03:54:59,715 INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1    | 2019-11-06 03:54:59,700 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3    | 2019-11-06 03:54:59,716 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="create plugin_setting table"
datanode_2    | 2019-11-06 03:54:59,715 INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 120s (custom)
datanode_3    | 2019-11-06 03:54:59,716 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: ConfigurationManager, init=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_1    | 2019-11-06 03:54:59,700 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: ConfigurationManager, init=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null, confs=<EMPTY_MAP>
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="create index UQE_plugin_setting_org_id_plugin_id - v1"
datanode_3    | 2019-11-06 03:54:59,717 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1    | 2019-11-06 03:54:59,700 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2    | 2019-11-06 03:54:59,715 INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="Add column plugin_version to plugin_settings"
datanode_1    | 2019-11-06 03:54:59,701 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3    | 2019-11-06 03:54:59,717 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2    | 2019-11-06 03:54:59,715 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="Update plugin_setting table charset"
datanode_1    | 2019-11-06 03:54:59,701 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c does not exist. Creating ...
datanode_3    | 2019-11-06 03:54:59,717 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c does not exist. Creating ...
datanode_2    | 2019-11-06 03:54:59,715 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C: ConfigurationManager, init=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_1    | 2019-11-06 03:54:59,764 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c/in_use.lock acquired by nodename 7@84fe8a1e2e5b
datanode_3    | 2019-11-06 03:54:59,804 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c/in_use.lock acquired by nodename 7@e05679a42f3d
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="create session table"
datanode_2    | 2019-11-06 03:54:59,716 INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1    | 2019-11-06 03:54:59,864 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c has been successfully formatted.
datanode_3    | 2019-11-06 03:54:59,864 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c has been successfully formatted.
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table playlist table"
datanode_2    | 2019-11-06 03:54:59,716 INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1    | 2019-11-06 03:54:59,864 INFO ratis.ContainerStateMachine: group-2E0B3439F29C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3    | 2019-11-06 03:54:59,864 INFO ratis.ContainerStateMachine: group-2E0B3439F29C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old table playlist_item table"
datanode_2    | 2019-11-06 03:54:59,716 INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c does not exist. Creating ...
datanode_1    | 2019-11-06 03:54:59,864 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_3    | 2019-11-06 03:54:59,864 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="create playlist table v2"
datanode_2    | 2019-11-06 03:54:59,764 INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c/in_use.lock acquired by nodename 7@e603cf941a98
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="create playlist item table v2"
datanode_2    | 2019-11-06 03:54:59,864 INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c has been successfully formatted.
datanode_3    | 2019-11-06 03:54:59,864 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="Update playlist table charset"
datanode_3    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2    | 2019-11-06 03:54:59,865 INFO ratis.ContainerStateMachine: group-2E0B3439F29C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="Update playlist_item table charset"
datanode_3    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="drop preferences table v2"
datanode_3    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
grafana_1     | t=2019-11-06T03:55:02+0000 lvl=info msg="Executing migration" logger=migrator id="drop preferences table v3"
datanode_1    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="create preferences table v3"
datanode_1    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3    | 2019-11-06 03:54:59,865 INFO segmented.SegmentedRaftLogWorker: new 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Update preferences table charset"
datanode_2    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1    | 2019-11-06 03:54:59,866 INFO segmented.SegmentedRaftLogWorker: new 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c
datanode_3    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Add column team_id in preferences"
datanode_3    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Update team_id column values in preferences"
datanode_3    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="create alert table v1"
datanode_3    | 2019-11-06 03:54:59,865 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2    | 2019-11-06 03:54:59,867 INFO segmented.SegmentedRaftLogWorker: new 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c
datanode_1    | 2019-11-06 03:54:59,868 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert org_id & id "
datanode_2    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1    | 2019-11-06 03:54:59,868 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert state"
datanode_2    | 2019-11-06 03:54:59,868 INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1    | 2019-11-06 03:54:59,868 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert dashboard_id"
datanode_1    | 2019-11-06 03:54:59,869 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2    | 2019-11-06 03:54:59,868 INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1    | 2019-11-06 03:54:59,869 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Create alert_rule_tag table v1"
datanode_2    | 2019-11-06 03:54:59,868 INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1    | 2019-11-06 03:54:59,869 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index alert_rule_tag.alert_id_tag_id"
datanode_2    | 2019-11-06 03:54:59,868 INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554432 (custom)
datanode_3    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1    | 2019-11-06 03:54:59,869 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="create alert_notification table v1"
datanode_2    | 2019-11-06 03:54:59,869 INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3    | 2019-11-06 03:54:59,866 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1    | 2019-11-06 03:54:59,870 INFO segmented.SegmentedRaftLogWorker: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Add column is_default"
datanode_2    | 2019-11-06 03:54:59,869 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3    | 2019-11-06 03:54:59,867 INFO segmented.SegmentedRaftLogWorker: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1    | 2019-11-06 03:54:59,870 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Add column frequency"
datanode_2    | 2019-11-06 03:54:59,869 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1    | 2019-11-06 03:54:59,871 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Add column send_reminder"
datanode_3    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1    | 2019-11-06 03:54:59,871 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2    | 2019-11-06 03:54:59,869 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="Add column disable_resolve_message"
datanode_1    | 2019-11-06 03:54:59,871 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2    | 2019-11-06 03:54:59,870 INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3    | 2019-11-06 03:54:59,867 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
grafana_1     | t=2019-11-06T03:55:03+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert_notification org_id & name"
datanode_1    | 2019-11-06 03:54:59,871 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-06 03:54:59,870 INFO segmented.SegmentedRaftLogWorker: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1    | 2019-11-06 03:54:59,871 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert table charset"
datanode_3    | 2019-11-06 03:54:59,868 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2    | 2019-11-06 03:54:59,871 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1    | 2019-11-06 03:54:59,872 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: start as a follower, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert_notification table charset"
datanode_3    | 2019-11-06 03:54:59,868 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-06 03:54:59,871 INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1    | 2019-11-06 03:54:59,872 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: changes role from      null to FOLLOWER at term 0 for startAsFollower
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="create notification_journal table v1"
datanode_3    | 2019-11-06 03:54:59,868 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_2    | 2019-11-06 03:54:59,871 INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1    | 2019-11-06 03:54:59,872 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start FollowerState
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="add index notification_journal org_id & alert_id & notifier_id"
datanode_3    | 2019-11-06 03:54:59,868 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: start as a follower, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_2    | 2019-11-06 03:54:59,871 INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1    | 2019-11-06 03:54:59,873 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E0B3439F29C,id=8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="drop alert_notification_journal"
datanode_3    | 2019-11-06 03:54:59,868 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2    | 2019-11-06 03:54:59,872 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-06 03:54:59,873 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="create alert_notification_state table v1"
datanode_2    | 2019-11-06 03:54:59,872 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_3    | 2019-11-06 03:54:59,868 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start FollowerState
datanode_1    | 2019-11-06 03:55:03,389 INFO impl.FollowerState: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412-FollowerState: change to CANDIDATE, lastRpcTime:5139ms, electionTimeout:5138ms
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="add index alert_notification_state org_id & alert_id & notifier_id"
datanode_2    | 2019-11-06 03:54:59,872 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C: start as a follower, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_3    | 2019-11-06 03:54:59,869 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E0B3439F29C,id=407c79ba-7a2c-49fa-93d7-ec61e39fb159
datanode_1    | 2019-11-06 03:55:03,391 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: shutdown FollowerState
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="Add for to alert table"
datanode_2    | 2019-11-06 03:54:59,872 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3    | 2019-11-06 03:54:59,869 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
datanode_1    | 2019-11-06 03:55:03,391 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="Add column uid in alert_notification"
datanode_2    | 2019-11-06 03:54:59,873 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: start FollowerState
datanode_3    | 2019-11-06 03:55:04,142 INFO impl.FollowerState: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D-FollowerState: change to CANDIDATE, lastRpcTime:5159ms, electionTimeout:5158ms
datanode_2    | 2019-11-06 03:54:59,873 INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E0B3439F29C,id=544cbf7c-62ca-4a7d-9a1b-834cf9fbed87
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="Update uid column values in alert_notification"
datanode_3    | 2019-11-06 03:55:04,144 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: shutdown FollowerState
datanode_1    | 2019-11-06 03:55:03,395 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start LeaderElection
datanode_2    | 2019-11-06 03:54:59,874 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index alert_notification_org_id_uid"
datanode_3    | 2019-11-06 03:55:04,144 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2    | 2019-11-06 03:55:04,761 INFO impl.FollowerState: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7-FollowerState: change to CANDIDATE, lastRpcTime:5175ms, electionTimeout:5174ms
datanode_1    | 2019-11-06 03:55:03,423 INFO impl.LeaderElection: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412-LeaderElection1: begin an election at term 1 for -1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858], old=null
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="Remove unique index org_id_name"
datanode_3    | 2019-11-06 03:55:04,149 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start LeaderElection
datanode_2    | 2019-11-06 03:55:04,763 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: shutdown FollowerState
datanode_1    | 2019-11-06 03:55:03,425 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: shutdown LeaderElection
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="Drop old annotation table v4"
datanode_3    | 2019-11-06 03:55:04,186 INFO impl.LeaderElection: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D-LeaderElection1: begin an election at term 1 for -1: [407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858], old=null
datanode_2    | 2019-11-06 03:55:04,764 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1    | 2019-11-06 03:55:03,425 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="create annotation table v5"
datanode_3    | 2019-11-06 03:55:04,188 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: shutdown LeaderElection
datanode_2    | 2019-11-06 03:55:04,769 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: start LeaderElection
datanode_1    | 2019-11-06 03:55:03,425 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412: change Leader from null to 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd at term 1 for becomeLeader, leader elected after 5257ms
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 0 v3"
datanode_3    | 2019-11-06 03:55:04,188 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2    | 2019-11-06 03:55:04,787 INFO impl.LeaderElection: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7-LeaderElection1: begin an election at term 1 for -1: [544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_1    | 2019-11-06 03:55:03,431 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
grafana_1     | t=2019-11-06T03:55:04+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 1 v3"
datanode_3    | 2019-11-06 03:55:04,188 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D: change Leader from null to 407c79ba-7a2c-49fa-93d7-ec61e39fb159 at term 1 for becomeLeader, leader elected after 5303ms
datanode_2    | 2019-11-06 03:55:04,790 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: shutdown LeaderElection
datanode_1    | 2019-11-06 03:55:03,431 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 2 v3"
datanode_3    | 2019-11-06 03:55:04,192 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2    | 2019-11-06 03:55:04,791 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1    | 2019-11-06 03:55:03,435 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3    | 2019-11-06 03:55:04,192 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2    | 2019-11-06 03:55:04,791 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7: change Leader from null to 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87 at term 1 for becomeLeader, leader elected after 5281ms
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 3 v3"
datanode_1    | 2019-11-06 03:55:03,442 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_3    | 2019-11-06 03:55:04,196 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="add index annotation 4 v3"
datanode_1    | 2019-11-06 03:55:03,442 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2    | 2019-11-06 03:55:04,797 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3    | 2019-11-06 03:55:04,200 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_1    | 2019-11-06 03:55:03,443 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Update annotation table charset"
datanode_2    | 2019-11-06 03:55:04,797 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3    | 2019-11-06 03:55:04,200 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1    | 2019-11-06 03:55:03,451 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start LeaderState
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add column region_id to annotation table"
datanode_2    | 2019-11-06 03:55:04,801 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3    | 2019-11-06 03:55:04,201 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1    | 2019-11-06 03:55:03,473 INFO segmented.SegmentedRaftLogWorker: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412-SegmentedRaftLogWorker: Starting segment from index:0
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Drop category_id index"
datanode_2    | 2019-11-06 03:55:04,809 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_3    | 2019-11-06 03:55:04,208 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start LeaderState
datanode_1    | 2019-11-06 03:55:03,483 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412: set configuration 0: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858], old=null at 0
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add column tags to annotation table"
datanode_2    | 2019-11-06 03:55:04,809 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1    | 2019-11-06 03:55:03,600 INFO segmented.SegmentedRaftLogWorker: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-1CFC7A583412-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d86ed64d-b074-4b09-bdd7-1cfc7a583412/current/log_inprogress_0
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Create annotation_tag table v2"
datanode_1    | 2019-11-06 03:55:04,890 INFO impl.FollowerState: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-FollowerState: change to CANDIDATE, lastRpcTime:5017ms, electionTimeout:5016ms
datanode_2    | 2019-11-06 03:55:04,810 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add unique index annotation_tag.annotation_id_tag_id"
datanode_1    | 2019-11-06 03:55:04,890 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: shutdown FollowerState
datanode_2    | 2019-11-06 03:55:04,821 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: start LeaderState
datanode_3    | 2019-11-06 03:55:04,226 INFO segmented.SegmentedRaftLogWorker: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-06 03:55:04,890 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Update alert annotations and set TEXT to empty"
datanode_2    | 2019-11-06 03:55:04,847 INFO segmented.SegmentedRaftLogWorker: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3    | 2019-11-06 03:55:04,234 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D: set configuration 0: [407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858], old=null at 0
datanode_1    | 2019-11-06 03:55:04,891 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start LeaderElection
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add created time to annotation table"
datanode_2    | 2019-11-06 03:55:04,870 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7: set configuration 0: [544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null at 0
datanode_1    | 2019-11-06 03:55:04,917 INFO impl.LeaderElection: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-LeaderElection2: begin an election at term 1 for -1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_3    | 2019-11-06 03:55:04,388 INFO segmented.SegmentedRaftLogWorker: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-CCA881BF2C5D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e1d9d096-32aa-4d4d-9808-cca881bf2c5d/current/log_inprogress_0
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add updated time to annotation table"
datanode_2    | 2019-11-06 03:55:04,997 INFO segmented.SegmentedRaftLogWorker: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-C41898DB61F7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ad64214d-69cc-4265-aed4-c41898db61f7/current/log_inprogress_0
datanode_3    | 2019-11-06 03:55:04,900 INFO impl.FollowerState: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-FollowerState: change to CANDIDATE, lastRpcTime:5031ms, electionTimeout:5027ms
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for created in annotation table"
datanode_2    | 2019-11-06 03:55:05,019 INFO impl.FollowerState: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-FollowerState: change to CANDIDATE, lastRpcTime:5146ms, electionTimeout:5146ms
datanode_3    | 2019-11-06 03:55:04,901 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: shutdown FollowerState
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for updated in annotation table"
datanode_2    | 2019-11-06 03:55:05,020 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: shutdown FollowerState
datanode_1    | 2019-11-06 03:55:05,163 INFO impl.LeaderElection: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-LeaderElection2: Election REJECTED; received 2 response(s) [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd<-407c79ba-7a2c-49fa-93d7-ec61e39fb159#0:FAIL-t1, 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd<-544cbf7c-62ca-4a7d-9a1b-834cf9fbed87#0:FAIL-t1] and 0 exception(s); 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C:t1, leader=null, voted=8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd, raftlog=8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_3    | 2019-11-06 03:55:04,901 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
grafana_1     | t=2019-11-06T03:55:05+0000 lvl=info msg="Executing migration" logger=migrator id="Convert existing annotations from seconds to milliseconds"
datanode_2    | 2019-11-06 03:55:05,020 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1    | 2019-11-06 03:55:05,164 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_3    | 2019-11-06 03:55:04,902 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start LeaderElection
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="Add epoch_end column"
datanode_1    | 2019-11-06 03:55:05,165 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: shutdown LeaderElection
datanode_2    | 2019-11-06 03:55:05,020 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: start LeaderElection
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="Add index for epoch_end"
datanode_1    | 2019-11-06 03:55:05,165 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start FollowerState
datanode_2    | 2019-11-06 03:55:05,057 INFO impl.LeaderElection: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-LeaderElection2: begin an election at term 1 for -1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="Make epoch_end the same as epoch"
datanode_1    | 2019-11-06 03:55:10,181 INFO impl.FollowerState: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-FollowerState: change to CANDIDATE, lastRpcTime:5016ms, electionTimeout:5016ms
datanode_3    | 2019-11-06 03:55:04,917 INFO impl.LeaderElection: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-LeaderElection2: begin an election at term 1 for -1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_2    | 2019-11-06 03:55:05,227 INFO impl.LeaderElection: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-LeaderElection2: Election REJECTED; received 2 response(s) [544cbf7c-62ca-4a7d-9a1b-834cf9fbed87<-8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd#0:FAIL-t1, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87<-407c79ba-7a2c-49fa-93d7-ec61e39fb159#0:FAIL-t1] and 0 exception(s); 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C:t1, leader=null, voted=544cbf7c-62ca-4a7d-9a1b-834cf9fbed87, raftlog=544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="Move region to single row"
datanode_1    | 2019-11-06 03:55:10,183 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: shutdown FollowerState
datanode_3    | 2019-11-06 03:55:05,096 INFO impl.LeaderElection: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-LeaderElection2: Election REJECTED; received 2 response(s) [407c79ba-7a2c-49fa-93d7-ec61e39fb159<-8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd#0:FAIL-t1, 407c79ba-7a2c-49fa-93d7-ec61e39fb159<-544cbf7c-62ca-4a7d-9a1b-834cf9fbed87#0:FAIL-t1] and 0 exception(s); 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C:t1, leader=null, voted=407c79ba-7a2c-49fa-93d7-ec61e39fb159, raftlog=407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_2    | 2019-11-06 03:55:05,229 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_1    | 2019-11-06 03:55:10,183 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="create test_data table"
datanode_3    | 2019-11-06 03:55:05,098 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_2    | 2019-11-06 03:55:05,229 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: shutdown LeaderElection
datanode_1    | 2019-11-06 03:55:10,184 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start LeaderElection
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard_version table v1"
datanode_3    | 2019-11-06 03:55:05,098 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: shutdown LeaderElection
datanode_2    | 2019-11-06 03:55:05,229 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: start FollowerState
datanode_1    | 2019-11-06 03:55:10,243 INFO impl.LeaderElection: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-LeaderElection3: begin an election at term 2 for -1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard_version.dashboard_id"
datanode_3    | 2019-11-06 03:55:05,098 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start FollowerState
datanode_1    | 2019-11-06 03:55:10,315 INFO impl.LeaderElection: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-LeaderElection3: Election PASSED; received 2 response(s) [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd<-407c79ba-7a2c-49fa-93d7-ec61e39fb159#0:FAIL-t2, 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd<-544cbf7c-62ca-4a7d-9a1b-834cf9fbed87#0:OK-t2] and 0 exception(s); 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C:t2, leader=null, voted=8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd, raftlog=8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_2    | 2019-11-06 03:55:10,272 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_version.dashboard_id and dashboard_version.version"
datanode_1    | 2019-11-06 03:55:10,315 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: shutdown LeaderElection
datanode_2    | 2019-11-06 03:55:10,273 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: shutdown FollowerState
datanode_3    | 2019-11-06 03:55:10,228 INFO impl.FollowerState: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-FollowerState: change to CANDIDATE, lastRpcTime:5129ms, electionTimeout:5087ms
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="Set dashboard version to 1 where 0"
datanode_1    | 2019-11-06 03:55:10,316 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_2    | 2019-11-06 03:55:10,274 INFO impl.RoleInfo: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87: start FollowerState
datanode_3    | 2019-11-06 03:55:10,229 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: shutdown FollowerState
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="save existing dashboard data in dashboard_version table v1"
datanode_1    | 2019-11-06 03:55:10,316 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: change Leader from null to 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd at term 2 for becomeLeader, leader elected after 10451ms
datanode_2    | 2019-11-06 03:55:10,274 INFO impl.FollowerState: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3    | 2019-11-06 03:55:10,230 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="alter dashboard_version.data to mediumtext v1"
datanode_1    | 2019-11-06 03:55:10,316 INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2    | 2019-11-06 03:55:10,406 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C: change Leader from null to 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd at term 2 for appendEntries, leader elected after 10541ms
datanode_3    | 2019-11-06 03:55:10,230 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start LeaderElection
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="create team table"
datanode_1    | 2019-11-06 03:55:10,317 INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2    | 2019-11-06 03:55:10,510 INFO impl.RaftServerImpl: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C: set configuration 0: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null at 0
datanode_3    | 2019-11-06 03:55:10,244 INFO impl.LeaderElection: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-LeaderElection3: begin an election at term 2 for -1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
datanode_1    | 2019-11-06 03:55:10,317 INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_2    | 2019-11-06 03:55:10,510 INFO segmented.SegmentedRaftLogWorker: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-06 03:55:10,317 INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_3    | 2019-11-06 03:55:10,333 INFO impl.LeaderElection: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-LeaderElection3: Election REJECTED; received 2 response(s) [407c79ba-7a2c-49fa-93d7-ec61e39fb159<-8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd#0:FAIL-t2, 407c79ba-7a2c-49fa-93d7-ec61e39fb159<-544cbf7c-62ca-4a7d-9a1b-834cf9fbed87#0:FAIL-t2] and 0 exception(s); 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C:t2, leader=null, voted=407c79ba-7a2c-49fa-93d7-ec61e39fb159, raftlog=407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="add index team.org_id"
datanode_2    | 2019-11-06 03:55:10,568 INFO segmented.SegmentedRaftLogWorker: 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87@group-2E0B3439F29C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c/current/log_inprogress_0
datanode_1    | 2019-11-06 03:55:10,317 INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3    | 2019-11-06 03:55:10,334 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index team_org_id_name"
datanode_1    | 2019-11-06 03:55:10,317 INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3    | 2019-11-06 03:55:10,334 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: shutdown LeaderElection
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="create team member table"
datanode_1    | 2019-11-06 03:55:10,320 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1    | 2019-11-06 03:55:10,321 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="add index team_member.org_id"
datanode_3    | 2019-11-06 03:55:10,335 INFO impl.RoleInfo: 407c79ba-7a2c-49fa-93d7-ec61e39fb159: start FollowerState
datanode_1    | 2019-11-06 03:55:10,321 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
grafana_1     | t=2019-11-06T03:55:06+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index team_member_org_id_team_id_user_id"
datanode_3    | 2019-11-06 03:55:10,407 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: change Leader from null to 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd at term 2 for appendEntries, leader elected after 10542ms
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column email to team table"
datanode_3    | 2019-11-06 03:55:10,510 INFO impl.RaftServerImpl: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C: set configuration 0: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null at 0
datanode_1    | 2019-11-06 03:55:10,326 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column external to team_member table"
datanode_3    | 2019-11-06 03:55:10,510 INFO segmented.SegmentedRaftLogWorker: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-06 03:55:10,327 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="Add column permission to team_member table"
datanode_1    | 2019-11-06 03:55:10,327 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="create dashboard acl table"
datanode_3    | 2019-11-06 03:55:10,596 INFO segmented.SegmentedRaftLogWorker: 407c79ba-7a2c-49fa-93d7-ec61e39fb159@group-2E0B3439F29C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c/current/log_inprogress_0
datanode_1    | 2019-11-06 03:55:10,329 WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReportRegistration(...) before.
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="add index dashboard_acl_dashboard_id"
datanode_1    | 2019-11-06 03:55:10,331 INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_acl_dashboard_id_user_id"
datanode_1    | 2019-11-06 03:55:10,331 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index dashboard_acl_dashboard_id_team_id"
datanode_1    | 2019-11-06 03:55:10,331 INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="save default acl rules in dashboard_acl table"
datanode_1    | 2019-11-06 03:55:10,331 INFO grpc.GrpcConfigKeys$Server: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="create tag table"
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="add index tag.key_value"
datanode_1    | 2019-11-06 03:55:10,331 INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="create login attempt table"
datanode_1    | 2019-11-06 03:55:10,331 INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1    | 2019-11-06 03:55:10,336 INFO impl.RoleInfo: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd: start LeaderState
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="add index login_attempt.username"
datanode_1    | 2019-11-06 03:55:10,336 INFO segmented.SegmentedRaftLogWorker: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1    | 2019-11-06 03:55:10,338 INFO impl.RaftServerImpl: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C: set configuration 0: [8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd:172.19.0.9:9858, 407c79ba-7a2c-49fa-93d7-ec61e39fb159:172.19.0.10:9858, 544cbf7c-62ca-4a7d-9a1b-834cf9fbed87:172.19.0.8:9858], old=null at 0
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="drop index IDX_login_attempt_username - v1"
datanode_1    | 2019-11-06 03:55:10,426 INFO segmented.SegmentedRaftLogWorker: 8ef3f4f3-ee5d-436e-a4c0-3d44a73c25dd@group-2E0B3439F29C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6a1176e0-1e20-4270-bd8a-2e0b3439f29c/current/log_inprogress_0
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="Rename table login_attempt to login_attempt_tmp_qwerty - v1"
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="create login_attempt v2"
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_login_attempt_username - v2"
grafana_1     | t=2019-11-06T03:55:07+0000 lvl=info msg="Executing migration" logger=migrator id="copy login_attempt v1 to v2"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="drop login_attempt_tmp_qwerty"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="create user auth table"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="create index IDX_user_auth_auth_module_auth_id - v1"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="alter user_auth.auth_id to length 190"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth access token to user_auth"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth refresh token to user_auth"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth token type to user_auth"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="Add OAuth expiry to user_auth"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="Add index to user_id column in user_auth"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="create server_lock table"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="add index server_lock.operation_uid"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="create user auth token table"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user_auth_token.auth_token"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index user_auth_token.prev_auth_token"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="create cache_data table"
grafana_1     | t=2019-11-06T03:55:08+0000 lvl=info msg="Executing migration" logger=migrator id="add unique index cache_data.cache_key"
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Created default admin" logger=sqlstore user=admin
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing HTTPServer" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing InternalMetricsService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing RemoteCache" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing QuotaService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing ServerLockService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing UserAuthTokenService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing PluginManager" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Starting plugin search" logger=plugins
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing RenderingService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing AlertEngine" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing DatasourceCacheService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing HooksService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing LoginService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing SearchService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing TracingService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing UsageStatsService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing CleanUpService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing NotificationService" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="Initializing provisioningServiceImpl" logger=server
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=warn msg="[Deprecated] the datasource provisioning config is outdated. please upgrade" logger=provisioning.datasources filename=/etc/grafana/provisioning/datasources/datasources.yml
grafana_1     | t=2019-11-06T03:55:09+0000 lvl=info msg="inserting datasource from configuration " logger=provisioning.datasources name=Prometheus
grafana_1     | t=2019-11-06T03:55:10+0000 lvl=eror msg="Can't read alert notification provisioning files from directory" logger=provisioning.notifiers path=/etc/grafana/provisioning/notifiers error="open /etc/grafana/provisioning/notifiers: no such file or directory"
grafana_1     | t=2019-11-06T03:55:10+0000 lvl=warn msg="[Deprecated] the dashboard provisioning config is outdated. please upgrade" logger=provisioning.dashboard filename=/etc/grafana/provisioning/dashboards/dashboards.yml
grafana_1     | t=2019-11-06T03:55:10+0000 lvl=warn msg="[Deprecated] The folder property is deprecated. Please use path instead." logger=provisioning.dashboard type=file name=default
grafana_1     | t=2019-11-06T03:55:10+0000 lvl=info msg="Backend rendering via phantomJS" logger=rendering
grafana_1     | t=2019-11-06T03:55:10+0000 lvl=warn msg="phantomJS is deprecated and will be removed in a future release. You should consider migrating from phantomJS to grafana-image-renderer plugin." logger=rendering
grafana_1     | t=2019-11-06T03:55:10+0000 lvl=info msg="Initializing Stream Manager"
grafana_1     | t=2019-11-06T03:55:10+0000 lvl=info msg="HTTP Server Listen" logger=http.server address=0.0.0.0:3000 protocol=http subUrl= socket=
