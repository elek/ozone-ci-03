<?xml version="1.0" encoding="UTF-8"?>
<robot rpa="false" generated="20191102 03:39:51.809" generator="Robot 3.1.1 (Python 2.7.5 on linux2)">
<suite source="/opt/ozone/smoketest/mapreduce.robot" id="s1" name="ozonesecure-mr-mapreduce">
<test id="s1-t1" name="Execute PI calculation">
<kw name="Execute" library="commonlib">
<arguments>
<arg>yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-${hadoop.version}.jar pi 3 3</arg>
</arguments>
<assign>
<var>${output}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191102 03:39:51.865" level="INFO">Running command 'yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar pi 3 3 2&gt;&amp;1'.</msg>
<msg timestamp="20191102 03:40:41.882" level="INFO">${rc} = 1</msg>
<msg timestamp="20191102 03:40:41.883" level="INFO">${output} = Number of Maps  = 3
Samples per Map = 3
2019-11-02 03:39:55 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-02 03:39:55 INFO  MetricsSystemImpl:374 - Scheduled Metr...</msg>
<status status="PASS" endtime="20191102 03:40:41.883" starttime="20191102 03:39:51.863"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191102 03:40:41.885" level="INFO">Number of Maps  = 3
Samples per Map = 3
2019-11-02 03:39:55 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-02 03:39:55 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-11-02 03:39:55 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
Wrote input for Map #0
Wrote input for Map #1
Wrote input for Map #2
Starting Job
2019-11-02 03:39:57 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.18.0.11:8032
2019-11-02 03:39:57 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.18.0.6:10200
2019-11-02 03:39:58 INFO  KMSClientProvider:1041 - New token created: (Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572665997979, maxDate=1573270797979, sequenceNumber=1, masterKeyId=2))
2019-11-02 03:39:58 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: OzoneToken, Service: 172.18.0.8:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1572665997661, maxDate=1573270797661, sequenceNumber=1, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null)
2019-11-02 03:39:58 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572665997979, maxDate=1573270797979, sequenceNumber=1, masterKeyId=2)
2019-11-02 03:39:58 INFO  FileInputFormat:292 - Total input files to process : 3
2019-11-02 03:39:58 INFO  JobSubmitter:202 - number of splits:3
2019-11-02 03:39:58 INFO  deprecation:1394 - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2019-11-02 03:39:59 INFO  JobSubmitter:298 - Submitting tokens for job: job_1572665944826_0001
2019-11-02 03:39:59 INFO  JobSubmitter:299 - Executing with tokens: [Kind: OzoneToken, Service: 172.18.0.8:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1572665997661, maxDate=1573270797661, sequenceNumber=1, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null), Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572665997979, maxDate=1573270797979, sequenceNumber=1, masterKeyId=2)]
2019-11-02 03:39:59 INFO  Configuration:2752 - resource-types.xml not found
2019-11-02 03:39:59 INFO  ResourceUtils:419 - Unable to find 'resource-types.xml'.
2019-11-02 03:39:59 INFO  TimelineClientImpl:129 - Timeline service address: jhs:8188
2019-11-02 03:40:01 INFO  YarnClientImpl:311 - Submitted application application_1572665944826_0001
2019-11-02 03:40:01 INFO  Job:1574 - The url to track the job: http://rm:8088/proxy/application_1572665944826_0001/
2019-11-02 03:40:01 INFO  Job:1619 - Running job: job_1572665944826_0001
2019-11-02 03:40:16 INFO  Job:1640 - Job job_1572665944826_0001 running in uber mode : false
2019-11-02 03:40:16 INFO  Job:1647 -  map 0% reduce 0%
2019-11-02 03:40:22 INFO  Job:1686 - Task Id : attempt_1572665944826_0001_m_000000_1000, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-02 03:40:23 INFO  Job:1686 - Task Id : attempt_1572665944826_0001_m_000001_1000, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-02 03:40:24 INFO  Job:1686 - Task Id : attempt_1572665944826_0001_m_000002_1000, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-02 03:40:29 INFO  Job:1647 -  map 33% reduce 0%
2019-11-02 03:40:29 INFO  Job:1686 - Task Id : attempt_1572665944826_0001_m_000002_1001, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-02 03:40:30 INFO  Job:1647 -  map 67% reduce 0%
2019-11-02 03:40:34 INFO  Job:1686 - Task Id : attempt_1572665944826_0001_m_000002_1002, Status : FAILED
Error: org.apache.hadoop.hdds.security.exception.SCMSecurityException: Failed to authenticate with GRPC XceiverServer with Ozone block token.
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:340)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:268)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:169)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:224)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:173)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:139)
	at org.apache.hadoop.fs.ozone.OzoneFSInputStream.read(OzoneFSInputStream.java:47)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:364)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2019-11-02 03:40:40 INFO  Job:1647 -  map 100% reduce 100%
2019-11-02 03:40:41 INFO  Job:1660 - Job job_1572665944826_0001 failed with state FAILED due to: Task failed task_1572665944826_0001_m_000002
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2019-11-02 03:40:41 INFO  Job:1665 - Counters: 41
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=525696
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=4
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=4
	Job Counters 
		Failed map tasks=6
		Killed reduce tasks=1
		Launched map tasks=8
		Launched reduce tasks=1
		Other local map tasks=5
		Rack-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=65186
		Total time spent by all reduces in occupied slots (ms)=16494
		Total time spent by all map tasks (ms)=32593
		Total time spent by all reduce tasks (ms)=8247
		Total vcore-milliseconds taken by all map tasks=32593
		Total vcore-milliseconds taken by all reduce tasks=8247
		Total megabyte-milliseconds taken by all map tasks=66750464
		Total megabyte-milliseconds taken by all reduce tasks=16889856
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=36
		Map output materialized bytes=56
		Input split bytes=292
		Combine input records=0
		Spilled Records=4
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=491
		CPU time spent (ms)=8200
		Physical memory (bytes) snapshot=1045676032
		Virtual memory (bytes) snapshot=7446433792
		Total committed heap usage (bytes)=3296722944
		Peak Map Physical memory (bytes)=533741568
		Peak Map Virtual memory (bytes)=3736748032
	File Input Format Counters 
		Bytes Read=0
Job job_1572665944826_0001 failed!</msg>
<status status="PASS" endtime="20191102 03:40:41.885" starttime="20191102 03:40:41.883"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191102 03:40:41.886" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<msg timestamp="20191102 03:40:41.887" level="FAIL">1 != 0</msg>
<status status="FAIL" endtime="20191102 03:40:41.887" starttime="20191102 03:40:41.885"></status>
</kw>
<status status="FAIL" endtime="20191102 03:40:41.887" starttime="20191102 03:39:51.862"></status>
</kw>
<timeout value="4 minutes"></timeout>
<status status="FAIL" endtime="20191102 03:40:41.888" critical="yes" starttime="20191102 03:39:51.862">1 != 0</status>
</test>
<test id="s1-t2" name="Execute WordCount">
<kw name="Generate Random String" library="String">
<doc>Generates a string with a desired ``length`` from the given ``chars``.</doc>
<arguments>
<arg>2</arg>
<arg>[NUMBERS]</arg>
</arguments>
<assign>
<var>${random}</var>
</assign>
<msg timestamp="20191102 03:40:41.890" level="INFO">${random} = 57</msg>
<status status="PASS" endtime="20191102 03:40:41.890" starttime="20191102 03:40:41.889"></status>
</kw>
<kw name="Execute" library="commonlib">
<arguments>
<arg>yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-${hadoop.version}.jar wordcount o3fs://bucket1.vol1/key1 o3fs://bucket1.vol1/key1-${random}.count</arg>
</arguments>
<assign>
<var>${output}</var>
</assign>
<kw name="Run And Return Rc And Output" library="OperatingSystem">
<doc>Runs the given command in the system and returns the RC and output.</doc>
<arguments>
<arg>${command}</arg>
</arguments>
<assign>
<var>${rc}</var>
<var>${output}</var>
</assign>
<msg timestamp="20191102 03:40:41.893" level="INFO">Running command 'yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar wordcount o3fs://bucket1.vol1/key1 o3fs://bucket1.vol1/key1-57.count 2&gt;&amp;1'.</msg>
<msg timestamp="20191102 03:41:31.076" level="INFO">${rc} = 255</msg>
<msg timestamp="20191102 03:41:31.076" level="INFO">${output} = 2019-11-02 03:40:44 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.18.0.11:8032
2019-11-02 03:40:44 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.18.0.6:10200
20...</msg>
<status status="PASS" endtime="20191102 03:41:31.076" starttime="20191102 03:40:41.891"></status>
</kw>
<kw name="Log" library="BuiltIn">
<doc>Logs the given message with the given level.</doc>
<arguments>
<arg>${output}</arg>
</arguments>
<msg timestamp="20191102 03:41:31.078" level="INFO">2019-11-02 03:40:44 INFO  RMProxy:133 - Connecting to ResourceManager at rm/172.18.0.11:8032
2019-11-02 03:40:44 INFO  AHSProxy:42 - Connecting to Application History server at jhs/172.18.0.6:10200
2019-11-02 03:40:45 INFO  KMSClientProvider:1041 - New token created: (Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572666045104, maxDate=1573270845104, sequenceNumber=2, masterKeyId=2))
2019-11-02 03:40:45 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: OzoneToken, Service: 172.18.0.8:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1572666044935, maxDate=1573270844935, sequenceNumber=2, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null)
2019-11-02 03:40:45 INFO  TokenCache:147 - Got dt for o3fs://bucket1.vol1; Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572666045104, maxDate=1573270845104, sequenceNumber=2, masterKeyId=2)
2019-11-02 03:40:45 INFO  JobSubmissionFiles:156 - Permissions on staging directory /user/hadoop/.staging are incorrect: rwxrwxrwx. Fixing permissions to correct value rwx------
2019-11-02 03:40:45 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2019-11-02 03:40:45 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2019-11-02 03:40:45 INFO  MetricsSystemImpl:191 - XceiverClientMetrics metrics system started
2019-11-02 03:40:46 INFO  FileInputFormat:292 - Total input files to process : 1
2019-11-02 03:40:47 INFO  JobSubmitter:202 - number of splits:1
2019-11-02 03:40:47 INFO  deprecation:1394 - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2019-11-02 03:40:47 INFO  JobSubmitter:298 - Submitting tokens for job: job_1572665944826_0002
2019-11-02 03:40:47 INFO  JobSubmitter:299 - Executing with tokens: [Kind: OzoneToken, Service: 172.18.0.8:9862, Ident: (OzoneToken owner=hadoop/rm@EXAMPLE.COM, renewer=rm, realUser=, issueDate=1572666044935, maxDate=1573270844935, sequenceNumber=2, masterKeyId=1, strToSign=null, signature=null, awsAccessKeyId=null), Kind: kms-dt, Service: kms://http@kms:9600/kms, Ident: (kms-dt owner=hadoop, renewer=rm, realUser=, issueDate=1572666045104, maxDate=1573270845104, sequenceNumber=2, masterKeyId=2)]
2019-11-02 03:40:47 INFO  Configuration:2752 - resource-types.xml not found
2019-11-02 03:40:47 INFO  ResourceUtils:419 - Unable to find 'resource-types.xml'.
2019-11-02 03:40:47 INFO  TimelineClientImpl:129 - Timeline service address: jhs:8188
2019-11-02 03:40:48 INFO  YarnClientImpl:311 - Submitted application application_1572665944826_0002
2019-11-02 03:40:48 INFO  Job:1574 - The url to track the job: http://rm:8088/proxy/application_1572665944826_0002/
2019-11-02 03:40:48 INFO  Job:1619 - Running job: job_1572665944826_0002
2019-11-02 03:40:59 INFO  Job:1640 - Job job_1572665944826_0002 running in uber mode : false
2019-11-02 03:40:59 INFO  Job:1647 -  map 0% reduce 0%
2019-11-02 03:41:00 INFO  ClientServiceDelegate:279 - Application state is completed. FinalApplicationStatus=FAILED. Redirecting to job history server
2019-11-02 03:41:01 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:02 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:03 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:04 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:05 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:06 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:07 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:08 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:09 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:10 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:10 INFO  ClientServiceDelegate:279 - Application state is completed. FinalApplicationStatus=FAILED. Redirecting to job history server
2019-11-02 03:41:11 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:12 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:13 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:14 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:15 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:16 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:17 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:18 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:19 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:20 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:20 INFO  ClientServiceDelegate:279 - Application state is completed. FinalApplicationStatus=FAILED. Redirecting to job history server
2019-11-02 03:41:21 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:22 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:23 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:24 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:25 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:26 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:27 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:28 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:29 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-11-02 03:41:30 INFO  Client:948 - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
java.io.IOException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:345)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:398)
	at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:878)
	at org.apache.hadoop.mapreduce.Job$6.run(Job.java:732)
	at org.apache.hadoop.mapreduce.Job$6.run(Job.java:729)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:729)
	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1652)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1591)
	at org.apache.hadoop.examples.WordCount.main(WordCount.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
Caused by: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy24.getTaskAttemptCompletionEvents(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:326)
	... 24 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 34 more</msg>
<status status="PASS" endtime="20191102 03:41:31.079" starttime="20191102 03:41:31.077"></status>
</kw>
<kw name="Should Be Equal As Integers" library="BuiltIn">
<doc>Fails if objects are unequal after converting them to integers.</doc>
<arguments>
<arg>${rc}</arg>
<arg>0</arg>
</arguments>
<msg timestamp="20191102 03:41:31.080" level="INFO">Argument types are:
&lt;type 'int'&gt;
&lt;type 'unicode'&gt;</msg>
<msg timestamp="20191102 03:41:31.081" level="FAIL">255 != 0</msg>
<status status="FAIL" endtime="20191102 03:41:31.081" starttime="20191102 03:41:31.079"></status>
</kw>
<status status="FAIL" endtime="20191102 03:41:31.081" starttime="20191102 03:40:41.890"></status>
</kw>
<timeout value="4 minutes"></timeout>
<status status="FAIL" endtime="20191102 03:41:31.082" critical="yes" starttime="20191102 03:40:41.888">255 != 0</status>
</test>
<doc>Execute MR jobs</doc>
<status status="FAIL" endtime="20191102 03:41:31.084" starttime="20191102 03:39:51.810"></status>
</suite>
<statistics>
<total>
<stat fail="2" pass="0">Critical Tests</stat>
<stat fail="2" pass="0">All Tests</stat>
</total>
<tag>
</tag>
<suite>
<stat fail="2" id="s1" name="ozonesecure-mr-mapreduce" pass="0">ozonesecure-mr-mapreduce</stat>
</suite>
</statistics>
<errors>
</errors>
</robot>
